<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:56:04 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. üíú&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt; &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://supervision.roboflow.com&quot;&gt; &lt;img width=&quot;100%&quot; src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/roboflow/notebooks&quot;&gt;notebooks&lt;/a&gt; | &lt;a href=&quot;https://github.com/roboflow/inference&quot;&gt;inference&lt;/a&gt; | &lt;a href=&quot;https://github.com/autodistill/autodistill&quot;&gt;autodistill&lt;/a&gt; | &lt;a href=&quot;https://github.com/roboflow/multimodal-maestro&quot;&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href=&quot;https://badge.fury.io/py/supervision&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/supervision.svg?sanitize=true&quot; alt=&quot;version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypistats.org/packages/supervision&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/supervision&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://snyk.io/advisor/python/supervision&quot;&gt;&lt;img src=&quot;https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true&quot; alt=&quot;snyk&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/roboflow/supervision/raw/main/LICENSE.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/supervision&quot; alt=&quot;license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://badge.fury.io/py/supervision&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/supervision&quot; alt=&quot;python-version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;colab&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://huggingface.co/spaces/Roboflow/Annotators&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue&quot; alt=&quot;gradio&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/GbfgXGJ8Bk&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk&quot; alt=&quot;discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://squidfunk.github.io/mkdocs-material/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white&quot; alt=&quot;built-with-material-for-mkdocs&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;a href=&quot;https://trendshift.io/repositories/124&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/124&quot; alt=&quot;roboflow%2Fsupervision | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;üëã hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù&lt;/p&gt; 
&lt;h2&gt;üíª install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href=&quot;https://www.python.org/&quot;&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href=&quot;https://roboflow.github.io/supervision/&quot;&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üî• quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href=&quot;https://supervision.roboflow.com/latest/detection/core/#detections&quot;&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&quot;yolov8s.pt&quot;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üëâ more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href=&quot;https://github.com/roboflow/inference&quot;&gt;Inference&lt;/a&gt; requires a &lt;a href=&quot;https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key&quot;&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id=&quot;yolov8s-640&quot;, api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href=&quot;https://supervision.roboflow.com/latest/detection/annotators/&quot;&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&quot;&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href=&quot;https://supervision.roboflow.com/latest/datasets/core/&quot;&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download(&quot;coco&quot;)

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f&quot;{dataset.location}/train&quot;,
    annotations_path=f&quot;{dataset.location}/train/_annotations.coco.json&quot;,
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;üëâ more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# [&#39;dog&#39;, &#39;person&#39;]

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# [&#39;cat&#39;]

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# [&#39;cat&#39;, &#39;dog&#39;, &#39;person&#39;]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üé¨ tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href=&quot;https://supervision.roboflow.com/develop/how_to/detect_and_annotate/&quot;&gt;how-to guides&lt;/a&gt;, &lt;a href=&quot;https://github.com/roboflow/supervision/tree/develop/examples&quot;&gt;end-to-end examples&lt;/a&gt;, &lt;a href=&quot;https://roboflow.github.io/cheatsheet-supervision/&quot;&gt;cheatsheet&lt;/a&gt;, and &lt;a href=&quot;https://supervision.roboflow.com/develop/cookbooks/&quot;&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align=&quot;left&quot;&gt; &lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1&quot; alt=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align=&quot;left&quot;&gt; &lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&quot; alt=&quot;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;üíú built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href=&quot;https://github.com/roboflow/supervision/discussions/categories/built-with-supervision&quot;&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&quot;&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&quot;&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&quot;&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href=&quot;https://roboflow.github.io/supervision&quot;&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;üèÜ contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href=&quot;https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md&quot;&gt;contributing guide&lt;/a&gt; to get started. Thank you üôè to all our contributors!&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/roboflow/supervision/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=roboflow/supervision&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt; 
  &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot; /&gt; 
  &lt;a href=&quot;https://roboflow.com&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt; 
  &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot; /&gt; 
  &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt; 
  &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot; /&gt; 
  &lt;a href=&quot;https://docs.roboflow.com&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt; 
  &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot; /&gt; 
  &lt;a href=&quot;https://discuss.roboflow.com&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584&quot; width=&quot;3%&quot; /&gt; &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt;
  &lt;a href=&quot;https://blog.roboflow.com&quot;&gt; &lt;img src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605&quot; width=&quot;3%&quot; /&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>hesreallyhim/awesome-claude-code</title>
      <link>https://github.com/hesreallyhim/awesome-claude-code</link>
      <description>&lt;p&gt;A curated list of awesome commands, files, and workflows for Claude Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;/h1&gt; 
&lt;!-- [![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re) --&gt; 
&lt;pre style=&quot;display: inline-block; text-align: left;&quot;&gt;
 ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚îê    ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚îê   ‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ    ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ ‚ñà‚îê ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚ñà‚ñà‚ñà‚ñà‚îå‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò
‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚îå‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚îÇ ‚îî‚îÄ‚îò ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚îî‚îÄ‚îò  ‚îî‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îò     ‚îî‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îê      ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚îê   ‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îê‚ñà‚ñà‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê      ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îå‚îÄ‚îÄ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò      ‚ñà‚ñà‚îÇ     ‚ñà‚ñà‚îÇ   ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚ñà‚ñà‚îå‚îÄ‚îÄ‚îò
‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚ñà‚ñà‚îÇ  ‚ñà‚ñà‚îÇ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê    ‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê‚îî‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îå‚îò‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îê
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îò  ‚îî‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/pre&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;p&gt;&lt;a href=&quot;https://awesome.re&quot;&gt;&lt;img src=&quot;https://awesome.re/badge-flat2.svg?sanitize=true&quot; alt=&quot;Awesome&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href=&quot;https://github.com/hesreallyhim/awesome-claude-code&quot;&gt;Awesome Claude Code&lt;/a&gt; ü§ù &lt;a href=&quot;https://github.com/hesreallyhim/awesome-claude-code-agents&quot;&gt;Awesome Claude Code Agents&lt;/a&gt;&lt;/h1&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;This is a curated list of slash-commands, &lt;code&gt;CLAUDE.md&lt;/code&gt; files, CLI tools, and other resources and guides for enhancing your &lt;a href=&quot;https://docs.anthropic.com/en/docs/claude-code&quot;&gt;Claude Code&lt;/a&gt; workflow, productivity, and vibes.&lt;/p&gt; 
&lt;!--lint enable double-link--&gt; 
&lt;p&gt;Claude Code is a cutting-edge CLI-based coding assistant and agent that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.&lt;/p&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-07-30 - Quick Update: Still trying to iron out the submission flow (sorry for anyone that received duplicate &quot;Congratulations!&quot; issues). If you end up fighting any of the programmatic submission tools, just submit something that has all the necessary data, and I&#39;ll take it from there once approved. Other notes: (i) I think it would be really cool/fun to set up a &quot;Claude Code Leaderboard&quot;, so feel free to weigh in on the &lt;a href=&quot;https://github.com/hesreallyhim/awesome-claude-code/discussions/81&quot;&gt;Discussion&lt;/a&gt;; (ii) I&#39;m still trying to figure out what to do about &lt;strong&gt;SUB AGENTS&lt;/strong&gt;, and I&#39;ve reached out to some of the other folks who have started similar repo&#39;s; (iii) Added a small section that will be updated with new submissions as they roll in.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;This Week&#39;s Additions ‚ú®&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Resources added in the past 7 days&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sirmalloc/ccstatusline&quot;&gt;&lt;code&gt;ccstatusline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/sirmalloc&quot;&gt;sirmalloc&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A highly customizable status line formatter for Claude Code CLI that displays model info, git branch, token usage, and other metrics in your terminal.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sculptdotfun/viberank&quot;&gt;&lt;code&gt;viberank&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/nikshepsvn&quot;&gt;nikshepsvn&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A community-driven leaderboard tool that enables developers to visualize, track, and compete based on their Claude Code usage statistics. It features robust data analytics, GitHub OAuth, data validation, and user-friendly CLI/web submission methods.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/manzaltu/claude-code-ide.el&quot;&gt;&lt;code&gt;claude-code-ide.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/manzaltu&quot;&gt;manzaltu&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; claude-code-ide.el integrates Claude Code with Emacs, like Anthropic‚Äôs VS Code/IntelliJ extensions. It shows ediff-based code suggestions, pulls LSP/flymake/flycheck diagnostics, and tracks buffer context. It adds an extensible MCP tool support for symbol refs/defs, project metadata, and tree-sitter AST queries.&lt;/p&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#workflows--knowledge-guides-&quot;&gt;Workflows &amp;amp; Knowledge Guides&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#tooling-&quot;&gt;Tooling&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ide-integrations&quot;&gt;IDE Integrations&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#statusline-&quot;&gt;Statusline&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#hooks-&quot;&gt;Hooks&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#slash-commands-&quot;&gt;Slash-Commands&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#version-control--git&quot;&gt;Version Control &amp;amp; Git&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#code-analysis--testing&quot;&gt;Code Analysis &amp;amp; Testing&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#context-loading--priming&quot;&gt;Context Loading &amp;amp; Priming&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#documentation--changelogs&quot;&gt;Documentation &amp;amp; Changelogs&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ci--deployment&quot;&gt;CI / Deployment&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project--task-management&quot;&gt;Project &amp;amp; Task Management&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#miscellaneous&quot;&gt;Miscellaneous&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#claudemd-files-&quot;&gt;CLAUDE.md Files&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#language-specific&quot;&gt;Language-Specific&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#domain-specific&quot;&gt;Domain-Specific&lt;/a&gt;&lt;br /&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;‚ñ´&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project-scaffolding--mcp&quot;&gt;Project Scaffolding &amp;amp; MCP&lt;/a&gt;&lt;br /&gt; ‚ñ™&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#official-documentation-&quot;&gt;Official Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Workflows &amp;amp; Knowledge Guides üß†&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A &lt;strong&gt;workflow&lt;/strong&gt; is a tightly coupled set of Claude Code-native resources that facilitate specific projects&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands&quot;&gt;&lt;code&gt;Blogging Platform Instructions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/cloudartisan&quot;&gt;cloudartisan&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0&lt;br /&gt; Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://claudelog.com&quot;&gt;&lt;code&gt;ClaudeLog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://www.reddit.com/user/inventor_black/&quot;&gt;InventorBlack&lt;/a&gt;&lt;br /&gt; A comprehensive knowledge base with detailed breakdowns of advanced &lt;a href=&quot;https://claudelog.com/mechanics/you-are-the-main-thread/&quot;&gt;mechanics&lt;/a&gt; including &lt;a href=&quot;https://claudelog.com/mechanics/claude-md-supremacy&quot;&gt;CLAUDE.md best practices&lt;/a&gt;, practical technique guides like &lt;a href=&quot;https://claudelog.com/mechanics/plan-mode&quot;&gt;plan mode&lt;/a&gt;, &lt;a href=&quot;https://claudelog.com/faqs/what-is-ultrathink/&quot;&gt;ultrathink&lt;/a&gt;, &lt;a href=&quot;https://claudelog.com/mechanics/task-agent-tools/&quot;&gt;sub-agents&lt;/a&gt;, &lt;a href=&quot;https://claudelog.com/mechanics/agent-first-design/&quot;&gt;agent-first design&lt;/a&gt; and &lt;a href=&quot;https://claudelog.com/configuration&quot;&gt;configuration guides&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/disler/just-prompt/tree/main/.claude/commands&quot;&gt;&lt;code&gt;Context Priming&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/disler&quot;&gt;disler&lt;/a&gt;&lt;br /&gt; Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/kingler/n8n_agent/tree/main/.claude/commands&quot;&gt;&lt;code&gt;n8n_agent&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/kingler&quot;&gt;kingler&lt;/a&gt;&lt;br /&gt; Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/steadycursor/steadystart/tree/main/.claude/commands&quot;&gt;&lt;code&gt;Project Bootstrapping and Task Management&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/steadycursor&quot;&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/scopecraft/command/tree/main/.claude/commands&quot;&gt;&lt;code&gt;Project Management, Implementation, Planning, and Release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/scopecraft&quot;&gt;scopecraft&lt;/a&gt;&lt;br /&gt; Really comprehensive set of commands for all aspects of SDLC.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/harperreed/dotfiles/tree/master/.claude/commands&quot;&gt;&lt;code&gt;Project Workflow System&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/harperreed&quot;&gt;harperreed&lt;/a&gt;&lt;br /&gt; A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://diwank.space/field-notes-from-shipping-real-code-with-claude&quot;&gt;&lt;code&gt;Shipping Real Code w/ Claude&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/creatorrr&quot;&gt;Diwank&lt;/a&gt;&lt;br /&gt; A detailed blog post explaining the author&#39;s process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Helmi/claude-simone&quot;&gt;&lt;code&gt;Simone&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Helmi&quot;&gt;Helmi&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands&quot;&gt;&lt;code&gt;Slash-commands megalist&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/wcygan&quot;&gt;wcygan&lt;/a&gt;&lt;br /&gt; A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Tooling üß∞&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tooling&lt;/strong&gt; denotes applications that are built on top of Claude Code and consist of more components than slash-commands and &lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ryoppippi/ccusage&quot;&gt;&lt;code&gt;CC Usage&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/ryoppippi&quot;&gt;ryoppippi&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/nyatinte/ccexp&quot;&gt;&lt;code&gt;ccexp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/nyatinte&quot;&gt;nyatinte&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Brads3290/cclogviewer&quot;&gt;&lt;code&gt;cclogviewer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Brads3290&quot;&gt;Brad S.&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A humble but handy utility for viewing Claude Code &lt;code&gt;.jsonl&lt;/code&gt; conversation files in a pretty HTML UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ruvnet/claude-code-flow&quot;&gt;&lt;code&gt;Claude Code Flow&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/ruvnet&quot;&gt;ruvnet&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor&quot;&gt;&lt;code&gt;Claude Code Usage Monitor&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Maciek-roboblog&quot;&gt;Maciek-roboblog&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A real-time terminal-based tool for monitoring Claude Code token usage. It shows live token consumption, burn rate, and predictions for token depletion. Features include visual progress bars, session-aware analytics, and support for multiple subscription plans.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/possibilities/claude-composer&quot;&gt;&lt;code&gt;Claude Composer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/possibilities&quot;&gt;Mike Bannister&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Unlicense&lt;br /&gt; A tool that adds small enhancements to Claude Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/claude-did-this/claude-hub&quot;&gt;&lt;code&gt;Claude Hub&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/claude-did-this&quot;&gt;Claude Did This&lt;/a&gt;&lt;br /&gt; A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/smtg-ai/claude-squad&quot;&gt;&lt;code&gt;Claude Squad&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/smtg-ai&quot;&gt;smtg-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/parruda/claude-swarm&quot;&gt;&lt;code&gt;Claude Swarm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/parruda&quot;&gt;parruda&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Launch Claude Code session that is connected to a swarm of Claude Code Agents.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/eyaltoledano/claude-task-master&quot;&gt;&lt;code&gt;Claude Task Master&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/eyaltoledano&quot;&gt;eyaltoledano&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/grahama1970/claude-task-runner&quot;&gt;&lt;code&gt;Claude Task Runner&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/grahama1970&quot;&gt;grahama1970&lt;/a&gt;&lt;br /&gt; A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/pchalasani/claude-code-tools&quot;&gt;&lt;code&gt;claude-code-tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/pchalasani&quot;&gt;Prasad Chalasani&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A collection of awesome tools, including tmux integrations, better session management, hooks that enhance security - a really well-done set of Claude Code enhancers, especially for tmux users.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/dagger/container-use&quot;&gt;&lt;code&gt;Container Use&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/dagger&quot;&gt;dagger&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/dtormoen/tsk&quot;&gt;&lt;code&gt;TSK - AI Agent Task Manager and Sandbox&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/dtormoen&quot;&gt;dtormoen&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A Rust CLI tool that lets you delegate development tasks to AI agents running in sandboxed Docker environments. Multiple agents work in parallel, returning git branches for human review.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Piebald-AI/tweakcc&quot;&gt;&lt;code&gt;tweakcc&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Piebald-AI&quot;&gt;Piebald-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Command-line tool to customize your Claude Code styling.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sculptdotfun/viberank&quot;&gt;&lt;code&gt;viberank&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/nikshepsvn&quot;&gt;nikshepsvn&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A community-driven leaderboard tool that enables developers to visualize, track, and compete based on their Claude Code usage statistics. It features robust data analytics, GitHub OAuth, data validation, and user-friendly CLI/web submission methods.&lt;/p&gt; 
&lt;h3&gt;IDE Integrations&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://marketplace.visualstudio.com/items?itemName=AndrePimenta.claude-code-chat&quot;&gt;&lt;code&gt;Claude Code Chat&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/andrepimenta&quot;&gt;andrepimenta&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;¬©&lt;br /&gt; An elegant and user-friendly Claude Code chat interface for VS Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/manzaltu/claude-code-ide.el&quot;&gt;&lt;code&gt;claude-code-ide.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/manzaltu&quot;&gt;manzaltu&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; claude-code-ide.el integrates Claude Code with Emacs, like Anthropic‚Äôs VS Code/IntelliJ extensions. It shows ediff-based code suggestions, pulls LSP/flymake/flycheck diagnostics, and tracks buffer context. It adds an extensible MCP tool support for symbol refs/defs, project metadata, and tree-sitter AST queries.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/stevemolitor/claude-code.el&quot;&gt;&lt;code&gt;claude-code.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/stevemolitor&quot;&gt;stevemolitor&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; An Emacs interface for Claude Code CLI.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/greggh/claude-code.nvim&quot;&gt;&lt;code&gt;claude-code.nvim&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/greggh&quot;&gt;greggh&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A seamless integration between Claude Code AI assistant and Neovim.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/stravu/crystal&quot;&gt;&lt;code&gt;crystal&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/stravu&quot;&gt;stravu&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Statusline üìä&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Statusline&lt;/strong&gt; configurations and customizations for Claude Code&#39;s status bar functionality&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sirmalloc/ccstatusline&quot;&gt;&lt;code&gt;ccstatusline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/sirmalloc&quot;&gt;sirmalloc&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A highly customizable status line formatter for Claude Code CLI that displays model info, git branch, token usage, and other metrics in your terminal.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Hooks ü™ù&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Hooks&lt;/strong&gt; are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude&#39;s agentic lifecycle.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;[Experimental]&lt;/strong&gt; - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/dazuiba/CCNotify&quot;&gt;&lt;code&gt;CC Notify&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/dazuiba&quot;&gt;dazuiba&lt;/a&gt;&lt;br /&gt; CCNotify provides desktop notifications for Claude Code, alerting you to input needs or task completion, with one-click jumps back to VS Code and task duration display.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/GowayLee/cchooks&quot;&gt;&lt;code&gt;cchooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/GowayLee&quot;&gt;GowayLee&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A lightweight Python SDK with a clean API and good documentation; simplifies the process of writing hooks and integrating them into your codebase, providing a nice abstraction over the JSON configuration files.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/beyondcode/claude-hooks-sdk&quot;&gt;&lt;code&gt;claude-code-hooks-sdk&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/beyondcode&quot;&gt;beyondcode&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/johnlindquist/claude-hooks&quot;&gt;&lt;code&gt;claude-hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/johnlindquist&quot;&gt;John Lindquist&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks&quot;&gt;&lt;code&gt;Linting, testing, and notifications (in go)&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Veraticus&quot;&gt;Josh Symonds&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/nizos/tdd-guard&quot;&gt;&lt;code&gt;TDD Guard&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/nizos&quot;&gt;Nizar Selander&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Slash-Commands üî™&lt;/h2&gt; 
&lt;h3&gt;Version Control &amp;amp; Git&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/danielscholl/mvn-mcp-server/raw/main/.claude/commands/bug-fix.md&quot;&gt;&lt;code&gt;/bug-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/danielscholl&quot;&gt;danielscholl&lt;/a&gt;&lt;br /&gt; Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/commit.md&quot;&gt;&lt;code&gt;/commit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/evmts&quot;&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/steadycursor/steadystart/raw/main/.claude/commands/2-commit-fast.md&quot;&gt;&lt;code&gt;/commit-fast&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/steadycursor&quot;&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/toyamarinyon/giselle/raw/main/.claude/commands/create-pr.md&quot;&gt;&lt;code&gt;/create-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/toyamarinyon&quot;&gt;toyamarinyon&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/liam-hq/liam/raw/main/.claude/commands/create-pull-request.md&quot;&gt;&lt;code&gt;/create-pull-request&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/liam-hq&quot;&gt;liam-hq&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/create-worktrees.md&quot;&gt;&lt;code&gt;/create-worktrees&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/evmts&quot;&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/jeremymailen/kotlinter-gradle/raw/master/.claude/commands/fix-github-issue.md&quot;&gt;&lt;code&gt;/fix-github-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/jeremymailen&quot;&gt;jeremymailen&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/metabase/metabase/raw/master/.claude/commands/fix-issue.md&quot;&gt;&lt;code&gt;/fix-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/metabase&quot;&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/metabase/metabase/raw/master/.claude/commands/fix-pr.md&quot;&gt;&lt;code&gt;/fix-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/metabase&quot;&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/husky.md&quot;&gt;&lt;code&gt;/husky&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/evmts&quot;&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/arkavo-org/opentdf-rs/raw/main/.claude/commands/pr-review.md&quot;&gt;&lt;code&gt;/pr-review&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/arkavo-org&quot;&gt;arkavo-org&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/giselles-ai/giselle/raw/main/.claude/commands/update-branch-name.md&quot;&gt;&lt;code&gt;/update-branch-name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/giselles-ai&quot;&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.&lt;/p&gt; 
&lt;h3&gt;Code Analysis &amp;amp; Testing&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rygwdn/slack-tools/raw/main/.claude/commands/check.md&quot;&gt;&lt;code&gt;/check&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/rygwdn&quot;&gt;rygwdn&lt;/a&gt;&lt;br /&gt; Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Graphlet-AI/eridu/raw/main/.claude/commands/clean.md&quot;&gt;&lt;code&gt;/clean&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Graphlet-AI&quot;&gt;Graphlet-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/kingler/n8n_agent/raw/main/.claude/commands/code_analysis.md&quot;&gt;&lt;code&gt;/code_analysis&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/kingler&quot;&gt;kingler&lt;/a&gt;&lt;br /&gt; Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/to4iki/ai-project-rules/raw/main/.claude/commands/optimize.md&quot;&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/to4iki&quot;&gt;to4iki&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rzykov/metabase/raw/master/.claude/commands/repro-issue.md&quot;&gt;&lt;code&gt;/repro-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/rzykov&quot;&gt;rzykov&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Creates reproducible test cases for GitHub issues, ensuring tests fail reliably and documenting clear reproduction steps for developers.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/zscott/pane/raw/main/.claude/commands/tdd.md&quot;&gt;&lt;code&gt;/tdd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/zscott&quot;&gt;zscott&lt;/a&gt;&lt;br /&gt; Guides development using Test-Driven Development principles, enforcing Red-Green-Refactor discipline, integrating with git workflow, and managing PR creation.&lt;/p&gt; 
&lt;h3&gt;Context Loading &amp;amp; Priming&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/elizaOS/elizaos.github.io/raw/main/.claude/commands/context-prime.md&quot;&gt;&lt;code&gt;/context-prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/elizaOS&quot;&gt;elizaOS&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Primes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/okuvshynov/cubestat/raw/main/.claude/commands/initref.md&quot;&gt;&lt;code&gt;/initref&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/okuvshynov&quot;&gt;okuvshynov&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Initializes reference documentation structure with standard doc templates, API reference setup, documentation conventions, and placeholder content generation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ethpandaops/xatu-data/raw/master/.claude/commands/load-llms-txt.md&quot;&gt;&lt;code&gt;/load-llms-txt&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/ethpandaops&quot;&gt;ethpandaops&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Loads LLM configuration files to context, importing specific terminology, model configurations, and establishing baseline terminology for AI discussions.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_coo_context.md&quot;&gt;&lt;code&gt;/load_coo_context&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Mjvolk3&quot;&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; References specific files for sparse matrix operations, explains transform usage, compares with previous approaches, and sets data formatting context for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_dango_pipeline.md&quot;&gt;&lt;code&gt;/load_dango_pipeline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Mjvolk3&quot;&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Sets context for model training by referencing pipeline files, establishing working context, and preparing for pipeline work with relevant documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/yzyydev/AI-Engineering-Structure/raw/main/.claude/commands/prime.md&quot;&gt;&lt;code&gt;/prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/yzyydev&quot;&gt;yzyydev&lt;/a&gt;&lt;br /&gt; Sets up initial project context by viewing directory structure and reading key files, creating standardized context with directory visualization and key documentation focus.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ddisisto/si/raw/main/.claude/commands/rsi.md&quot;&gt;&lt;code&gt;/rsi&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/ddisisto&quot;&gt;ddisisto&lt;/a&gt;&lt;br /&gt; Reads all commands and key project files to optimize AI-assisted development by streamlining the process, loading command context, and setting up for better development workflow.&lt;/p&gt; 
&lt;h3&gt;Documentation &amp;amp; Changelogs&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/berrydev-ai/blockdoc-python/raw/main/.claude/commands/add-to-changelog.md&quot;&gt;&lt;code&gt;/add-to-changelog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/berrydev-ai&quot;&gt;berrydev-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Adds new entries to changelog files while maintaining format consistency, properly documenting changes, and following established project standards for version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/jerseycheese/Narraitor/tree/feature/issue-227-ai-suggestions/.claude/commands/analyze-issue.md&quot;&gt;&lt;code&gt;/create-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/jerseycheese&quot;&gt;jerseycheese&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Analyzes code structure and purpose to create comprehensive documentation detailing inputs/outputs, behavior, user interaction flows, and edge cases with error handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/slunsford/coffee-analytics/raw/main/.claude/commands/docs.md&quot;&gt;&lt;code&gt;/docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/slunsford&quot;&gt;slunsford&lt;/a&gt;&lt;br /&gt; Generates comprehensive documentation that follows project structure, documenting APIs and usage patterns with consistent formatting for better user understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/explain-issue-fix.md&quot;&gt;&lt;code&gt;/explain-issue-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/hackdays-io&quot;&gt;hackdays-io&lt;/a&gt;&lt;br /&gt; Documents solution approaches for GitHub issues, explaining technical decisions, detailing challenges overcome, and providing implementation context for better understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Consiliency/Flutter-Structurizr/raw/main/.claude/commands/update-docs.md&quot;&gt;&lt;code&gt;/update-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Consiliency&quot;&gt;Consiliency&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Reviews current documentation status, updates implementation progress, reviews phase documents, and maintains documentation consistency across the project.&lt;/p&gt; 
&lt;h3&gt;CI / Deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/kelp/webdown/raw/main/.claude/commands/release.md&quot;&gt;&lt;code&gt;/release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/kelp&quot;&gt;kelp&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Manages software releases by updating changelogs, reviewing README changes, evaluating version increments, and documenting release changes for better version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/run-ci.md&quot;&gt;&lt;code&gt;/run-ci&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/hackdays-io&quot;&gt;hackdays-io&lt;/a&gt;&lt;br /&gt; Activates virtual environments, runs CI-compatible check scripts, iteratively fixes errors, and ensures all tests pass before completion.&lt;/p&gt; 
&lt;h3&gt;Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/scopecraft/command/raw/main/.claude/commands/create-command.md&quot;&gt;&lt;code&gt;/create-command&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/scopecraft&quot;&gt;scopecraft&lt;/a&gt;&lt;br /&gt; Guides Claude through creating new custom commands with proper structure by analyzing requirements, templating commands by category, enforcing command standards, and creating supporting documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-jtbd.md&quot;&gt;&lt;code&gt;/create-jtbd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/taddyorg&quot;&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Creates Jobs-to-be-Done frameworks that outline user needs with structured format, focusing on specific user problems and organizing by job categories for product development.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-prd.md&quot;&gt;&lt;code&gt;/create-prd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/taddyorg&quot;&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Generates comprehensive product requirement documents outlining detailed specifications, requirements, and features following standardized document structure and format.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Wirasm/claudecode-utils/raw/main/.claude/commands/create-prp.md&quot;&gt;&lt;code&gt;/create-prp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Wirasm&quot;&gt;Wirasm&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates product requirement plans by reading PRP methodology, following template structure, creating comprehensive requirements, and structuring product definitions for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/disler/just-prompt/raw/main/.claude/commands/project_hello_w_name.md&quot;&gt;&lt;code&gt;/project_hello_w_name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/disler&quot;&gt;disler&lt;/a&gt;&lt;br /&gt; Creates customizable greeting components with name input, demonstrating argument passing, component reusability, state management, and user input handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/chrisleyva/todo-slash-command/raw/main/todo.md&quot;&gt;&lt;code&gt;/todo&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/chrisleyva&quot;&gt;chrisleyva&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; A convenient command to quickly manage project todo items without leaving the Claude Code interface, featuring due dates, sorting, task prioritization, and comprehensive todo list management.&lt;/p&gt; 
&lt;h3&gt;Miscellaneous&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/TuckerTucker/tkr-portfolio/raw/main/.claude/commands/five.md&quot;&gt;&lt;code&gt;/five&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/TuckerTucker&quot;&gt;TuckerTucker&lt;/a&gt;&lt;br /&gt; Applies the &quot;five whys&quot; methodology to perform root cause analysis, identify underlying issues, and create solution approaches for complex problems.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/fixing_go_in_graph.md&quot;&gt;&lt;code&gt;/fixing_go_in_graph&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Mjvolk3&quot;&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Focuses on Gene Ontology annotation integration in graph databases, handling multiple data sources, addressing graph representation issues, and ensuring correct data incorporation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/GaloyMoney/lana-bank/raw/main/.claude/commands/mermaid.md&quot;&gt;&lt;code&gt;/mermaid&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/GaloyMoney&quot;&gt;GaloyMoney&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Generates Mermaid diagrams from SQL schema files, creating entity relationship diagrams with table properties, validating diagram compilation, and ensuring complete entity coverage.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/review_dcell_model.md&quot;&gt;&lt;code&gt;/review_dcell_model&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Mjvolk3&quot;&gt;Mjvolk3&lt;/a&gt;&lt;br /&gt; Reviews old Dcell implementation files, comparing with newer Dango model, noting changes over time, and analyzing refactoring approaches for better code organization.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/zuplo/docs/raw/main/.claude/commands/use-stepper.md&quot;&gt;&lt;code&gt;/use-stepper&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/zuplo&quot;&gt;zuplo&lt;/a&gt;&lt;br /&gt; Reformats documentation to use React Stepper component, transforming heading formats, applying proper indentation, and maintaining markdown compatibility with admonition formatting.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;CLAUDE.md Files üìÇ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/strong&gt; are files that contain important guidelines and context-specfic information or instructions that help Claude Code to better understand your project and your coding standards&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Language-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/didalgolab/ai-intellij-plugin/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;AI IntelliJ Plugin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/didalgolab&quot;&gt;didalgolab&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides comprehensive Gradle commands for IntelliJ plugin development with platform-specific coding patterns, detailed package structure guidelines, and clear internationalization standards.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/alexei-led/aws-mcp-server/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;AWS MCP Server&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/alexei-led&quot;&gt;alexei-led&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Features multiple Python environment setup options with detailed code style guidelines, comprehensive error handling recommendations, and security considerations for AWS CLI interactions.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/touchlab/DroidconKotlin/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;DroidconKotlin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/touchlab&quot;&gt;touchlab&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Delivers comprehensive Gradle commands for cross-platform Kotlin Multiplatform development with clear module structure and practical guidance for dependency injection.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/expectedparrot/edsl/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;EDSL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/expectedparrot&quot;&gt;expectedparrot&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers detailed build and test commands with strict code style enforcement, comprehensive testing requirements, and standardized development workflow using Black and mypy.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/giselles-ai/giselle/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Giselle&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/giselles-ai&quot;&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Provides detailed build and test commands using pnpm and Vitest with strict code formatting requirements and comprehensive naming conventions for code consistency.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hashintel/hash/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;HASH&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/hashintel&quot;&gt;hashintel&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Features comprehensive repository structure breakdown with strong emphasis on coding standards, detailed Rust documentation guidelines, and systematic PR review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/inkline/inkline/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Inkline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/inkline&quot;&gt;inkline&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Structures development workflow using pnpm with emphasis on TypeScript and Vue 3 Composition API, detailed component creation process, and comprehensive testing recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/mattgodbolt/jsbeeb/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;JSBeeb&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/mattgodbolt&quot;&gt;mattgodbolt&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; Provides development guide for JavaScript BBC Micro emulator with build and testing instructions, architecture documentation, and debugging workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/LamoomAI/lamoom-python/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Lamoom Python&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/LamoomAI&quot;&gt;LamoomAI&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br /&gt; Serves as reference for production prompt engineering library with load balancing of AI Models, API documentation, and usage patterns with examples.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langgraphjs/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;LangGraphJS&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/langchain-ai&quot;&gt;langchain-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers comprehensive build and test commands with detailed TypeScript style guidelines, layered library architecture, and monorepo structure using yarn workspaces.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/metabase/metabase/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;Metabase&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/metabase&quot;&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br /&gt; Details workflow for REPL-driven development in Clojure/ClojureScript with emphasis on incremental development, testing, and step-by-step approach for feature implementation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sgcarstrends/backend/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;SG Cars Trends Backend&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/sgcarstrends&quot;&gt;sgcarstrends&lt;/a&gt;&lt;br /&gt; Provides comprehensive structure for TypeScript monorepo projects with detailed commands for development, testing, deployment, and AWS/Cloudflare integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/spylang/spy/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;SPy&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/spylang&quot;&gt;spylang&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Enforces strict coding conventions with comprehensive testing guidelines, multiple code compilation options, and backend-specific test decorators for targeted filtering.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/KarpelesLab/tpl/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;TPL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/KarpelesLab&quot;&gt;KarpelesLab&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Details Go project conventions with comprehensive error handling recommendations, table-driven testing approach guidelines, and modernization suggestions for latest Go features.&lt;/p&gt; 
&lt;h3&gt;Domain-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Layr-Labs/avs-vibe-developer-guide/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;AVS Vibe Developer Guide&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Layr-Labs&quot;&gt;Layr-Labs&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Structures AI-assisted EigenLayer AVS development workflow with consistent naming conventions for prompt files and established terminology standards for blockchain concepts.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/CommE2E/comm/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;Comm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/CommE2E&quot;&gt;CommE2E&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;BSD-3-Clause&lt;br /&gt; Serves as a development reference for E2E-encrypted messaging applications with code organization architecture, security implementation details, and testing procedures.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/badass-courses/course-builder/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Course Builder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/badass-courses&quot;&gt;badass-courses&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Enables real-time multiplayer capabilities for collaborative course creation with diverse tech stack integration and monorepo architecture using Turborepo.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/eastlondoner/cursor-tools/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Cursor Tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/eastlondoner&quot;&gt;eastlondoner&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Creates a versatile AI command interface supporting multiple providers and models with flexible command options and browser automation through &quot;Stagehand&quot; feature.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/soramimi/Guitar/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;Guitar&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/soramimi&quot;&gt;soramimi&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;GPL-2.0&lt;br /&gt; Serves as development guide for Guitar Git GUI Client with build commands for various platforms, code style guidelines for contributing, and project structure explanation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Fimeg/NetworkChronicles/raw/legacy-v1/CLAUDE.md&quot;&gt;&lt;code&gt;Network Chronicles&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Fimeg&quot;&gt;Fimeg&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Presents detailed implementation plan for AI-driven game characters with technical specifications for LLM integration, character guidelines, and service discovery mechanics.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/different-ai/note-companion/raw/master/CLAUDE.md&quot;&gt;&lt;code&gt;Note Companion&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/different-ai&quot;&gt;different-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Provides detailed styling isolation techniques for Obsidian plugins using Tailwind with custom prefix to prevent style conflicts and practical troubleshooting steps.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ParetoSecurity/pareto-mac/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Pareto Mac&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/ParetoSecurity&quot;&gt;ParetoSecurity&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br /&gt; Serves as development guide for Mac security audit tool with build instructions, contribution guidelines, testing procedures, and workflow documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/steadycursor/steadystart/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;SteadyStart&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/steadycursor&quot;&gt;steadycursor&lt;/a&gt;&lt;br /&gt; Clear and direct instructives about style, permissions, Claude&#39;s &quot;role&quot;, communications, and documentation of Claude Code sessions for other team members to stay abreast.&lt;/p&gt; 
&lt;h3&gt;Project Scaffolding &amp;amp; MCP&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/basicmachines-co/basic-memory/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Basic Memory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/basicmachines-co&quot;&gt;basicmachines-co&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br /&gt; Presents an innovative AI-human collaboration framework with Model Context Protocol for bidirectional LLM-markdown communication and flexible knowledge structure for complex projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/grahama1970/claude-code-mcp-enhanced/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;claude-code-mcp-enhanced&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/grahama1970&quot;&gt;grahama1970&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Provides detailed and emphatic instructions for Claude to follow as a coding agent, with testing guidance, code examples, and compliance checks.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/Family-IT-Guy/perplexity-mcp/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Perplexity MCP&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/Family-IT-Guy&quot;&gt;Family-IT-Guy&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;ISC&lt;br /&gt; Offers clear step-by-step installation instructions with multiple configuration options, detailed troubleshooting guidance, and concise architecture overview of the MCP protocol.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Official Documentation üèõÔ∏è&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Links to some of Anthropic&#39;s terrific documentation and resources regarding Claude Code&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.anthropic.com/en/docs/claude-code&quot;&gt;&lt;code&gt;Anthropic Documentation&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/anthropics&quot;&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;¬©&lt;br /&gt; The official documentation for Claude Code, including installation instructions, usage guidelines, API references, tutorials, examples, loads of information that I won&#39;t list individually. Like Claude Code, the documentation is frequently updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/anthropics/anthropic-quickstarts/raw/main/CLAUDE.md&quot;&gt;&lt;code&gt;Anthropic Quickstarts&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/anthropics&quot;&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Offers comprehensive development guides for three distinct AI-powered demo projects with standardized workflows, strict code style guidelines, and containerization instructions.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/anthropics/claude-code-action/tree/main/examples&quot;&gt;&lt;code&gt;Claude Code GitHub Actions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href=&quot;https://github.com/anthropics&quot;&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚öñÔ∏è&amp;nbsp;&amp;nbsp;MIT&lt;br /&gt; Official GitHub Actions integration for Claude Code with examples and documentation for automating AI-powered workflows in CI/CD pipelines.&lt;/p&gt; 
&lt;h2&gt;Contributing üåª&lt;/h2&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;&lt;a href=&quot;https://github.com/hesreallyhim/awesome-claude-code/issues/new?template=submit-resource.yml&quot;&gt;Submit a new resource here!&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;It&#39;s easy! Just click the link above and fill out the form. No Git knowledge required - our automated system handles everything for you.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We especially welcome:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Proven, effective resources that follow best practices and may even be in use in production&lt;/li&gt; 
 &lt;li&gt;Innovative, creative, or experimental workflows that push the boundaries of Claude Code&#39;s capabilities&lt;/li&gt; 
 &lt;li&gt;Additional libraries and tooling that are built on top of Claude Code&lt;/li&gt; 
 &lt;li&gt;Applications of Claude Code outside of the traditional &quot;coding assistant&quot; context (CI/CD, testing, documentation, dev-ops, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for the complete submission guide and review process.&lt;/p&gt; 
&lt;p&gt;For suggestions about the repository itself, please &lt;a href=&quot;https://github.com/hesreallyhim/awesome-claude-code/issues/new&quot;&gt;open a general issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a &lt;a href=&quot;https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/code-of-conduct.md&quot;&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to abide by its terms.&lt;/p&gt; 
&lt;h3&gt;A note about licenses&lt;/h3&gt; 
&lt;p&gt;Because simply listing a hyperlink does not qualify as redistribution, the license of the original source is not relevant to its inclusion. However, for posterity and convenience, we do host copies of all resources whose license permits it. Therefore, please include information about the resource&#39;s license. Additionally, take note: &lt;em&gt;if you do not include a LICENSE in your GitHub repo, then by default it is fully copyrighted and redistribution is not allowed&lt;/em&gt;. So, if you are intending to make an open source project, it&#39;s critical to pick from one of the many available open source licenses. This is just a reminder that without a LICENSE, your project is not open source (it&#39;s merely source-code-available) - it may of course still be included on this list, but this notice is to inform readers about the default rules regarding GitHub and LICENSE files. See &lt;a href=&quot;https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository&quot;&gt;here&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.getzep.com/&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73&quot; width=&quot;150&quot; alt=&quot;Zep Logo&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align=&quot;center&quot;&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align=&quot;center&quot;&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/lint.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat&quot; alt=&quot;Lint&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true&quot; alt=&quot;Unit Tests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true&quot; alt=&quot;MyPy Check&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://img.shields.io/github/stars/getzep/graphiti&quot; alt=&quot;GitHub Repo stars&quot; /&gt; &lt;a href=&quot;https://discord.com/invite/W8Kw6bsgXQ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat&quot; alt=&quot;arXiv&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/graphiti/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen&quot; alt=&quot;Release&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://trendshift.io/repositories/12986&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12986&quot; alt=&quot;getzep%2Fgraphiti | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md&quot;&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif&quot; alt=&quot;Graphiti temporal walkthrough&quot; width=&quot;700px&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;&quot;Kendra loves Adidas shoes.&quot;&lt;/em&gt; Each fact is a &quot;triplet&quot; represented by two entities, or nodes (&quot;Kendra&quot;, &quot;Adidas shoes&quot;), and their relationship, or edge (&quot;loves&quot;). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep&#39;s Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href=&quot;https://www.getzep.com&quot;&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we&#39;ve demonstrated Zep is the &lt;a href=&quot;https://blog.getzep.com/state-of-the-art-agent-memory/&quot;&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We&#39;re excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png&quot; alt=&quot;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&quot; width=&quot;700px&quot; /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif&quot; alt=&quot;Graphiti structured + unstructured demo&quot; width=&quot;700px&quot; /&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href=&quot;https://neo4j.com/download/&quot;&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti&#39;s ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md&quot;&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j or FalkorDB database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti&#39;s knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md&quot;&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md&quot;&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri=&quot;bolt://localhost:7687&quot;,
    user=&quot;neo4j&quot;,
    password=&quot;password&quot;,
    database=&quot;my_custom_database&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host=&quot;localhost&quot;,
    port=6379,
    username=&quot;falkor_user&quot;,  # Optional
    password=&quot;falkor_password&quot;,  # Optional
    database=&quot;my_custom_graph&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;USE_PARALLEL_RUNTIME&lt;/code&gt; is an optional boolean variable that can be set to true if you wish to enable Neo4j&#39;s parallel runtime feature for several of our search queries. Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances, as such this feature is off by default.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = &quot;&amp;lt;your-api-key&amp;gt;&quot;
api_version = &quot;&amp;lt;your-api-version&amp;gt;&quot;
llm_endpoint = &quot;&amp;lt;your-llm-endpoint&amp;gt;&quot;  # e.g., &quot;https://your-llm-resource.openai.azure.com/&quot;
embedding_endpoint = &quot;&amp;lt;your-embedding-endpoint&amp;gt;&quot;  # e.g., &quot;https://your-embedding-resource.openai.azure.com/&quot;

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model=&quot;gpt-4.1-nano&quot;,
    model=&quot;gpt-4.1-mini&quot;,
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=OpenAIClient(
        config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model=&quot;text-embedding-3-small-deployment&quot;  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google&#39;s Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you&#39;ll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add &quot;graphiti-core[google-genai]&quot;

# or

pip install &quot;graphiti-core[google-genai]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = &quot;&amp;lt;your-google-api-key&amp;gt;&quot;

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.0-flash&quot;
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model=&quot;embedding-001&quot;
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.5-flash-lite-preview-06-17&quot;
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini&#39;s log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama&#39;s OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models: ollama pull deepseek-r1:7b # LLM ollama pull nomic-embed-text # embeddings&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key=&quot;abc&quot;,  # Ollama doesn&#39;t require a real API key
    model=&quot;deepseek-r1:7b&quot;,
    small_model=&quot;deepseek-r1:7b&quot;,
    base_url=&quot;http://localhost:11434/v1&quot;, # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key=&quot;abc&quot;,
            embedding_model=&quot;nomic-embed-text&quot;,
            embedding_dim=768,
            base_url=&quot;http://localhost:11434/v1&quot;,
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti&quot;&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti/graphiti/quick-start&quot;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti/graphiti/lang-graph-agent&quot;&gt;Building an agent with LangChain&#39;s LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here&#39;s exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you&#39;re using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don&#39;t Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py&quot;&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo &#39;export GRAPHITI_TELEMETRY_ENABLED=false&#39; &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo &#39;export GRAPHITI_TELEMETRY_ENABLED=false&#39; &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import os
os.environ[&#39;GRAPHITI_TELEMETRY_ENABLED&#39;] = &#39;false&#39;

# Then initialize Graphiti as usual
from graphiti_core import Graphiti
graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it&#39;s code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href=&quot;https://discord.com/invite/W8Kw6bsgXQ&quot;&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NanmiCoder/MediaCrawler</title>
      <link>https://github.com/NanmiCoder/MediaCrawler</link>
      <description>&lt;p&gt;Â∞èÁ∫¢‰π¶Á¨îËÆ∞ | ËØÑËÆ∫Áà¨Ëô´„ÄÅÊäñÈü≥ËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅÂø´ÊâãËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅB Á´ôËßÜÈ¢ë ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÂæÆÂçöÂ∏ñÂ≠ê ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÁôæÂ∫¶Ë¥¥ÂêßÂ∏ñÂ≠ê ÔΩú ÁôæÂ∫¶Ë¥¥ÂêßËØÑËÆ∫ÂõûÂ§çÁà¨Ëô´ | Áü•‰πéÈóÆÁ≠îÊñáÁ´†ÔΩúËØÑËÆ∫Áà¨Ëô´&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üî• MediaCrawler - Ëá™Â™í‰ΩìÂπ≥Âè∞Áà¨Ëô´ üï∑Ô∏è&lt;/h1&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://trendshift.io/repositories/8291&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://trendshift.io/api/badge/repositories/8291&quot; alt=&quot;NanmiCoder%2FMediaCrawler | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/NanmiCoder/MediaCrawler/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social&quot; alt=&quot;GitHub Stars&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/NanmiCoder/MediaCrawler/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social&quot; alt=&quot;GitHub Forks&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/NanmiCoder/MediaCrawler/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/NanmiCoder/MediaCrawler&quot; alt=&quot;GitHub Issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/NanmiCoder/MediaCrawler/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler&quot; alt=&quot;GitHub Pull Requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/NanmiCoder/MediaCrawler/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/NanmiCoder/MediaCrawler&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3_%E4%B8%AD%E6%96%87-%E5%BD%93%E5%89%8D-blue&quot; alt=&quot;‰∏≠Êñá&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_en.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%87%BA%F0%9F%87%B8_English-Available-green&quot; alt=&quot;English&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_es.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%F0%9F%87%AA%F0%9F%87%B8_Espa%C3%B1ol-Available-green&quot; alt=&quot;Espa√±ol&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ÂÖçË¥£Â£∞ÊòéÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Â§ßÂÆ∂ËØ∑‰ª•Â≠¶‰π†‰∏∫ÁõÆÁöÑ‰ΩøÁî®Êú¨‰ªìÂ∫ì‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏èÔºå&lt;a href=&quot;https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China&quot;&gt;Áà¨Ëô´ËøùÊ≥ïËøùËßÑÁöÑÊ°à‰ª∂&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;Êú¨‰ªìÂ∫ìÁöÑÊâÄÊúâÂÜÖÂÆπ‰ªÖ‰æõÂ≠¶‰π†ÂíåÂèÇËÄÉ‰πãÁî®ÔºåÁ¶ÅÊ≠¢Áî®‰∫éÂïÜ‰∏öÁî®ÈÄî„ÄÇ‰ªª‰Ωï‰∫∫ÊàñÁªÑÁªá‰∏çÂæóÂ∞ÜÊú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÁî®‰∫éÈùûÊ≥ïÁî®ÈÄîÊàñ‰æµÁäØ‰ªñ‰∫∫ÂêàÊ≥ïÊùÉÁõä„ÄÇÊú¨‰ªìÂ∫ìÊâÄÊ∂âÂèäÁöÑÁà¨Ëô´ÊäÄÊúØ‰ªÖÁî®‰∫éÂ≠¶‰π†ÂíåÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫éÂØπÂÖ∂‰ªñÂπ≥Âè∞ËøõË°åÂ§ßËßÑÊ®°Áà¨Ëô´ÊàñÂÖ∂‰ªñÈùûÊ≥ïË°å‰∏∫„ÄÇÂØπ‰∫éÂõ†‰ΩøÁî®Êú¨‰ªìÂ∫ìÂÜÖÂÆπËÄåÂºïËµ∑ÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊú¨‰ªìÂ∫ì‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ‰ΩøÁî®Êú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÂç≥Ë°®Á§∫ÊÇ®ÂêåÊÑèÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÊù°Ê¨æÂíåÊù°‰ª∂„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÇπÂáªÊü•ÁúãÊõ¥‰∏∫ËØ¶ÁªÜÁöÑÂÖçË¥£Â£∞Êòé„ÄÇ&lt;a href=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/#disclaimer&quot;&gt;ÁÇπÂáªË∑≥ËΩ¨&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìñ È°πÁõÆÁÆÄ‰ªã&lt;/h2&gt; 
&lt;p&gt;‰∏Ä‰∏™ÂäüËÉΩÂº∫Â§ßÁöÑ&lt;strong&gt;Â§öÂπ≥Âè∞Ëá™Â™í‰ΩìÊï∞ÊçÆÈááÈõÜÂ∑•ÂÖ∑&lt;/strong&gt;ÔºåÊîØÊåÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅBÁ´ô„ÄÅÂæÆÂçö„ÄÅË¥¥Âêß„ÄÅÁü•‰πéÁ≠â‰∏ªÊµÅÂπ≥Âè∞ÁöÑÂÖ¨ÂºÄ‰ø°ÊÅØÊäìÂèñ„ÄÇ&lt;/p&gt; 
&lt;h3&gt;üîß ÊäÄÊúØÂéüÁêÜ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†∏ÂøÉÊäÄÊúØ&lt;/strong&gt;ÔºöÂü∫‰∫é &lt;a href=&quot;https://playwright.dev/&quot;&gt;Playwright&lt;/a&gt; ÊµèËßàÂô®Ëá™Âä®ÂåñÊ°ÜÊû∂ÁôªÂΩï‰øùÂ≠òÁôªÂΩïÊÄÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êó†ÈúÄJSÈÄÜÂêë&lt;/strong&gt;ÔºöÂà©Áî®‰øùÁïôÁôªÂΩïÊÄÅÁöÑÊµèËßàÂô®‰∏ä‰∏ãÊñáÁéØÂ¢ÉÔºåÈÄöËøá JS Ë°®ËææÂºèËé∑ÂèñÁ≠æÂêçÂèÇÊï∞&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÁâπÁÇπ&lt;/strong&gt;ÔºöÊó†ÈúÄÈÄÜÂêëÂ§çÊùÇÁöÑÂä†ÂØÜÁÆóÊ≥ïÔºåÂ§ßÂπÖÈôç‰ΩéÊäÄÊúØÈó®Êßõ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ú® ÂäüËÉΩÁâπÊÄß&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Âπ≥Âè∞&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆËØçÊêúÁ¥¢&lt;/th&gt; 
   &lt;th&gt;ÊåáÂÆöÂ∏ñÂ≠êIDÁà¨Âèñ&lt;/th&gt; 
   &lt;th&gt;‰∫åÁ∫ßËØÑËÆ∫&lt;/th&gt; 
   &lt;th&gt;ÊåáÂÆöÂàõ‰ΩúËÄÖ‰∏ªÈ°µ&lt;/th&gt; 
   &lt;th&gt;ÁôªÂΩïÊÄÅÁºìÂ≠ò&lt;/th&gt; 
   &lt;th&gt;IP‰ª£ÁêÜÊ±†&lt;/th&gt; 
   &lt;th&gt;ÁîüÊàêËØÑËÆ∫ËØç‰∫ëÂõæ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Â∞èÁ∫¢‰π¶&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÊäñÈü≥&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Âø´Êâã&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;B Á´ô&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÂæÆÂçö&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ë¥¥Âêß&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Áü•‰πé&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details id=&quot;pro-version&quot;&gt; 
 &lt;summary&gt;üîó &lt;strong&gt;üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏ÉÔºÅÊõ¥Â§öÁöÑÂäüËÉΩÔºåÊõ¥Â•ΩÁöÑÊû∂ÊûÑËÆæËÆ°ÔºÅ&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏ÉÔºÅ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‰∏ìÊ≥®‰∫éÂ≠¶‰π†ÊàêÁÜüÈ°πÁõÆÁöÑÊû∂ÊûÑËÆæËÆ°Ôºå‰∏ç‰ªÖ‰ªÖÊòØÁà¨Ëô´ÊäÄÊúØÔºåPro ÁâàÊú¨ÁöÑ‰ª£Á†ÅËÆæËÆ°ÊÄùË∑ØÂêåÊ†∑ÂÄºÂæóÊ∑±ÂÖ•Â≠¶‰π†ÔºÅ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/MediaCrawlerPro&quot;&gt;MediaCrawlerPro&lt;/a&gt; Áõ∏ËæÉ‰∫éÂºÄÊ∫êÁâàÊú¨ÁöÑÊ†∏ÂøÉ‰ºòÂäøÔºö&lt;/p&gt; 
 &lt;h4&gt;üéØ Ê†∏ÂøÉÂäüËÉΩÂçáÁ∫ß&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;Êñ≠ÁÇπÁª≠Áà¨ÂäüËÉΩ&lt;/strong&gt;ÔºàÈáçÁÇπÁâπÊÄßÔºâ&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;Â§öË¥¶Âè∑ + IP‰ª£ÁêÜÊ±†ÊîØÊåÅ&lt;/strong&gt;ÔºàÈáçÁÇπÁâπÊÄßÔºâ&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;ÂéªÈô§ Playwright ‰æùËµñ&lt;/strong&gt;Ôºå‰ΩøÁî®Êõ¥ÁÆÄÂçï&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;ÂÆåÊï¥ Linux ÁéØÂ¢ÉÊîØÊåÅ&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;üèóÔ∏è Êû∂ÊûÑËÆæËÆ°‰ºòÂåñ&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;‰ª£Á†ÅÈáçÊûÑ‰ºòÂåñ&lt;/strong&gt;ÔºåÊõ¥ÊòìËØªÊòìÁª¥Êä§ÔºàËß£ËÄ¶ JS Á≠æÂêçÈÄªËæëÔºâ&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;‰ºÅ‰∏öÁ∫ß‰ª£Á†ÅË¥®Èáè&lt;/strong&gt;ÔºåÈÄÇÂêàÊûÑÂª∫Â§ßÂûãÁà¨Ëô´È°πÁõÆ&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;ÂÆåÁæéÊû∂ÊûÑËÆæËÆ°&lt;/strong&gt;ÔºåÈ´òÊâ©Â±ïÊÄßÔºåÊ∫êÁ†ÅÂ≠¶‰π†‰ª∑ÂÄºÊõ¥Â§ß&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;üéÅ È¢ùÂ§ñÂäüËÉΩ&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;Ëá™Â™í‰ΩìËßÜÈ¢ë‰∏ãËΩΩÂô®Ê°åÈù¢Á´Ø&lt;/strong&gt;ÔºàÈÄÇÂêàÂ≠¶‰π†ÂÖ®Ê†àÂºÄÂèëÔºâ&lt;/li&gt; 
  &lt;li&gt;‚úÖ &lt;strong&gt;Â§öÂπ≥Âè∞È¶ñÈ°µ‰ø°ÊÅØÊµÅÊé®Ëçê&lt;/strong&gt;ÔºàHomeFeedÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; &lt;strong&gt;Âü∫‰∫éËá™Â™í‰ΩìÂπ≥Âè∞ÁöÑAI AgentÊ≠£Âú®ÂºÄÂèë‰∏≠ üöÄüöÄ&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÁÇπÂáªÊü•ÁúãÔºö&lt;a href=&quot;https://github.com/MediaCrawlerPro&quot;&gt;MediaCrawlerPro È°πÁõÆ‰∏ªÈ°µ&lt;/a&gt; Êõ¥Â§ö‰ªãÁªç&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;ÂºÄÊ∫ê‰∏çÊòìÔºåÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìã ÂâçÁΩÆ‰æùËµñ&lt;/h2&gt; 
&lt;h3&gt;üöÄ uv ÂÆâË£ÖÔºàÊé®ËçêÔºâ&lt;/h3&gt; 
&lt;p&gt;Âú®ËøõË°å‰∏ã‰∏ÄÊ≠•Êìç‰Ωú‰πãÂâçÔºåËØ∑Á°Æ‰øùÁîµËÑë‰∏äÂ∑≤ÁªèÂÆâË£Ö‰∫Ü uvÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâË£ÖÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href=&quot;https://docs.astral.sh/uv/getting-started/installation&quot;&gt;uv ÂÆòÊñπÂÆâË£ÖÊåáÂçó&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È™åËØÅÂÆâË£Ö&lt;/strong&gt;ÔºöÁªàÁ´ØËæìÂÖ•ÂëΩ‰ª§ &lt;code&gt;uv --version&lt;/code&gt;ÔºåÂ¶ÇÊûúÊ≠£Â∏∏ÊòæÁ§∫ÁâàÊú¨Âè∑ÔºåËØÅÊòéÂ∑≤ÁªèÂÆâË£ÖÊàêÂäü&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êé®ËçêÁêÜÁî±&lt;/strong&gt;Ôºöuv ÊòØÁõÆÂâçÊúÄÂº∫ÁöÑ Python ÂåÖÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåÈÄüÂ∫¶Âø´„ÄÅ‰æùËµñËß£ÊûêÂáÜÁ°Æ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üü¢ Node.js ÂÆâË£Ö&lt;/h3&gt; 
&lt;p&gt;È°πÁõÆ‰æùËµñ Node.jsÔºåËØ∑ÂâçÂæÄÂÆòÁΩë‰∏ãËΩΩÂÆâË£ÖÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰∏ãËΩΩÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href=&quot;https://nodejs.org/en/download/&quot;&gt;https://nodejs.org/en/download/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁâàÊú¨Ë¶ÅÊ±Ç&lt;/strong&gt;Ôºö&amp;gt;= 16.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Python ÂåÖÂÆâË£Ö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# ËøõÂÖ•È°πÁõÆÁõÆÂΩï
cd MediaCrawler

# ‰ΩøÁî® uv sync ÂëΩ‰ª§Êù•‰øùËØÅ python ÁâàÊú¨ÂíåÁõ∏ÂÖ≥‰æùËµñÂåÖÁöÑ‰∏ÄËá¥ÊÄß
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê ÊµèËßàÂô®È©±Âä®ÂÆâË£Ö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®
uv run playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° ÊèêÁ§∫&lt;/strong&gt;ÔºöMediaCrawler ÁõÆÂâçÂ∑≤ÁªèÊîØÊåÅ‰ΩøÁî® playwright ËøûÊé•‰Ω†Êú¨Âú∞ÁöÑ Chrome ÊµèËßàÂô®‰∫ÜÔºå‰∏Ä‰∫õÂõ†‰∏∫ Webdriver ÂØºËá¥ÁöÑÈóÆÈ¢òËøéÂàÉËÄåËß£‰∫Ü„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁõÆÂâçÂºÄÊîæ‰∫Ü &lt;code&gt;xhs&lt;/code&gt; Âíå &lt;code&gt;dy&lt;/code&gt; Ëøô‰∏§‰∏™‰ΩøÁî® CDP ÁöÑÊñπÂºèËøûÊé•Êú¨Âú∞ÊµèËßàÂô®ÔºåÂ¶ÇÊúâÈúÄË¶ÅÔºåÊü•Áúã &lt;code&gt;config/base_config.py&lt;/code&gt; ‰∏≠ÁöÑÈÖçÁΩÆÈ°π„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ ËøêË°åÁà¨Ëô´Á®ãÂ∫è&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# È°πÁõÆÈªòËÆ§ÊòØÊ≤°ÊúâÂºÄÂêØËØÑËÆ∫Áà¨ÂèñÊ®°ÂºèÔºåÂ¶ÇÈúÄËØÑËÆ∫ËØ∑Âú® config/base_config.py ‰∏≠ÁöÑ ENABLE_GET_COMMENTS ÂèòÈáè‰øÆÊîπ
# ‰∏Ä‰∫õÂÖ∂‰ªñÊîØÊåÅÈ°πÔºå‰πüÂèØ‰ª•Âú® config/base_config.py Êü•ÁúãÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
uv run main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
uv run main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
uv run main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîó &lt;strong&gt;‰ΩøÁî® Python ÂéüÁîü venv ÁÆ°ÁêÜÁéØÂ¢ÉÔºà‰∏çÊé®ËçêÔºâ&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÂàõÂª∫Âπ∂ÊøÄÊ¥ª Python ËôöÊãüÁéØÂ¢É&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Â¶ÇÊûúÊòØÁà¨ÂèñÊäñÈü≥ÂíåÁü•‰πéÔºåÈúÄË¶ÅÊèêÂâçÂÆâË£Ö nodejs ÁéØÂ¢ÉÔºåÁâàÊú¨Â§ß‰∫éÁ≠â‰∫éÔºö&lt;code&gt;16&lt;/code&gt; Âç≥ÂèØ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# ËøõÂÖ•È°πÁõÆÊ†πÁõÆÂΩï
cd MediaCrawler

# ÂàõÂª∫ËôöÊãüÁéØÂ¢É
# ÊàëÁöÑ python ÁâàÊú¨ÊòØÔºö3.9.6Ôºårequirements.txt ‰∏≠ÁöÑÂ∫ìÊòØÂü∫‰∫éËøô‰∏™ÁâàÊú¨ÁöÑ
# Â¶ÇÊûúÊòØÂÖ∂‰ªñ python ÁâàÊú¨ÔºåÂèØËÉΩ requirements.txt ‰∏≠ÁöÑÂ∫ì‰∏çÂÖºÂÆπÔºåÈúÄËá™Ë°åËß£ÂÜ≥
python -m venv venv

# macOS &amp;amp; Linux ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
source venv/bin/activate

# Windows ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ÂÆâË£Ö‰æùËµñÂ∫ì&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ÂÆâË£Ö playwright ÊµèËßàÂô®È©±Âä®&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ËøêË°åÁà¨Ëô´Á®ãÂ∫èÔºàÂéüÁîüÁéØÂ¢ÉÔºâ&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# È°πÁõÆÈªòËÆ§ÊòØÊ≤°ÊúâÂºÄÂêØËØÑËÆ∫Áà¨ÂèñÊ®°ÂºèÔºåÂ¶ÇÈúÄËØÑËÆ∫ËØ∑Âú® config/base_config.py ‰∏≠ÁöÑ ENABLE_GET_COMMENTS ÂèòÈáè‰øÆÊîπ
# ‰∏Ä‰∫õÂÖ∂‰ªñÊîØÊåÅÈ°πÔºå‰πüÂèØ‰ª•Âú® config/base_config.py Êü•ÁúãÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
python main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
python main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
python main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üíæ Êï∞ÊçÆ‰øùÂ≠ò&lt;/h2&gt; 
&lt;p&gt;ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÂ≠òÂÇ®ÊñπÂºèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Êï∞ÊçÆÂ∫ì&lt;/strong&gt;ÔºöËΩªÈáèÁ∫ßÊï∞ÊçÆÂ∫ìÔºåÊó†ÈúÄÊúçÂä°Âô®ÔºåÈÄÇÂêà‰∏™‰∫∫‰ΩøÁî®ÔºàÊé®ËçêÔºâ 
  &lt;ul&gt; 
   &lt;li&gt;ÂèÇÊï∞Ôºö&lt;code&gt;--save_data_option sqlite&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Ëá™Âä®ÂàõÂª∫Êï∞ÊçÆÂ∫ìÊñá‰ª∂&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MySQL Êï∞ÊçÆÂ∫ì&lt;/strong&gt;ÔºöÊîØÊåÅÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì MySQL ‰∏≠‰øùÂ≠òÔºàÈúÄË¶ÅÊèêÂâçÂàõÂª∫Êï∞ÊçÆÂ∫ìÔºâ 
  &lt;ul&gt; 
   &lt;li&gt;ÊâßË°å &lt;code&gt;python db.py&lt;/code&gt; ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÔºàÂè™Âú®È¶ñÊ¨°ÊâßË°åÔºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CSV Êñá‰ª∂&lt;/strong&gt;ÔºöÊîØÊåÅ‰øùÂ≠òÂà∞ CSV ‰∏≠Ôºà&lt;code&gt;data/&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON Êñá‰ª∂&lt;/strong&gt;ÔºöÊîØÊåÅ‰øùÂ≠òÂà∞ JSON ‰∏≠Ôºà&lt;code&gt;data/&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‰ΩøÁî®Á§∫‰æãÔºö&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# ‰ΩøÁî® SQLiteÔºàÊé®Ëçê‰∏™‰∫∫Áî®Êà∑‰ΩøÁî®Ôºâ
uv run main.py --platform xhs --lt qrcode --type search --save_data_option sqlite

# ‰ΩøÁî® MySQL
uv run main.py --platform xhs --lt qrcode --type search --save_data_option db
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/MediaCrawlerPro&quot;&gt;üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏É üöÄÔºÅÊõ¥Â§öÁöÑÂäüËÉΩÔºåÊõ¥Â•ΩÁöÑÊû∂ÊûÑËÆæËÆ°ÔºÅ&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Á§æÂå∫‰∏éÊîØÊåÅ&lt;/h2&gt; 
&lt;h3&gt;üí¨ ‰∫§ÊµÅÁæ§ÁªÑ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂæÆ‰ø°‰∫§ÊµÅÁæ§&lt;/strong&gt;Ôºö&lt;a href=&quot;https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html&quot;&gt;ÁÇπÂáªÂä†ÂÖ•&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö ÊñáÊ°£‰∏éÊïôÁ®ã&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Âú®Á∫øÊñáÊ°£&lt;/strong&gt;Ôºö&lt;a href=&quot;https://nanmicoder.github.io/MediaCrawler/&quot;&gt;MediaCrawler ÂÆåÊï¥ÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áà¨Ëô´ÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href=&quot;https://github.com/NanmiCoder/CrawlerTutorial&quot;&gt;CrawlerTutorial ÂÖçË¥πÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ÂÖ∂‰ªñÂ∏∏ËßÅÈóÆÈ¢òÂèØ‰ª•Êü•ÁúãÂú®Á∫øÊñáÊ°£&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âú®Á∫øÊñáÊ°£ÂåÖÂê´‰ΩøÁî®ÊñπÊ≥ï„ÄÅÂ∏∏ËßÅÈóÆÈ¢ò„ÄÅÂä†ÂÖ•È°πÁõÆ‰∫§ÊµÅÁæ§Á≠â„ÄÇ &lt;a href=&quot;https://nanmicoder.github.io/MediaCrawler/&quot;&gt;MediaCrawlerÂú®Á∫øÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;‰ΩúËÄÖÊèê‰æõÁöÑÁü•ËØÜÊúçÂä°&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûúÊÉ≥Âø´ÈÄüÂÖ•Èó®ÂíåÂ≠¶‰π†ËØ•È°πÁõÆÁöÑ‰ΩøÁî®„ÄÅÊ∫êÁ†ÅÊû∂ÊûÑËÆæËÆ°Á≠â„ÄÅÂ≠¶‰π†ÁºñÁ®ãÊäÄÊúØ„ÄÅ‰∫¶ÊàñËÄÖÊÉ≥‰∫ÜËß£MediaCrawlerProÁöÑÊ∫ê‰ª£Á†ÅËÆæËÆ°ÂèØ‰ª•Áúã‰∏ãÊàëÁöÑÁü•ËØÜ‰ªòË¥πÊ†èÁõÆ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://nanmicoder.github.io/MediaCrawler/%E7%9F%A5%E8%AF%86%E4%BB%98%E8%B4%B9%E4%BB%8B%E7%BB%8D.html&quot;&gt;‰ΩúËÄÖÁöÑÁü•ËØÜ‰ªòË¥πÊ†èÁõÆ‰ªãÁªç&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star Ë∂ãÂäøÂõæ&lt;/h2&gt; 
&lt;p&gt;Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºåËÆ©Êõ¥Â§öÁöÑ‰∫∫ÁúãÂà∞ MediaCrawlerÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#NanmiCoder/MediaCrawler&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üí∞ ËµûÂä©ÂïÜÂ±ïÁ§∫&lt;/h3&gt; 
&lt;a href=&quot;https://www.swiftproxy.net/?ref=nanmi&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_5.png&quot; /&gt; &lt;br /&gt; Swiftproxy - 90M+ ÂÖ®ÁêÉÈ´òË¥®ÈáèÁ∫ØÂáÄ‰ΩèÂÆÖIPÔºåÊ≥®ÂÜåÂèØÈ¢ÜÂÖçË¥π 500MB ÊµãËØïÊµÅÈáèÔºåÂä®ÊÄÅÊµÅÈáè‰∏çËøáÊúüÔºÅ &amp;gt; ‰∏ìÂ±ûÊäòÊâ£Á†ÅÔºö**GHB5** Á´ã‰∫´‰πùÊäò‰ºòÊÉ†ÔºÅ &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;a href=&quot;https://www.thordata.com/?ls=github&amp;amp;lk=Crawler&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_7.png&quot; /&gt; &lt;br /&gt; ThordataÊòØÂÖ®ÁêÉ‰ª£ÁêÜIPËß£ÂÜ≥ÊñπÊ°àÊèê‰æõÂïÜÔºåÊîØÊåÅÂ§ßËßÑÊ®°ÈááÈõÜÂÖ¨ÂÖ±ÁΩëÁªúÊï∞ÊçÆÔºåÊèê‰æõ 195+ ÂõΩÂÆ∂ÂüéÂ∏Ç„ÄÅ6000 ‰∏á‰ΩèÂÆÖIPÔºå‰ª∑Ê†º‰ΩéËá≥ $0.65/GBÔºåÊîØÊåÅ‰∏çÈôêÊµÅÈáè„ÄÅ‰∏çÈôêIP„ÄÅ‰∏çÈôêÂπ∂ÂèëÔºõËøòÂåÖÊã¨Êú¨ÂúüÁã¨‰∫´ISPÈùôÊÄÅ‰ª£ÁêÜÂíåÈ´òÊÄßËÉΩÊï∞ÊçÆ‰∏≠ÂøÉ‰ª£ÁêÜÔºàÂùá‰∏∫ $0.75/IPÔºåÂºπÊÄßÂÆö‰ª∑Ôºâ„ÄÇÁÇπÂáªÂõæÁâáÊ≥®ÂÜåÂêéËÅîÁ≥ª‰∏≠ÊñáÂÆ¢ÊúçÂç≥ÂèØÂÖçË¥πËØïÁî®ÔºåÁé∞Âú®È¶ñÂÖÖËøòÊúâËµ†ÈÄÅÂêåÈ¢ùÈáëÈ¢ùÊ¥ªÂä®„ÄÇÂèØ‰∏éEasySpiderÂ∑•ÂÖ∑ÈÖçÂêà‰ΩøÁî®ÔºåÈ´òÊïàÈááÈõÜÁΩëÁªúÊï∞ÊçÆ„ÄÇ &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;a href=&quot;https://h.wandouip.com&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_8.jpg&quot; /&gt; &lt;br /&gt; Ë±åË±ÜHTTPËá™Ëê•ÂçÉ‰∏áÁ∫ßIPËµÑÊ∫êÊ±†ÔºåIPÁ∫ØÂáÄÂ∫¶‚â•99.8%ÔºåÊØèÊó•‰øùÊåÅIPÈ´òÈ¢ëÊõ¥Êñ∞ÔºåÂø´ÈÄüÂìçÂ∫îÔºåÁ®≥ÂÆöËøûÊé•ÔºåÊª°Ë∂≥Â§öÁßç‰∏öÂä°Âú∫ÊôØÔºåÊîØÊåÅÊåâÈúÄÂÆöÂà∂ÔºåÊ≥®ÂÜåÂÖçË¥πÊèêÂèñ10000ip„ÄÇ &lt;/a&gt; 
&lt;h3&gt;ü§ù Êàê‰∏∫ËµûÂä©ËÄÖ&lt;/h3&gt; 
&lt;p&gt;Êàê‰∏∫ËµûÂä©ËÄÖÔºåÂèØ‰ª•Â∞ÜÊÇ®ÁöÑ‰∫ßÂìÅÂ±ïÁ§∫Âú®ËøôÈáåÔºåÊØèÂ§©Ëé∑ÂæóÂ§ßÈáèÊõùÂÖâÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËÅîÁ≥ªÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂæÆ‰ø°Ôºö&lt;code&gt;yzglan&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ÈÇÆÁÆ±Ôºö&lt;code&gt;relakkes@gmail.com&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö ÂèÇËÄÉ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞èÁ∫¢‰π¶ÂÆ¢Êà∑Á´Ø&lt;/strong&gt;Ôºö&lt;a href=&quot;https://github.com/ReaJason/xhs&quot;&gt;ReaJason ÁöÑ xhs ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Áü≠‰ø°ËΩ¨Âèë&lt;/strong&gt;Ôºö&lt;a href=&quot;https://github.com/pppscn/SmsForwarder&quot;&gt;SmsForwarder ÂèÇËÄÉ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÁΩëÁ©øÈÄèÂ∑•ÂÖ∑&lt;/strong&gt;Ôºö&lt;a href=&quot;https://ngrok.com/docs/&quot;&gt;ngrok ÂÆòÊñπÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ÂÖçË¥£Â£∞Êòé&lt;/h1&gt; 
&lt;div id=&quot;disclaimer&quot;&gt; 
 &lt;h2&gt;1. È°πÁõÆÁõÆÁöÑ‰∏éÊÄßË¥®&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÊú¨È°πÁõÆ‚ÄùÔºâÊòØ‰Ωú‰∏∫‰∏Ä‰∏™ÊäÄÊúØÁ†îÁ©∂‰∏éÂ≠¶‰π†Â∑•ÂÖ∑ËÄåÂàõÂª∫ÁöÑÔºåÊó®Âú®Êé¢Á¥¢ÂíåÂ≠¶‰π†ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊäÄÊúØ„ÄÇÊú¨È°πÁõÆ‰∏ìÊ≥®‰∫éËá™Â™í‰ΩìÂπ≥Âè∞ÁöÑÊï∞ÊçÆÁà¨ÂèñÊäÄÊúØÁ†îÁ©∂ÔºåÊó®Âú®Êèê‰æõÁªôÂ≠¶‰π†ËÄÖÂíåÁ†îÁ©∂ËÄÖ‰Ωú‰∏∫ÊäÄÊúØ‰∫§ÊµÅ‰πãÁî®„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;2. Ê≥ïÂæãÂêàËßÑÊÄßÂ£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÂºÄÂèëËÄÖÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÂºÄÂèëËÄÖ‚ÄùÔºâÈÉëÈáçÊèêÈÜíÁî®Êà∑Âú®‰∏ãËΩΩ„ÄÅÂÆâË£ÖÂíå‰ΩøÁî®Êú¨È°πÁõÆÊó∂Ôºå‰∏•Ê†ºÈÅµÂÆà‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁΩëÁªúÂÆâÂÖ®Ê≥ï„Äã„ÄÅ„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂèçÈó¥Ë∞çÊ≥ï„ÄãÁ≠âÊâÄÊúâÈÄÇÁî®ÁöÑÂõΩÂÆ∂Ê≥ïÂæãÂíåÊîøÁ≠ñ„ÄÇÁî®Êà∑Â∫îËá™Ë°åÊâøÊãÖ‰∏ÄÂàáÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄåÂèØËÉΩÂºïËµ∑ÁöÑÊ≥ïÂæãË¥£‰ªª„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;3. ‰ΩøÁî®ÁõÆÁöÑÈôêÂà∂&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰∏•Á¶ÅÁî®‰∫é‰ªª‰ΩïÈùûÊ≥ïÁõÆÁöÑÊàñÈùûÂ≠¶‰π†„ÄÅÈùûÁ†îÁ©∂ÁöÑÂïÜ‰∏öË°å‰∏∫„ÄÇÊú¨È°πÁõÆ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ï‰æµÂÖ•‰ªñ‰∫∫ËÆ°ÁÆóÊú∫Á≥ªÁªüÔºå‰∏çÂæóÁî®‰∫é‰ªª‰Ωï‰æµÁäØ‰ªñ‰∫∫Áü•ËØÜ‰∫ßÊùÉÊàñÂÖ∂‰ªñÂêàÊ≥ïÊùÉÁõäÁöÑË°å‰∏∫„ÄÇÁî®Êà∑Â∫î‰øùËØÅÂÖ∂‰ΩøÁî®Êú¨È°πÁõÆÁöÑÁõÆÁöÑÁ∫ØÂ±û‰∏™‰∫∫Â≠¶‰π†ÂíåÊäÄÊúØÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ïÊ¥ªÂä®„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;4. ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;ÂºÄÂèëËÄÖÂ∑≤Â∞ΩÊúÄÂ§ßÂä™ÂäõÁ°Æ‰øùÊú¨È°πÁõÆÁöÑÊ≠£ÂΩìÊÄßÂèäÂÆâÂÖ®ÊÄßÔºå‰ΩÜ‰∏çÂØπÁî®Êà∑‰ΩøÁî®Êú¨È°πÁõÆÂèØËÉΩÂºïËµ∑ÁöÑ‰ªª‰ΩïÂΩ¢ÂºèÁöÑÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª„ÄÇÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÁî±‰∫é‰ΩøÁî®Êú¨È°πÁõÆËÄåÂØºËá¥ÁöÑ‰ªª‰ΩïÊï∞ÊçÆ‰∏¢Â§±„ÄÅËÆæÂ§áÊçüÂùè„ÄÅÊ≥ïÂæãËØâËÆºÁ≠â„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;5. Áü•ËØÜ‰∫ßÊùÉÂ£∞Êòé&lt;/h2&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÁöÑÁü•ËØÜ‰∫ßÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÊú¨È°πÁõÆÂèóÂà∞Ëëó‰ΩúÊùÉÊ≥ïÂíåÂõΩÈôÖËëó‰ΩúÊùÉÊù°Á∫¶‰ª•ÂèäÂÖ∂‰ªñÁü•ËØÜ‰∫ßÊùÉÊ≥ïÂæãÂíåÊù°Á∫¶ÁöÑ‰øùÊä§„ÄÇÁî®Êà∑Âú®ÈÅµÂÆàÊú¨Â£∞ÊòéÂèäÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÁöÑÂâçÊèê‰∏ãÔºåÂèØ‰ª•‰∏ãËΩΩÂíå‰ΩøÁî®Êú¨È°πÁõÆ„ÄÇ&lt;/p&gt; 
 &lt;h2&gt;6. ÊúÄÁªàËß£ÈáäÊùÉ&lt;/h2&gt; 
 &lt;p&gt;ÂÖ≥‰∫éÊú¨È°πÁõÆÁöÑÊúÄÁªàËß£ÈáäÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÂºÄÂèëËÄÖ‰øùÁïôÈöèÊó∂Êõ¥ÊîπÊàñÊõ¥Êñ∞Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊùÉÂà©ÔºåÊÅï‰∏çÂè¶Ë°åÈÄöÁü•„ÄÇ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;JetBrains ÂºÄÊ∫êËÆ∏ÂèØËØÅÊîØÊåÅ&lt;/h3&gt; 
&lt;p&gt;ÊÑüË∞¢ JetBrains ‰∏∫Êú¨È°πÁõÆÊèê‰æõÂÖçË¥πÁöÑÂºÄÊ∫êËÆ∏ÂèØËØÅÊîØÊåÅÔºÅ&lt;/p&gt; 
&lt;a href=&quot;https://www.jetbrains.com/?from=MediaCrawler&quot;&gt; &lt;img src=&quot;https://www.jetbrains.com/company/brand/img/jetbrains_logo.png&quot; width=&quot;100&quot; alt=&quot;JetBrains&quot; /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://frappe.io/hr&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png&quot; height=&quot;80px&quot; width=&quot;80px&quot; alt=&quot;Frappe HR Logo&quot; /&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/frappe/hrms/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/frappe/hrms&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://trendshift.io/repositories/10972&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10972&quot; alt=&quot;frappe%2Fhrms | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png&quot; /&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://frappe.io/hr&quot;&gt;Website&lt;/a&gt; - 
 &lt;a href=&quot;https://docs.frappe.io/hr/introduction&quot;&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It&#39;s a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn&#39;t find any &quot;true&quot; open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png&quot; /&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png&quot; /&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png&quot; /&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png&quot; /&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png&quot; /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/frappe/frappe&quot;&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/frappe/frappe-ui&quot;&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href=&quot;https://frappecloud.com&quot;&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href=&quot;https://github.com/frappe/press&quot;&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href=&quot;https://frappecloud.com/hrms/signup&quot; target=&quot;_blank&quot;&gt; 
  &lt;picture&gt; 
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/try-on-fc-white.png&quot; /&gt; 
   &lt;img src=&quot;https://frappe.io/files/try-on-fc-black.png&quot; alt=&quot;Try on Frappe Cloud&quot; height=&quot;28&quot; /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href=&quot;https://docs.docker.com/&quot;&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href=&quot;https://frappeframework.com/docs/user/en/installation&quot;&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://frappe.school&quot;&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.frappe.io/hr&quot;&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discuss.erpnext.com/&quot;&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://t.me/frappehr&quot;&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/frappe/erpnext/wiki/Issue-Guidelines&quot;&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://erpnext.com/security&quot;&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/frappe/erpnext/wiki/Contribution-Guidelines&quot;&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href=&quot;https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md&quot;&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align=&quot;center&quot; style=&quot;padding-top: 0.75rem;&quot;&gt; 
 &lt;a href=&quot;https://frappe.io&quot; target=&quot;_blank&quot;&gt; 
  &lt;picture&gt; 
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://frappe.io/files/Frappe-white.png&quot; /&gt; 
   &lt;img src=&quot;https://frappe.io/files/Frappe-black.png&quot; alt=&quot;Frappe Technologies&quot; height=&quot;28&quot; /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt; üöÖ LiteLLM &lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://render.com/deploy?repo=https://github.com/BerriAI/litellm&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://render.com/images/deploy-to-render-button.svg?sanitize=true&quot; alt=&quot;Deploy to Render&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://railway.app/template/HLP0Ub?referralCode=jch2ME&quot;&gt; &lt;img src=&quot;https://railway.app/button.svg?sanitize=true&quot; alt=&quot;Deploy on Railway&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br /&gt; &lt;/p&gt; 
&lt;h4 align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot; target=&quot;_blank&quot;&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/hosted&quot; target=&quot;_blank&quot;&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/enterprise&quot; target=&quot;_blank&quot;&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align=&quot;center&quot;&gt; &lt;a href=&quot;https://pypi.org/project/litellm/&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/pypi/v/litellm.svg?sanitize=true&quot; alt=&quot;PyPI Version&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://www.ycombinator.com/companies/berriai&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&quot; alt=&quot;Y Combinator W23&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://wa.link/huol9n&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square&quot; alt=&quot;Whatsapp&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square&quot; alt=&quot;Discord&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square&quot; alt=&quot;Slack&quot; /&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider&#39;s &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/output&quot;&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;[&#39;choices&#39;][0][&#39;message&#39;][&#39;content&#39;]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href=&quot;https://docs.litellm.ai/docs/routing&quot;&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot;&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs&quot;&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href=&quot;https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs&quot;&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üö® &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/release_cycle&quot;&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href=&quot;https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+&quot;&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href=&quot;https://docs.litellm.ai/docs/&quot;&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href=&quot;https://docs.litellm.ai/docs/migration&quot;&gt;here&lt;/a&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot; /&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion
import os

## set ENV variables
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;
os.environ[&quot;ANTHROPIC_API_KEY&quot;] = &quot;your-anthropic-key&quot;

messages = [{ &quot;content&quot;: &quot;Hello, how are you?&quot;,&quot;role&quot;: &quot;user&quot;}]

# openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages)

# anthropic call
response = completion(model=&quot;anthropic/claude-sonnet-4-20250514&quot;, messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &quot;id&quot;: &quot;chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de&quot;,
    &quot;created&quot;: 1751494488,
    &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
    &quot;object&quot;: &quot;chat.completion&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: &quot;stop&quot;,
            &quot;index&quot;: 0,
            &quot;message&quot;: {
                &quot;content&quot;: &quot;Hello! I&#39;m doing well, thank you for asking. I&#39;m here and ready to help with whatever you&#39;d like to discuss or work on. How are you doing today?&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;tool_calls&quot;: null,
                &quot;function_call&quot;: null
            }
        }
    ],
    &quot;usage&quot;: {
        &quot;completion_tokens&quot;: 39,
        &quot;prompt_tokens&quot;: 13,
        &quot;total_tokens&quot;: 52,
        &quot;completion_tokens_details&quot;: null,
        &quot;prompt_tokens_details&quot;: {
            &quot;audio_tokens&quot;: null,
            &quot;cached_tokens&quot;: 0
        },
        &quot;cache_creation_input_tokens&quot;: 0,
        &quot;cache_read_input_tokens&quot;: 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href=&quot;https://docs.litellm.ai/docs/providers&quot;&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-completion&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = &quot;Hello, how are you?&quot;
    messages = [{&quot;content&quot;: user_message, &quot;role&quot;: &quot;user&quot;}]
    response = await acompletion(model=&quot;openai/gpt-4o&quot;, messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response. Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or &quot;&quot;)

# claude sonnet 4
response = completion(&#39;anthropic/claude-sonnet-4-20250514&#39;, messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &quot;id&quot;: &quot;chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca&quot;,
    &quot;created&quot;: 1751494808,
    &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
    &quot;object&quot;: &quot;chat.completion.chunk&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: null,
            &quot;index&quot;: 0,
            &quot;delta&quot;: {
                &quot;provider_specific_fields&quot;: null,
                &quot;content&quot;: &quot;Hello&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;function_call&quot;: null,
                &quot;tool_calls&quot;: null,
                &quot;audio&quot;: null
            },
            &quot;logprobs&quot;: null
        }
    ],
    &quot;provider_specific_fields&quot;: null,
    &quot;stream_options&quot;: null,
    &quot;citations&quot;: null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href=&quot;https://docs.litellm.ai/docs/observability/callbacks&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ[&quot;LUNARY_PUBLIC_KEY&quot;] = &quot;your-lunary-public-key&quot;
os.environ[&quot;HELICONE_API_KEY&quot;] = &quot;your-helicone-auth-key&quot;
os.environ[&quot;LANGFUSE_PUBLIC_KEY&quot;] = &quot;&quot;
os.environ[&quot;LANGFUSE_SECRET_KEY&quot;] = &quot;&quot;
os.environ[&quot;ATHINA_API_KEY&quot;] = &quot;your-athina-api-key&quot;

os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;

# set callbacks
litellm.success_callback = [&quot;lunary&quot;, &quot;mlflow&quot;, &quot;langfuse&quot;, &quot;athina&quot;, &quot;helicone&quot;] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi üëã - i&#39;m openai&quot;}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot;&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/hosted&quot;&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth&quot;&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class&quot;&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend&quot;&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/users#set-rate-limits&quot;&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìñ Proxy Endpoints - &lt;a href=&quot;https://litellm-api.up.railway.app/&quot;&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install &#39;litellm[proxy]&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] üí° &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/user_keys&quot;&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key=&quot;anything&quot;,base_url=&quot;http://0.0.0.0:4000&quot;) # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model=&quot;gpt-3.5-turbo&quot;, messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;this is a test request, write a short poem&quot;
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo &#39;LITELLM_MASTER_KEY=&quot;sk-1234&quot;&#39; &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/
# password generator to get a random hash for litellm salt key
echo &#39;LITELLM_SALT_KEY=&quot;sk-1234&quot;&#39; &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src=&quot;https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033&quot; alt=&quot;ui_3&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;curl &#39;http://0.0.0.0:4000/key/generate&#39; \
--header &#39;Authorization: Bearer sk-1234&#39; \
--header &#39;Content-Type: application/json&#39; \
--data-raw &#39;{&quot;models&quot;: [&quot;gpt-3.5-turbo&quot;, &quot;gpt-4&quot;, &quot;claude-2&quot;], &quot;duration&quot;: &quot;20m&quot;,&quot;metadata&quot;: {&quot;user&quot;: &quot;ishaan@berri.ai&quot;, &quot;team&quot;: &quot;core-infra&quot;}}&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;{
    &quot;key&quot;: &quot;sk-kdEXbIqZRwEeEiHwdg7sFA&quot;, # Bearer token
    &quot;expires&quot;: &quot;2023-11-19T01:38:25.838000+00:00&quot; # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href=&quot;https://docs.litellm.ai/docs/providers&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/#basic-usage&quot;&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#streaming-responses&quot;&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-completion&quot;&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-streaming&quot;&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/embedding/supported_embedding&quot;&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/image_generation&quot;&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/openai&quot;&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/meta_llama&quot;&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/azure&quot;&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aiml&quot;&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aws_sagemaker&quot;&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/bedrock&quot;&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/vertex&quot;&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/palm&quot;&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/gemini&quot;&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/mistral&quot;&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/cloudflare_workers&quot;&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/cohere&quot;&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/anthropic&quot;&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/empower&quot;&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/huggingface&quot;&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/replicate&quot;&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/togetherai&quot;&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/openrouter&quot;&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/ai21&quot;&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/baseten&quot;&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/vllm&quot;&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/nlp_cloud&quot;&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aleph_alpha&quot;&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/petals&quot;&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/ollama&quot;&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/deepinfra&quot;&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/perplexity&quot;&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/groq&quot;&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/deepseek&quot;&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/anyscale&quot;&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/watsonx&quot;&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/voyage&quot;&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/xinference&quot;&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/friendliai&quot;&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/galadriel&quot;&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/gradient_ai&quot;&gt;GradientAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link&quot;&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/featherless_ai&quot;&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/nebius&quot;&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/&quot;&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; ‚Üí &lt;code&gt;make install-dev&lt;/code&gt; ‚Üí &lt;code&gt;make format&lt;/code&gt; ‚Üí &lt;code&gt;make lint&lt;/code&gt; ‚Üí &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href=&quot;https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md&quot;&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat&quot;&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Features under the &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/enterprise&quot;&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you&#39;re fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href=&quot;https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href=&quot;https://google.github.io/styleguide/pyguide.html&quot;&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run all checks locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make lint           # Run all linting (matches CI)
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version&quot;&gt;Schedule Demo üëã&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt;Community Discord üí≠&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3&quot;&gt;Community Slack üí≠&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers üìû +1 (770) 8783-106 / ‚Ä≠+1 (412) 618-6238‚Ä¨&lt;/li&gt; 
 &lt;li&gt;Our emails ‚úâÔ∏è &lt;a href=&quot;mailto:ishaan@berri.ai&quot;&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href=&quot;mailto:krrish@berri.ai&quot;&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href=&quot;https://github.com/BerriAI/litellm/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=BerriAI/litellm&quot; /&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e &quot;.[all]&quot;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;uvicorn litellm.proxy.proxy_server:app --host localhost --port 4000 --reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>hummingbot/hummingbot</title>
      <link>https://github.com/hummingbot/hummingbot</link>
      <description>&lt;p&gt;Open source software that helps you create and deploy high-frequency crypto trading bots&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/3213d7f8-414b-4df8-8c1b-a0cd142a82d8&quot; alt=&quot;Hummingbot&quot; /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hummingbot/hummingbot/raw/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-informational.svg?sanitize=true&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/_hummingbot&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url?url=https://twitter.com/_hummingbot?style=social&amp;amp;label=_hummingbot&quot; alt=&quot;Twitter&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/@hummingbot&quot;&gt;&lt;img src=&quot;https://img.shields.io/youtube/channel/subscribers/UCxzzdEnDRbylLMWmaMjywOA&quot; alt=&quot;Youtube&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/hummingbot&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/530578568154054663?logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Hummingbot is an open-source framework that helps you design and deploy automated trading strategies, or &lt;strong&gt;bots&lt;/strong&gt;, that can run on many centralized or decentralized exchanges. Over the past year, Hummingbot users have generated over $34 billion in trading volume across 140+ unique trading venues.&lt;/p&gt; 
&lt;p&gt;The Hummingbot codebase is free and publicly available under the Apache 2.0 open-source license. Our mission is to &lt;strong&gt;democratize high-frequency trading&lt;/strong&gt; by creating a global community of algorithmic traders and developers that share knowledge and contribute to the codebase.&lt;/p&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hummingbot.org&quot;&gt;Website and Docs&lt;/a&gt;: Official Hummingbot website and documeniuntation&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hummingbot.org/installation/docker/&quot;&gt;Installation&lt;/a&gt;: Install Hummingbot on various platforms&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/hummingbot&quot;&gt;Discord&lt;/a&gt;: The main gathering spot for the global Hummingbot community&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/c/hummingbot&quot;&gt;YouTube&lt;/a&gt;: Videos that teach you how to get the most of of Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://twitter.com/_hummingbot&quot;&gt;Twitter&lt;/a&gt;: Get the latest announcements about Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://p.datadoghq.com/sb/a96a744f5-a15479d77992ccba0d23aecfd4c87a52&quot;&gt;Reported Volumes&lt;/a&gt;: Reported trading volumes across all Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hummingbot.substack.com&quot;&gt;Newsletter&lt;/a&gt;: Get our newsletter whenever we ship a new release&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Exchange Connectors&lt;/h2&gt; 
&lt;p&gt;Hummingbot connectors standardize REST and WebSocket API interfaces to different types of exchanges, enabling you to build sophisticated trading strategies that can be deployed across many exchanges with minimal changes. We classify exchanges into the following categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CEX&lt;/strong&gt;: Centralized exchanges that take custody of your funds. Use API keys to connect with Hummingbot.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEX&lt;/strong&gt;: Decentralized, non-custodial exchanges that operate on a blockchain. Use wallet keys to connect with Hummingbot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, connectors differ based on the type of market supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Spot&lt;/strong&gt;: Connectors to spot markets on central limit order book (CLOB) exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Perp&lt;/strong&gt;: Connectors to perpetual futures markets on CLOB exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMM&lt;/strong&gt;: Connectors to spot markets on Automatic Market Maker (AMM) decentralized exchanges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Exchange Sponsors&lt;/h3&gt; 
&lt;p&gt;We are grateful for the following exchanges that support the development and maintenance of Hummingbot via broker partnerships and sponsorships.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Market Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://accounts.binance.com/register?ref=CBWO4LU6&quot;&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/binance/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://accounts.binance.com/register?ref=CBWO4LU6&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Binance using Hummingbot&#39;s referral link for a 10% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://accounts.binance.com/register?ref=CBWO4LU6&quot;&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/binance/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://accounts.binance.com/register?ref=CBWO4LU6&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Binance using Hummingbot&#39;s referral link for a 10% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.gate.io/referral/invite/HBOTGATE_0_103&quot;&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/gate-io/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.gate.io/referral/invite/HBOTGATE_0_103&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Gate.io using Hummingbot&#39;s referral link for a 10% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.gate.io/referral/invite/HBOTGATE_0_103&quot;&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/gate-io/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.gate.io/referral/invite/HBOTGATE_0_103&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Gate.io using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;htx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223&quot;&gt;HTX (Huobi)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/huobi/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for HTX using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.kucoin.com/r/af/hummingbot&quot;&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/kucoin/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.kucoin.com/r/af/hummingbot&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Kucoin using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.kucoin.com/r/af/hummingbot&quot;&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/kucoin/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.kucoin.com/r/af/hummingbot&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Kucoin using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.okx.com/join/1931920269&quot;&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/okx/okx/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.okx.com/join/1931920269&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Kucoin using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.okx.com/join/1931920269&quot;&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/okx/okx/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.okx.com/join/1931920269&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange&quot; alt=&quot;Sign up for Kucoin using Hummingbot&#39;s referral link for a 20% discount!&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dydx_v4_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.dydx.exchange/&quot;&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/dydx/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;hyperliquid_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hyperliquid.io/&quot;&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/hyperliquid/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xrpl&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://xrpl.org/&quot;&gt;XRP Ledger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/xrpl/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Other Exchange Connectors&lt;/h3&gt; 
&lt;p&gt;Currently, the master branch of Hummingbot also includes the following exchange connectors, which are maintained and updated through the Hummingbot Foundation governance process. See &lt;a href=&quot;https://hummingbot.org/governance/&quot;&gt;Governance&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ascend_ex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AscendEx&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/ascendex/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;balancer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Balancer&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/balancer/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bing_x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BingX&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bing_x/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitget_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitget&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bitget-perpetual/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitmart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BitMart&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bitmart/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitrue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitrue&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bitrue/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitstamp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitstamp&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bitstamp/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;btc_markets&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BTC Markets&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/btc-markets/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bybit/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/bybit/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;carbon&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Carbon&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/carbon/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;coinbase_advanced_trade&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Coinbase&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/coinbase/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;cube&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cube&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/cube/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;curve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Curve&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/curve/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dexalot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dexalot&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/dexalot/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/injective/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/injective/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kraken&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Kraken&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/kraken/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mad_meerkat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Mad Meerkat&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/mad-meerkat/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mexc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;MEXC&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/mexc/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openocean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenOcean&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/openocean/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pancakeswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PancakeSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/pancakeswap/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pangolin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pangolin&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/pangolin/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;quickswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;QuickSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/quickswap/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;sushiswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;SushiSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/sushiswap/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tinyman&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Tinyman&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/tinyman/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;traderjoe&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Trader Joe&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/traderjoe/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;uniswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Uniswap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/gateway/uniswap/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vertex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Vertex&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/vertex/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vvs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;VVS&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/vvs/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xsswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;XSSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://hummingbot.org/exchanges/xswap/&quot;&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Other Hummingbot Repos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hummingbot/deploy&quot;&gt;Deploy&lt;/a&gt;: Deploy Hummingbot in various configurations with Docker&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hummingbot/dashboard&quot;&gt;Dashboard&lt;/a&gt;: Web app that help you create, backtest, deploy, and manage Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hummingbot/quants-lab&quot;&gt;Quants Lab&lt;/a&gt;: Juypter notebooks that enable you to fetch data and perform research using Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hummingbot/gateway&quot;&gt;Gateway&lt;/a&gt;: Typescript based API client for DEX connectors&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/hummingbot/hummingbot-site&quot;&gt;Hummingbot Site&lt;/a&gt;: Official documentation for Hummingbot - we welcome contributions here too!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;The Hummingbot architecture features modular components that can be maintained and extended by individual community members.&lt;/p&gt; 
&lt;p&gt;We welcome contributions from the community! Please review these &lt;a href=&quot;https://raw.githubusercontent.com/hummingbot/hummingbot/master/CONTRIBUTING.md&quot;&gt;guidelines&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;p&gt;To have your exchange connector or other pull request merged into the codebase, please submit a New Connector Proposal or Pull Request Proposal, following these &lt;a href=&quot;https://hummingbot.org/governance/proposals/&quot;&gt;guidelines&lt;/a&gt;. Note that you will need some amount of &lt;a href=&quot;https://etherscan.io/token/0xe5097d9baeafb89f9bcb78c9290d545db5f9e9cb&quot;&gt;HBOT tokens&lt;/a&gt; in your Ethereum wallet to submit a proposal.&lt;/p&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;License&lt;/strong&gt;: Hummingbot is open source and licensed under &lt;a href=&quot;https://raw.githubusercontent.com/hummingbot/hummingbot/master/LICENSE&quot;&gt;Apache 2.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data collection&lt;/strong&gt;: See &lt;a href=&quot;https://hummingbot.org/reporting/&quot;&gt;Reporting&lt;/a&gt; for information on anonymous data collection and reporting in Hummingbot.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üî¨ Open Deep Research&lt;/h1&gt; 
&lt;img width=&quot;1388&quot; height=&quot;298&quot; alt=&quot;full_diagram&quot; src=&quot;https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69&quot; /&gt; 
&lt;p&gt;Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers. It&#39;s performance is on par with many popular deep research agents (&lt;a href=&quot;https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard&quot;&gt;see Deep Research Bench leaderboard&lt;/a&gt;).&lt;/p&gt; 
&lt;img width=&quot;817&quot; height=&quot;666&quot; alt=&quot;Screenshot 2025-07-13 at 11 21 12‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f&quot; /&gt; 
&lt;h3&gt;üî• Recent Updates&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;August 7, 2025&lt;/strong&gt;: Added GPT-5 and updated the Deep Research Bench evaluation w/ GPT-5 results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;August 2, 2025&lt;/strong&gt;: Achieved #6 ranking on the &lt;a href=&quot;https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard&quot;&gt;Deep Research Bench Leaderboard&lt;/a&gt; with an overall score of 0.4344.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;July 30, 2025&lt;/strong&gt;: Read about the evolution from our original implementations to the current version in our &lt;a href=&quot;https://rlancemartin.github.io/2025/07/30/bitter_lesson/&quot;&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;July 16, 2025&lt;/strong&gt;: Read more in our &lt;a href=&quot;https://blog.langchain.com/open-deep-research/&quot;&gt;blog&lt;/a&gt; and watch our &lt;a href=&quot;https://www.youtube.com/watch?v=agGiWUpxkhg&quot;&gt;video&lt;/a&gt; for a quick overview.&lt;/p&gt; 
&lt;h3&gt;üöÄ Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository and activate a virtual environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv sync
# or
uv pip install -r pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file to customize the environment variables (for model selection, search tools, and other configuration settings):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Launch agent with the LangGraph server locally:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install dependencies and start the LangGraph server
uvx --refresh --from &quot;langgraph-cli[inmem]&quot; --with-editable . --python 3.11 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will open the LangGraph Studio UI in your browser.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- üöÄ API: http://127.0.0.1:2024
- üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- üìö API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ask a question in the &lt;code&gt;messages&lt;/code&gt; input field and click &lt;code&gt;Submit&lt;/code&gt;. Select different configuration in the &quot;Manage Assistants&quot; tab.&lt;/p&gt; 
&lt;h3&gt;‚öôÔ∏è Configurations&lt;/h3&gt; 
&lt;h4&gt;LLM &lt;span&gt;üß†&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports a wide range of LLM providers via the &lt;a href=&quot;https://python.langchain.com/docs/how_to/chat_models_universal_init/&quot;&gt;init_chat_model() API&lt;/a&gt;. It uses LLMs for a few different tasks. See the below model fields in the &lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py&quot;&gt;configuration.py&lt;/a&gt; file for more details. This can be accessed via the LangGraph Studio UI.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Summarization&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-mini&lt;/code&gt;): Summarizes search API results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Power the search agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Compresses research findings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Final Report Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Write the final report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the selected model will need to support &lt;a href=&quot;https://python.langchain.com/docs/integrations/chat/&quot;&gt;structured outputs&lt;/a&gt; and &lt;a href=&quot;https://python.langchain.com/docs/how_to/tool_calling/&quot;&gt;tool calling&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: For OpenRouter: Follow &lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408&quot;&gt;this guide&lt;/a&gt; and for local models via Ollama see &lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318&quot;&gt;setup instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Search API &lt;span&gt;üîç&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports a wide range of search tools. By default it uses the &lt;a href=&quot;https://www.tavily.com/&quot;&gt;Tavily&lt;/a&gt; search API. Has full MCP compatibility and work native web search for Anthropic and OpenAI. See the &lt;code&gt;search_api&lt;/code&gt; and &lt;code&gt;mcp_config&lt;/code&gt; fields in the &lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py&quot;&gt;configuration.py&lt;/a&gt; file for more details. This can be accessed via the LangGraph Studio UI.&lt;/p&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;See the fields in the &lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py&quot;&gt;configuration.py&lt;/a&gt; for various other settings to customize the behavior of Open Deep Research.&lt;/p&gt; 
&lt;h3&gt;üìä Evaluation&lt;/h3&gt; 
&lt;p&gt;Open Deep Research is configured for evaluation with &lt;a href=&quot;https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard&quot;&gt;Deep Research Bench&lt;/a&gt;. This benchmark has 100 PhD-level research tasks (50 English, 50 Chinese), crafted by domain experts across 22 fields (e.g., Science &amp;amp; Tech, Business &amp;amp; Finance) to mirror real-world deep-research needs. It has 2 evaluation metrics, but the leaderboard is based on the RACE score. This uses LLM-as-a-judge (Gemini) to evaluate research reports against a golden set of reports compiled by experts across a set of metrics.&lt;/p&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Warning: Running across the 100 examples can cost ~$20-$100 depending on the model selection.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The dataset is available on &lt;a href=&quot;https://smith.langchain.com/public/c5e7a6ad-fdba-478c-88e6-3a388459ce8b/d&quot;&gt;LangSmith via this link&lt;/a&gt;. To kick off evaluation, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will provide a link to a LangSmith experiment, which will have a name &lt;code&gt;YOUR_EXPERIMENT_NAME&lt;/code&gt;. Once this is done, extract the results to a JSONL file that can be submitted to the Deep Research Bench.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python tests/extract_langsmith_data.py --project-name &quot;YOUR_EXPERIMENT_NAME&quot; --model-name &quot;you-model-name&quot; --dataset-name &quot;deep_research_bench&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates &lt;code&gt;tests/expt_results/deep_research_bench_model-name.jsonl&lt;/code&gt; with the required format. Move the generated JSONL file to a local clone of the Deep Research Bench repository and follow their &lt;a href=&quot;https://github.com/Ayanami0730/deep_research_bench?tab=readme-ov-file#quick-start&quot;&gt;Quick Start guide&lt;/a&gt; for evaluation submission.&lt;/p&gt; 
&lt;h4&gt;Results&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Commit&lt;/th&gt; 
   &lt;th&gt;Summarization&lt;/th&gt; 
   &lt;th&gt;Research&lt;/th&gt; 
   &lt;th&gt;Compression&lt;/th&gt; 
   &lt;th&gt;Total Cost&lt;/th&gt; 
   &lt;th&gt;Total Tokens&lt;/th&gt; 
   &lt;th&gt;RACE Score&lt;/th&gt; 
   &lt;th&gt;Experiment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPT-5&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/pull/168/commits&quot;&gt;ca3951d&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;openai:gpt-5&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;204,640,896&lt;/td&gt; 
   &lt;td&gt;0.4943&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-613c-4bda-8bde-f64f0422bbf3/compare?selectedSessions=4d5941c8-69ce-4f3d-8b3e-e3c99dfbd4cc&amp;amp;baseline=undefined&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Defaults&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/commit/6532a4176a93cc9bb2102b3d825dcefa560c85d9&quot;&gt;6532a41&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$45.98&lt;/td&gt; 
   &lt;td&gt;58,015,332&lt;/td&gt; 
   &lt;td&gt;0.4309&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=cf4355d7-6347-47e2-a774-484f290e79bc&amp;amp;baseline=undefined&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Claude Sonnet 4&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/pull/163/commits/f877ea93641680879c420ea991e998b47aab9bcc&quot;&gt;f877ea9&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;anthropic:claude-sonnet-4-20250514&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$187.09&lt;/td&gt; 
   &lt;td&gt;138,917,050&lt;/td&gt; 
   &lt;td&gt;0.4401&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=04f6002d-6080-4759-bcf5-9a52e57449ea&amp;amp;baseline=undefined&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deep Research Bench Submission&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/langchain-ai/open_deep_research/commit/c0a160b57a9b5ecd4b8217c3811a14d8eff97f72&quot;&gt;c0a160b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-nano&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$87.83&lt;/td&gt; 
   &lt;td&gt;207,005,549&lt;/td&gt; 
   &lt;td&gt;0.4344&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=e6647f74-ad2f-4cb9-887e-acb38b5f73c0&amp;amp;baseline=undefined&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üöÄ Deployments and Usage&lt;/h3&gt; 
&lt;h4&gt;LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;Follow the &lt;a href=&quot;https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart&quot;&gt;quickstart&lt;/a&gt; to start LangGraph server locally and test the agent out on LangGraph Studio.&lt;/p&gt; 
&lt;h4&gt;Hosted deployment&lt;/h4&gt; 
&lt;p&gt;You can easily deploy to &lt;a href=&quot;https://langchain-ai.github.io/langgraph/concepts/#deployment-options&quot;&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Open Agent Platform&lt;/h4&gt; 
&lt;p&gt;Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.&lt;/p&gt; 
&lt;p&gt;We&#39;ve deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out &lt;a href=&quot;https://oap.langchain.com&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.oap.langchain.com/quickstart&quot;&gt;Deploy Open Agent Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.oap.langchain.com/setup/agents&quot;&gt;Add Deep Researcher to OAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Legacy Implementations üèõÔ∏è&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;src/legacy/&lt;/code&gt; folder contains two earlier implementations that provide alternative approaches to automated research. They are less performant than the current implementation, but provide alternative ideas understanding the different approaches to deep research.&lt;/p&gt; 
&lt;h4&gt;1. Workflow Implementation (&lt;code&gt;legacy/graph.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plan-and-Execute&lt;/strong&gt;: Structured workflow with human-in-the-loop planning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequential Processing&lt;/strong&gt;: Creates sections one by one with reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Control&lt;/strong&gt;: Allows feedback and approval of report plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Focused&lt;/strong&gt;: Emphasizes accuracy through iterative refinement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Multi-Agent Implementation (&lt;code&gt;legacy/multi_agent.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervisor-Researcher Architecture&lt;/strong&gt;: Coordinated multi-agent system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing&lt;/strong&gt;: Multiple researchers work simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Optimized&lt;/strong&gt;: Faster report generation through concurrency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Support&lt;/strong&gt;: Extensive Model Context Protocol integration&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://pypi.org/project/markitdown/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/markitdown.svg?sanitize=true&quot; alt=&quot;PyPI&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/pypi/dd/markitdown&quot; alt=&quot;PyPI - Downloads&quot; /&gt; &lt;a href=&quot;https://github.com/microsoft/autogen&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue&quot; alt=&quot;Built by AutoGen Team&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href=&quot;https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp&quot;&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install &#39;markitdown[all]&#39;&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href=&quot;https://github.com/deanmalmgren/textract&quot;&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI&#39;s GPT-4o, natively &quot;&lt;em&gt;speak&lt;/em&gt;&quot; Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use &#39;uv pip install&#39; rather than just &#39;pip install&#39; to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install &#39;markitdown[all]&#39;&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e &#39;packages/markitdown[all]&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install &#39;markitdown[pdf, docx, pptx]&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;markitdown path-to-file.pdf -o document.md -d -e &quot;&amp;lt;document_intelligence_endpoint&amp;gt;&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href=&quot;https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert(&quot;test.xlsx&quot;)
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint=&quot;&amp;lt;document_intelligence_endpoint&amp;gt;&quot;)
result = md.convert(&quot;test.pdf&quot;)
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions, provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model=&quot;gpt-4o&quot;)
result = md.convert(&quot;example.jpg&quot;)
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&quot;https://cla.opensource.microsoft.com&quot;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/&quot;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/faq/&quot;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&quot;mailto:opencode@microsoft.com&quot;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as &#39;open for contribution&#39; and &#39;open for reviewing&#39; to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href=&quot;https://github.com/microsoft/markitdown/issues&quot;&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href=&quot;https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22&quot;&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href=&quot;https://github.com/microsoft/markitdown/pulls&quot;&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href=&quot;https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22&quot;&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&quot;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&quot;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png&quot; /&gt; 
  &lt;img alt=&quot;vLLM&quot; src=&quot;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png&quot; width=&quot;55%&quot; /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align=&quot;center&quot;&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; | &lt;a href=&quot;https://docs.vllm.ai&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://blog.vllm.ai/&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://arxiv.org/abs/2309.06180&quot;&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://x.com/vllm_project&quot;&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://discuss.vllm.ai&quot;&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://slack.vllm.ai&quot;&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href=&quot;https://mp.weixin.qq.com/s/dgkWg1WFpWGO2jCdTqQHxA&quot;&gt;vLLM Beijing Meetup&lt;/a&gt; focusing on large-scale LLM deployment! Please find the meetup slides &lt;a href=&quot;https://drive.google.com/drive/folders/1Pid6NSFLU43DZRi0EaTcPgXsAzDvbBqF&quot;&gt;here&lt;/a&gt; and the recording &lt;a href=&quot;https://www.chaspark.com/#/live/1166916873711665152&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] We hosted &lt;a href=&quot;https://lu.ma/c1rqyf1f&quot;&gt;NYC vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1_q_aW_ioMJWUImf1s1YM-ZhjXz8cUeL0IJvaquOYBeA/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] vLLM is now a hosted project under PyTorch Foundation! Please find the announcement &lt;a href=&quot;https://pytorch.org/blog/pytorch-foundation-welcomes-vllm/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01] We are excited to announce the alpha release of vLLM V1: A major architectural upgrade with 1.7x speedup! Clean code, optimized execution loop, zero-overhead prefix caching, enhanced multimodal support, and more. Please check out our blog post &lt;a href=&quot;https://blog.vllm.ai/2025/01/27/v1-alpha-release.html&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/04] We hosted &lt;a href=&quot;https://www.sginnovate.com/event/limited-availability-morning-evening-slots-remaining-inaugural-vllm-asia-developer-day&quot;&gt;Asia Developer Day&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/19cp6Qu8u48ihB91A064XfaXruNYiBOUKrBxAmDOllOo/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href=&quot;https://lu.ma/vllm-ollama&quot;&gt;vLLM x Ollama Inference Night&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/16T2PDD1YwRnZ4Tu8Q5r6n53c5Lr5c73UV9Vd2_eBo4U/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href=&quot;https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg&quot;&gt;the first vLLM China Meetup&lt;/a&gt;! Please find the meetup slides from vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/1REHvfQMKGnvz6p3Fd23HhSO4c8j5WPGZV0bKYLwnHyQ/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href=&quot;https://lu.ma/7mu4k4xx&quot;&gt;the East Coast vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1NHiv8EUFF1NLd3fEYODm56nDmL26lEeXCaDgyDlTsRs/edit#slide=id.g31441846c39_0_0&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/02] We hosted &lt;a href=&quot;https://lu.ma/h7g3kuj9&quot;&gt;the ninth vLLM meetup&lt;/a&gt; with Meta! Please find the meetup slides from vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/1jzC_PZVXrVNSFVCW-V4cFXb6pn7zZ2CyP_Flwo05aqg/edit?usp=sharing&quot;&gt;here&lt;/a&gt; and AMD &lt;a href=&quot;https://drive.google.com/file/d/1Zk5qEJIkTmlQ2eQcXQZlljAx3m9s7nwn/view?usp=sharing&quot;&gt;here&lt;/a&gt;. The slides from Meta will not be posted.&lt;/li&gt; 
  &lt;li&gt;[2025/01] We hosted &lt;a href=&quot;https://lu.ma/zep56hui&quot;&gt;the eighth vLLM meetup&lt;/a&gt; with Google Cloud! Please find the meetup slides from vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/1epVkt4Zu8Jz_S5OhEHPc798emsYh2BwYfRuDDVEF7u4/edit?usp=sharing&quot;&gt;here&lt;/a&gt;, and Google Cloud team &lt;a href=&quot;https://drive.google.com/file/d/1h24pHewANyRL11xy5dXUbvRC9F9Kkjix/view?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/12] vLLM joins &lt;a href=&quot;https://pytorch.org/blog/vllm-joins-pytorch&quot;&gt;pytorch ecosystem&lt;/a&gt;! Easy, Fast, and Cheap LLM Serving for Everyone!&lt;/li&gt; 
  &lt;li&gt;[2024/11] We hosted &lt;a href=&quot;https://lu.ma/h0qvrajz&quot;&gt;the seventh vLLM meetup&lt;/a&gt; with Snowflake! Please find the meetup slides from vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/1e3CxQBV3JsfGp30SwyvS3eM_tW-ghOhJ9PAJGK6KR54/edit?usp=sharing&quot;&gt;here&lt;/a&gt;, and Snowflake team &lt;a href=&quot;https://docs.google.com/presentation/d/1qF3RkDAbOULwz9WK5TOltt2fE9t6uIc_hVNLFAaQX6A/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/10] We have just created a developer slack (&lt;a href=&quot;https://slack.vllm.ai&quot;&gt;slack.vllm.ai&lt;/a&gt;) focusing on coordinating contributions and discussing features. Please feel free to join us there!&lt;/li&gt; 
  &lt;li&gt;[2024/10] Ray Summit 2024 held a special track for vLLM! Please find the opening talk slides from the vLLM team &lt;a href=&quot;https://docs.google.com/presentation/d/1B_KQxpHBTRa_mDF-tR6i8rWdOU5QoTZNcEg2MKZxEHM/edit?usp=sharing&quot;&gt;here&lt;/a&gt;. Learn more from the &lt;a href=&quot;https://www.youtube.com/playlist?list=PLzTswPQNepXl6AQwifuwUImLPFRVpksjR&quot;&gt;talks&lt;/a&gt; from other vLLM contributors and users!&lt;/li&gt; 
  &lt;li&gt;[2024/09] We hosted &lt;a href=&quot;https://lu.ma/87q3nvnh&quot;&gt;the sixth vLLM meetup&lt;/a&gt; with NVIDIA! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1wrLGwytQfaOTd5wCGSPNhoaW3nq0E-9wqyP7ny93xRs/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] We hosted &lt;a href=&quot;https://lu.ma/lp0gyjqr&quot;&gt;the fifth vLLM meetup&lt;/a&gt; with AWS! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1RgUD8aCfcHocghoP3zmXzck9vX3RCI9yfUAB2Bbcl4Y/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] In partnership with Meta, vLLM officially supports Llama 3.1 with FP8 quantization and pipeline parallelism! Please check out our blog post &lt;a href=&quot;https://blog.vllm.ai/2024/07/23/llama31.html&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/06] We hosted &lt;a href=&quot;https://lu.ma/agivllm&quot;&gt;the fourth vLLM meetup&lt;/a&gt; with Cloudflare and BentoML! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/04] We hosted &lt;a href=&quot;https://robloxandvllmmeetup2024.splashthat.com/&quot;&gt;the third vLLM meetup&lt;/a&gt; with Roblox! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1A--47JAK4BJ39t954HyTkvtfwn0fkqtsL8NGFuslReM/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/01] We hosted &lt;a href=&quot;https://lu.ma/ygxbpzhl&quot;&gt;the second vLLM meetup&lt;/a&gt; with IBM! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/12mI2sKABnUw5RBWXDYY-HtHth4iMSNcEoQ10jDQbxgA/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/10] We hosted &lt;a href=&quot;https://lu.ma/first-vllm-meetup&quot;&gt;the first vLLM meetup&lt;/a&gt; with a16z! Please find the meetup slides &lt;a href=&quot;https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/08] We would like to express our sincere gratitude to &lt;a href=&quot;https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/&quot;&gt;Andreessen Horowitz&lt;/a&gt; (a16z) for providing a generous grant to support the open-source development and research of vLLM.&lt;/li&gt; 
  &lt;li&gt;[2023/06] We officially released vLLM! FastChat-vLLM integration has powered &lt;a href=&quot;https://chat.lmsys.org&quot;&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid-April. Check out our &lt;a href=&quot;https://vllm.ai&quot;&gt;blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href=&quot;https://sky.cs.berkeley.edu&quot;&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href=&quot;https://blog.vllm.ai/2023/06/20/vllm.html&quot;&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href=&quot;https://arxiv.org/abs/2210.17323&quot;&gt;GPTQ&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2306.00978&quot;&gt;AWQ&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2309.05516&quot;&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, TPU, and AWS Neuron&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href=&quot;https://docs.vllm.ai/en/latest/models/supported_models.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href=&quot;https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source&quot;&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href=&quot;https://docs.vllm.ai/en/latest/&quot;&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.vllm.ai/en/latest/getting_started/installation.html&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.vllm.ai/en/latest/getting_started/quickstart.html&quot;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.vllm.ai/en/latest/models/supported_models.html&quot;&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href=&quot;https://docs.vllm.ai/en/latest/contributing/index.html&quot;&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;vLLM is a community project. Our compute resources for development and testing are supported by the following organizations. Thank you for your support!&lt;/p&gt; 
&lt;!-- Note: Please sort them in alphabetical order. --&gt; 
&lt;!-- Note: Please keep these consistent with docs/community/sponsors.md --&gt; 
&lt;p&gt;Cash Donations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a16z&lt;/li&gt; 
 &lt;li&gt;Dropbox&lt;/li&gt; 
 &lt;li&gt;Sequoia Capital&lt;/li&gt; 
 &lt;li&gt;Skywork AI&lt;/li&gt; 
 &lt;li&gt;ZhenFund&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compute Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alibaba Cloud&lt;/li&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
 &lt;li&gt;Anyscale&lt;/li&gt; 
 &lt;li&gt;AWS&lt;/li&gt; 
 &lt;li&gt;Crusoe Cloud&lt;/li&gt; 
 &lt;li&gt;Databricks&lt;/li&gt; 
 &lt;li&gt;DeepInfra&lt;/li&gt; 
 &lt;li&gt;Google Cloud&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Lambda Lab&lt;/li&gt; 
 &lt;li&gt;Nebius&lt;/li&gt; 
 &lt;li&gt;Novita AI&lt;/li&gt; 
 &lt;li&gt;NVIDIA&lt;/li&gt; 
 &lt;li&gt;Replicate&lt;/li&gt; 
 &lt;li&gt;Roblox&lt;/li&gt; 
 &lt;li&gt;RunPod&lt;/li&gt; 
 &lt;li&gt;Trainy&lt;/li&gt; 
 &lt;li&gt;UC Berkeley&lt;/li&gt; 
 &lt;li&gt;UC San Diego&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Slack Sponsor: Anyscale&lt;/p&gt; 
&lt;p&gt;We also have an official fundraising venue through &lt;a href=&quot;https://opencollective.com/vllm&quot;&gt;OpenCollective&lt;/a&gt;. We plan to use the fund to support the development, maintenance, and adoption of vLLM.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href=&quot;https://arxiv.org/abs/2309.06180&quot;&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href=&quot;https://github.com/vllm-project/vllm/issues&quot;&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href=&quot;https://discuss.vllm.ai&quot;&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href=&quot;https://slack.vllm.ai&quot;&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub&#39;s &lt;a href=&quot;https://github.com/vllm-project/vllm/security/advisories&quot;&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href=&quot;mailto:vllm-questions@lists.berkeley.edu&quot;&gt;vllm-questions@lists.berkeley.edu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM&#39;s logo, please refer to &lt;a href=&quot;https://github.com/vllm-project/media-kit&quot;&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3</title>
      <link>https://github.com/QwenLM/Qwen3</link>
      <description>&lt;p&gt;Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Qwen3&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/logo_qwen3.png&quot; width=&quot;400&quot; /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; üíú &lt;a href=&quot;https://chat.qwen.ai/&quot;&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ó &lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü§ñ &lt;a href=&quot;https://modelscope.cn/organization/qwen&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üìë &lt;a href=&quot;https://arxiv.org/abs/2505.09388&quot;&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; üìë &lt;a href=&quot;https://qwenlm.github.io/blog/qwen3/&quot;&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ÔΩú &amp;nbsp;&amp;nbsp;üìñ &lt;a href=&quot;https://qwen.readthedocs.io/&quot;&gt;Documentation&lt;/a&gt; &lt;br /&gt; üñ•Ô∏è &lt;a href=&quot;https://huggingface.co/spaces/Qwen/Qwen3-Demo&quot;&gt;Demo&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;üí¨ &lt;a href=&quot;https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png&quot;&gt;WeChat (ÂæÆ‰ø°)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;ü´® &lt;a href=&quot;https://discord.gg/CV4E9rpNSD&quot;&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-&lt;/code&gt; or visit the &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f&quot;&gt;Qwen3 collection&lt;/a&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;p&gt;To learn more about Qwen3, feel free to read our documentation [&lt;a href=&quot;https://qwen.readthedocs.io/en/latest/&quot;&gt;EN&lt;/a&gt;|&lt;a href=&quot;https://qwen.readthedocs.io/zh-cn/latest/&quot;&gt;ZH&lt;/a&gt;]. Our documentation consists of the following sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quickstart: the basic usages and demonstrations;&lt;/li&gt; 
 &lt;li&gt;Inference: the guidance for the inference with Transformers, including batch inference, streaming, etc.;&lt;/li&gt; 
 &lt;li&gt;Run Locally: the instructions for running LLM locally on CPU and GPU, with frameworks like llama.cpp and Ollama;&lt;/li&gt; 
 &lt;li&gt;Deployment: the demonstration of how to deploy Qwen for large-scale inference with frameworks like SGLang, vLLM, TGI, etc.;&lt;/li&gt; 
 &lt;li&gt;Quantization: the practice of quantizing LLMs with GPTQ, AWQ, as well as the guidance for how to make high-quality quantized GGUF files;&lt;/li&gt; 
 &lt;li&gt;Training: the instructions for post-training, including SFT and RLHF (TODO) with frameworks like Axolotl, LLaMA-Factory, etc.&lt;/li&gt; 
 &lt;li&gt;Framework: the usage of Qwen with frameworks for application, e.g., RAG, Agent, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;Qwen3-2507&lt;/h3&gt; 
&lt;p&gt;Over the past three months, we continued to explore the potential of the Qwen3 families and we are excited to introduce the updated &lt;strong&gt;Qwen3-2507&lt;/strong&gt; in two variants, Qwen3-Instruct-2507 and Qwen3-Thinking-2507, and three sizes, 235B-A22B, 30B-A3B, and 4B.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Qwen3-Instruct-2507&lt;/strong&gt; is the updated version of the previous Qwen3 non-thinking mode, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significant improvements&lt;/strong&gt; in general capabilities, including &lt;strong&gt;instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Substantial gains&lt;/strong&gt; in long-tail knowledge coverage across &lt;strong&gt;multiple languages&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better alignment&lt;/strong&gt; with user preferences in &lt;strong&gt;subjective and open-ended tasks&lt;/strong&gt;, enabling more helpful responses and higher-quality text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced capabilities&lt;/strong&gt; in &lt;strong&gt;256K-token long-context understanding&lt;/strong&gt;, extendable up to &lt;strong&gt;1 million tokens&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen3-Thinking-2507&lt;/strong&gt; is the continuation of Qwen3 thinking model, with improved quality and depth of reasoning, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significantly improved performance&lt;/strong&gt; on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise ‚Äî achieving &lt;strong&gt;state-of-the-art results among open-weight thinking models&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better general capabilities&lt;/strong&gt;, such as instruction following, tool usage, text generation, and alignment with human preferences.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced 256K long-context understanding&lt;/strong&gt; capabilities, extendable up to &lt;strong&gt;1 million tokens&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Previous Qwen3 Release&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;Qwen3 (aka Qwen3-2504)&lt;/h3&gt; 
 &lt;p&gt; We are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. These models represent our most advanced and intelligent systems to date, improving from our experience in building QwQ and Qwen2.5. We are making the weights of Qwen3 available to the public, including both dense and Mixture-of-Expert (MoE) models. &lt;br /&gt;&lt;br /&gt; The highlights from Qwen3 include: &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;b&gt;Dense and Mixture-of-Experts (MoE) models of various sizes&lt;/b&gt;, available in 0.6B, 1.7B, 4B, 8B, 14B, 32B and 30B-A3B, 235B-A22B.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Seamless switching between thinking mode&lt;/b&gt; (for complex logical reasoning, math, and coding) and &lt;b&gt;non-thinking mode&lt;/b&gt; (for efficient, general-purpose chat), ensuring optimal performance across various scenarios.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Significantly enhancement in reasoning capabilities&lt;/b&gt;, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Superior human preference alignment&lt;/b&gt;, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Expertise in agent capabilities&lt;/b&gt;, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Support of 100+ languages and dialects&lt;/b&gt; with strong capabilities for &lt;b&gt;multilingual instruction following&lt;/b&gt; and &lt;b&gt;translation&lt;/b&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.08.08: You can now use Qwen3-2507 to handle ultra-long inputs of &lt;strong&gt;1 million tokens&lt;/strong&gt;! See the update modelcards (&lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507&quot;&gt;235B-A22B-Instruct-2507&lt;/a&gt;, &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507&quot;&gt;235B-A22B-Thinking-2507&lt;/a&gt;, &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507&quot;&gt;A30B-A3B-Instruct-2507&lt;/a&gt;, &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507&quot;&gt;A30B-A3B-Thinking-2507&lt;/a&gt;) for how to enable this feature.&lt;/li&gt; 
 &lt;li&gt;2025.08.06: The final open release of Qwen3-2507, &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&quot;&gt;Qwen3-4B-Instruct-2507&lt;/a&gt; and &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&quot;&gt;Qwen3-4B-Thinking-2507&lt;/a&gt;, is out!&lt;/li&gt; 
 &lt;li&gt;2025.07.31: Qwen3-30B-A3B-Thinking-2507 is released. Check out the &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507&quot;&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.30: Qwen3-30B-A3B-Instruct-2507 is released. Check out the &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507&quot;&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.25: We released the updated version of Qwen3-235B-A22B thinking mode, named Qwen3-235B-A22B-Thinking-2507. Check out the &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507&quot;&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.21: We released the updated version of Qwen3-235B-A22B non-thinking mode, named Qwen3-235B-A22B-Instruct-2507, featuring significant enhancements over the previous version and supporting 256K-token long-context understanding. Check our &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507&quot;&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.04.29: We released the Qwen3 series. Check our &lt;a href=&quot;https://qwenlm.github.io/blog/qwen3&quot;&gt;blog&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check our &lt;a href=&quot;https://qwenlm.github.io/blog/qwen2.5&quot;&gt;blog&lt;/a&gt; for more!&lt;/li&gt; 
 &lt;li&gt;2024.06.06: We released the Qwen2 series. Check our &lt;a href=&quot;https://qwenlm.github.io/blog/qwen2/&quot;&gt;blog&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;2024.03.28: We released the first MoE model of Qwen: Qwen1.5-MoE-A2.7B! Temporarily, only HF transformers and vLLM support the model. We will soon add the support of llama.cpp, mlx-lm, etc. Check our &lt;a href=&quot;https://qwenlm.github.io/blog/qwen-moe/&quot;&gt;blog&lt;/a&gt; for more information!&lt;/li&gt; 
 &lt;li&gt;2024.02.05: We released the Qwen1.5 series.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Detailed evaluation results are reported in this &lt;a href=&quot;https://qwenlm.github.io/blog/qwen3/&quot;&gt;üìë blog (Qwen3-2504)&lt;/a&gt; and this &lt;a href=&quot;&quot;&gt;üìë blog (Qwen3-2507) [coming soon]&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For requirements on GPU memory and the respective throughput, see results &lt;a href=&quot;https://qwen.readthedocs.io/en/latest/getting_started/speed_benchmark.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Run Qwen3&lt;/h2&gt; 
&lt;h3&gt;ü§ó Transformers&lt;/h3&gt; 
&lt;p&gt;Transformers is a library of pretrained natural language processing for inference and training. The latest version of &lt;code&gt;transformers&lt;/code&gt; is recommended and &lt;code&gt;transformers&amp;gt;=4.51.0&lt;/code&gt; is required.&lt;/p&gt; 
&lt;h4&gt;Qwen3-Instruct-2507&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-30B-A3B-Instruct-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;Qwen/Qwen3-30B-A3B-Instruct-2507&quot;

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;
)

# prepare the model input
prompt = &quot;Give me a short introduction to large language model.&quot;
messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=16384
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

content = tokenizer.decode(output_ids, skip_special_tokens=True)

print(&quot;content:&quot;, content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Qwen3-Instruct-2507 supports only non-thinking mode and does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks in its output. Meanwhile, specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Qwen3-Thinking-2507&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-30B-A3B-Thinking-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;Qwen/Qwen3-30B-A3B-Thinking-2507&quot;

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;
)

# prepare the model input
prompt = &quot;Give me a short introduction to large language model.&quot;
messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

# parsing thinking content
try:
    # rindex finding 151668 (&amp;lt;/think&amp;gt;)
    index = len(output_ids) - output_ids[::-1].index(151668)
except ValueError:
    index = 0

thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(&quot;\n&quot;)
content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(&quot;\n&quot;)

print(&quot;thinking content:&quot;, thinking_content)  # no opening &amp;lt;think&amp;gt; tag
print(&quot;content:&quot;, content)

&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Qwen3-Thinking-2507 supports only thinking mode. Additionally, to enforce model thinking, the default chat template automatically includes &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;. Therefore, it is normal for the model&#39;s output to contain only &lt;code&gt;&amp;lt;/think&amp;gt;&lt;/code&gt; without an explicit opening &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; tag.&lt;/p&gt; 
 &lt;p&gt;Qwen3-Thinking-2507 also features an increased thinking length. We strongly recommend its use in highly complex reasoning tasks with adequate maximum generation length.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Switching Thinking/Non-thinking Modes for Previous Qwen3 Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; By default, Qwen3 models will think before response. This could be controlled by &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;enable_thinking=False&lt;/code&gt;: Passing &lt;code&gt;enable_thinking=False&lt;/code&gt; to `tokenizer.apply_chat_template` will strictly prevent the model from generating thinking content.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;/think&lt;/code&gt; and &lt;code&gt;/no_think&lt;/code&gt; instructions: Use those words in the system or user message to signify whether Qwen3 should think. In multi-turn conversations, the latest instruction is followed.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;ModelScope&lt;/h3&gt; 
&lt;p&gt;We strongly advise users especially those in mainland China to use ModelScope. ModelScope adopts a Python API similar to Transformers. The CLI tool &lt;code&gt;modelscope download&lt;/code&gt; can help you solve issues concerning downloading checkpoints. For vLLM and SGLang, the environment variable &lt;code&gt;VLLM_USE_MODELSCOPE=true&lt;/code&gt; and &lt;code&gt;SGLANG_USE_MODELSCOPE=true&lt;/code&gt; can be used respectively.&lt;/p&gt; 
&lt;h3&gt;llama.cpp&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp&quot;&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; enables LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware. &lt;code&gt;llama.cpp&amp;gt;=b5401&lt;/code&gt; is recommended for the full support of Qwen3.&lt;/p&gt; 
&lt;p&gt;To use the CLI, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;./llama-cli -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --color -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift
# CTRL+C to exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the API server, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;./llama-server -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --reasoning-format deepseek -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A simple web front end will be at &lt;code&gt;http://localhost:8080&lt;/code&gt; and an OpenAI-compatible API will be at &lt;code&gt;http://localhost:8080/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For additional guides, please refer to &lt;a href=&quot;https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html&quot;&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] llama.cpp adopts &quot;rotating context management&quot; and infinite generation is made possible by evicting earlier tokens. It could configured by parameters and the commands above effectively disable it. For more details, please refer to &lt;a href=&quot;https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html#llama-cli&quot;&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Ollama&lt;/h3&gt; 
&lt;p&gt;After &lt;a href=&quot;https://ollama.com/&quot;&gt;installing Ollama&lt;/a&gt;, you can initiate the Ollama service with the following command (Ollama v0.9.0 or higher is recommended):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;ollama serve
# You need to keep this service running whenever you are using ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To pull a model checkpoint and run the model, use the &lt;code&gt;ollama run&lt;/code&gt; command. You can specify a model size by adding a suffix to &lt;code&gt;qwen3&lt;/code&gt;, such as &lt;code&gt;:8b&lt;/code&gt; or &lt;code&gt;:30b-a3b&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;ollama run qwen3:8b
# Setting parameters, type &quot;/set parameter num_ctx 40960&quot; and &quot;/set parameter num_predict 32768&quot;
# To exit, type &quot;/bye&quot; and press ENTER
# For Qwen3-2504 models,
# - To enable thinking, which is the default, type &quot;/set think&quot;
# - To disable thinking, type &quot;/set nothink&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also access the Ollama service via its OpenAI-compatible API. Please note that you need to (1) keep &lt;code&gt;ollama serve&lt;/code&gt; running while using the API, and (2) execute &lt;code&gt;ollama run qwen3:8b&lt;/code&gt; before utilizing this API to ensure that the model checkpoint is prepared. The API is at &lt;code&gt;http://localhost:11434/v1/&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;For additional details, please visit &lt;a href=&quot;https://ollama.com/&quot;&gt;ollama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ollama&#39;s naming may not be consistent with the Qwen&#39;s original naming. For example, &lt;code&gt;qwen3:30b-a3b&lt;/code&gt; in Ollama points to &lt;code&gt;qwen3:30b-a3b-thinking-2507-q4_K_M&lt;/code&gt; as of August 2025. Please check &lt;a href=&quot;https://ollama.com/library/qwen3/tags&quot;&gt;https://ollama.com/library/qwen3/tags&lt;/a&gt; before use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ollama adopts the same &quot;rotating context management&quot; with llama.cpp. However, its default settings (&lt;code&gt;num_ctx&lt;/code&gt; 2048 and &lt;code&gt;num_predict&lt;/code&gt; -1), suggesting infinite generation with a 2048-token context, could lead to trouble for Qwen3 models. We recommend setting &lt;code&gt;num_ctx&lt;/code&gt; and &lt;code&gt;num_predict&lt;/code&gt; properly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LMStudio&lt;/h3&gt; 
&lt;p&gt;Qwen3 has already been supported by &lt;a href=&quot;https://lmstudio.ai/&quot;&gt;lmstudio.ai&lt;/a&gt;. You can directly use LMStudio with our GGUF files.&lt;/p&gt; 
&lt;h3&gt;ExecuTorch&lt;/h3&gt; 
&lt;p&gt;To export and run on ExecuTorch (iOS, Android, Mac, Linux, and more), please follow this &lt;a href=&quot;https://github.com/pytorch/executorch/raw/main/examples/models/qwen3/README.md&quot;&gt;example&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MNN&lt;/h3&gt; 
&lt;p&gt;To export and run on MNN, which supports Qwen3 on mobile devices, please visit &lt;a href=&quot;https://github.com/alibaba/MNN&quot;&gt;Alibaba MNN&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MLX LM&lt;/h3&gt; 
&lt;p&gt;If you are running on Apple Silicon, &lt;a href=&quot;https://github.com/ml-explore/mlx-lm&quot;&gt;&lt;code&gt;mlx-lm&lt;/code&gt;&lt;/a&gt; also supports Qwen3 (&lt;code&gt;mlx-lm&amp;gt;=0.24.0&lt;/code&gt;). Look for models ending with MLX on Hugging Face Hub.&lt;/p&gt; 
&lt;h3&gt;OpenVINO&lt;/h3&gt; 
&lt;p&gt;If you are running on Intel CPU or GPU, &lt;a href=&quot;https://github.com/openvinotoolkit&quot;&gt;OpenVINO toolkit&lt;/a&gt; supports Qwen3. You can follow this &lt;a href=&quot;https://github.com/openvinotoolkit/openvino_notebooks/raw/latest/notebooks/llm-chatbot/llm-chatbot.ipynb&quot;&gt;chatbot example&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deploy Qwen3&lt;/h2&gt; 
&lt;p&gt;Qwen3 is supported by multiple inference frameworks. Here we demonstrate the usage of &lt;code&gt;SGLang&lt;/code&gt;, &lt;code&gt;vLLM&lt;/code&gt; and &lt;code&gt;TensorRT-LLM&lt;/code&gt;. You can also find Qwen3 models from various inference providers, e.g., &lt;a href=&quot;https://www.alibabacloud.com/en/product/modelstudio&quot;&gt;Alibaba Cloud Model Studio&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SGLang&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sgl-project/sglang&quot;&gt;SGLang&lt;/a&gt; is a fast serving framework for large language models and vision language models. SGLang could be used to launch a server with OpenAI-compatible API service. &lt;code&gt;sglang&amp;gt;=0.4.6.post1&lt;/code&gt; is required.&lt;/p&gt; 
&lt;p&gt;For Qwen3-Instruct-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Instruct-2507 --port 30000 --context-length 262144
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3-Thinking-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 --port 30000 --context-length 262144 --reasoning-parser deepseek-r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3, it is&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-8B --port 30000 --context-length 131072 --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:30000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Due to the preprocessing of API requests in SGLang, which drops all &lt;code&gt;reasoning_content&lt;/code&gt; fields, the quality of &lt;strong&gt;multi-step tool use with Qwen3 thinking models&lt;/strong&gt; may be suboptimal, which requires the existence of the related thinking content. While the fixes are being worked on, as a workdaround, we recommend passing the content as it is, without extracting thinking content, and the chat template will correctly handle the processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;vLLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM&lt;/a&gt; is a high-throughput and memory-efficient inference and serving engine for LLMs. &lt;code&gt;vllm&amp;gt;=0.9.0&lt;/code&gt; is recommended.&lt;/p&gt; 
&lt;p&gt;For Qwen3-Instruct-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;vllm serve Qwen/Qwen3-30B-A3B-Instruct-2507 --port 8000 --max-model-len 262144
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3-Thinking-2507,&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;vllm serve Qwen/Qwen3-30B-A3B-Thinking-2507 --port 8000 --max-model-len 262144 --enable-reasoning --reasoning-parser deepseek_r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Qwen3, it is&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;vllm serve Qwen/Qwen3-8B --port 8000 --max-model-len 131072 --enable-reasoning --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Due to the preprocessing of API requests in vLLM, which drops all &lt;code&gt;reasoning_content&lt;/code&gt; fields, the quality of &lt;strong&gt;multi-step tool use with Qwen3 thinking models&lt;/strong&gt; may be suboptimal, which requires the existence of the related thinking content. While the fixes are being worked on, as a workdaround, we recommend passing the content as it is, without extracting thinking content, and the chat template will correctly handle the processing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM&quot;&gt;TensorRT-LLM&lt;/a&gt; is an open-source LLM inference engine from NVIDIA, which provides optimizations including custom attention kernels, quantization and more on NVIDIA GPUs. Qwen3 is supported in its re-architected &lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/torch.html&quot;&gt;PyTorch backend&lt;/a&gt;. &lt;code&gt;tensorrt_llm&amp;gt;=0.20.0rc3&lt;/code&gt; is recommended. Please refer to the &lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM/raw/main/examples/models/core/qwen/README.md#qwen3&quot;&gt;README&lt;/a&gt; page for more details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;trtllm-serve Qwen/Qwen3-8B --host localhost --port 8000 --backend pytorch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;MindIE&lt;/h3&gt; 
&lt;p&gt;For deployment on Ascend NPUs, please visit &lt;a href=&quot;https://modelers.cn/&quot;&gt;Modelers&lt;/a&gt; and search for Qwen3.&lt;/p&gt; 
&lt;!-- 
### OpenLLM

[OpenLLM](https://github.com/bentoml/OpenLLM) allows you to easily run¬†Qwen2.5 as OpenAI-compatible APIs. You can start a model server using `openllm serve`. For example:

```bash
openllm serve qwen2.5:7b
```

The server is active at `http://localhost:3000/`, providing OpenAI-compatible APIs. You can create an OpenAI client to call its chat API. For more information, refer to [our documentation](https://qwen.readthedocs.io/en/latest/deployment/openllm.html). --&gt; 
&lt;h2&gt;Build with Qwen3&lt;/h2&gt; 
&lt;h3&gt;Tool Use&lt;/h3&gt; 
&lt;p&gt;For tool use capabilities, we recommend taking a look at &lt;a href=&quot;https://github.com/QwenLM/Qwen-Agent&quot;&gt;Qwen-Agent&lt;/a&gt;, which provides a wrapper around these APIs to support tool use or function calling with MCP support. Tool use with Qwen3 can also be conducted with SGLang, vLLM, Transformers, llama.cpp, Ollama, etc. Follow guides in our documentation to see how to enable the support.&lt;/p&gt; 
&lt;h3&gt;Finetuning&lt;/h3&gt; 
&lt;p&gt;We advise you to use training frameworks, including &lt;a href=&quot;https://github.com/OpenAccess-AI-Collective/axolotl&quot;&gt;Axolotl&lt;/a&gt;, &lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;UnSloth&lt;/a&gt;, &lt;a href=&quot;https://github.com/modelscope/swift&quot;&gt;Swift&lt;/a&gt;, &lt;a href=&quot;https://github.com/hiyouga/LLaMA-Factory&quot;&gt;Llama-Factory&lt;/a&gt;, etc., to finetune your models with SFT, DPO, GRPO, etc.&lt;/p&gt; 
&lt;h2&gt;License Agreement&lt;/h2&gt; 
&lt;p&gt;All our open-weight models are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{qwen3,
    title={Qwen3 Technical Report}, 
    author={An Yang and Anfeng Li and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Gao and Chengen Huang and Chenxu Lv and Chujie Zheng and Dayiheng Liu and Fan Zhou and Fei Huang and Feng Hu and Hao Ge and Haoran Wei and Huan Lin and Jialong Tang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jing Zhou and Jingren Zhou and Junyang Lin and Kai Dang and Keqin Bao and Kexin Yang and Le Yu and Lianghao Deng and Mei Li and Mingfeng Xue and Mingze Li and Pei Zhang and Peng Wang and Qin Zhu and Rui Men and Ruize Gao and Shixuan Liu and Shuang Luo and Tianhao Li and Tianyi Tang and Wenbiao Yin and Xingzhang Ren and Xinyu Wang and Xinyu Zhang and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yinger Zhang and Yu Wan and Yuqiong Liu and Zekun Wang and Zeyu Cui and Zhenru Zhang and Zhipeng Zhou and Zihan Qiu},
    journal = {arXiv preprint arXiv:2505.09388},
    year={2025}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{qwen2,
    title   = {Qwen2 Technical Report}, 
    author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal = {arXiv preprint arXiv:2407.10671},
    year    = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href=&quot;https://discord.gg/z3GAxXZ9Ce&quot;&gt;Discord&lt;/a&gt; or &lt;a href=&quot;https://raw.githubusercontent.com/QwenLM/Qwen3/main/assets/wechat.png&quot;&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Financial data aggregator for humans and AI agents.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot; /&gt; 
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot; /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href=&quot;https://x.com/openbb_finance&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance&quot; alt=&quot;Twitter&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.com/invite/xPHTuHCmuV&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/831165782750789672&quot; alt=&quot;Discord Shield&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode&quot; alt=&quot;Open in Dev Containers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt; &lt;img src=&quot;https://github.com/codespaces/badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt; &lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/openbb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package&quot; alt=&quot;PyPI&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href=&quot;https://my.openbb.co/login&quot;&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href=&quot;https://docs.openbb.co/platform/reference&quot;&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href=&quot;https://pro.openbb.co&quot;&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href=&quot;https://pro.openbb.co&quot;&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot; /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href=&quot;https://docs.openbb.co/workspace&quot;&gt;docs&lt;/a&gt; or &lt;a href=&quot;https://github.com/OpenBB-finance/backends-for-openbb&quot;&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href=&quot;https://github.com/OpenBB-finance/agents-for-openbb&quot;&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;pip install &quot;openbb[all]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href=&quot;http://127.0.0.1:6900&quot;&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href=&quot;https://pro.openbb.co/&quot;&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069&quot; alt=&quot;CleanShot 2025-05-17 at 09 51 56@2x&quot; /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the &quot;Apps&quot; tab&lt;/li&gt; 
 &lt;li&gt;Click on &quot;Connect backend&quot;&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href=&quot;http://127.0.0.1:6900&quot;&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on &quot;Add&quot;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That&#39;s it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed=&quot;closed&quot;&gt; 
 &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href=&quot;https://pypi.org/project/openbb/&quot;&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href=&quot;https://docs.openbb.co/platform/installation&quot;&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href=&quot;https://docs.openbb.co/cli/installation&quot;&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href=&quot;https://docs.openbb.co/platform/developer_guide/misc/contributing&quot;&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn&#39;t exist already &lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D&quot;&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D&quot;&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D&quot;&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href=&quot;https://openbb.co/discord&quot;&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href=&quot;https://openbb.co/links&quot;&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href=&quot;https://openbb.co/links&quot;&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href=&quot;https://openbb.co/open&quot;&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark&quot; alt=&quot;Star History Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn&#39;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot; /&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>OpenPipe/ART</title>
      <link>https://github.com/OpenPipe/ART</link>
      <description>&lt;p&gt;Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, Kimi, and more!&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://art.openpipe.ai&quot;&gt;
   &lt;picture&gt; 
    &lt;img alt=&quot;ART logo&quot; src=&quot;https://github.com/openpipe/art/raw/main/assets/ART_logo.png&quot; width=&quot;160px&quot; /&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
 &lt;h1&gt;Agent Reinforcement Trainer&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; Train multi-step agents for real-world tasks using GRPO. &lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/openpipe/art/raw/main/CONTRIBUTING.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-blue.svg?sanitize=true&quot; alt=&quot;PRs-Welcome&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/openpipe-art/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/openpipe-art?color=364fc7&quot; alt=&quot;PyPI version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Train Agent&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://discord.gg/zbBHRUpwf4&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Join%20Discord-5865F2?style=plastic&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Join Discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://art.openpipe.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Documentation-orange?style=plastic&amp;amp;logo=gitbook&amp;amp;logoColor=white&quot; alt=&quot;Documentation&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üîå MCP‚Ä¢RL: Teach your agents to master MCP&lt;/h2&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/assets/MCP_RL_diagram.svg?sanitize=true&quot; width=&quot;7000&quot; /&gt; 
&lt;p&gt;&lt;strong&gt;MCP‚Ä¢RL&lt;/strong&gt; enables you to train agents to effectively use any MCP (Model Context Protocol) server with minimal setup. Simply provide a server URL and MCP‚Ä¢RL will:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Automatically discover server tools&lt;/li&gt; 
 &lt;li&gt;Design input tasks that utilize those tools&lt;/li&gt; 
 &lt;li&gt;Train the model to improve performance on the MCP server using RULER&lt;/li&gt; 
 &lt;li&gt;Test on new tasks to validate the trained model&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;‚ú® &lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No labeled data&lt;/strong&gt; - MCP‚Ä¢RL learns what tasks a server will be used for by analyzing its tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General-purpose&lt;/strong&gt; - Optimizes models for any MCP server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong performance&lt;/strong&gt; - Matches or exceeds SOTA performance in 2/3 benchmarks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy integration&lt;/strong&gt; - No customization of your MCP server required!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from art.rewards import ruler_score_group

# Specialize a model for NWS MCP server
MCP_SERVER_URL = &quot;https://server.smithery.ai/@smithery-ai/national-weather-service/mcp&quot;

# Generate training scenarios based on MCP tools
scenarios = await generate_scenarios(
    num_scenarios=24,
    server_url=MCP_SERVER_URL,
)

# ...run the agent...

# Use RULER to assign relative scores to each trajectory
scored_groups = []
for group in groups:
    judged_group = await ruler_score_group(group)
    scored_groups.append(judged_group)

# Train the model to improve performance on the MCP server
await model.train(scored_groups)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ART Overview&lt;/h2&gt; 
&lt;p&gt;ART is an open-source RL framework that improves agent reliability by allowing LLMs to &lt;strong&gt;learn from experience&lt;/strong&gt;. ART provides an ergonomic harness for integrating GRPO into any python application. For a quick hands-on introduction, run one of the notebooks below. When you&#39;re ready to learn more, check out the &lt;a href=&quot;https://art.openpipe.ai&quot;&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìí Notebooks&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Task&lt;/th&gt; 
   &lt;th&gt;Example Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Comparative Performance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MCP‚Ä¢RL&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/mcp-rl/mcp-rl.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B masters the NWS MCP server&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ART‚Ä¢E [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/art-e.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to search emails using RULER&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://github.com/openpipe/art/raw/main/assets/benchmarks/email_agent/accuracy-training-progress.svg?sanitize=true&quot; height=&quot;72&quot; /&gt; &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/art-e/art_e/evaluate/display_benchmarks.ipynb&quot;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;2048&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/2048/2048.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play 2048&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://github.com/openpipe/art/raw/main/assets/benchmarks/2048/accuracy-training-progress.svg?sanitize=true&quot; height=&quot;72&quot; /&gt; &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/2048/benchmark_2048.ipynb&quot;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Clue&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/temporal_clue/temporal-clue.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 7B learns to solve Temporal Clue&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tic Tac Toe&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/tic_tac_toe/tic-tac-toe.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Tic Tac Toe&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://github.com/openpipe/art/raw/main/assets/benchmarks/tic-tac-toe-local/accuracy-training-progress.svg?sanitize=true&quot; height=&quot;72&quot; /&gt; &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/tic_tac_toe/benchmark_tic_tac_toe.ipynb&quot;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Codenames&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/codenames/Codenames_RL.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Qwen 2.5 3B learns to play Codenames&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://github.com/openpipe/art/raw/main/assets/benchmarks/codenames/win_rate_over_time.png&quot; height=&quot;72&quot; /&gt; &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/examples/codenames/Codenames_RL.ipynb&quot;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AutoRL [RULER]&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://colab.research.google.com/github/openpipe/art/blob/main/examples/auto_rl.ipynb&quot;&gt;üèãÔ∏è Train agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Train Qwen 2.5 7B to master any task&lt;/td&gt; 
   &lt;td&gt;[Link coming soon]&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üì∞ ART News&lt;/h2&gt; 
&lt;p&gt;Explore our latest research and updates on building SOTA agents.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href=&quot;https://x.com/corbtt/status/1953171838382817625&quot;&gt;MCP‚Ä¢RL: Teach Your Model to Master Any MCP Server&lt;/a&gt;&lt;/strong&gt; - Automatically train models to effectively use MCP server tools through reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href=&quot;https://x.com/mattshumer_/status/1950572449025650733&quot;&gt;AutoRL: Zero-Data Training for Any Task&lt;/a&gt;&lt;/strong&gt; - Train custom AI models without labeled data using automatic input generation and RULER evaluation.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href=&quot;https://openpipe.ai/blog/ruler-easy-mode-for-rl-rewards&quot;&gt;RULER: Easy Mode for RL Rewards&lt;/a&gt;&lt;/strong&gt; is now available for automatic reward generation in reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href=&quot;https://openpipe.ai/blog/art-e-mail-agent&quot;&gt;ART¬∑E: How We Built an Email Research Agent That Beats o3&lt;/a&gt;&lt;/strong&gt; demonstrates a Qwen 2.5 14B email agent outperforming OpenAI&#39;s o3.&lt;/li&gt; 
 &lt;li&gt;üóûÔ∏è &lt;strong&gt;&lt;a href=&quot;https://openpipe.ai/blog/art-trainer&quot;&gt;ART Trainer: A New RL Trainer for Agents&lt;/a&gt;&lt;/strong&gt; enables easy training of LLM-based agents using GRPO.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://openpipe.ai/blog&quot;&gt;üìñ See all blog posts ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why ART?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ART provides convenient wrappers for introducing RL training into &lt;strong&gt;existing applications&lt;/strong&gt;. We abstract the training server into a modular service that your code doesn&#39;t need to interface with.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Train from anywhere.&lt;/strong&gt; Run the ART client on your laptop and let the ART server kick off an ephemeral GPU-enabled environment, or run on a local GPU.&lt;/li&gt; 
 &lt;li&gt;Integrations with hosted platforms like W&amp;amp;B, Langfuse, and OpenPipe provide flexible observability and &lt;strong&gt;simplify debugging&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;ART is customizable with &lt;strong&gt;intelligent defaults&lt;/strong&gt;. You can configure training parameters and inference engine configurations to meet specific needs, or take advantage of the defaults, which have been optimized for training efficiency and stability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;ART agents can be trained from any client machine that runs python. To add to an existing project, run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install openpipe-art
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ ART‚Ä¢E Agent&lt;/h2&gt; 
&lt;p&gt;Curious about how to use ART for a real-world task? Check out the &lt;a href=&quot;https://openpipe.ai/blog/art-e-mail-agent&quot;&gt;ART‚Ä¢E Agent&lt;/a&gt; blog post, where we detail how we trained Qwen 2.5 14B to beat o3 at email retrieval!&lt;/p&gt; 
&lt;img src=&quot;https://github.com/openpipe/art/raw/main/assets/ART_E_graphs.png&quot; width=&quot;700&quot; /&gt; 
&lt;h2&gt;üîÅ Training Loop Overview&lt;/h2&gt; 
&lt;p&gt;ART&#39;s functionality is divided into a &lt;strong&gt;client&lt;/strong&gt; and a &lt;strong&gt;server&lt;/strong&gt;. The OpenAI-compatible client is responsible for interfacing between ART and your codebase. Using the client, you can pass messages and get completions from your LLM as it improves. The server runs independently on any machine with a GPU. It abstracts away the complexity of the inference and training portions of the RL loop while allowing for some custom configuration. An outline of the training loop is shown below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;Your code uses the ART client to perform an agentic workflow (usually executing several rollouts in parallel to gather data faster).&lt;/li&gt; 
   &lt;li&gt;Completion requests are routed to the ART server, which runs the model&#39;s latest LoRA in vLLM.&lt;/li&gt; 
   &lt;li&gt;As the agent executes, each &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, and &lt;code&gt;assistant&lt;/code&gt; message is stored in a Trajectory.&lt;/li&gt; 
   &lt;li&gt;When a rollout finishes, your code assigns a &lt;code&gt;reward&lt;/code&gt; to its Trajectory, indicating the performance of the LLM.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;When each rollout has finished, Trajectories are grouped and sent to the server. Inference is blocked while training executes.&lt;/li&gt; 
   &lt;li&gt;The server trains your model using GRPO, initializing from the latest checkpoint (or an empty LoRA on the first iteration).&lt;/li&gt; 
   &lt;li&gt;The server saves the newly trained LoRA to a local directory and loads it into vLLM.&lt;/li&gt; 
   &lt;li&gt;Inference is unblocked and the loop resumes at step 1.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This training loop runs until a specified number of inference and training iterations have completed.&lt;/p&gt; 
&lt;h2&gt;üß© Supported Models&lt;/h2&gt; 
&lt;p&gt;ART should work with most vLLM/HuggingFace-transformers compatible causal language models, or at least the ones supported by &lt;a href=&quot;https://docs.unsloth.ai/get-started/all-our-models&quot;&gt;Unsloth&lt;/a&gt;. Gemma 3 does not appear to be supported for the time being. If any other model isn&#39;t working for you, please let us know on &lt;a href=&quot;https://discord.gg/zbBHRUpwf4&quot;&gt;Discord&lt;/a&gt; or open an issue on &lt;a href=&quot;https://github.com/openpipe/art/issues&quot;&gt;GitHub&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;ART is in active development, and contributions are most welcome! Please see the &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; file for more information.&lt;/p&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@misc{hilton2025art,
  author = {Brad Hilton and Kyle Corbitt and David Corbitt and Saumya Gandhi and Angky William and Bohdan Kovalenskyi and Andie Jones},
  title = {ART: Agent Reinforcement Trainer},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openpipe/art}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;This repository&#39;s source code is available under the &lt;a href=&quot;https://raw.githubusercontent.com/OpenPipe/ART/main/LICENSE&quot;&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üôè Credits&lt;/h2&gt; 
&lt;p&gt;ART stands on the shoulders of giants. While we owe many of the ideas and early experiments that led to ART&#39;s development to the open source RL community at large, we&#39;re especially grateful to the authors of the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;Unsloth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/trl&quot;&gt;trl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pytorch/torchtune&quot;&gt;torchtune&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/skypilot-org/skypilot&quot;&gt;SkyPilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, thank you to our partners who&#39;ve helped us test ART in the wild! We&#39;re excited to see what you all build with it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sgl-project/sglang</title>
      <link>https://github.com/sgl-project/sglang</link>
      <description>&lt;p&gt;SGLang is a fast serving framework for large language models and vision language models.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot; id=&quot;sglangtop&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png&quot; alt=&quot;logo&quot; width=&quot;400&quot; margin=&quot;10px&quot; /&gt; 
 &lt;p&gt;&lt;a href=&quot;https://pypi.org/project/sglang&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/sglang&quot; alt=&quot;PyPI&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;https://static.pepy.tech/badge/sglang?period=month&quot; alt=&quot;PyPI - Downloads&quot; /&gt; &lt;a href=&quot;https://github.com/sgl-project/sglang/tree/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/sgl-project/sglang.svg?sanitize=true&quot; alt=&quot;license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/sgl-project/sglang/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-closed-raw/sgl-project/sglang&quot; alt=&quot;issue resolution&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/sgl-project/sglang/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-raw/sgl-project/sglang&quot; alt=&quot;open issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://deepwiki.com/sgl-project/sglang&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg?sanitize=true&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;| &lt;a href=&quot;https://lmsys.org/blog/2025-05-05-large-scale-ep/&quot;&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://docs.sglang.ai/&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://slack.sglang.ai/&quot;&gt;&lt;strong&gt;Join Slack&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://meeting.sglang.ai/&quot;&gt;&lt;strong&gt;Join Bi-Weekly Development Meeting&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/sgl-project/sglang/issues/7736&quot;&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#slides&quot;&gt;&lt;strong&gt;Slides&lt;/strong&gt;&lt;/a&gt; |&lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/08] üî• SGLang provides day-0 support for OpenAI gpt-oss model (&lt;a href=&quot;https://github.com/sgl-project/sglang/issues/8833&quot;&gt;instructions&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2025/06] üî• SGLang, the high-performance serving infrastructure powering trillions of tokens daily, has been awarded the third batch of the Open Source AI Grant by a16z (&lt;a href=&quot;https://a16z.com/advancing-open-source-ai-through-benchmarks-and-bold-experimentation/&quot;&gt;a16z blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/06] üî• Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part I): 2.7x Higher Decoding Throughput (&lt;a href=&quot;https://lmsys.org/blog/2025-06-16-gb200-part-1/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/05] üî• Deploying DeepSeek with PD Disaggregation and Large-scale Expert Parallelism on 96 H100 GPUs (&lt;a href=&quot;https://lmsys.org/blog/2025-05-05-large-scale-ep/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/03] Supercharge DeepSeek-R1 Inference on AMD Instinct MI300X (&lt;a href=&quot;https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1-Part2/README.html&quot;&gt;AMD blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2025/03] SGLang Joins PyTorch Ecosystem: Efficient LLM Serving Engine (&lt;a href=&quot;https://pytorch.org/blog/sglang-joins-pytorch/&quot;&gt;PyTorch blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2024/12] v0.4 Release: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs (&lt;a href=&quot;https://lmsys.org/blog/2024-12-04-sglang-v0-4/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/02] Unlock DeepSeek-R1 Inference Performance on AMD Instinct‚Ñ¢ MI300X GPU (&lt;a href=&quot;https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1_Perf/README.html&quot;&gt;AMD blog&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;[2025/01] SGLang provides day one support for DeepSeek V3/R1 models on NVIDIA and AMD GPUs with DeepSeek-specific optimizations. (&lt;a href=&quot;https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3&quot;&gt;instructions&lt;/a&gt;, &lt;a href=&quot;https://www.amd.com/en/developer/resources/technical-articles/amd-instinct-gpus-power-deepseek-v3-revolutionizing-ai-development-with-sglang.html&quot;&gt;AMD blog&lt;/a&gt;, &lt;a href=&quot;https://x.com/lmsysorg/status/1887262321636221412&quot;&gt;10+ other companies&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;[2024/10] The First SGLang Online Meetup (&lt;a href=&quot;https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#the-first-sglang-online-meetup&quot;&gt;slides&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/09] v0.3 Release: 7x Faster DeepSeek MLA, 1.5x Faster torch.compile, Multi-Image/Video LLaVA-OneVision (&lt;a href=&quot;https://lmsys.org/blog/2024-09-04-sglang-v0-3/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/07] v0.2 Release: Faster Llama3 Serving with SGLang Runtime (vs. TensorRT-LLM, vLLM) (&lt;a href=&quot;https://lmsys.org/blog/2024-07-25-sglang-llama3/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/02] SGLang enables &lt;strong&gt;3x faster JSON decoding&lt;/strong&gt; with compressed finite state machine (&lt;a href=&quot;https://lmsys.org/blog/2024-02-05-compressed-fsm/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/01] SGLang provides up to &lt;strong&gt;5x faster inference&lt;/strong&gt; with RadixAttention (&lt;a href=&quot;https://lmsys.org/blog/2024-01-17-sglang/&quot;&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/01] SGLang powers the serving of the official &lt;strong&gt;LLaVA v1.6&lt;/strong&gt; release demo (&lt;a href=&quot;https://github.com/haotian-liu/LLaVA?tab=readme-ov-file#demo&quot;&gt;usage&lt;/a&gt;).&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language. The core features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Backend Runtime&lt;/strong&gt;: Provides efficient serving with RadixAttention for prefix caching, zero-overhead CPU scheduler, prefill-decode disaggregation, speculative decoding, continuous batching, paged attention, tensor/pipeline/expert/data parallelism, structured outputs, chunked prefill, quantization (FP4/FP8/INT4/AWQ/GPTQ), and multi-lora batching.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Frontend Language&lt;/strong&gt;: Offers an intuitive interface for programming LLM applications, including chained generation calls, advanced prompting, control flow, multi-modal inputs, parallelism, and external interactions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensive Model Support&lt;/strong&gt;: Supports a wide range of generative models (Llama, Qwen, DeepSeek, Kimi, GPT, Gemma, Mistral, etc.), embedding models (e5-mistral, gte, mcdse) and reward models (Skywork), with easy extensibility for integrating new models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Community&lt;/strong&gt;: SGLang is open-source and backed by an active community with wide industry adoption.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sglang.ai/get_started/install.html&quot;&gt;Install SGLang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sglang.ai/basic_usage/send_request.html&quot;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sglang.ai/basic_usage/openai_api_completions.html&quot;&gt;Backend Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sglang.ai/references/frontend/frontend_tutorial.html&quot;&gt;Frontend Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sglang.ai/developer_guide/contribution_guide.html&quot;&gt;Contribution Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmark and Performance&lt;/h2&gt; 
&lt;p&gt;Learn more in the release blogs: &lt;a href=&quot;https://lmsys.org/blog/2024-07-25-sglang-llama3/&quot;&gt;v0.2 blog&lt;/a&gt;, &lt;a href=&quot;https://lmsys.org/blog/2024-09-04-sglang-v0-3/&quot;&gt;v0.3 blog&lt;/a&gt;, &lt;a href=&quot;https://lmsys.org/blog/2024-12-04-sglang-v0-4/&quot;&gt;v0.4 blog&lt;/a&gt;, &lt;a href=&quot;https://lmsys.org/blog/2025-05-05-large-scale-ep/&quot;&gt;Large-scale expert parallelism&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sgl-project/sglang/issues/7736&quot;&gt;Development Roadmap (2025 H2)&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Adoption and Sponsorship&lt;/h2&gt; 
&lt;p&gt;SGLang has been deployed at large scale, generating trillions of tokens in production each day. It is trusted and adopted by a wide range of leading enterprises and institutions, including xAI, AMD, NVIDIA, Intel, LinkedIn, Cursor, Oracle Cloud, Google Cloud, Microsoft Azure, AWS, Atlas Cloud, Voltage Park, Nebius, DataCrunch, Novita, InnoMatrix, MIT, UCLA, the University of Washington, Stanford, UC Berkeley, Tsinghua University, Jam &amp;amp; Tea Studios, Baseten, and other major technology organizations across North America and Asia. As an open-source LLM inference engine, SGLang has become the de facto industry standard, with deployments running on over 1,000,000 GPUs worldwide.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/sgl-project/sgl-learning-materials/refs/heads/main/slides/adoption.png&quot; alt=&quot;logo&quot; width=&quot;800&quot; margin=&quot;10px&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;For enterprises interested in adopting or deploying SGLang at scale, including technical consulting, sponsorship opportunities, or partnership inquiries, please contact us at &lt;a href=&quot;mailto:contact@sglang.ai&quot;&gt;contact@sglang.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;We learned the design and reused code from the following projects: &lt;a href=&quot;https://github.com/guidance-ai/guidance&quot;&gt;Guidance&lt;/a&gt;, &lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM&lt;/a&gt;, &lt;a href=&quot;https://github.com/ModelTC/lightllm&quot;&gt;LightLLM&lt;/a&gt;, &lt;a href=&quot;https://github.com/flashinfer-ai/flashinfer&quot;&gt;FlashInfer&lt;/a&gt;, &lt;a href=&quot;https://github.com/outlines-dev/outlines&quot;&gt;Outlines&lt;/a&gt;, and &lt;a href=&quot;https://github.com/eth-sri/lmql&quot;&gt;LMQL&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
