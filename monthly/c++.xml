<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub C++ Monthly Trending</title>
    <description>Monthly Trending of C++ in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:51:27 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ocornut/imgui</title>
      <link>https://github.com/ocornut/imgui</link>
      <description>&lt;p&gt;Dear ImGui: Bloat-free Graphical User interface for C++ with minimal dependencies&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dear ImGui&lt;/h1&gt; 
&lt;center&gt;
 &lt;b&gt;&lt;i&gt;&quot;Give someone state and they&#39;ll have a bug one day, but teach them how to represent state in two separate locations that have to be kept in sync and they&#39;ll have bugs for a lifetime.&quot;&lt;/i&gt;&lt;/b&gt;
&lt;/center&gt; 
&lt;a href=&quot;https://twitter.com/rygorous/status/1507178315886444544&quot;&gt;-ryg&lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/actions?workflow=build&quot;&gt;&lt;img src=&quot;https://github.com/ocornut/imgui/workflows/build/badge.svg?sanitize=true&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ocornut/imgui/actions?workflow=static-analysis&quot;&gt;&lt;img src=&quot;https://github.com/ocornut/imgui/workflows/static-analysis/badge.svg?sanitize=true&quot; alt=&quot;Static Analysis Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ocornut/imgui_test_engine/actions?workflow=tests&quot;&gt;&lt;img src=&quot;https://github.com/ocornut/imgui_test_engine/workflows/tests/badge.svg?sanitize=true&quot; alt=&quot;Tests Status&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;sub&gt;(This library is available under a free and permissive license, but needs financial support to sustain its continued improvements. In addition to maintenance and stability there are many desirable features yet to be added. If your company is using Dear ImGui, please consider reaching out.)&lt;/sub&gt;&lt;/p&gt; 
&lt;p&gt;Businesses: support continued development and maintenance via invoiced sponsoring/support contracts: &lt;br /&gt;&amp;nbsp;&amp;nbsp;&lt;em&gt;E-mail: contact @ dearimgui dot com&lt;/em&gt; &lt;br /&gt;Individuals: support continued development and maintenance &lt;a href=&quot;https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=WGHNC6MBFLZ2S&quot;&gt;here&lt;/a&gt;. Also see &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Funding&quot;&gt;Funding&lt;/a&gt; page.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#the-pitch&quot;&gt;The Pitch&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#usage&quot;&gt;Usage&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#how-it-works&quot;&gt;How it works&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#releases--changelogs&quot;&gt;Releases &amp;amp; Changelogs&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#demo&quot;&gt;Demo&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#getting-started--integration&quot;&gt;Getting Started &amp;amp; Integration&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#gallery&quot;&gt;Gallery&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#support-frequently-asked-questions-faq&quot;&gt;Support, FAQ&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#how-to-help&quot;&gt;How to help&lt;/a&gt; - &lt;strong&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Funding&quot;&gt;Funding &amp;amp; Sponsors&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#credits&quot;&gt;Credits&lt;/a&gt; - &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#license&quot;&gt;License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/wiki&quot;&gt;Wiki&lt;/a&gt; - &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Useful-Extensions&quot;&gt;Extensions&lt;/a&gt; - &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Bindings&quot;&gt;Language bindings &amp;amp; framework backends&lt;/a&gt; - &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui&quot;&gt;Software using Dear ImGui&lt;/a&gt; - &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Quotes&quot;&gt;User quotes&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;The Pitch&lt;/h3&gt; 
&lt;p&gt;Dear ImGui is a &lt;strong&gt;bloat-free graphical user interface library for C++&lt;/strong&gt;. It outputs optimized vertex buffers that you can render anytime in your 3D-pipeline-enabled application. It is fast, portable, renderer agnostic, and self-contained (no external dependencies).&lt;/p&gt; 
&lt;p&gt;Dear ImGui is designed to &lt;strong&gt;enable fast iterations&lt;/strong&gt; and to &lt;strong&gt;empower programmers&lt;/strong&gt; to create &lt;strong&gt;content creation tools and visualization / debug tools&lt;/strong&gt; (as opposed to UI for the average end-user). It favors simplicity and productivity toward this goal and lacks certain features commonly found in more high-level libraries. Among other things, full internationalization (right-to-left text, bidirectional text, text shaping etc.) and accessibility features are not supported.&lt;/p&gt; 
&lt;p&gt;Dear ImGui is particularly suited to integration in game engines (for tooling), real-time 3D applications, fullscreen applications, embedded applications, or any applications on console platforms where operating system features are non-standard.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimize state synchronization.&lt;/li&gt; 
 &lt;li&gt;Minimize UI-related state storage on user side.&lt;/li&gt; 
 &lt;li&gt;Minimize setup and maintenance.&lt;/li&gt; 
 &lt;li&gt;Easy to use to create dynamic UI which are the reflection of a dynamic data set.&lt;/li&gt; 
 &lt;li&gt;Easy to use to create code-driven and data-driven tools.&lt;/li&gt; 
 &lt;li&gt;Easy to use to create ad hoc short-lived tools and long-lived, more elaborate tools.&lt;/li&gt; 
 &lt;li&gt;Easy to hack and improve.&lt;/li&gt; 
 &lt;li&gt;Portable, minimize dependencies, run on target (consoles, phones, etc.).&lt;/li&gt; 
 &lt;li&gt;Efficient runtime and memory consumption.&lt;/li&gt; 
 &lt;li&gt;Battle-tested, used by &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui&quot;&gt;many major actors in the game industry&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The core of Dear ImGui is self-contained within a few platform-agnostic files&lt;/strong&gt; which you can easily compile in your application/engine. They are all the files in the root folder of the repository (imgui*.cpp, imgui*.h). &lt;strong&gt;No specific build process is required&lt;/strong&gt;. You can add the .cpp files into your existing project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Backends for a variety of graphics API and rendering platforms&lt;/strong&gt; are provided in the &lt;a href=&quot;https://github.com/ocornut/imgui/tree/master/backends&quot;&gt;backends/&lt;/a&gt; folder, along with example applications in the &lt;a href=&quot;https://github.com/ocornut/imgui/tree/master/examples&quot;&gt;examples/&lt;/a&gt; folder. You may also create your own backend. Anywhere where you can render textured triangles, you can render Dear ImGui.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/ocornut/imgui/master/#getting-started--integration&quot;&gt;Getting Started &amp;amp; Integration&lt;/a&gt; section of this document for more details.&lt;/p&gt; 
&lt;p&gt;After Dear ImGui is set up in your application, you can use it from _anywhere_ in your program loop:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;ImGui::Text(&quot;Hello, world %d&quot;, 123);
if (ImGui::Button(&quot;Save&quot;))
    MySaveFunction();
ImGui::InputText(&quot;string&quot;, buf, IM_ARRAYSIZE(buf));
ImGui::SliderFloat(&quot;float&quot;, &amp;amp;f, 0.0f, 1.0f);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/191050833-b7ecf528-bfae-4a9f-ac1b-f3d83437a2f4.png&quot; alt=&quot;sample code output (dark, segoeui font, freetype)&quot; /&gt; &lt;img src=&quot;https://user-images.githubusercontent.com/8225057/191050838-8742efd4-504d-4334-a9a2-e756d15bc2ab.png&quot; alt=&quot;sample code output (light, segoeui font, freetype)&quot; /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;// Create a window called &quot;My First Tool&quot;, with a menu bar.
ImGui::Begin(&quot;My First Tool&quot;, &amp;amp;my_tool_active, ImGuiWindowFlags_MenuBar);
if (ImGui::BeginMenuBar())
{
    if (ImGui::BeginMenu(&quot;File&quot;))
    {
        if (ImGui::MenuItem(&quot;Open..&quot;, &quot;Ctrl+O&quot;)) { /* Do stuff */ }
        if (ImGui::MenuItem(&quot;Save&quot;, &quot;Ctrl+S&quot;))   { /* Do stuff */ }
        if (ImGui::MenuItem(&quot;Close&quot;, &quot;Ctrl+W&quot;))  { my_tool_active = false; }
        ImGui::EndMenu();
    }
    ImGui::EndMenuBar();
}

// Edit a color stored as 4 floats
ImGui::ColorEdit4(&quot;Color&quot;, my_color);

// Generate samples and plot them
float samples[100];
for (int n = 0; n &amp;lt; 100; n++)
    samples[n] = sinf(n * 0.2f + ImGui::GetTime() * 1.5f);
ImGui::PlotLines(&quot;Samples&quot;, samples, 100);

// Display contents in a scrolling region
ImGui::TextColored(ImVec4(1,1,0,1), &quot;Important Stuff&quot;);
ImGui::BeginChild(&quot;Scrolling&quot;);
for (int n = 0; n &amp;lt; 50; n++)
    ImGui::Text(&quot;%04d: Some text&quot;, n);
ImGui::EndChild();
ImGui::End();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/191055698-690a5651-458f-4856-b5a9-e8cc95c543e2.gif&quot; alt=&quot;my_first_tool_v188&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Dear ImGui allows you to &lt;strong&gt;create elaborate tools&lt;/strong&gt; as well as very short-lived ones. On the extreme side of short-livedness: using the Edit&amp;amp;Continue (hot code reload) feature of modern compilers you can add a few widgets to tweak variables while your application is running, and remove the code a minute later! Dear ImGui is not just for tweaking values. You can use it to trace a running algorithm by just emitting text commands. You can use it along with your own reflection data to browse your dataset live. You can use it to expose the internals of a subsystem in your engine, to create a logger, an inspection tool, a profiler, a debugger, an entire game-making editor/framework, etc.&lt;/p&gt; 
&lt;h3&gt;How it works&lt;/h3&gt; 
&lt;p&gt;The IMGUI paradigm through its API tries to minimize superfluous state duplication, state synchronization, and state retention from the user&#39;s point of view. It is less error-prone (less code and fewer bugs) than traditional retained-mode interfaces, and lends itself to creating dynamic user interfaces. Check out the Wiki&#39;s &lt;a href=&quot;https://github.com/ocornut/imgui/wiki#about-the-imgui-paradigm&quot;&gt;About the IMGUI paradigm&lt;/a&gt; section for more details.&lt;/p&gt; 
&lt;p&gt;Dear ImGui outputs vertex buffers and command lists that you can easily render in your application. The number of draw calls and state changes required to render them is fairly small. Because Dear ImGui doesn&#39;t know or touch graphics state directly, you can call its functions anywhere in your code (e.g. in the middle of a running algorithm, or in the middle of your own rendering process). Refer to the sample applications in the examples/ folder for instructions on how to integrate Dear ImGui with your existing codebase.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;A common misunderstanding is to mistake immediate mode GUI for immediate mode rendering, which usually implies hammering your driver/GPU with a bunch of inefficient draw calls and state changes as the GUI functions are called. This is NOT what Dear ImGui does. Dear ImGui outputs vertex buffers and a small list of draw calls batches. It never touches your GPU directly. The draw call batches are decently optimal and you can render them later, in your app or even remotely.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Releases &amp;amp; Changelogs&lt;/h3&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/ocornut/imgui/releases&quot;&gt;Releases&lt;/a&gt; page for decorated Changelogs. Reading the changelogs is a good way to keep up to date with the things Dear ImGui has to offer, and maybe will give you ideas of some features that you&#39;ve been ignoring until now!&lt;/p&gt; 
&lt;h3&gt;Demo&lt;/h3&gt; 
&lt;p&gt;Calling the &lt;code&gt;ImGui::ShowDemoWindow()&lt;/code&gt; function will create a demo window showcasing a variety of features and examples. The code is always available for reference in &lt;code&gt;imgui_demo.cpp&lt;/code&gt;. &lt;a href=&quot;https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v167/v167-misc.png&quot;&gt;Here&#39;s how the demo looks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You should be able to build the examples from sources. If you don&#39;t, let us know! If you want to have a quick look at some Dear ImGui features, you can download Windows binaries of the demo app here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.dearimgui.com/binaries/imgui-demo-binaries-20250625.zip&quot;&gt;imgui-demo-binaries-20250625.zip&lt;/a&gt; (Windows, 1.92.0, built 2025/06/25, master) or &lt;a href=&quot;https://www.dearimgui.com/binaries&quot;&gt;older binaries&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The demo applications are not DPI aware so expect some blurriness on a 4K screen. For DPI awareness in your application, you can load/reload your font at a different scale and scale your style with &lt;code&gt;style.ScaleAllSizes()&lt;/code&gt; (see &lt;a href=&quot;https://www.dearimgui.com/faq&quot;&gt;FAQ&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Getting Started &amp;amp; Integration&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; guide for details.&lt;/p&gt; 
&lt;p&gt;On most platforms and when using C++, &lt;strong&gt;you should be able to use a combination of the &lt;a href=&quot;https://github.com/ocornut/imgui/tree/master/backends&quot;&gt;imgui_impl_xxxx&lt;/a&gt; backends without modification&lt;/strong&gt; (e.g. &lt;code&gt;imgui_impl_win32.cpp&lt;/code&gt; + &lt;code&gt;imgui_impl_dx11.cpp&lt;/code&gt;). If your engine supports multiple platforms, consider using more imgui_impl_xxxx files instead of rewriting them: this will be less work for you, and you can get Dear ImGui running immediately. You can &lt;em&gt;later&lt;/em&gt; decide to rewrite a custom backend using your custom engine functions if you wish so.&lt;/p&gt; 
&lt;p&gt;Integrating Dear ImGui within your custom engine is a matter of 1) wiring mouse/keyboard/gamepad inputs 2) uploading a texture to your GPU/render engine 3) providing a render function that can bind textures and render textured triangles, which is essentially what Backends are doing. The &lt;a href=&quot;https://github.com/ocornut/imgui/tree/master/examples&quot;&gt;examples/&lt;/a&gt; folder is populated with applications doing just that: setting up a window and using backends. If you follow the &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; guide it should in theory take you less than an hour to integrate Dear ImGui. &lt;strong&gt;Make sure to spend time reading the &lt;a href=&quot;https://www.dearimgui.com/faq&quot;&gt;FAQ&lt;/a&gt;, comments, and the examples applications!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Officially maintained backends/bindings (in repository):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Renderers: DirectX9, DirectX10, DirectX11, DirectX12, Metal, OpenGL/ES/ES2, SDL_GPU, SDL_Renderer2/3, Vulkan, WebGPU.&lt;/li&gt; 
 &lt;li&gt;Platforms: GLFW, SDL2/SDL3, Win32, Glut, OSX, Android.&lt;/li&gt; 
 &lt;li&gt;Frameworks: Allegro5, Emscripten.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Bindings&quot;&gt;Third-party backends/bindings&lt;/a&gt; wiki page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Languages: C, C# and: Beef, ChaiScript, CovScript, Crystal, D, Go, Haskell, Haxe/hxcpp, Java, JavaScript, Julia, Kotlin, Lobster, Lua, Nim, Odin, Pascal, PureBasic, Python, ReaScript, Ruby, Rust, Swift, Zig...&lt;/li&gt; 
 &lt;li&gt;Frameworks: AGS/Adventure Game Studio, Amethyst, Blender, bsf, Cinder, Cocos2d-x, Defold, Diligent Engine, Ebiten, Flexium, GML/Game Maker Studio, GLEQ, Godot, GTK3, Irrlicht Engine, JUCE, LÖVE+LUA, Mach Engine, Magnum, Marmalade, Monogame, NanoRT, nCine, Nim Game Lib, Nintendo 3DS/Switch/WiiU (homebrew), Ogre, openFrameworks, OSG/OpenSceneGraph, Orx, Photoshop, px_render, Qt/QtDirect3D, raylib, SFML, Sokol, Unity, Unreal Engine 4/5, UWP, vtk, VulkanHpp, VulkanSceneGraph, Win32 GDI, WxWidgets.&lt;/li&gt; 
 &lt;li&gt;Many bindings are auto-generated (by good old &lt;a href=&quot;https://github.com/cimgui/cimgui&quot;&gt;cimgui&lt;/a&gt; or newer/experimental &lt;a href=&quot;https://github.com/dearimgui/dear_bindings&quot;&gt;dear_bindings&lt;/a&gt;), you can use their metadata output to generate bindings for other languages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Useful-Extensions&quot;&gt;Useful Extensions/Widgets&lt;/a&gt; wiki page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automation/testing, Text editors, node editors, timeline editors, plotting, software renderers, remote network access, memory editors, gizmos, etc. Notable and well supported extensions include &lt;a href=&quot;https://github.com/epezent/implot&quot;&gt;ImPlot&lt;/a&gt; and &lt;a href=&quot;https://github.com/ocornut/imgui_test_engine&quot;&gt;Dear ImGui Test Engine&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also see &lt;a href=&quot;https://github.com/ocornut/imgui/wiki&quot;&gt;Wiki&lt;/a&gt; for more links and ideas.&lt;/p&gt; 
&lt;h3&gt;Gallery&lt;/h3&gt; 
&lt;p&gt;Examples projects using Dear ImGui: &lt;a href=&quot;https://github.com/wolfpld/tracy&quot;&gt;Tracy&lt;/a&gt; (profiler), &lt;a href=&quot;https://github.com/WerWolv/ImHex&quot;&gt;ImHex&lt;/a&gt; (hex editor/data analysis), &lt;a href=&quot;https://remedybg.itch.io/remedybg&quot;&gt;RemedyBG&lt;/a&gt; (debugger) and &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Software-using-Dear-ImGui&quot;&gt;hundreds of others&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more user-submitted screenshots of projects using Dear ImGui, check out the &lt;a href=&quot;https://github.com/ocornut/imgui/issues?q=label%3Agallery&quot;&gt;Gallery Threads&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;For a list of third-party widgets and extensions, check out the &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Useful-Extensions&quot;&gt;Useful Extensions/Widgets&lt;/a&gt; wiki page.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Custom engine &lt;a href=&quot;https://github.com/tksuoran/erhe&quot;&gt;erhe&lt;/a&gt; (docking branch)&lt;br /&gt;&lt;a href=&quot;https://user-images.githubusercontent.com/994606/147875067-a848991e-2ad2-4fd3-bf71-4aeb8a547bcf.png&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/190203358-6988b846-0686-480e-8663-1311fbd18abd.jpg&quot; alt=&quot;erhe&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Custom engine for &lt;a href=&quot;http://www.TheDragonsTrap.com&quot;&gt;Wonder Boy: The Dragon&#39;s Trap&lt;/a&gt; (2017)&lt;br /&gt;&lt;a href=&quot;https://cloud.githubusercontent.com/assets/8225057/20628927/33e14cac-b329-11e6-80f6-9524e93b048a.png&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/190203379-57fcb80e-4aec-4fec-959e-17ddd3cd71e5.jpg&quot; alt=&quot;the dragon&#39;s trap&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Custom engine (untitled)&lt;br /&gt;&lt;a href=&quot;https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v160/editor_white.png&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/190203393-c5ac9f22-b900-4d1e-bfeb-6027c63e3d92.jpg&quot; alt=&quot;editor white&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Tracy Profiler (&lt;a href=&quot;https://github.com/wolfpld/tracy&quot;&gt;github&lt;/a&gt;)&lt;br /&gt;&lt;a href=&quot;https://raw.githubusercontent.com/wiki/ocornut/imgui/web/v176/tracy_profiler.png&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/8225057/190203401-7b595f6e-607c-44d3-97ea-4c2673244dfb.jpg&quot; alt=&quot;tracy profiler&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Support, Frequently Asked Questions (FAQ)&lt;/h3&gt; 
&lt;p&gt;See: &lt;a href=&quot;https://github.com/ocornut/imgui/raw/master/docs/FAQ.md&quot;&gt;Frequently Asked Questions (FAQ)&lt;/a&gt; where common questions are answered.&lt;/p&gt; 
&lt;p&gt;See: &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; and &lt;a href=&quot;https://github.com/ocornut/imgui/wiki&quot;&gt;Wiki&lt;/a&gt; for many links, references, articles.&lt;/p&gt; 
&lt;p&gt;See: &lt;a href=&quot;https://github.com/ocornut/imgui/wiki#about-the-imgui-paradigm&quot;&gt;Articles about the IMGUI paradigm&lt;/a&gt; to read/learn about the Immediate Mode GUI paradigm.&lt;/p&gt; 
&lt;p&gt;See: &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Upcoming-Changes&quot;&gt;Upcoming Changes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See: &lt;a href=&quot;https://github.com/ocornut/imgui_test_engine&quot;&gt;Dear ImGui Test Engine + Test Suite&lt;/a&gt; for Automation &amp;amp; Testing.&lt;/p&gt; 
&lt;p&gt;For the purposes of getting search engines to crawl the wiki, here&#39;s a link to the &lt;a href=&quot;https://github-wiki-see.page/m/ocornut/imgui/wiki&quot;&gt;Crawlable Wiki&lt;/a&gt; (not for humans, &lt;a href=&quot;https://github-wiki-see.page/&quot;&gt;here&#39;s why&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Getting started? For first-time users having issues compiling/linking/running or issues loading fonts, please use &lt;a href=&quot;https://github.com/ocornut/imgui/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;. For ANY other questions, bug reports, requests, feedback, please post on &lt;a href=&quot;https://github.com/ocornut/imgui/issues&quot;&gt;GitHub Issues&lt;/a&gt;. Please read and fill the New Issue template carefully.&lt;/p&gt; 
&lt;p&gt;Private support is available for paying business customers (E-mail: &lt;em&gt;contact @ dearimgui dot com&lt;/em&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Which version should I get?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We occasionally tag &lt;a href=&quot;https://github.com/ocornut/imgui/releases&quot;&gt;Releases&lt;/a&gt; (with nice releases notes) but it is generally safe and recommended to sync to latest &lt;code&gt;master&lt;/code&gt; or &lt;code&gt;docking&lt;/code&gt; branch. The library is fairly stable and regressions tend to be fixed fast when reported. Advanced users may want to use the &lt;code&gt;docking&lt;/code&gt; branch with &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Multi-Viewports&quot;&gt;Multi-Viewport&lt;/a&gt; and &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Docking&quot;&gt;Docking&lt;/a&gt; features. This branch is kept in sync with master regularly.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Who uses Dear ImGui?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Quotes&quot;&gt;Quotes&lt;/a&gt;, &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Funding&quot;&gt;Funding &amp;amp; Sponsors&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Software-using-dear-imgui&quot;&gt;Software using Dear ImGui&lt;/a&gt; Wiki pages for an idea of who is using Dear ImGui. Please add your game/software if you can! Also, see the &lt;a href=&quot;https://github.com/ocornut/imgui/issues?q=label%3Agallery&quot;&gt;Gallery Threads&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;How to help&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;How can I help?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://github.com/ocornut/imgui/issues&quot;&gt;GitHub Forum/Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;You may help with development and submit pull requests! Please understand that by submitting a PR you are also submitting a request for the maintainer to review your code and then take over its maintenance forever. PR should be crafted both in the interest of the end-users and also to ease the maintainer into understanding and accepting it.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Help-Wanted&quot;&gt;Help wanted&lt;/a&gt; on the &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/&quot;&gt;Wiki&lt;/a&gt; for some more ideas.&lt;/li&gt; 
 &lt;li&gt;Be a &lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Funding&quot;&gt;Funding Supporter&lt;/a&gt;! Have your company financially support this project via invoiced sponsors/maintenance or by buying a license for &lt;a href=&quot;https://github.com/ocornut/imgui_test_engine&quot;&gt;Dear ImGui Test Engine&lt;/a&gt; (please reach out: contact AT dearimgui DOT com).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Ongoing Dear ImGui development is and has been financially supported by users and private sponsors. &lt;br /&gt;Please see the &lt;strong&gt;&lt;a href=&quot;https://github.com/ocornut/imgui/wiki/Funding&quot;&gt;detailed list of current and past Dear ImGui funding supporters and sponsors&lt;/a&gt;&lt;/strong&gt; for details. &lt;br /&gt;From November 2014 to December 2019, ongoing development has also been financially supported by its users on Patreon and through individual donations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;THANK YOU to all past and present supporters for helping to keep this project alive and thriving!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Dear ImGui is using software and services provided free of charge for open source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pvs-studio.com/en/pvs-studio/?utm_source=website&amp;amp;utm_medium=github&amp;amp;utm_campaign=open_source&quot;&gt;PVS-Studio&lt;/a&gt; for static analysis (supports C/C++/C#/Java).&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/features/actions&quot;&gt;GitHub actions&lt;/a&gt; for continuous integration systems.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenCppCoverage/OpenCppCoverage&quot;&gt;OpenCppCoverage&lt;/a&gt; for code coverage analysis.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Developed by &lt;a href=&quot;https://www.miracleworld.net&quot;&gt;Omar Cornut&lt;/a&gt; and every direct or indirect &lt;a href=&quot;https://github.com/ocornut/imgui/graphs/contributors&quot;&gt;contributors&lt;/a&gt; to the GitHub. The early version of this library was developed with the support of &lt;a href=&quot;https://www.mediamolecule.com&quot;&gt;Media Molecule&lt;/a&gt; and first used internally on the game &lt;a href=&quot;https://tearaway.mediamolecule.com&quot;&gt;Tearaway&lt;/a&gt; (PS Vita).&lt;/p&gt; 
&lt;p&gt;Recurring contributors include Rokas Kupstys &lt;a href=&quot;https://github.com/rokups&quot;&gt;@rokups&lt;/a&gt; (2020-2022): a good portion of work on automation system and regression tests now available in &lt;a href=&quot;https://github.com/ocornut/imgui_test_engine&quot;&gt;Dear ImGui Test Engine&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Maintenance/support contracts, sponsoring invoices and other B2B transactions are hosted and handled by &lt;a href=&quot;https://www.discohello.com&quot;&gt;Disco Hello&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Omar: &quot;I first discovered the IMGUI paradigm at &lt;a href=&quot;https://www.q-games.com&quot;&gt;Q-Games&lt;/a&gt; where Atman Binstock had dropped his own simple implementation in the codebase, which I spent quite some time improving and thinking about. It turned out that Atman was exposed to the concept directly by working with Casey. When I moved to Media Molecule I rewrote a new library trying to overcome the flaws and limitations of the first one I&#39;ve worked with. It became this library and since then I have spent an unreasonable amount of time iterating and improving it.&quot;&lt;/p&gt; 
&lt;p&gt;Embeds &lt;a href=&quot;https://www.proggyfonts.net&quot;&gt;ProggyClean.ttf&lt;/a&gt; font by Tristan Grimmer (MIT license). &lt;br /&gt;Embeds &lt;a href=&quot;https://github.com/nothings/stb/&quot;&gt;stb_textedit.h, stb_truetype.h, stb_rect_pack.h&lt;/a&gt; by Sean Barrett (public domain).&lt;/p&gt; 
&lt;p&gt;Inspiration, feedback, and testing for early versions: Casey Muratori, Atman Binstock, Mikko Mononen, Emmanuel Briney, Stefan Kamoda, Anton Mikhailov, Matt Willis. Special thanks to Alex Evans, Patrick Doane, Marco Koegler for kindly helping. Also thank you to everyone posting feedback, questions and patches on GitHub.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Dear ImGui is licensed under the MIT License, see &lt;a href=&quot;https://github.com/ocornut/imgui/raw/master/LICENSE.txt&quot;&gt;LICENSE.txt&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>meshtastic/firmware</title>
      <link>https://github.com/meshtastic/firmware</link>
      <description>&lt;p&gt;The official firmware for Meshtastic, an open-source, off-grid mesh communication system.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/meshtastic/firmware/master/.github/meshtastic_logo.png&quot; alt=&quot;Meshtastic Logo&quot; width=&quot;80&quot; /&gt; 
 &lt;h1&gt;Meshtastic Firmware&lt;/h1&gt; 
 &lt;p&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/meshtastic/firmware/total&quot; alt=&quot;GitHub release downloads&quot; /&gt; &lt;a href=&quot;https://github.com/meshtastic/firmware/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/meshtastic/firmware/main_matrix.yml?branch=master&amp;amp;label=actions&amp;amp;logo=github&amp;amp;color=yellow&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://cla-assistant.io/meshtastic/firmware&quot;&gt;&lt;img src=&quot;https://cla-assistant.io/readme/badge/meshtastic/firmware&quot; alt=&quot;CLA assistant&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/meshtastic/&quot;&gt;&lt;img src=&quot;https://opencollective.com/meshtastic/tiers/badge.svg?label=Fiscal%20Contributors&amp;amp;color=deeppink&quot; alt=&quot;Fiscal Contributors&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://vercel.com?utm_source=meshtastic&amp;amp;utm_campaign=oss&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Powered%20by&amp;amp;message=Vercel&amp;amp;style=flat&amp;amp;logo=vercel&amp;amp;color=000000&quot; alt=&quot;Vercel&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://trendshift.io/repositories/5524&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5524&quot; alt=&quot;meshtastic%2Ffirmware | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;  
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://meshtastic.org&quot;&gt;Website&lt;/a&gt; - 
 &lt;a href=&quot;https://meshtastic.org/docs/&quot;&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the official device firmware for Meshtastic, an open-source LoRa mesh networking project designed for long-range, low-power communication without relying on internet or cellular infrastructure. The firmware supports various hardware platforms, including ESP32, nRF52, RP2040/RP2350, and Linux-based devices.&lt;/p&gt; 
&lt;p&gt;Meshtastic enables text messaging, location sharing, and telemetry over a decentralized mesh network, making it ideal for outdoor adventures, emergency preparedness, and remote operations.&lt;/p&gt; 
&lt;h3&gt;Get Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;&lt;a href=&quot;https://meshtastic.org/docs/development/firmware/build&quot;&gt;Building Instructions&lt;/a&gt;&lt;/strong&gt; – Learn how to compile the firmware from source.&lt;/li&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;&lt;a href=&quot;https://meshtastic.org/docs/getting-started/flashing-firmware/&quot;&gt;Flashing Instructions&lt;/a&gt;&lt;/strong&gt; – Install or update the firmware on your device.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join our community and help improve Meshtastic! 🚀&lt;/p&gt; 
&lt;h2&gt;Stats&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://repobeats.axiom.co/api/embed/8025e56c482ec63541593cc5bd322c19d5c0bdcf.svg?sanitize=true&quot; alt=&quot;Alt&quot; title=&quot;Repobeats analytics image&quot; /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WasmEdge/WasmEdge</title>
      <link>https://github.com/WasmEdge/WasmEdge</link>
      <description>&lt;p&gt;WasmEdge is a lightweight, high-performance, and extensible WebAssembly runtime for cloud native, edge, and decentralized applications. It powers serverless apps, embedded functions, microservices, smart contracts, and IoT devices.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;right&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/README-zh.md&quot;&gt;中文&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/README-zh-TW.md&quot;&gt;正體中文&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/README-ja.md&quot;&gt;日本語で読む&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/docs/wasmedge-runtime-logo.png&quot; alt=&quot;WasmEdge Logo&quot; /&gt;&lt;/p&gt; 
 &lt;h1&gt;&lt;a href=&quot;https://llamaedge.com/docs/user-guide/llm/get-started-with-llamaedge&quot;&gt;🤩 WasmEdge is the easiest and fastest way to run LLMs on your own devices. 🤩&lt;/a&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;a href=&quot;https://trendshift.io/repositories/2481&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/2481&quot; alt=&quot;WasmEdge%2FWasmEdge | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;WasmEdge is a lightweight, high-performance, and extensible WebAssembly runtime. It is &lt;a href=&quot;https://ieeexplore.ieee.org/document/9214403&quot;&gt;the fastest Wasm VM&lt;/a&gt;. WasmEdge is an official sandbox project hosted by the &lt;a href=&quot;https://www.cncf.io/&quot;&gt;CNCF&lt;/a&gt;. &lt;a href=&quot;https://github.com/LlamaEdge/LlamaEdge&quot;&gt;LlamaEdge&lt;/a&gt; is an application framework built on top of WasmEdge to run GenAI models (e.g., &lt;a href=&quot;https://llamaedge.com/docs/user-guide/llm/get-started-with-llamaedge&quot;&gt;LLM&lt;/a&gt;, &lt;a href=&quot;https://llamaedge.com/docs/user-guide/speech-to-text/quick-start-whisper&quot;&gt;speech-to-text&lt;/a&gt;, &lt;a href=&quot;https://llamaedge.com/docs/user-guide/text-to-image/quick-start-sd&quot;&gt;text-to-image&lt;/a&gt;, and &lt;a href=&quot;https://github.com/LlamaEdge/whisper-api-server&quot;&gt;TTS&lt;/a&gt;) across GPUs on servers, personal computers, and edge devices. Additional &lt;a href=&quot;https://wasmedge.org/docs/start/usage/use-cases/&quot;&gt;use cases&lt;/a&gt; include microservices on the edge cloud, serverless SaaS APIs, embedded functions, smart contracts, and smart devices.&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/WasmEdge/WasmEdge/actions/workflows/build.yml?query=event%3Apush++branch%3Amaster&quot;&gt;&lt;img src=&quot;https://github.com/WasmEdge/WasmEdge/actions/workflows/build.yml/badge.svg?sanitize=true&quot; alt=&quot;build&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/WasmEdge/WasmEdge&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/WasmEdge/WasmEdge/branch/master/graph/badge.svg?sanitize=true&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/WasmEdge/WasmEdge/actions/workflows/codeql-analysis.yml?query=event%3Apush++branch%3Amaster&quot;&gt;&lt;img src=&quot;https://github.com/WasmEdge/WasmEdge/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true&quot; alt=&quot;CodeQL&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://app.fossa.com/projects/git%2Bgithub.com%2FWasmEdge%2FWasmEdge?ref=badge_shield&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/git%2Bgithub.com%2FWasmEdge%2FWasmEdge.svg?type=shield&quot; alt=&quot;FOSSA Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/5059&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/5059/badge&quot; alt=&quot;CII Best Practices&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Quick start guides&lt;/h1&gt; 
&lt;p&gt;🚀 &lt;a href=&quot;https://wasmedge.org/docs/start/install&quot;&gt;Install&lt;/a&gt; WasmEdge &lt;br /&gt; 👷🏻‍♂️ &lt;a href=&quot;https://wasmedge.org/docs/category/build-wasmedge-from-source&quot;&gt;Build&lt;/a&gt; and &lt;a href=&quot;https://wasmedge.org/docs/contribute/&quot;&gt;contribute to&lt;/a&gt; WasmEdge &lt;br /&gt; ⌨️ &lt;a href=&quot;https://wasmedge.org/docs/category/running-with-wasmedge&quot;&gt;Run&lt;/a&gt; a standalone Wasm program or a &lt;a href=&quot;https://wasmedge.org/docs/category/develop-wasm-apps-in-javascript&quot;&gt;JavaScript program&lt;/a&gt; from CLI or &lt;a href=&quot;https://wasmedge.org/docs/start/getting-started/quick_start_docker&quot;&gt;Docker&lt;/a&gt; &lt;br /&gt; 🤖 &lt;a href=&quot;https://llamaedge.com/docs/user-guide/llm/get-started-with-llamaedge&quot;&gt;Chat&lt;/a&gt; with an open source LLM via &lt;a href=&quot;https://github.com/LlamaEdge/LlamaEdge&quot;&gt;LlamaEdge&lt;/a&gt; &lt;br /&gt; 🔌 Embed a Wasm function in your &lt;a href=&quot;https://wasmedge.org/docs/category/go-sdk-for-embedding-wasmedge&quot;&gt;Go&lt;/a&gt;, &lt;a href=&quot;https://wasmedge.org/docs/category/rust-sdk-for-embedding-wasmedge&quot;&gt;Rust&lt;/a&gt;, or &lt;a href=&quot;https://wasmedge.org/docs/category/c-sdk-for-embedding-wasmedge&quot;&gt;C&lt;/a&gt; app &lt;br /&gt; 🛠 Manage and orchestrate Wasm runtimes using &lt;a href=&quot;https://wasmedge.org/docs/category/deploy-wasmedge-apps-in-kubernetes&quot;&gt;Kubernetes&lt;/a&gt;, &lt;a href=&quot;https://wasmedge.org/docs/embed/use-case/yomo&quot;&gt;data streaming frameworks&lt;/a&gt;, and &lt;a href=&quot;https://medium.com/ethereum-on-steroids/running-ethereum-smart-contracts-in-a-substrate-blockchain-56fbc27fc95a&quot;&gt;blockchains&lt;/a&gt; &lt;br /&gt; 📚 &lt;strong&gt;&lt;a href=&quot;https://wasmedge.org/docs/&quot;&gt;Check out our official documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;The WasmEdge Runtime provides a well-defined execution sandbox for its contained WebAssembly bytecode program. The runtime offers isolation and protection for operating system resources (e.g., file system, sockets, environment variables, processes) and memory space. The most important use case for WasmEdge is to safely execute user-defined or community-contributed code as plug-ins in a software product (e.g., SaaS, software-defined vehicles, edge nodes, or even blockchain nodes). It enables third-party developers, vendors, suppliers, and community members to extend and customize the software product. &lt;strong&gt;&lt;a href=&quot;https://wasmedge.org/docs/contribute/users&quot;&gt;Learn more here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2010.07115&quot;&gt;A Lightweight Design for High-performance Serverless Computing&lt;/a&gt;, published on IEEE Software, Jan 2021. &lt;a href=&quot;https://arxiv.org/abs/2010.07115&quot;&gt;https://arxiv.org/abs/2010.07115&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/articles/arm-vs-x86-cloud-performance/&quot;&gt;Performance Analysis for Arm vs. x86 CPUs in the Cloud&lt;/a&gt;, published on infoQ.com, Jan 2021. &lt;a href=&quot;https://www.infoq.com/articles/arm-vs-x86-cloud-performance/&quot;&gt;https://www.infoq.com/articles/arm-vs-x86-cloud-performance/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.suborbital.dev/suborbital-wasmedge&quot;&gt;WasmEdge is the fastest WebAssembly Runtime in Suborbital Reactr test suite&lt;/a&gt;, Dec 2021&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;WasmEdge can run standard WebAssembly bytecode programs compiled from C/C++, Rust, Swift, AssemblyScript, or Kotlin source code. It &lt;a href=&quot;https://wasmedge.org/docs/category/develop-wasm-apps-in-javascript&quot;&gt;runs JavaScript&lt;/a&gt;, including 3rd party ES6, CJS, and NPM modules, in a secure, fast, lightweight, portable, and containerized sandbox. It also supports mixing of those languages (e.g., to &lt;a href=&quot;https://wasmedge.org/docs/develop/javascript/rust&quot;&gt;use Rust to implement a JavaScript API&lt;/a&gt;), the &lt;a href=&quot;https://wasmedge.org/docs/develop/javascript/networking#fetch-client&quot;&gt;Fetch&lt;/a&gt; API, and &lt;a href=&quot;https://wasmedge.org/docs/develop/javascript/ssr&quot;&gt;Server-side Rendering (SSR)&lt;/a&gt; functions on edge servers.&lt;/p&gt; 
&lt;p&gt;WasmEdge supports &lt;a href=&quot;https://wasmedge.org/docs/start/wasmedge/extensions/proposals&quot;&gt;all standard WebAssembly features and many proposed extensions&lt;/a&gt;. It also supports a number of extensions tailored for cloud-native and edge computing uses (e.g., the &lt;a href=&quot;https://wasmedge.org/docs/category/socket-networking&quot;&gt;WasmEdge network sockets&lt;/a&gt;,&lt;a href=&quot;https://wasmedge.org/docs/category/database-drivers&quot;&gt;Postgres and MySQL-based database driver&lt;/a&gt;, and the &lt;a href=&quot;https://wasmedge.org/docs/category/ai-inference&quot;&gt;WasmEdge AI extension&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more about &lt;a href=&quot;https://wasmedge.org/docs/start/wasmedge/features&quot;&gt;technical highlights&lt;/a&gt; of WasmEdge.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Integrations and management&lt;/h2&gt; 
&lt;p&gt;WasmEdge and its contained wasm program can be started from the &lt;a href=&quot;https://wasmedge.org/docs/category/running-with-wasmedge&quot;&gt;CLI&lt;/a&gt; as a new process, or from an existing process. If started from an existing process (e.g., from a running &lt;a href=&quot;https://wasmedge.org/docs/category/go-sdk-for-embedding-wasmedge&quot;&gt;Go&lt;/a&gt; or &lt;a href=&quot;https://wasmedge.org/docs/category/rust-sdk-for-embedding-wasmedge&quot;&gt;Rust&lt;/a&gt; program), WasmEdge will simply run inside the process as a function. Currently, WasmEdge is not yet thread-safe. In order to use WasmEdge in your own application or cloud-native frameworks, please refer to the guides below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wasmedge.org/docs/embed/overview&quot;&gt;Embed WasmEdge into a host application&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wasmedge.org/docs/category/deploy-wasmedge-apps-in-kubernetes&quot;&gt;Orchestrate and manage WasmEdge instances using container tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wasmedge.org/docs/develop/rust/dapr&quot;&gt;Run a WasmEdge app as a Dapr microservice&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Please check out our:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/docs/CONTRIBUTING.md&quot;&gt;Contributing Guide&lt;/a&gt; for how to get started&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/docs/GOVERNANCE.md&quot;&gt;Governance documentation&lt;/a&gt; for project decision-making processes&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/docs/CODE_OF_CONDUCT.md&quot;&gt;Code of Conduct&lt;/a&gt; for community standards&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to become a maintainer? See our &lt;a href=&quot;https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/CONTRIBUTION_LADDER.md&quot;&gt;Contributor Ladder&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href=&quot;https://github.com/WasmEdge/WasmEdge/raw/master/docs/ROADMAP.md&quot;&gt;project roadmap&lt;/a&gt; to see the upcoming features and plans for WasmEdge.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feel free to open a GitHub issue on a related project or to join the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Mailing list: Send an email to &lt;a href=&quot;https://groups.google.com/g/wasmedge/&quot;&gt;WasmEdge@googlegroups.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord: Join the &lt;a href=&quot;https://discord.gg/h4KDyB8XTt&quot;&gt;WasmEdge Discord server&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Slack: Join the #WasmEdge channel on the &lt;a href=&quot;https://slack.cncf.io/&quot;&gt;CNCF Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;X (formerly Twitter): Follow @realwasmedge on &lt;a href=&quot;https://x.com/realwasmedge&quot;&gt;X&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href=&quot;https://wasmedge.org/docs/contribute/users/&quot;&gt;list of Adopters&lt;/a&gt; who are using WasmEdge in their projects.&lt;/p&gt; 
&lt;h2&gt;Community Meeting&lt;/h2&gt; 
&lt;p&gt;We host a monthly community meeting to showcase new features, demo new use cases, and a Q&amp;amp;A part. Everyone is welcome!&lt;/p&gt; 
&lt;p&gt;Time: The first Tuesday of each month at 11PM Hong Kong Time/ 7AM PST.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/1iFlVl7R97Lze4RDykzElJGDjjWYDlkI8Rhf8g4dQ5Rk/edit#&quot;&gt;Public meeting agenda/notes&lt;/a&gt; | &lt;a href=&quot;https://us06web.zoom.us/j/82221747919?pwd=3MORhaxDk15rACk7mNDvyz9KtaEbWy.1&quot;&gt;Zoom link&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://app.fossa.com/projects/git%2Bgithub.com%2FWasmEdge%2FWasmEdge?ref=badge_large&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/git%2Bgithub.com%2FWasmEdge%2FWasmEdge.svg?type=large&quot; alt=&quot;FOSSA Status&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harfbuzz/harfbuzz</title>
      <link>https://github.com/harfbuzz/harfbuzz</link>
      <description>&lt;p&gt;HarfBuzz text shaping engine&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/linux.yml&quot;&gt;&lt;img src=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/linux.yml/badge.svg?sanitize=true&quot; alt=&quot;Linux CI Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/macos.yml&quot;&gt;&lt;img src=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/macos.yml/badge.svg?sanitize=true&quot; alt=&quot;macoOS CI Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/msvc.yml&quot;&gt;&lt;img src=&quot;https://github.com/harfbuzz/harfbuzz/actions/workflows/msvc.yml/badge.svg?sanitize=true&quot; alt=&quot;Windows CI Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/index.html#harfbuzz&quot;&gt;&lt;img src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/harfbuzz.svg?sanitize=true&quot; alt=&quot;OSS-Fuzz Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://scan.coverity.com/projects/harfbuzz&quot;&gt;&lt;img src=&quot;https://scan.coverity.com/projects/15166/badge.svg?sanitize=true&quot; alt=&quot;Coverity Scan Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://repology.org/project/harfbuzz/versions&quot;&gt;&lt;img src=&quot;https://repology.org/badge/tiny-repos/harfbuzz.svg?sanitize=true&quot; alt=&quot;Packaging status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://securityscorecards.dev/viewer/?uri=github.com/harfbuzz/harfbuzz&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/harfbuzz/harfbuzz/badge&quot; alt=&quot;OpenSSF Scorecard&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;HarfBuzz&lt;/h1&gt; 
&lt;p&gt;HarfBuzz is a text shaping engine. It primarily supports &lt;a href=&quot;https://docs.microsoft.com/en-us/typography/opentype/spec/&quot;&gt;OpenType&lt;/a&gt;, but also &lt;a href=&quot;https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6AATIntro.html&quot;&gt;Apple Advanced Typography&lt;/a&gt;. HarfBuzz is used in Android, Chrome, ChromeOS, Firefox, GNOME, GTK+, KDE, Qt, LibreOffice, OpenJDK, XeTeX, PlayStation, Microsoft Edge, Adobe Photoshop, Illustrator, InDesign, Godot Engine, Unreal Engine, QuarkXPress, Figma, Canva, and other places.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://xkcd.com/2347/&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/xkcd.png&quot; alt=&quot;xkcd-derived image&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For bug reports, mailing list, and other information please visit:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;http://harfbuzz.org/&quot;&gt;http://harfbuzz.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For license information, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/COPYING&quot;&gt;COPYING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For user manual as well as API documentation, check: &lt;a href=&quot;https://harfbuzz.github.io&quot;&gt;https://harfbuzz.github.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;For tarball releases of HarfBuzz, look &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz/releases&quot;&gt;here&lt;/a&gt;. At the same place you will also find Win32/Win64 binary bundles that include &lt;code&gt;libharfbuzz&lt;/code&gt; DLL, &lt;code&gt;hb-view.exe&lt;/code&gt;, &lt;code&gt;hb-shape.exe&lt;/code&gt;, and all dependencies.&lt;/p&gt; 
&lt;p&gt;The canonical source tree is available on &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz&quot;&gt;github&lt;/a&gt;. Both development and user support discussion around HarfBuzz happens on &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz&quot;&gt;github&lt;/a&gt; as well.&lt;/p&gt; 
&lt;p&gt;The API that comes with &lt;code&gt;hb.h&lt;/code&gt; will not change incompatibly. Other, peripheral, headers are more likely to go through minor modifications, but again, we do our best to never change API in an incompatible way. We will never break the ABI.&lt;/p&gt; 
&lt;p&gt;The API and ABI are stable even across major version number jumps. In fact, current HarfBuzz is API/ABI compatible all the way back to the 0.9.x series. If one day we need to break the API/ABI, that would be called a new a library.&lt;/p&gt; 
&lt;p&gt;As such, we bump the major version number only when we add major new features, the minor version when there is new API, and the micro version when there are bug fixes.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;For build information, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/BUILD.md&quot;&gt;BUILD.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For custom configurations, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/CONFIG.md&quot;&gt;CONFIG.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For testing and profiling, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/TESTING.md&quot;&gt;TESTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For using with Python, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/README.python.md&quot;&gt;README.python.md&lt;/a&gt;. There is also &lt;a href=&quot;https://github.com/harfbuzz/uharfbuzz&quot;&gt;uharfbuzz&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For cross-compiling to Windows from Linux or macOS, see &lt;a href=&quot;https://raw.githubusercontent.com/harfbuzz/harfbuzz/main/README.mingw.md&quot;&gt;README.mingw.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To report bugs or submit patches please use &lt;a href=&quot;https://github.com/harfbuzz/harfbuzz&quot;&gt;github&lt;/a&gt; issues and pull-requests.&lt;/p&gt; 
&lt;h3&gt;Developer documents&lt;/h3&gt; 
&lt;p&gt;To get a better idea of where HarfBuzz stands in the text rendering stack you may want to read &lt;a href=&quot;https://behdad.org/text2024&quot;&gt;State of Text Rendering 2024&lt;/a&gt;. Here are a few presentation slides about HarfBuzz at the Internationalization and Unicode Conference over the years:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2014 – &lt;a href=&quot;https://docs.google.com/presentation/d/1x97pfbB1gbD53Yhz6-_yBUozQMVJ_5yMqqR_D-R7b7I/preview&quot;&gt;Unicode, OpenType, and HarfBuzz: Closing the Circle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2012 – &lt;a href=&quot;https://docs.google.com/presentation/d/1ySTZaXP5XKFg0OpmHZM00v5b17GSr3ojnzJekl4U8qI/preview&quot;&gt;HarfBuzz, The Free and Open Text Shaping Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2016 – &lt;a href=&quot;https://behdad.org/doc/harfbuzz10years-slides.pdf&quot;&gt;Ten Years of HarfBuzz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2009 – &lt;a href=&quot;https://behdad.org/doc/harfbuzz2009-slides.pdf&quot;&gt;HarfBuzz: the Free and Open Shaping Engine&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More presentations and papers are available on &lt;a href=&quot;https://behdad.org/&quot;&gt;behdad&lt;/a&gt;&#39;s website. In particular, the following &lt;em&gt;studies&lt;/em&gt; are relevant to HarfBuzz development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025 – &lt;a href=&quot;https://docs.google.com/document/d/1aH_waagdEM5UhslQxCeFEb82ECBhPlZjy5_MwLNLBYo/preview&quot;&gt;Introducing HarfRust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025 – &lt;a href=&quot;https://docs.google.com/document/d/1_vZrt97OorJ0jA1YzJ29LRcGr3YGrNJANdOABjVZGEs/preview&quot;&gt;Subsetting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025 – &lt;a href=&quot;https://docs.google.com/document/d/1_VgObf6Je0J8byMLsi7HCQHnKo2emGnx_ib_sHo-bt4/preview&quot;&gt;Caching&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025 – &lt;a href=&quot;https://docs.google.com/document/d/1Y-u08l9YhObRVObETZt1k8f_5lQdOix9TRH3zEXaoAw/preview&quot;&gt;&lt;code&gt;hb-decycler&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2022 – &lt;a href=&quot;https://docs.google.com/document/d/1o-xvxCbgMe9JYFHLVnPjk01ZY_8Cj0vB9-KTI1d0nyk/preview&quot;&gt;&lt;code&gt;hb-iter&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2022 – &lt;a href=&quot;https://docs.google.com/document/d/18hI56KJpvXtwWbc9QSaz9zzhJwIMnrJ-zkAaKS-W-8k/preview&quot;&gt;A C library written in C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2022 – &lt;a href=&quot;https://docs.google.com/document/d/1wskYbA-czBt57oH9gEuGf3sWbTx7bfOiEIcDs36-heo/preview&quot;&gt;The case of the slow &lt;code&gt;hb-ft&lt;/code&gt; &lt;code&gt;&amp;gt;h_advance&lt;/code&gt; function&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2022 – &lt;a href=&quot;https://docs.google.com/document/d/1Xq3owVt61HVkJqbLFHl73il6pcTy6PdPJJ7bSouQiQw/preview&quot;&gt;PackTab: A static integer table packer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2020 – &lt;a href=&quot;https://prezi.com/view/THNPJGFVDUCWoM20syev/&quot;&gt;HarfBuzz OT+AAT &quot;Unishaper&quot;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2014 – &lt;a href=&quot;https://docs.google.com/document/d/1wMPwVNBvsIriamcyBO5aNs7Cdr8lmbwLJ8GmZBAswF4/preview&quot;&gt;Building the Indic Shaper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2012 – &lt;a href=&quot;https://docs.google.com/document/d/12jfNpQJzeVIAxoUSpk7KziyINAa1msbGliyXqguS86M/preview&quot;&gt;Memory Consumption&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Name&lt;/h2&gt; 
&lt;p&gt;HarfBuzz (حرف‌باز) is the literal Persian translation of “&lt;a href=&quot;https://docs.microsoft.com/en-us/typography/opentype/spec/&quot;&gt;OpenType&lt;/a&gt;”, transliterated using the Latin script. It also means &quot;talkative&quot; or &quot;glib&quot; (also a nod to the GNOME project where HarfBuzz originates from).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Background: Originally there was this font format called TrueType. People and companies started calling their type engines all things ending in Type: FreeType, CoolType, ClearType, etc. And then came OpenType, which is the successor of TrueType. So, for my OpenType implementation, I decided to stick with the concept but use the Persian translation. Which is fitting given that Persian is written in the Arabic script, and OpenType is an extension of TrueType that adds support for complex script rendering, and HarfBuzz is an implementation of OpenType complex text shaping.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Distribution&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Packaging status of HarfBuzz&lt;/summary&gt; 
 &lt;p&gt;&lt;a href=&quot;https://repology.org/project/harfbuzz/versions&quot;&gt;&lt;img src=&quot;https://repology.org/badge/vertical-allrepos/harfbuzz.svg?header=harfbuzz&quot; alt=&quot;Packaging status&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>tesseract-ocr/tesseract</title>
      <link>https://github.com/tesseract-ocr/tesseract</link>
      <description>&lt;p&gt;Tesseract Open Source OCR Engine (main repository)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tesseract OCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://scan.coverity.com/projects/tesseract-ocr&quot;&gt;&lt;img src=&quot;https://scan.coverity.com/projects/tesseract-ocr/badge.svg?sanitize=true&quot; alt=&quot;Coverity Scan Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/security/code-scanning&quot;&gt;&lt;img src=&quot;https://github.com/tesseract-ocr/tesseract/workflows/CodeQL/badge.svg?sanitize=true&quot; alt=&quot;CodeQL&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://issues.oss-fuzz.com/issues?q=is:open%20title:tesseract-ocr&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen&quot; alt=&quot;OSS-Fuzz&quot; /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache--2.0-blue.svg?sanitize=true&quot; alt=&quot;GitHub license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/releases/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/download-all%20releases-brightgreen.svg?sanitize=true&quot; alt=&quot;Downloads&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#tesseract-ocr&quot;&gt;Tesseract OCR&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#about&quot;&gt;About&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#brief-history&quot;&gt;Brief history&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#installing-tesseract&quot;&gt;Installing Tesseract&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#running-tesseract&quot;&gt;Running Tesseract&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#for-developers&quot;&gt;For developers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#support&quot;&gt;Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#dependencies&quot;&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/#latest-version-of-readme&quot;&gt;Latest Version of README&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;This package contains an &lt;strong&gt;OCR engine&lt;/strong&gt; - &lt;code&gt;libtesseract&lt;/code&gt; and a &lt;strong&gt;command line program&lt;/strong&gt; - &lt;code&gt;tesseract&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Tesseract 4 adds a new neural net (LSTM) based &lt;a href=&quot;https://en.wikipedia.org/wiki/Optical_character_recognition&quot;&gt;OCR engine&lt;/a&gt; which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0). It also needs &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Data-Files.html&quot;&gt;traineddata&lt;/a&gt; files which support the legacy engine, for example those from the &lt;a href=&quot;https://github.com/tesseract-ocr/tessdata&quot;&gt;tessdata&lt;/a&gt; repository.&lt;/p&gt; 
&lt;p&gt;Stefan Weil is the current lead developer. Ray Smith was the lead developer until 2018. The maintainer is Zdenko Podobny. For a list of contributors see &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/AUTHORS&quot;&gt;AUTHORS&lt;/a&gt; and GitHub&#39;s log of &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/graphs/contributors&quot;&gt;contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Tesseract has &lt;strong&gt;unicode (UTF-8) support&lt;/strong&gt;, and can &lt;strong&gt;recognize &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html&quot;&gt;more than 100 languages&lt;/a&gt;&lt;/strong&gt; &quot;out of the box&quot;.&lt;/p&gt; 
&lt;p&gt;Tesseract supports &lt;strong&gt;&lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/InputFormats&quot;&gt;various image formats&lt;/a&gt;&lt;/strong&gt; including PNG, JPEG and TIFF.&lt;/p&gt; 
&lt;p&gt;Tesseract supports &lt;strong&gt;various output formats&lt;/strong&gt;: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV, ALTO and PAGE.&lt;/p&gt; 
&lt;p&gt;You should note that in many cases, in order to get better OCR results, you&#39;ll need to &lt;strong&gt;&lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html&quot;&gt;improve the quality&lt;/a&gt; of the image&lt;/strong&gt; you are giving Tesseract.&lt;/p&gt; 
&lt;p&gt;This project &lt;strong&gt;does not include a GUI application&lt;/strong&gt;. If you need one, please see the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html&quot;&gt;3rdParty&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;p&gt;Tesseract &lt;strong&gt;can be trained to recognize other languages&lt;/strong&gt;. See &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html&quot;&gt;Tesseract Training&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Brief history&lt;/h2&gt; 
&lt;p&gt;Tesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.&lt;/p&gt; 
&lt;p&gt;Major version 5 is the current stable version and started with release &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0&quot;&gt;5.0.0&lt;/a&gt; on November 30, 2021. Newer minor versions and bugfix versions are available from &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/releases/&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Latest source code is available from &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/tree/main&quot;&gt;main branch on GitHub&lt;/a&gt;. Open issues can be found in &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/issues&quot;&gt;issue tracker&lt;/a&gt;, and &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Planning.html&quot;&gt;planning documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;strong&gt;&lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html&quot;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/ChangeLog&quot;&gt;Change Log&lt;/a&gt;&lt;/strong&gt; for more details of the releases.&lt;/p&gt; 
&lt;h2&gt;Installing Tesseract&lt;/h2&gt; 
&lt;p&gt;You can either &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Installation.html&quot;&gt;Install Tesseract via pre-built binary package&lt;/a&gt; or &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Compiling.html&quot;&gt;build it from source&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Before building Tesseract from source, please check that your system has a compiler which is one of the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/supported-compilers.html&quot;&gt;supported compilers&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running Tesseract&lt;/h2&gt; 
&lt;p&gt;Basic &lt;strong&gt;&lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html&quot;&gt;command line usage&lt;/a&gt;&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the various command line options use &lt;code&gt;tesseract --help&lt;/code&gt; or &lt;code&gt;man tesseract&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Examples can be found in the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;For developers&lt;/h2&gt; 
&lt;p&gt;Developers can use &lt;code&gt;libtesseract&lt;/code&gt; &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/include/tesseract/capi.h&quot;&gt;C&lt;/a&gt; or &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/include/tesseract/baseapi.h&quot;&gt;C++&lt;/a&gt; API to build their own application. If you need bindings to &lt;code&gt;libtesseract&lt;/code&gt; for other programming languages, please see the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers&quot;&gt;wrapper&lt;/a&gt; section in the AddOns documentation.&lt;/p&gt; 
&lt;p&gt;Documentation of Tesseract generated from source code by doxygen can be found on &lt;a href=&quot;https://tesseract-ocr.github.io/&quot;&gt;tesseract-ocr.github.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Before you submit an issue, please review &lt;strong&gt;&lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/CONTRIBUTING.md&quot;&gt;the guidelines for this repository&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;For support, first read the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/&quot;&gt;documentation&lt;/a&gt;, particularly the &lt;a href=&quot;https://tesseract-ocr.github.io/tessdoc/FAQ.html&quot;&gt;FAQ&lt;/a&gt; to see if your problem is addressed there. If not, search the &lt;a href=&quot;https://groups.google.com/g/tesseract-ocr&quot;&gt;Tesseract user forum&lt;/a&gt;, the &lt;a href=&quot;https://groups.google.com/g/tesseract-dev&quot;&gt;Tesseract developer forum&lt;/a&gt; and &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/issues&quot;&gt;past issues&lt;/a&gt;, and if you still can&#39;t find what you need, ask for support in the mailing-lists.&lt;/p&gt; 
&lt;p&gt;Mailing-lists:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://groups.google.com/g/tesseract-ocr&quot;&gt;tesseract-ocr&lt;/a&gt; - For tesseract users.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://groups.google.com/g/tesseract-dev&quot;&gt;tesseract-dev&lt;/a&gt; - For tesseract developers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please report an issue only for a &lt;strong&gt;bug&lt;/strong&gt;, not for asking questions.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;The code in this repository is licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This software depends on other packages that may be licensed under different open source licenses.&lt;/p&gt; 
&lt;p&gt;Tesseract uses &lt;a href=&quot;http://leptonica.com/&quot;&gt;Leptonica library&lt;/a&gt; which essentially uses a &lt;a href=&quot;http://leptonica.com/about-the-license.html&quot;&gt;BSD 2-clause license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Tesseract uses &lt;a href=&quot;https://github.com/DanBloomberg/leptonica&quot;&gt;Leptonica library&lt;/a&gt; for opening input images (e.g. not documents like pdf). It is suggested to use leptonica with built-in support for &lt;a href=&quot;https://zlib.net&quot;&gt;zlib&lt;/a&gt;, &lt;a href=&quot;https://sourceforge.net/projects/libpng&quot;&gt;png&lt;/a&gt; and &lt;a href=&quot;http://www.simplesystems.org/libtiff&quot;&gt;tiff&lt;/a&gt; (for multipage tiff).&lt;/p&gt; 
&lt;h2&gt;Latest Version of README&lt;/h2&gt; 
&lt;p&gt;For the latest online version of the README.md see:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/tesseract-ocr/tesseract/raw/main/README.md&quot;&gt;https://github.com/tesseract-ocr/tesseract/blob/main/README.md&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hyprwm/Hyprland</title>
      <link>https://github.com/hyprwm/Hyprland</link>
      <description>&lt;p&gt;Hyprland is an independent, highly customizable, dynamic tiling Wayland compositor that doesn&#39;t sacrifice on its looks.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/hyprwm/Hyprland/main/assets/header.svg?sanitize=true&quot; width=&quot;750&quot; height=&quot;300&quot; alt=&quot;banner&quot; /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/hyprwm/Hyprland/actions/workflows/ci.yaml&quot;&gt;&lt;img src=&quot;https://github.com/hyprwm/Hyprland/actions/workflows/ci.yaml/badge.svg?sanitize=true&quot; alt=&quot;Badge Workflow&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/hyprwm/Hyprland/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/hyprwm/Hyprland&quot; alt=&quot;Badge License&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/github/languages/top/hyprwm/Hyprland&quot; alt=&quot;Badge Language&quot; /&gt; &lt;a href=&quot;https://github.com/hyprwm/Hyprland/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/hyprwm/Hyprland&quot; alt=&quot;Badge Pull Requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hyprwm/Hyprland/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/hyprwm/Hyprland&quot; alt=&quot;Badge Issues&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/badge/Hi-mom!-ff69b4&quot; alt=&quot;Badge Hi Mom&quot; /&gt;&lt;br /&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Hyprland is a 100% independent, dynamic tiling Wayland compositor that doesn&#39;t sacrifice on its looks.&lt;/p&gt; 
 &lt;p&gt;It provides the latest Wayland features, is highly customizable, has all the eyecandy, the most powerful plugins, easy IPC, much more QoL stuff than other compositors and more... &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://wiki.hypr.land/Getting-Started/Installation/&quot;&gt;&lt;kbd&gt; &lt;br /&gt; Install &lt;br /&gt; &lt;/kbd&gt;&lt;/a&gt;&lt;/strong&gt;  &lt;strong&gt;&lt;a href=&quot;https://wiki.hypr.land/Getting-Started/Master-Tutorial/&quot;&gt;&lt;kbd&gt; &lt;br /&gt; Quick Start &lt;br /&gt; &lt;/kbd&gt;&lt;/a&gt;&lt;/strong&gt;  &lt;strong&gt;&lt;a href=&quot;https://wiki.hypr.land/Configuring/&quot;&gt;&lt;kbd&gt; &lt;br /&gt; Configure &lt;br /&gt; &lt;/kbd&gt;&lt;/a&gt;&lt;/strong&gt;  &lt;strong&gt;&lt;a href=&quot;https://wiki.hypr.land/Contributing-and-Debugging/&quot;&gt;&lt;kbd&gt; &lt;br /&gt; Contribute &lt;br /&gt; &lt;/kbd&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;All of the eyecandy: gradient borders, blur, animations, shadows and much more&lt;/li&gt; 
 &lt;li&gt;A lot of customization&lt;/li&gt; 
 &lt;li&gt;100% independent, no wlroots, no libweston, no kwin, no mutter.&lt;/li&gt; 
 &lt;li&gt;Custom bezier curves for the best animations&lt;/li&gt; 
 &lt;li&gt;Powerful plugin support&lt;/li&gt; 
 &lt;li&gt;Built-in plugin manager&lt;/li&gt; 
 &lt;li&gt;Tearing support for better gaming performance&lt;/li&gt; 
 &lt;li&gt;Easily expandable and readable codebase&lt;/li&gt; 
 &lt;li&gt;Fast and active development&lt;/li&gt; 
 &lt;li&gt;Not afraid to provide bleeding-edge features&lt;/li&gt; 
 &lt;li&gt;Config reloaded instantly upon saving&lt;/li&gt; 
 &lt;li&gt;Fully dynamic workspaces&lt;/li&gt; 
 &lt;li&gt;Two built-in layouts and more available as plugins&lt;/li&gt; 
 &lt;li&gt;Global keybinds passed to your apps of choice&lt;/li&gt; 
 &lt;li&gt;Tiling/pseudotiling/floating/fullscreen windows&lt;/li&gt; 
 &lt;li&gt;Special workspaces (scratchpads)&lt;/li&gt; 
 &lt;li&gt;Window groups (tabbed mode)&lt;/li&gt; 
 &lt;li&gt;Powerful window/monitor/layer rules&lt;/li&gt; 
 &lt;li&gt;Socket-based IPC&lt;/li&gt; 
 &lt;li&gt;Native IME and Input Panels Support&lt;/li&gt; 
 &lt;li&gt;and much more...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;h1&gt;Gallery&lt;/h1&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;img src=&quot;https://i.ibb.co/XxFY75Mk/greerggergerhtrytghjnyhjn.png&quot; alt=&quot;Preview A&quot; /&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;img src=&quot;https://i.ibb.co/C1yTb0r/falf.png&quot; alt=&quot;Preview B&quot; /&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;img src=&quot;https://i.ibb.co/2Yc4q835/hyprland-preview-b.png&quot; alt=&quot;Preview C&quot; /&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Special Thanks&lt;/h1&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://gitlab.freedesktop.org/wlroots/wlroots&quot;&gt;wlroots&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For powering Hyprland in the past&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://gitlab.freedesktop.org/wlroots/wlroots/-/blob/master/tinywl/tinywl.c&quot;&gt;tinywl&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For showing how 2 do stuff&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/swaywm/sway&quot;&gt;Sway&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For showing how 2 do stuff the overkill way&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/inclement/vivarium&quot;&gt;Vivarium&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For showing how 2 do stuff the simple way&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://codeberg.org/dwl/dwl&quot;&gt;dwl&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For showing how 2 do stuff the hacky way&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/WayfireWM/wayfire&quot;&gt;Wayfire&lt;/a&gt;&lt;/strong&gt; - &lt;em&gt;For showing how 2 do some graphics stuff&lt;/em&gt;&lt;/p&gt; 
&lt;!----&gt; 
&lt;!--{ Thanks }---------------------------------&gt; 
&lt;!--{ Images }---------------------------------&gt; 
&lt;!--{ Badges }---------------------------------&gt;</description>
    </item>
    
    <item>
      <title>nomic-ai/gpt4all</title>
      <link>https://github.com/nomic-ai/gpt4all</link>
      <description>&lt;p&gt;GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt;GPT4All&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; Now with support for DeepSeek R1 Distillations &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.nomic.ai/gpt4all&quot;&gt;Website&lt;/a&gt; • &lt;a href=&quot;https://docs.gpt4all.io&quot;&gt;Documentation&lt;/a&gt; • &lt;a href=&quot;https://discord.gg/mGZE39AS3e&quot;&gt;Discord&lt;/a&gt; • &lt;a href=&quot;https://www.youtube.com/watch?v=gQcZDXRVJok&quot;&gt;YouTube Tutorial&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; GPT4All runs large language models (LLMs) privately on everyday desktops &amp;amp; laptops. &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; No API calls or GPUs required - you can just download the application and &lt;a href=&quot;https://docs.gpt4all.io/gpt4all_desktop/quickstart.html#quickstart&quot;&gt;get started&lt;/a&gt;. &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; Read about what&#39;s new in &lt;a href=&quot;https://www.nomic.ai/blog/tag/gpt4all&quot;&gt;our blog&lt;/a&gt;. &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://nomic.ai/gpt4all/#newsletter-form&quot;&gt;Subscribe to the newsletter&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/nomic-ai/gpt4all/assets/70534565/513a0f15-4964-4109-89e4-4f9a9011f311&quot;&gt;https://github.com/nomic-ai/gpt4all/assets/70534565/513a0f15-4964-4109-89e4-4f9a9011f311&lt;/a&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; GPT4All is made possible by our compute partner &lt;a href=&quot;https://www.paperspace.com/&quot;&gt;Paperspace&lt;/a&gt;. &lt;/p&gt; 
&lt;h2&gt;Download Links&lt;/h2&gt; 
&lt;p&gt; — &lt;a href=&quot;https://gpt4all.io/installers/gpt4all-installer-win64.exe&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/windows.png&quot; style=&quot;height: 1em; width: auto&quot; /&gt; Windows Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href=&quot;https://gpt4all.io/installers/gpt4all-installer-win64-arm.exe&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/windows.png&quot; style=&quot;height: 1em; width: auto&quot; /&gt; Windows ARM Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href=&quot;https://gpt4all.io/installers/gpt4all-installer-darwin.dmg&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/mac.png&quot; style=&quot;height: 1em; width: auto&quot; /&gt; macOS Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href=&quot;https://gpt4all.io/installers/gpt4all-installer-linux.run&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/ubuntu.svg?sanitize=true&quot; style=&quot;height: 1em; width: auto&quot; /&gt; Ubuntu Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; The Windows and Linux builds require Intel Core i3 2nd Gen / AMD Bulldozer, or better. &lt;/p&gt; 
&lt;p&gt; The Windows ARM build supports Qualcomm Snapdragon and Microsoft SQ1/SQ2 processors. &lt;/p&gt; 
&lt;p&gt; The Linux build is x86-64 only (no ARM). &lt;/p&gt; 
&lt;p&gt; The macOS build requires Monterey 12.6 or newer. Best results with Apple Silicon M-series processors. &lt;/p&gt; 
&lt;p&gt;See the full &lt;a href=&quot;https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-chat/system_requirements.md&quot;&gt;System Requirements&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt; &lt;a href=&quot;https://flathub.org/apps/io.gpt4all.gpt4all&quot;&gt; &lt;img style=&quot;height: 2em; width: auto&quot; alt=&quot;Get it on Flathub&quot; src=&quot;https://flathub.org/api/badge&quot; /&gt;&lt;br /&gt; Flathub (community maintained) &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Install GPT4All Python&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;gpt4all&lt;/code&gt; gives you access to LLMs with our Python client around &lt;a href=&quot;https://github.com/ggerganov/llama.cpp&quot;&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; implementations.&lt;/p&gt; 
&lt;p&gt;Nomic contributes to open source software like &lt;a href=&quot;https://github.com/ggerganov/llama.cpp&quot;&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; to make LLMs accessible and efficient &lt;strong&gt;for all&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install gpt4all
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from gpt4all import GPT4All
model = GPT4All(&quot;Meta-Llama-3-8B-Instruct.Q4_0.gguf&quot;) # downloads / loads a 4.66GB LLM
with model.chat_session():
    print(model.generate(&quot;How can I run LLMs efficiently on my laptop?&quot;, max_tokens=1024))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;🦜&lt;/span&gt;&lt;span&gt;🔗&lt;/span&gt; &lt;a href=&quot;https://python.langchain.com/v0.2/docs/integrations/providers/gpt4all/&quot;&gt;Langchain&lt;/a&gt; &lt;span&gt;🗃&lt;/span&gt; &lt;a href=&quot;https://github.com/weaviate/weaviate&quot;&gt;Weaviate Vector Database&lt;/a&gt; - &lt;a href=&quot;https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-gpt4all&quot;&gt;module docs&lt;/a&gt; &lt;span&gt;🔭&lt;/span&gt; &lt;a href=&quot;https://github.com/openlit/openlit&quot;&gt;OpenLIT (OTel-native Monitoring)&lt;/a&gt; - &lt;a href=&quot;https://docs.openlit.io/latest/integrations/gpt4all&quot;&gt;Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release History&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;July 2nd, 2024&lt;/strong&gt;: V3.0.0 Release 
  &lt;ul&gt; 
   &lt;li&gt;Fresh redesign of the chat application UI&lt;/li&gt; 
   &lt;li&gt;Improved user workflow for LocalDocs&lt;/li&gt; 
   &lt;li&gt;Expanded access to more model architectures&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;October 19th, 2023&lt;/strong&gt;: GGUF Support Launches with Support for: 
  &lt;ul&gt; 
   &lt;li&gt;Mistral 7b base model, an updated model gallery on our website, several new local code models including Rift Coder v1.5&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan&quot;&gt;Nomic Vulkan&lt;/a&gt; support for Q4_0 and Q4_1 quantizations in GGUF.&lt;/li&gt; 
   &lt;li&gt;Offline build support for running old versions of the GPT4All Local LLM Chat Client.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;September 18th, 2023&lt;/strong&gt;: &lt;a href=&quot;https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan&quot;&gt;Nomic Vulkan&lt;/a&gt; launches supporting local LLM inference on NVIDIA and AMD GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 2023&lt;/strong&gt;: Stable support for LocalDocs, a feature that allows you to privately and locally chat with your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 28th, 2023&lt;/strong&gt;: &lt;a href=&quot;https://github.com/nomic-ai/gpt4all/tree/cef74c2be20f5b697055d5b8b506861c7b997fab/gpt4all-api&quot;&gt;Docker-based API server&lt;/a&gt; launches allowing inference of local LLMs from an OpenAI-compatible HTTP endpoint.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;GPT4All welcomes contributions, involvement, and discussion from the open source community! Please see CONTRIBUTING.md and follow the issues, bug reports, and PR markdown templates.&lt;/p&gt; 
&lt;p&gt;Check project discord, with project owners, or through existing issues/PRs to avoid duplicate work. Please make sure to tag all of the above with relevant project identifiers or your contribution could potentially get lost. Example tags: &lt;code&gt;backend&lt;/code&gt;, &lt;code&gt;bindings&lt;/code&gt;, &lt;code&gt;python-bindings&lt;/code&gt;, &lt;code&gt;documentation&lt;/code&gt;, etc.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, models or data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{gpt4all,
  author = {Yuvanesh Anand and Zach Nussbaum and Brandon Duderstadt and Benjamin Schmidt and Andriy Mulyar},
  title = {GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nomic-ai/gpt4all}},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>HIllya51/LunaTranslator</title>
      <link>https://github.com/HIllya51/LunaTranslator</link>
      <description>&lt;p&gt;视觉小说翻译器，支持HOOK、OCR、剪贴板等。Visual Novel Translator, support HOOK / OCR / Clipboard&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;简体中文 | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_en.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_cht.md&quot;&gt;繁體中文&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_ko.md&quot;&gt;한국어&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_ja.md&quot;&gt;日本語&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_vi.md&quot;&gt;Tiếng Việt&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/main/README_ru.md&quot;&gt;Русский язык&lt;/a&gt;&lt;/h3&gt; 
&lt;h1&gt;LunaTranslator &lt;a href=&quot;https://docs.lunatranslator.org/zh/README.html&quot;&gt;下载 &amp;amp; 启动 &amp;amp; 更新&lt;/a&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;一款视觉小说翻译器&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;如果使用中遇到困难，可以查阅&lt;a href=&quot;https://docs.lunatranslator.org/zh&quot;&gt;使用说明&lt;/a&gt;、观看&lt;a href=&quot;https://space.bilibili.com/592120404/video&quot;&gt;我的B站视频&lt;/a&gt;，也欢迎加入&lt;a href=&quot;https://qm.qq.com/q/I5rr3uEpi2&quot;&gt;QQ群&lt;/a&gt;。&lt;/h3&gt; 
&lt;h2&gt;功能支持&lt;/h2&gt; 
&lt;h4&gt;文本输入&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HOOK&lt;/strong&gt; 支持使用HOOK方式获取文本。对于部分游戏引擎，还支持&lt;a href=&quot;https://docs.lunatranslator.org/zh/embedtranslate.html&quot;&gt;内嵌翻译&lt;/a&gt;。还支持提取部分&lt;a href=&quot;https://docs.lunatranslator.org/zh/emugames.html&quot;&gt;模拟器&lt;/a&gt;上运行的游戏的文本。对于不支持或支持不好的游戏，请&lt;a href=&quot;https://github.com/HIllya51/LunaTranslator/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=01_game_request.yaml&quot;&gt;提交反馈&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OCR&lt;/strong&gt; 支持 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/useapis/ocrapi.html&quot;&gt;离线OCR&lt;/a&gt;&lt;/strong&gt; 和 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/useapis/ocrapi.html&quot;&gt;在线OCR&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;剪贴板&lt;/strong&gt; 支持从剪贴板中获取文本进行翻译，也可以将提取的文本输出到剪贴板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt; 还支持 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/sr.html&quot;&gt;语音识别&lt;/a&gt;&lt;/strong&gt; 和&lt;strong&gt;文件翻译&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;翻译器&lt;/h4&gt; 
&lt;p&gt;支持几乎所有能想得到的翻译引擎，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;在线翻译&lt;/strong&gt; 支持大量免注册开箱即用的在线翻译接口，也支持使用用户注册的API的 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/useapis/tsapi.html&quot;&gt;传统翻译&lt;/a&gt;&lt;/strong&gt; 和 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/guochandamoxing.html&quot;&gt;大模型翻译&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线翻译&lt;/strong&gt; 支持常见 &lt;strong&gt;传统翻译&lt;/strong&gt; 引擎和离线部署的 &lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/offlinellm.html&quot;&gt;大模型翻译&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;预翻译&lt;/strong&gt; 支持读取预翻译文件，支持翻译缓存&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持自定义翻译扩展&lt;/strong&gt; 支持使用python语言扩展其他翻译接口&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;其他功能&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/ttsengines.html&quot;&gt;语音合成&lt;/a&gt;&lt;/strong&gt; 支持 &lt;strong&gt;离线TTS&lt;/strong&gt; 和 &lt;strong&gt;在线TTS&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/qa1.html&quot;&gt;日语分词及假名注音&lt;/a&gt;&lt;/strong&gt; 支持使用 Mecab 等分词和显示假名&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/internaldict.html&quot;&gt;查词&lt;/a&gt;&lt;/strong&gt; 支持使用 &lt;strong&gt;离线辞书&lt;/strong&gt; ( MDICT ) 和 &lt;strong&gt;在线辞书&lt;/strong&gt; 进行单词查询&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/qa2.html&quot;&gt;Anki&lt;/a&gt;&lt;/strong&gt; 支持使用一键添加单词到anki中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.lunatranslator.org/zh/yomitan.html&quot;&gt;加载浏览器插件&lt;/a&gt;&lt;/strong&gt; 可以在软件内加载Yomitan等浏览器插件以辅助实现一些其他功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;支持作者&lt;/h2&gt; 
&lt;p&gt;软件维护不易，如果您感觉该软件对你有帮助，欢迎通过&lt;a href=&quot;https://afdian.com/a/HIllya51&quot;&gt;爱发电&lt;/a&gt;，或微信扫码赞助，您的支持将成为软件长期维护的助力，谢谢~&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://afdian.com/a/HIllya51&quot;&gt;&lt;img width=&quot;200&quot; src=&quot;https://pic1.afdiancdn.com/static/img/welcome/button-sponsorme.png&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/src/files/static/zan.jpg&quot; style=&quot;height: 350px !important;&quot; /&gt; 
&lt;h2&gt;开源许可&lt;/h2&gt; 
&lt;p&gt;LunaTranslator使用 &lt;a href=&quot;https://raw.githubusercontent.com/HIllya51/LunaTranslator/LICENSE&quot;&gt;GPLv3&lt;/a&gt; 许可证。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chromium/chromium</title>
      <link>https://github.com/chromium/chromium</link>
      <description>&lt;p&gt;The official GitHub mirror of the Chromium source&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitHub Copilot Integration in Chromium&lt;/h1&gt; 
&lt;p&gt;This directory provides instructions and prompts for integrating GitHub Copilot with the chromium codebase.&lt;/p&gt; 
&lt;p&gt;This directory is currently in a prototyping state and may be removed in the future. As we add support for multiple coding IDE/agents, we will likely pull common prompts and instructions into a central directory with stubs for bespoke IDE/agent integration. Please check with your organization before using GitHub Copilot.&lt;/p&gt; 
&lt;h2&gt;Where is copilot-instructions.md?&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/copilot-instructions.md&quot;&gt;&lt;code&gt;copilot-intructions.md&lt;/code&gt;&lt;/a&gt; is typically a single instruction file that contains default instructions for a workspace. These instructions are automatically included in every chat request.&lt;/p&gt; 
&lt;p&gt;Until the prompt in &lt;code&gt;copilot-intructions.md&lt;/code&gt; is generally agreed upon for the chromium repo, this file is intentionally excluded from the repo, and added to the &lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/.gitignore&quot;&gt;.gitignore&lt;/a&gt; for your customization.&lt;/p&gt; 
&lt;p&gt;For generating your own &lt;code&gt;copilot-intructions.md&lt;/code&gt;, type &lt;code&gt;/create_copilot_instructions&lt;/code&gt; in GitHub Copilot to get started.&lt;/p&gt; 
&lt;h2&gt;Code Layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/instructions/&quot;&gt;.github/instructions&lt;/a&gt;: Custom instructions for specific tasks. For example, you can create instruction files for different programming languages, frameworks, or project types. You can attach individual prompt files to a chat request, or you can configure them to be automatically included for specific files or folders with &lt;code&gt;applyTo&lt;/code&gt; syntax.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/prompts/&quot;&gt;.github/prompts&lt;/a&gt;: Prompt files can be easily triggered from chat with &lt;code&gt;/&lt;/code&gt; and allow you to craft complete prompts in Markdown files. Unlike custom instructions that supplement your chat queries prompts, prompt files are standalone prompts that you can store within your workspace and share with others. With prompt files, you can create reusable templates for common tasks, store domain expertise in the codebase, and standardize AI interactions across your team.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/resources/&quot;&gt;.github/resources&lt;/a&gt;: Prompt files that are resources for use by other prompts and instructions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;User Specific Prompts&lt;/h2&gt; 
&lt;p&gt;Users can create their own prompts or instructions that match the regex &lt;code&gt;.github/**/user_.md&lt;/code&gt; which is captured in the &lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/.gitignore&quot;&gt;.gitignore&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing Guidelines&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;/git_commit_ghc&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/instructions/&quot;&gt;.github/instructions&lt;/a&gt;: Instructions that are automatically picked up using &lt;code&gt;applyTo&lt;/code&gt; syntax will have a much higher review bar then those without it.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/prompts/&quot;&gt;.github/prompts&lt;/a&gt;: All prompts should specify a &lt;code&gt;mode&lt;/code&gt; and &lt;code&gt;description&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chromium/chromium/main/resources/&quot;&gt;.github/resources&lt;/a&gt;: All prompt resources should have an active reference or usecase a file in &lt;code&gt;instructions&lt;/code&gt; or &lt;code&gt;prompts&lt;/code&gt;, and should be cleaned up if their references are modified or removed.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ml-explore/mlx</title>
      <link>https://github.com/ml-explore/mlx</link>
      <description>&lt;p&gt;MLX: An array framework for Apple silicon&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLX&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ml-explore/mlx/main/#quickstart&quot;&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/ml-explore/mlx/main/#installation&quot;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://ml-explore.github.io/mlx/build/html/index.html&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/ml-explore/mlx/main/#examples&quot;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://circleci.com/gh/ml-explore/mlx&quot;&gt;&lt;img src=&quot;https://circleci.com/gh/ml-explore/mlx.svg?style=svg&quot; alt=&quot;CircleCI&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MLX is an array framework for machine learning on Apple silicon, brought to you by Apple machine learning research.&lt;/p&gt; 
&lt;p&gt;Some key features of MLX include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Familiar APIs&lt;/strong&gt;: MLX has a Python API that closely follows NumPy. MLX also has fully featured C++, &lt;a href=&quot;https://github.com/ml-explore/mlx-c&quot;&gt;C&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ml-explore/mlx-swift/&quot;&gt;Swift&lt;/a&gt; APIs, which closely mirror the Python API. MLX has higher-level packages like &lt;code&gt;mlx.nn&lt;/code&gt; and &lt;code&gt;mlx.optimizers&lt;/code&gt; with APIs that closely follow PyTorch to simplify building more complex models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Composable function transformations&lt;/strong&gt;: MLX supports composable function transformations for automatic differentiation, automatic vectorization, and computation graph optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Lazy computation&lt;/strong&gt;: Computations in MLX are lazy. Arrays are only materialized when needed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic graph construction&lt;/strong&gt;: Computation graphs in MLX are constructed dynamically. Changing the shapes of function arguments does not trigger slow compilations, and debugging is simple and intuitive.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-device&lt;/strong&gt;: Operations can run on any of the supported devices (currently the CPU and the GPU).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified memory&lt;/strong&gt;: A notable difference from MLX and other frameworks is the &lt;em&gt;unified memory model&lt;/em&gt;. Arrays in MLX live in shared memory. Operations on MLX arrays can be performed on any of the supported device types without transferring data.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MLX is designed by machine learning researchers for machine learning researchers. The framework is intended to be user-friendly, but still efficient to train and deploy models. The design of the framework itself is also conceptually simple. We intend to make it easy for researchers to extend and improve MLX with the goal of quickly exploring new ideas.&lt;/p&gt; 
&lt;p&gt;The design of MLX is inspired by frameworks like &lt;a href=&quot;https://numpy.org/doc/stable/index.html&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, &lt;a href=&quot;https://github.com/google/jax&quot;&gt;Jax&lt;/a&gt;, and &lt;a href=&quot;https://arrayfire.org/&quot;&gt;ArrayFire&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;The &lt;a href=&quot;https://github.com/ml-explore/mlx-examples&quot;&gt;MLX examples repo&lt;/a&gt; has a variety of examples, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/transformer_lm&quot;&gt;Transformer language model&lt;/a&gt; training.&lt;/li&gt; 
 &lt;li&gt;Large-scale text generation with &lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/llms/llama&quot;&gt;LLaMA&lt;/a&gt; and finetuning with &lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/lora&quot;&gt;LoRA&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generating images with &lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/stable_diffusion&quot;&gt;Stable Diffusion&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Speech recognition with &lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/whisper&quot;&gt;OpenAI&#39;s Whisper&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://ml-explore.github.io/mlx/build/html/usage/quick_start.html&quot;&gt;quick start guide&lt;/a&gt; in the documentation.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;MLX is available on &lt;a href=&quot;https://pypi.org/project/mlx/&quot;&gt;PyPI&lt;/a&gt;. To install MLX on macOS, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install mlx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install the CUDA backend on Linux, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install mlx[cuda]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a CPU-only Linux package, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install mlx[cpu]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Checkout the &lt;a href=&quot;https://ml-explore.github.io/mlx/build/html/install.html#&quot;&gt;documentation&lt;/a&gt; for more information on building the C++ and Python APIs from source.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href=&quot;https://github.com/ml-explore/mlx/tree/main/CONTRIBUTING.md&quot;&gt;contribution guidelines&lt;/a&gt; for more information on contributing to MLX. See the &lt;a href=&quot;https://ml-explore.github.io/mlx/build/html/install.html&quot;&gt;docs&lt;/a&gt; for more information on building from source, and running tests.&lt;/p&gt; 
&lt;p&gt;We are grateful for all of &lt;a href=&quot;https://github.com/ml-explore/mlx/tree/main/ACKNOWLEDGMENTS.md#Individual-Contributors&quot;&gt;our contributors&lt;/a&gt;. If you contribute to MLX and wish to be acknowledged, please add your name to the list in your pull request.&lt;/p&gt; 
&lt;h2&gt;Citing MLX&lt;/h2&gt; 
&lt;p&gt;The MLX software suite was initially developed with equal contribution by Awni Hannun, Jagrit Digani, Angelos Katharopoulos, and Ronan Collobert. If you find MLX useful in your research and wish to cite it, please use the following BibTex entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@software{mlx2023,
  author = {Awni Hannun and Jagrit Digani and Angelos Katharopoulos and Ronan Collobert},
  title = {{MLX}: Efficient and flexible machine learning on Apple silicon},
  url = {https://github.com/ml-explore},
  version = {0.0},
  year = {2023},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>opencv/opencv</title>
      <link>https://github.com/opencv/opencv</link>
      <description>&lt;p&gt;Open Source Computer Vision Library&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;OpenCV: Open Source Computer Vision Library&lt;/h2&gt; 
&lt;h3&gt;Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Homepage: &lt;a href=&quot;https://opencv.org&quot;&gt;https://opencv.org&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Courses: &lt;a href=&quot;https://opencv.org/courses&quot;&gt;https://opencv.org/courses&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Docs: &lt;a href=&quot;https://docs.opencv.org/4.x/&quot;&gt;https://docs.opencv.org/4.x/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Q&amp;amp;A forum: &lt;a href=&quot;https://forum.opencv.org&quot;&gt;https://forum.opencv.org&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;previous forum (read only): &lt;a href=&quot;http://answers.opencv.org&quot;&gt;http://answers.opencv.org&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Issue tracking: &lt;a href=&quot;https://github.com/opencv/opencv/issues&quot;&gt;https://github.com/opencv/opencv/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Additional OpenCV functionality: &lt;a href=&quot;https://github.com/opencv/opencv_contrib&quot;&gt;https://github.com/opencv/opencv_contrib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Donate to OpenCV: &lt;a href=&quot;https://opencv.org/support/&quot;&gt;https://opencv.org/support/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Please read the &lt;a href=&quot;https://github.com/opencv/opencv/wiki/How_to_contribute&quot;&gt;contribution guidelines&lt;/a&gt; before starting work on a pull request.&lt;/p&gt; 
&lt;h4&gt;Summary of the guidelines:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;One pull request per issue;&lt;/li&gt; 
 &lt;li&gt;Choose the right base branch;&lt;/li&gt; 
 &lt;li&gt;Include tests and documentation;&lt;/li&gt; 
 &lt;li&gt;Clean up &quot;oops&quot; commits before submitting;&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;a href=&quot;https://github.com/opencv/opencv/wiki/Coding_Style_Guide&quot;&gt;coding style guide&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://form.jotform.com/233105358823151&quot;&gt;Submit your OpenCV-based project&lt;/a&gt; for inclusion in Community Friday on opencv.org&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://youtube.com/@opencvofficial&quot;&gt;Subscribe to the OpenCV YouTube Channel&lt;/a&gt; featuring OpenCV Live, an hour-long streaming show&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://linkedin.com/company/opencv/&quot;&gt;Follow OpenCV on LinkedIn&lt;/a&gt; for daily posts showing the state-of-the-art in computer vision &amp;amp; AI&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://form.jotform.com/232745316792159&quot;&gt;Apply to be an OpenCV Volunteer&lt;/a&gt; to help organize events and online campaigns as well as amplify them&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://mastodon.social/@opencv&quot;&gt;Follow OpenCV on Mastodon&lt;/a&gt; in the Fediverse&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://twitter.com/opencvlive&quot;&gt;Follow OpenCV on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://opencv.ai&quot;&gt;OpenCV.ai&lt;/a&gt;: Computer Vision and AI development services from the OpenCV team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ethereum/solidity</title>
      <link>https://github.com/ethereum/solidity</link>
      <description>&lt;p&gt;Solidity, the Smart Contract Programming Language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Solidity Contract-Oriented Programming Language&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://matrix.to/#/#ethereum_solidity:gitter.im&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Matrix%20-chat-brightgreen?style=plastic&amp;amp;logo=matrix&quot; alt=&quot;Matrix Chat&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://gitter.im/ethereum/solidity&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gitter%20-chat-brightgreen?style=plastic&amp;amp;logo=gitter&quot; alt=&quot;Gitter Chat&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://forum.soliditylang.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Solidity_Forum%20-discuss-brightgreen?style=plastic&amp;amp;logo=discourse&quot; alt=&quot;Solidity&amp;nbsp;Forum&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://X.com/solidity_lang&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/solidity_lang?style=plastic&amp;amp;logo=x&quot; alt=&quot;X Follow&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://fosstodon.org/@solidity&quot;&gt;&lt;img src=&quot;https://img.shields.io/mastodon/follow/000335908?domain=https%3A%2F%2Ffosstodon.org%2F&amp;amp;logo=mastodon&amp;amp;style=plastic&quot; alt=&quot;Mastodon Follow&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can talk to us on Gitter and Matrix, tweet at us on X (previously Twitter) or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome!&lt;/p&gt; 
&lt;p&gt;Solidity is a statically-typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform.&lt;/p&gt; 
&lt;p&gt;For a good overview and starting point, please check out the official &lt;a href=&quot;https://soliditylang.org&quot;&gt;Solidity Language Portal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#build-and-install&quot;&gt;Build and Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#example&quot;&gt;Example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#documentation&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#development&quot;&gt;Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#maintainers&quot;&gt;Maintainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/#security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Background&lt;/h2&gt; 
&lt;p&gt;Solidity is a statically-typed curly-braces programming language designed for developing smart contracts that run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer network where nobody has special authority over the execution, and thus they allow anyone to implement tokens of value, ownership, voting, and other kinds of logic.&lt;/p&gt; 
&lt;p&gt;When deploying contracts, you should use the latest released version of Solidity. This is because breaking changes, as well as new features and bug fixes, are introduced regularly. We currently use a 0.x version number &lt;a href=&quot;https://semver.org/#spec-item-4&quot;&gt;to indicate this fast pace of change&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Build and Install&lt;/h2&gt; 
&lt;p&gt;Instructions about how to build and install the Solidity compiler can be found in the &lt;a href=&quot;https://docs.soliditylang.org/en/latest/installing-solidity.html#building-from-source&quot;&gt;Solidity documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A &quot;Hello World&quot; program in Solidity is of even less use than in other languages, but still:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-solidity&quot;&gt;// SPDX-License-Identifier: MIT
pragma solidity &amp;gt;=0.6.0 &amp;lt;0.9.0;

contract HelloWorld {
    function helloWorld() external pure returns (string memory) {
        return &quot;Hello, World!&quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get started with Solidity, you can use &lt;a href=&quot;https://remix.ethereum.org/&quot;&gt;Remix&lt;/a&gt;, which is a browser-based IDE. Here are some example contracts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.soliditylang.org/en/latest/solidity-by-example.html#voting&quot;&gt;Voting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.soliditylang.org/en/latest/solidity-by-example.html#blind-auction&quot;&gt;Blind Auction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.soliditylang.org/en/latest/solidity-by-example.html#safe-remote-purchase&quot;&gt;Safe remote purchase&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.soliditylang.org/en/latest/solidity-by-example.html#micropayment-channel&quot;&gt;Micropayment Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The Solidity documentation is hosted using &lt;a href=&quot;https://docs.soliditylang.org&quot;&gt;Read the Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Solidity is still under development. Contributions are always welcome! Please follow the &lt;a href=&quot;https://docs.soliditylang.org/en/latest/contributing.html&quot;&gt;Developer&#39;s Guide&lt;/a&gt; if you want to help.&lt;/p&gt; 
&lt;p&gt;You can find our current feature and bug priorities for forthcoming releases in the &lt;a href=&quot;https://github.com/ethereum/solidity/projects&quot;&gt;projects section&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;The Solidity programming language and compiler are open-source community projects governed by a core team. The core team is sponsored by the &lt;a href=&quot;https://ethereum.foundation/&quot;&gt;Ethereum Foundation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Solidity is licensed under &lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/LICENSE.txt&quot;&gt;GNU General Public License v3.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some third-party code has its &lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/cmake/templates/license.h.in&quot;&gt;own licensing terms&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;The security policy may be &lt;a href=&quot;https://raw.githubusercontent.com/ethereum/solidity/develop/SECURITY.md&quot;&gt;found here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>godotengine/godot</title>
      <link>https://github.com/godotengine/godot</link>
      <description>&lt;p&gt;Godot Engine – Multi-platform 2D and 3D game engine&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Godot Engine&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://godotengine.org&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/godotengine/godot/master/logo_outlined.svg?sanitize=true&quot; width=&quot;400&quot; alt=&quot;Godot Engine logo&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;2D and 3D cross-platform game engine&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://godotengine.org&quot;&gt;Godot Engine&lt;/a&gt; is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface.&lt;/strong&gt; It provides a comprehensive set of &lt;a href=&quot;https://godotengine.org/features&quot;&gt;common tools&lt;/a&gt;, so that users can focus on making games without having to reinvent the wheel. Games can be exported with one click to a number of platforms, including the major desktop platforms (Linux, macOS, Windows), mobile platforms (Android, iOS), as well as Web-based platforms and &lt;a href=&quot;https://docs.godotengine.org/en/latest/tutorials/platform/consoles.html&quot;&gt;consoles&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Free, open source and community-driven&lt;/h2&gt; 
&lt;p&gt;Godot is completely free and open source under the very permissive &lt;a href=&quot;https://godotengine.org/license&quot;&gt;MIT license&lt;/a&gt;. No strings attached, no royalties, nothing. The users&#39; games are theirs, down to the last line of engine code. Godot&#39;s development is fully independent and community-driven, empowering users to help shape their engine to match their expectations. It is supported by the &lt;a href=&quot;https://godot.foundation/&quot;&gt;Godot Foundation&lt;/a&gt; not-for-profit.&lt;/p&gt; 
&lt;p&gt;Before being open sourced in &lt;a href=&quot;https://github.com/godotengine/godot/commit/0b806ee0fc9097fa7bda7ac0109191c9c5e0a1ac&quot;&gt;February 2014&lt;/a&gt;, Godot had been developed by &lt;a href=&quot;https://github.com/reduz&quot;&gt;Juan Linietsky&lt;/a&gt; and &lt;a href=&quot;https://github.com/punto-&quot;&gt;Ariel Manzur&lt;/a&gt; (both still maintaining the project) for several years as an in-house engine, used to publish several work-for-hire titles.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/godotengine/godot-design/master/screenshots/editor_tps_demo_1920x1080.jpg&quot; alt=&quot;Screenshot of a 3D scene in the Godot Engine editor&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Getting the engine&lt;/h2&gt; 
&lt;h3&gt;Binary downloads&lt;/h3&gt; 
&lt;p&gt;Official binaries for the Godot editor and the export templates can be found &lt;a href=&quot;https://godotengine.org/download&quot;&gt;on the Godot website&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling from source&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.godotengine.org/en/latest/contributing/development/compiling&quot;&gt;See the official docs&lt;/a&gt; for compilation instructions for every supported platform.&lt;/p&gt; 
&lt;h2&gt;Community and contributing&lt;/h2&gt; 
&lt;p&gt;Godot is not only an engine but an ever-growing community of users and engine developers. The main community channels are listed &lt;a href=&quot;https://godotengine.org/community&quot;&gt;on the homepage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The best way to get in touch with the core engine developers is to join the &lt;a href=&quot;https://chat.godotengine.org&quot;&gt;Godot Contributors Chat&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started contributing to the project, see the &lt;a href=&quot;https://raw.githubusercontent.com/godotengine/godot/master/CONTRIBUTING.md&quot;&gt;contributing guide&lt;/a&gt;. This document also includes guidelines for reporting bugs.&lt;/p&gt; 
&lt;h2&gt;Documentation and demos&lt;/h2&gt; 
&lt;p&gt;The official documentation is hosted on &lt;a href=&quot;https://docs.godotengine.org&quot;&gt;Read the Docs&lt;/a&gt;. It is maintained by the Godot community in its own &lt;a href=&quot;https://github.com/godotengine/godot-docs&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href=&quot;https://docs.godotengine.org/en/latest/classes/&quot;&gt;class reference&lt;/a&gt; is also accessible from the Godot editor.&lt;/p&gt; 
&lt;p&gt;We also maintain official demos in their own &lt;a href=&quot;https://github.com/godotengine/godot-demo-projects&quot;&gt;GitHub repository&lt;/a&gt; as well as a list of &lt;a href=&quot;https://github.com/godotengine/awesome-godot&quot;&gt;awesome Godot community resources&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There are also a number of other &lt;a href=&quot;https://docs.godotengine.org/en/latest/community/tutorials.html&quot;&gt;learning resources&lt;/a&gt; provided by the community, such as text and video tutorials, demos, etc. Consult the &lt;a href=&quot;https://godotengine.org/community&quot;&gt;community channels&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.codetriage.com/godotengine/godot&quot;&gt;&lt;img src=&quot;https://www.codetriage.com/godotengine/godot/badges/users.svg?sanitize=true&quot; alt=&quot;Code Triagers Badge&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://hosted.weblate.org/engage/godot-engine/?utm_source=widget&quot;&gt;&lt;img src=&quot;https://hosted.weblate.org/widgets/godot-engine/-/godot/svg-badge.svg?sanitize=true&quot; alt=&quot;Translate on Weblate&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.tickgit.com/browse?repo=github.com/godotengine/godot&quot;&gt;&lt;img src=&quot;https://badgen.net/https/api.tickgit.com/badgen/github.com/godotengine/godot&quot; alt=&quot;TODOs&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>electron/electron</title>
      <link>https://github.com/electron/electron</link>
      <description>&lt;p&gt;Build cross-platform desktop apps with JavaScript, HTML, and CSS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://electronjs.org&quot;&gt;&lt;img src=&quot;https://electronjs.org/images/electron-logo.svg?sanitize=true&quot; alt=&quot;Electron Logo&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/electron/electron/actions/workflows/build.yml&quot;&gt;&lt;img src=&quot;https://github.com/electron/electron/actions/workflows/build.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/electronjs&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/745037351163527189?color=%237289DA&amp;amp;label=chat&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Electron Discord Invite&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;📝&lt;/span&gt; Available Translations: 🇨🇳 🇧🇷 🇪🇸 🇯🇵 🇷🇺 🇫🇷 🇺🇸 🇩🇪. View these docs in other languages on our &lt;a href=&quot;https://crowdin.com/project/electron&quot;&gt;Crowdin&lt;/a&gt; project.&lt;/p&gt; 
&lt;p&gt;The Electron framework lets you write cross-platform desktop applications using JavaScript, HTML and CSS. It is based on &lt;a href=&quot;https://nodejs.org/&quot;&gt;Node.js&lt;/a&gt; and &lt;a href=&quot;https://www.chromium.org&quot;&gt;Chromium&lt;/a&gt; and is used by the &lt;a href=&quot;https://github.com/Microsoft/vscode/&quot;&gt;Visual Studio Code&lt;/a&gt; and many other &lt;a href=&quot;https://electronjs.org/apps&quot;&gt;apps&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Follow &lt;a href=&quot;https://twitter.com/electronjs&quot;&gt;@electronjs&lt;/a&gt; on Twitter for important announcements.&lt;/p&gt; 
&lt;p&gt;This project adheres to the Contributor Covenant &lt;a href=&quot;https://github.com/electron/electron/tree/main/CODE_OF_CONDUCT.md&quot;&gt;code of conduct&lt;/a&gt;. By participating, you are expected to uphold this code. Please report unacceptable behavior to &lt;a href=&quot;mailto:coc@electronjs.org&quot;&gt;coc@electronjs.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install prebuilt Electron binaries, use &lt;a href=&quot;https://docs.npmjs.com/&quot;&gt;&lt;code&gt;npm&lt;/code&gt;&lt;/a&gt;. The preferred method is to install Electron as a development dependency in your app:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;npm install electron --save-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options and troubleshooting tips, see &lt;a href=&quot;https://raw.githubusercontent.com/electron/electron/main/docs/tutorial/installation.md&quot;&gt;installation&lt;/a&gt;. For info on how to manage Electron versions in your apps, see &lt;a href=&quot;https://raw.githubusercontent.com/electron/electron/main/docs/tutorial/electron-versioning.md&quot;&gt;Electron versioning&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;Each Electron release provides binaries for macOS, Windows, and Linux.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS (Big Sur and up): Electron provides 64-bit Intel and Apple Silicon / ARM binaries for macOS.&lt;/li&gt; 
 &lt;li&gt;Windows (Windows 10 and up): Electron provides &lt;code&gt;ia32&lt;/code&gt; (&lt;code&gt;x86&lt;/code&gt;), &lt;code&gt;x64&lt;/code&gt; (&lt;code&gt;amd64&lt;/code&gt;), and &lt;code&gt;arm64&lt;/code&gt; binaries for Windows. Windows on ARM support was added in Electron 5.0.8. Support for Windows 7, 8 and 8.1 was &lt;a href=&quot;https://www.electronjs.org/blog/windows-7-to-8-1-deprecation-notice&quot;&gt;removed in Electron 23, in line with Chromium&#39;s Windows deprecation policy&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Linux: The prebuilt binaries of Electron are built on Ubuntu 20.04. They have also been verified to work on: 
  &lt;ul&gt; 
   &lt;li&gt;Ubuntu 18.04 and newer&lt;/li&gt; 
   &lt;li&gt;Fedora 32 and newer&lt;/li&gt; 
   &lt;li&gt;Debian 10 and newer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Electron Fiddle&lt;/h2&gt; 
&lt;p&gt;Use &lt;a href=&quot;https://github.com/electron/fiddle&quot;&gt;&lt;code&gt;Electron Fiddle&lt;/code&gt;&lt;/a&gt; to build, run, and package small Electron experiments, to see code examples for all of Electron&#39;s APIs, and to try out different versions of Electron. It&#39;s designed to make the start of your journey with Electron easier.&lt;/p&gt; 
&lt;h2&gt;Resources for learning Electron&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://electronjs.org/docs&quot;&gt;electronjs.org/docs&lt;/a&gt; - All of Electron&#39;s documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/electron/fiddle&quot;&gt;electron/fiddle&lt;/a&gt; - A tool to build, run, and package small Electron experiments&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://electronjs.org/community#boilerplates&quot;&gt;electronjs.org/community#boilerplates&lt;/a&gt; - Sample starter apps created by the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Programmatic usage&lt;/h2&gt; 
&lt;p&gt;Most people use Electron from the command line, but if you require &lt;code&gt;electron&lt;/code&gt; inside your &lt;strong&gt;Node app&lt;/strong&gt; (not your Electron app) it will return the file path to the binary. Use this to spawn Electron from Node scripts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const electron = require(&#39;electron&#39;)
const proc = require(&#39;node:child_process&#39;)

// will print something similar to /Users/maf/.../Electron
console.log(electron)

// spawn Electron
const child = proc.spawn(electron)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Mirrors&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://npmmirror.com/mirrors/electron/&quot;&gt;China&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://www.electronjs.org/docs/latest/tutorial/installation#mirror&quot;&gt;Advanced Installation Instructions&lt;/a&gt; to learn how to use a custom mirror.&lt;/p&gt; 
&lt;h2&gt;Documentation translations&lt;/h2&gt; 
&lt;p&gt;We crowdsource translations for our documentation via &lt;a href=&quot;https://crowdin.com/project/electron&quot;&gt;Crowdin&lt;/a&gt;. We currently accept translations for Chinese (Simplified), French, German, Japanese, Portuguese, Russian, and Spanish.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you are interested in reporting/fixing issues and contributing directly to the code base, please see &lt;a href=&quot;https://raw.githubusercontent.com/electron/electron/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for more information on what we&#39;re looking for and how to get started.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Info on reporting bugs, getting help, finding third-party tools and sample apps, and more can be found on the &lt;a href=&quot;https://www.electronjs.org/community&quot;&gt;Community page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/electron/electron/raw/main/LICENSE&quot;&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;When using Electron logos, make sure to follow &lt;a href=&quot;https://trademark-policy.openjsf.org/&quot;&gt;OpenJS Foundation Trademark Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ggml-org/llama.cpp</title>
      <link>https://github.com/ggml-org/llama.cpp</link>
      <description>&lt;p&gt;LLM inference in C/C++&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llama.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png&quot; alt=&quot;llama&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&quot; alt=&quot;License: MIT&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/ggml-org/llama.cpp&quot; alt=&quot;Release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml&quot;&gt;&lt;img src=&quot;https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg?sanitize=true&quot; alt=&quot;Server&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/205&quot;&gt;Manifesto&lt;/a&gt; / &lt;a href=&quot;https://github.com/ggml-org/ggml&quot;&gt;ggml&lt;/a&gt; / &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/raw/master/docs/ops.md&quot;&gt;ops&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;LLM inference in C/C++&lt;/p&gt; 
&lt;h2&gt;Recent API changes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/issues/9289&quot;&gt;Changelog for &lt;code&gt;libllama&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/issues/9291&quot;&gt;Changelog for &lt;code&gt;llama-server&lt;/code&gt; REST API&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hot topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for the &lt;code&gt;gpt-oss&lt;/code&gt; model with native MXFP4 format has been added | &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/15091&quot;&gt;PR&lt;/a&gt; | &lt;a href=&quot;https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss&quot;&gt;Collaboration with NVIDIA&lt;/a&gt; | &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/15095&quot;&gt;Comment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hot PRs: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pulls?q=is%3Apr+label%3Ahot+&quot;&gt;All&lt;/a&gt; | &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pulls?q=is%3Apr+label%3Ahot+is%3Aopen&quot;&gt;Open&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Multimodal support arrived in &lt;code&gt;llama-server&lt;/code&gt;: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/12898&quot;&gt;#12898&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/multimodal.md&quot;&gt;documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code extension for FIM completions: &lt;a href=&quot;https://github.com/ggml-org/llama.vscode&quot;&gt;https://github.com/ggml-org/llama.vscode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Vim/Neovim plugin for FIM completions: &lt;a href=&quot;https://github.com/ggml-org/llama.vim&quot;&gt;https://github.com/ggml-org/llama.vim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Introducing GGUF-my-LoRA &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/10123&quot;&gt;https://github.com/ggml-org/llama.cpp/discussions/10123&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face Inference Endpoints now support GGUF out of the box! &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/9669&quot;&gt;https://github.com/ggml-org/llama.cpp/discussions/9669&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face GGUF editor: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/9268&quot;&gt;discussion&lt;/a&gt; | &lt;a href=&quot;https://huggingface.co/spaces/CISCai/gguf-editor&quot;&gt;tool&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Getting started with llama.cpp is straightforward. Here are several ways to install it on your machine:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;llama.cpp&lt;/code&gt; using &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/install.md&quot;&gt;brew, nix or winget&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run with Docker - see our &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/docker.md&quot;&gt;Docker documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download pre-built binaries from the &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/releases&quot;&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Build from source by cloning this repository - check out &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md&quot;&gt;our build guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once installed, you&#39;ll need a model to work with. Head to the &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/#obtaining-and-quantizing-models&quot;&gt;Obtaining and quantizing models&lt;/a&gt; section to learn more.&lt;/p&gt; 
&lt;p&gt;Example command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;# Use a local model file
llama-cli -m my_model.gguf

# Or download and run a model directly from Hugging Face
llama-cli -hf ggml-org/gemma-3-1b-it-GGUF

# Launch OpenAI-compatible API server
llama-server -hf ggml-org/gemma-3-1b-it-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Description&lt;/h2&gt; 
&lt;p&gt;The main goal of &lt;code&gt;llama.cpp&lt;/code&gt; is to enable LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware - locally and in the cloud.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Plain C/C++ implementation without any dependencies&lt;/li&gt; 
 &lt;li&gt;Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks&lt;/li&gt; 
 &lt;li&gt;AVX, AVX2, AVX512 and AMX support for x86 architectures&lt;/li&gt; 
 &lt;li&gt;1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use&lt;/li&gt; 
 &lt;li&gt;Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)&lt;/li&gt; 
 &lt;li&gt;Vulkan and SYCL backend support&lt;/li&gt; 
 &lt;li&gt;CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;llama.cpp&lt;/code&gt; project is the main playground for developing new features for the &lt;a href=&quot;https://github.com/ggml-org/ggml&quot;&gt;ggml&lt;/a&gt; library.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Models&lt;/summary&gt; 
 &lt;p&gt;Typically finetunes of the base models below are supported as well.&lt;/p&gt; 
 &lt;p&gt;Instructions for adding support for new models: &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/development/HOWTO-add-model.md&quot;&gt;HOWTO-add-model.md&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Text-only&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; LLaMA 🦙&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; LLaMA 2 🦙🦙&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; LLaMA 3 🦙🦙🦙&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/mistralai/Mistral-7B-v0.1&quot;&gt;Mistral 7B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=mistral-ai/Mixtral&quot;&gt;Mixtral MoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/databricks/dbrx-instruct&quot;&gt;DBRX&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=tiiuae/falcon&quot;&gt;Falcon&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ymcui/Chinese-LLaMA-Alpaca&quot;&gt;Chinese LLaMA / Alpaca&lt;/a&gt; and &lt;a href=&quot;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&quot;&gt;Chinese LLaMA-2 / Alpaca-2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/bofenghuang/vigogne&quot;&gt;Vigogne (French)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/5423&quot;&gt;BERT&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://bair.berkeley.edu/blog/2023/04/03/koala/&quot;&gt;Koala&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=baichuan-inc/Baichuan&quot;&gt;Baichuan 1 &amp;amp; 2&lt;/a&gt; + &lt;a href=&quot;https://huggingface.co/hiyouga/baichuan-7b-sft&quot;&gt;derivations&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=BAAI/Aquila&quot;&gt;Aquila 1 &amp;amp; 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/3187&quot;&gt;Starcoder models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/smallcloudai/Refact-1_6B-fim&quot;&gt;Refact&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/3417&quot;&gt;MPT&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/3553&quot;&gt;Bloom&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=01-ai/Yi&quot;&gt;Yi models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/stabilityai&quot;&gt;StableLM models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=deepseek-ai/deepseek&quot;&gt;Deepseek models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=Qwen/Qwen&quot;&gt;Qwen models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/3557&quot;&gt;PLaMo-13B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=microsoft/phi&quot;&gt;Phi models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/11003&quot;&gt;PhiMoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/gpt2&quot;&gt;GPT-2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/5118&quot;&gt;Orion 14B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=internlm2&quot;&gt;InternLM2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/WisdomShell/codeshell&quot;&gt;CodeShell&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://ai.google.dev/gemma&quot;&gt;Gemma&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/state-spaces/mamba&quot;&gt;Mamba&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/keyfan/grok-1-hf&quot;&gt;Grok-1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=xverse&quot;&gt;Xverse&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=CohereForAI/c4ai-command-r&quot;&gt;Command-R models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=sea-lion&quot;&gt;SEA-LION&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/GritLM/GritLM-7B&quot;&gt;GritLM-7B&lt;/a&gt; + &lt;a href=&quot;https://huggingface.co/GritLM/GritLM-8x7B&quot;&gt;GritLM-8x7B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://allenai.org/olmo&quot;&gt;OLMo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://allenai.org/olmo&quot;&gt;OLMo 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/allenai/OLMoE-1B-7B-0924&quot;&gt;OLMoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330&quot;&gt;Granite models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/EleutherAI/gpt-neox&quot;&gt;GPT-NeoX&lt;/a&gt; + &lt;a href=&quot;https://github.com/EleutherAI/pythia&quot;&gt;Pythia&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520&quot;&gt;Snowflake-Arctic MoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=Smaug&quot;&gt;Smaug&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/LumiOpen/Poro-34B&quot;&gt;Poro 34B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/1bitLLM&quot;&gt;Bitnet b1.58 models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=flan-t5&quot;&gt;Flan T5&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca&quot;&gt;Open Elm models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/THUDM/chatglm3-6b&quot;&gt;ChatGLM3-6b&lt;/a&gt; + &lt;a href=&quot;https://huggingface.co/THUDM/glm-4-9b&quot;&gt;ChatGLM4-9b&lt;/a&gt; + &lt;a href=&quot;https://huggingface.co/THUDM/glm-edge-1.5b-chat&quot;&gt;GLMEdge-1.5b&lt;/a&gt; + &lt;a href=&quot;https://huggingface.co/THUDM/glm-edge-4b-chat&quot;&gt;GLMEdge-4b&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e&quot;&gt;GLM-4-0414&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966&quot;&gt;SmolLM&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct&quot;&gt;EXAONE-3.0-7.8B-Instruct&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a&quot;&gt;FalconMamba Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/inceptionai/jais-13b-chat&quot;&gt;Jais&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a&quot;&gt;Bielik-11B-v2.3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/BlinkDL/RWKV-LM&quot;&gt;RWKV-6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1&quot;&gt;QRWKV-6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct&quot;&gt;GigaChat-20B-A3B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/trillionlabs/Trillion-7B-preview&quot;&gt;Trillion-7B-preview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32&quot;&gt;Ling models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38&quot;&gt;LFM2 models&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Multimodal&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e&quot;&gt;LLaVA 1.5 models&lt;/a&gt;, &lt;a href=&quot;https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2&quot;&gt;LLaVA 1.6 models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=SkunkworksAI/Bakllava&quot;&gt;BakLLaVA&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/NousResearch/Obsidian-3B-V0.5&quot;&gt;Obsidian&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=Lin-Chen/ShareGPT4V&quot;&gt;ShareGPT4V&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=mobileVLM&quot;&gt;MobileVLM 1.7B/3B models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=Yi-VL&quot;&gt;Yi-VL&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=MiniCPM&quot;&gt;Mini CPM&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/vikhyatk/moondream2&quot;&gt;Moondream&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://github.com/BAAI-DCAI/Bunny&quot;&gt;Bunny&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/models?search=glm-edge&quot;&gt;GLM-EDGE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d&quot;&gt;Qwen2-VL&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Bindings&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Python: &lt;a href=&quot;https://github.com/ddh0/easy-llama&quot;&gt;ddh0/easy-llama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Python: &lt;a href=&quot;https://github.com/abetlen/llama-cpp-python&quot;&gt;abetlen/llama-cpp-python&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Go: &lt;a href=&quot;https://github.com/go-skynet/go-llama.cpp&quot;&gt;go-skynet/go-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Node.js: &lt;a href=&quot;https://github.com/withcatai/node-llama-cpp&quot;&gt;withcatai/node-llama-cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JS/TS (llama.cpp server client): &lt;a href=&quot;https://modelfusion.dev/integration/model-provider/llamacpp&quot;&gt;lgrammel/modelfusion&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JS/TS (Programmable Prompt Engine CLI): &lt;a href=&quot;https://github.com/offline-ai/cli&quot;&gt;offline-ai/cli&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JavaScript/Wasm (works in browser): &lt;a href=&quot;https://github.com/tangledgroup/llama-cpp-wasm&quot;&gt;tangledgroup/llama-cpp-wasm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Typescript/Wasm (nicer API, available on npm): &lt;a href=&quot;https://github.com/ngxson/wllama&quot;&gt;ngxson/wllama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ruby: &lt;a href=&quot;https://github.com/yoshoku/llama_cpp.rb&quot;&gt;yoshoku/llama_cpp.rb&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (more features): &lt;a href=&quot;https://github.com/edgenai/llama_cpp-rs&quot;&gt;edgenai/llama_cpp-rs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (nicer API): &lt;a href=&quot;https://github.com/mdrokz/rust-llama.cpp&quot;&gt;mdrokz/rust-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (more direct bindings): &lt;a href=&quot;https://github.com/utilityai/llama-cpp-rs&quot;&gt;utilityai/llama-cpp-rs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (automated build from crates.io): &lt;a href=&quot;https://github.com/ShelbyJenkins/llm_client&quot;&gt;ShelbyJenkins/llm_client&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;C#/.NET: &lt;a href=&quot;https://github.com/SciSharp/LLamaSharp&quot;&gt;SciSharp/LLamaSharp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;C#/VB.NET (more features - community license): &lt;a href=&quot;https://docs.lm-kit.com/lm-kit-net/index.html&quot;&gt;LM-Kit.NET&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Scala 3: &lt;a href=&quot;https://github.com/donderom/llm4s&quot;&gt;donderom/llm4s&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Clojure: &lt;a href=&quot;https://github.com/phronmophobic/llama.clj&quot;&gt;phronmophobic/llama.clj&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;React Native: &lt;a href=&quot;https://github.com/mybigday/llama.rn&quot;&gt;mybigday/llama.rn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Java: &lt;a href=&quot;https://github.com/kherud/java-llama.cpp&quot;&gt;kherud/java-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zig: &lt;a href=&quot;https://github.com/Deins/llama.cpp.zig&quot;&gt;deins/llama.cpp.zig&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Flutter/Dart: &lt;a href=&quot;https://github.com/netdur/llama_cpp_dart&quot;&gt;netdur/llama_cpp_dart&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Flutter: &lt;a href=&quot;https://github.com/xuegao-tzx/Fllama&quot;&gt;xuegao-tzx/Fllama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;PHP (API bindings and features built on top of llama.cpp): &lt;a href=&quot;https://github.com/distantmagic/resonance&quot;&gt;distantmagic/resonance&lt;/a&gt; &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/pull/6326&quot;&gt;(more info)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Guile Scheme: &lt;a href=&quot;https://savannah.nongnu.org/projects/guile-llama-cpp&quot;&gt;guile_llama_cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Swift &lt;a href=&quot;https://github.com/srgtuszy/llama-cpp-swift&quot;&gt;srgtuszy/llama-cpp-swift&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Swift &lt;a href=&quot;https://github.com/ShenghaiWang/SwiftLlama&quot;&gt;ShenghaiWang/SwiftLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Delphi &lt;a href=&quot;https://github.com/Embarcadero/llama-cpp-delphi&quot;&gt;Embarcadero/llama-cpp-delphi&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;UIs&lt;/summary&gt; 
 &lt;p&gt;&lt;em&gt;(to have a project listed here, it should clearly state that it depends on &lt;code&gt;llama.cpp&lt;/code&gt;)&lt;/em&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/yaroslavyaroslav/OpenAI-sublime-text&quot;&gt;AI Sublime Text plugin&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/cztomsik/ava&quot;&gt;cztomsik/ava&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/alexpinel/Dot&quot;&gt;Dot&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/ylsdamxssjxxdd/eva&quot;&gt;eva&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/iohub/coLLaMA&quot;&gt;iohub/collama&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/janhq/jan&quot;&gt;janhq/jan&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/johnbean393/Sidekick&quot;&gt;johnbean393/Sidekick&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/zhouwg/kantv?tab=readme-ov-file&quot;&gt;KanTV&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/firatkiral/kodibot&quot;&gt;KodiBot&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.vim&quot;&gt;llama.vim&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/abgulati/LARS&quot;&gt;LARS&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/vietanhdev/llama-assistant&quot;&gt;Llama Assistant&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/guinmoon/LLMFarm?tab=readme-ov-file&quot;&gt;LLMFarm&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/undreamai/LLMUnity&quot;&gt;LLMUnity&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://lmstudio.ai/&quot;&gt;LMStudio&lt;/a&gt; (proprietary)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/mudler/LocalAI&quot;&gt;LocalAI&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/LostRuins/koboldcpp&quot;&gt;LostRuins/koboldcpp&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://mindmac.app&quot;&gt;MindMac&lt;/a&gt; (proprietary)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/MindWorkAI/AI-Studio&quot;&gt;MindWorkAI/AI-Studio&lt;/a&gt; (FSL-1.1-MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/Mobile-Artificial-Intelligence/maid&quot;&gt;Mobile-Artificial-Intelligence/maid&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/Mozilla-Ocho/llamafile&quot;&gt;Mozilla-Ocho/llamafile&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/nat/openplayground&quot;&gt;nat/openplayground&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/nomic-ai/gpt4all&quot;&gt;nomic-ai/gpt4all&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/ollama/ollama&quot;&gt;ollama/ollama&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/oobabooga/text-generation-webui&quot;&gt;oobabooga/text-generation-webui&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/a-ghorbani/pocketpal-ai&quot;&gt;PocketPal AI&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/psugihara/FreeChat&quot;&gt;psugihara/FreeChat&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/ptsochantaris/emeltal&quot;&gt;ptsochantaris/emeltal&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/pythops/tenere&quot;&gt;pythops/tenere&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/containers/ramalama&quot;&gt;ramalama&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/semperai/amica&quot;&gt;semperai/amica&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/withcatai/catai&quot;&gt;withcatai/catai&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/blackhole89/autopen&quot;&gt;Autopen&lt;/a&gt; (GPL)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Tools&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/akx/ggify&quot;&gt;akx/ggify&lt;/a&gt; – download PyTorch models from HuggingFace Hub and convert them to GGML&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/akx/ollama-dl&quot;&gt;akx/ollama-dl&lt;/a&gt; – download models from the Ollama library to be used directly with llama.cpp&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/crashr/gppm&quot;&gt;crashr/gppm&lt;/a&gt; – launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser&quot;&gt;gpustack/gguf-parser&lt;/a&gt; - review/check the GGUF file and estimate the memory usage&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902&quot;&gt;Styled Lines&lt;/a&gt; (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Infrastructure&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/intentee/paddler&quot;&gt;Paddler&lt;/a&gt; - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/gpustack/gpustack&quot;&gt;GPUStack&lt;/a&gt; - Manage GPU clusters for running LLMs&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/onicai/llama_cpp_canister&quot;&gt;llama_cpp_canister&lt;/a&gt; - llama.cpp as a smart contract on the Internet Computer, using WebAssembly&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/mostlygeek/llama-swap&quot;&gt;llama-swap&lt;/a&gt; - transparent proxy that adds automatic model switching with llama-server&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/kalavai-net/kalavai-client&quot;&gt;Kalavai&lt;/a&gt; - Crowdsource end to end LLM deployment at any scale&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/InftyAI/llmaz&quot;&gt;llmaz&lt;/a&gt; - ☸️ Easy, advanced inference platform for large language models on Kubernetes.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Games&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://github.com/MorganRO8/Lucys_Labyrinth&quot;&gt;Lucy&#39;s Labyrinth&lt;/a&gt; - A simple maze game where agents controlled by an AI model will try to trick you.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Supported backends&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Target devices&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#metal-build&quot;&gt;Metal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#blas-build&quot;&gt;BLAS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/BLIS.md&quot;&gt;BLIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/SYCL.md&quot;&gt;SYCL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Intel and Nvidia GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#musa&quot;&gt;MUSA&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Moore Threads GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#cuda&quot;&gt;CUDA&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Nvidia GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#hip&quot;&gt;HIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#vulkan&quot;&gt;Vulkan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#cann&quot;&gt;CANN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ascend NPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/OPENCL.md&quot;&gt;OpenCL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Adreno GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#webgpu&quot;&gt;WebGPU [In Progress]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc&quot;&gt;RPC&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Obtaining and quantizing models&lt;/h2&gt; 
&lt;p&gt;The &lt;a href=&quot;https://huggingface.co&quot;&gt;Hugging Face&lt;/a&gt; platform hosts a &lt;a href=&quot;https://huggingface.co/models?library=gguf&amp;amp;sort=trending&quot;&gt;number of LLMs&lt;/a&gt; compatible with &lt;code&gt;llama.cpp&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://huggingface.co/models?library=gguf&amp;amp;sort=trending&quot;&gt;Trending&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://huggingface.co/models?sort=trending&amp;amp;search=llama+gguf&quot;&gt;LLaMA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can either manually download the GGUF file or directly use any &lt;code&gt;llama.cpp&lt;/code&gt;-compatible models from &lt;a href=&quot;https://huggingface.co/&quot;&gt;Hugging Face&lt;/a&gt; or other model hosting sites, such as &lt;a href=&quot;https://modelscope.cn/&quot;&gt;ModelScope&lt;/a&gt;, by using this CLI argument: &lt;code&gt;-hf &amp;lt;user&amp;gt;/&amp;lt;model&amp;gt;[:quant]&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;llama-cli -hf ggml-org/gemma-3-1b-it-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, the CLI would download from Hugging Face, you can switch to other options with the environment variable &lt;code&gt;MODEL_ENDPOINT&lt;/code&gt;. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. &lt;code&gt;MODEL_ENDPOINT=https://www.modelscope.cn/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading a model, use the CLI tools to run it locally - see below.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;llama.cpp&lt;/code&gt; requires the model to be stored in the &lt;a href=&quot;https://github.com/ggml-org/ggml/raw/master/docs/gguf.md&quot;&gt;GGUF&lt;/a&gt; file format. Models in other data formats can be converted to GGUF using the &lt;code&gt;convert_*.py&lt;/code&gt; Python scripts in this repo.&lt;/p&gt; 
&lt;p&gt;The Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with &lt;code&gt;llama.cpp&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href=&quot;https://huggingface.co/spaces/ggml-org/gguf-my-repo&quot;&gt;GGUF-my-repo space&lt;/a&gt; to convert to GGUF format and quantize model weights to smaller sizes&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href=&quot;https://huggingface.co/spaces/ggml-org/gguf-my-lora&quot;&gt;GGUF-my-LoRA space&lt;/a&gt; to convert LoRA adapters to GGUF format (more info: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/10123&quot;&gt;https://github.com/ggml-org/llama.cpp/discussions/10123&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href=&quot;https://huggingface.co/spaces/CISCai/gguf-editor&quot;&gt;GGUF-editor space&lt;/a&gt; to edit GGUF meta data in the browser (more info: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/9268&quot;&gt;https://github.com/ggml-org/llama.cpp/discussions/9268&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href=&quot;https://ui.endpoints.huggingface.co/&quot;&gt;Inference Endpoints&lt;/a&gt; to directly host &lt;code&gt;llama.cpp&lt;/code&gt; in the cloud (more info: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/9669&quot;&gt;https://github.com/ggml-org/llama.cpp/discussions/9669&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more about model quantization, &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/quantize/README.md&quot;&gt;read this documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/main&quot;&gt;&lt;code&gt;llama-cli&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A CLI tool for accessing and experimenting with most of &lt;code&gt;llama.cpp&lt;/code&gt;&#39;s functionality.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Run in conversation mode&lt;/summary&gt; 
   &lt;p&gt;Models with a built-in chat template will automatically activate conversation mode. If this doesn&#39;t occur, you can manually enable it by adding &lt;code&gt;-cnv&lt;/code&gt; and specifying a suitable chat template with &lt;code&gt;--chat-template NAME&lt;/code&gt;&lt;/p&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-cli -m model.gguf

# &amp;gt; hi, who are you?
# Hi there! I&#39;m your helpful assistant! I&#39;m an AI-powered chatbot designed to assist and provide information to users like you. I&#39;m here to help answer your questions, provide guidance, and offer support on a wide range of topics. I&#39;m a friendly and knowledgeable AI, and I&#39;m always happy to help with anything you need. What&#39;s on your mind, and how can I assist you today?
#
# &amp;gt; what is 1+1?
# Easy peasy! The answer to 1+1 is... 2!
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run in conversation mode with custom chat template&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# use the &quot;chatml&quot; template (use -h to see the list of supported templates)
llama-cli -m model.gguf -cnv --chat-template chatml

# use a custom template
llama-cli -m model.gguf -cnv --in-prefix &#39;User: &#39; --reverse-prompt &#39;User:&#39;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run simple text completion&lt;/summary&gt; 
   &lt;p&gt;To disable conversation mode explicitly, use &lt;code&gt;-no-cnv&lt;/code&gt;&lt;/p&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-cli -m model.gguf -p &quot;I believe the meaning of life is&quot; -n 128 -no-cnv

# I believe the meaning of life is to find your own truth and to live in accordance with it. For me, this means being true to myself and following my passions, even if they don&#39;t align with societal expectations. I think that&#39;s what I love about yoga – it&#39;s not just a physical practice, but a spiritual one too. It&#39;s about connecting with yourself, listening to your inner voice, and honoring your own unique journey.
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Constrain the output with a custom grammar&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p &#39;Request: schedule a call at 8pm; Command:&#39;

# {&quot;appointmentTime&quot;: &quot;8pm&quot;, &quot;appointmentDetails&quot;: &quot;schedule a a call&quot;}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/&quot;&gt;grammars/&lt;/a&gt; folder contains a handful of sample grammars. To write your own, check out the &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/README.md&quot;&gt;GBNF Guide&lt;/a&gt;.&lt;/p&gt; 
   &lt;p&gt;For authoring more complex JSON grammars, check out &lt;a href=&quot;https://grammar.intrinsiclabs.ai/&quot;&gt;https://grammar.intrinsiclabs.ai/&lt;/a&gt;&lt;/p&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/server&quot;&gt;&lt;code&gt;llama-server&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A lightweight, &lt;a href=&quot;https://github.com/openai/openai-openapi&quot;&gt;OpenAI API&lt;/a&gt; compatible, HTTP server for serving LLMs.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Start a local HTTP server with default configuration on port 8080&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-server -m model.gguf --port 8080

# Basic web UI can be accessed via browser: http://localhost:8080
# Chat completion endpoint: http://localhost:8080/v1/chat/completions
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Support multiple-users and parallel decoding&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# up to 4 concurrent requests, each with 4096 max context
llama-server -m model.gguf -c 16384 -np 4
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Enable speculative decoding&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# the draft.gguf model should be a small variant of the target model.gguf
llama-server -m model.gguf -md draft.gguf
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Serve an embedding model&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# use the /embedding endpoint
llama-server -m model.gguf --embedding --pooling cls -ub 8192
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Serve a reranking model&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# use the /reranking endpoint
llama-server -m model.gguf --reranking
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Constrain all outputs with a grammar&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# custom grammar
llama-server -m model.gguf --grammar-file grammar.gbnf

# JSON
llama-server -m model.gguf --grammar-file grammars/json.gbnf
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/perplexity&quot;&gt;&lt;code&gt;llama-perplexity&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A tool for measuring the &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/perplexity/README.md&quot;&gt;perplexity&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/%5Bhttps://huggingface.co/docs/transformers/perplexity%5D(https://huggingface.co/docs/transformers/perplexity)&quot;&gt;^1&lt;/a&gt; (and other quality metrics) of a model over a given text.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Measure the perplexity over a text file&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-perplexity -m model.gguf -f file.txt

# [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...
# Final estimate: PPL = 5.4007 +/- 0.67339
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Measure KL divergence&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# TODO
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/llama-bench&quot;&gt;&lt;code&gt;llama-bench&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;Benchmark the performance of the inference for various parameters.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Run default benchmark&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-bench -m model.gguf

# Output:
# | model               |       size |     params | backend    | threads |          test |                  t/s |
# | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |
# | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 ± 20.55 |
# | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 ± 0.81 |
#
# build: 3e0ba0e60 (4229)
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/run&quot;&gt;&lt;code&gt;llama-run&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A comprehensive example for running &lt;code&gt;llama.cpp&lt;/code&gt; models. Useful for inferencing. Used with RamaLama &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/%5BRamaLama%5D(https://github.com/containers/ramalama)&quot;&gt;^3&lt;/a&gt;.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run a model with a specific prompt (by default it&#39;s pulled from Ollama registry)&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-run granite-code
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/examples/simple&quot;&gt;&lt;code&gt;llama-simple&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A minimal example for implementing apps with &lt;code&gt;llama.cpp&lt;/code&gt;. Useful for developers.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Basic text completion&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;llama-simple -m model.gguf

# Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called &quot;The Art of
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Contributors can open PRs&lt;/li&gt; 
 &lt;li&gt;Collaborators can push to branches in the &lt;code&gt;llama.cpp&lt;/code&gt; repo and merge PRs into the &lt;code&gt;master&lt;/code&gt; branch&lt;/li&gt; 
 &lt;li&gt;Collaborators will be invited based on contributions&lt;/li&gt; 
 &lt;li&gt;Any help with managing issues, PRs and projects is very appreciated!&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;good first issues&lt;/a&gt; for tasks suitable for first contributions&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for more information&lt;/li&gt; 
 &lt;li&gt;Make sure to read this: &lt;a href=&quot;https://github.com/ggml-org/llama.cpp/discussions/205&quot;&gt;Inference at the edge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;A bit of backstory for those who are interested: &lt;a href=&quot;https://changelog.com/podcast/532&quot;&gt;Changelog podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/main/README.md&quot;&gt;main (cli)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/server/README.md&quot;&gt;server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/README.md&quot;&gt;GBNF grammars&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development documentation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md&quot;&gt;How to build&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/docker.md&quot;&gt;Running on Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/android.md&quot;&gt;Build on Android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/development/token_generation_performance_tips.md&quot;&gt;Performance troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&amp;amp;-Tricks&quot;&gt;GGML tips &amp;amp; tricks&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Seminal papers and background on the models&lt;/h4&gt; 
&lt;p&gt;If your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLaMA: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://ai.facebook.com/blog/large-language-model-llama-meta-ai/&quot;&gt;Introducing LLaMA: A foundational, 65-billion-parameter large language model&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2302.13971&quot;&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;GPT-3 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2005.14165&quot;&gt;Language Models are Few-Shot Learners&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;GPT-3.5 / InstructGPT / ChatGPT: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://openai.com/research/instruction-following&quot;&gt;Aligning language models to follow instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2203.02155&quot;&gt;Training language models to follow instructions with human feedback&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;XCFramework&lt;/h2&gt; 
&lt;p&gt;The XCFramework is a precompiled version of the library for iOS, visionOS, tvOS, and macOS. It can be used in Swift projects without the need to compile the library from source. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;// swift-tools-version: 5.10
// The swift-tools-version declares the minimum version of Swift required to build this package.

import PackageDescription

let package = Package(
    name: &quot;MyLlamaPackage&quot;,
    targets: [
        .executableTarget(
            name: &quot;MyLlamaPackage&quot;,
            dependencies: [
                &quot;LlamaFramework&quot;
            ]),
        .binaryTarget(
            name: &quot;LlamaFramework&quot;,
            url: &quot;https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip&quot;,
            checksum: &quot;c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab&quot;
        )
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above example is using an intermediate build &lt;code&gt;b5046&lt;/code&gt; of the library. This can be modified to use a different version by changing the URL and checksum.&lt;/p&gt; 
&lt;h2&gt;Completions&lt;/h2&gt; 
&lt;p&gt;Command-line completion is available for some environments.&lt;/p&gt; 
&lt;h4&gt;Bash Completion&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ build/bin/llama-cli --completion-bash &amp;gt; ~/.llama-completion.bash
$ source ~/.llama-completion.bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally this can be added to your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt; to load it automatically. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-console&quot;&gt;$ echo &quot;source ~/.llama-completion.bash&quot; &amp;gt;&amp;gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/yhirose/cpp-httplib&quot;&gt;yhirose/cpp-httplib&lt;/a&gt; - Single-header HTTP server, used by &lt;code&gt;llama-server&lt;/code&gt; - MIT license&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nothings/stb&quot;&gt;stb-image&lt;/a&gt; - Single-header image format decoder, used by multimodal subsystem - Public domain&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nlohmann/json&quot;&gt;nlohmann/json&lt;/a&gt; - Single-header JSON library, used by various tools/examples - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/google/minja&quot;&gt;minja&lt;/a&gt; - Minimal Jinja parser in C++, used by various tools/examples - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/run/linenoise.cpp/linenoise.cpp&quot;&gt;linenoise.cpp&lt;/a&gt; - C++ library that provides readline-like line editing capabilities, used by &lt;code&gt;llama-run&lt;/code&gt; - BSD 2-Clause License&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://curl.se/&quot;&gt;curl&lt;/a&gt; - Client-side URL transfer library, used by various tools/examples - &lt;a href=&quot;https://curl.se/docs/copyright.html&quot;&gt;CURL License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mackron/miniaudio&quot;&gt;miniaudio.h&lt;/a&gt; - Single-header audio format decoder, used by multimodal subsystem - Public domain&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>amnezia-vpn/amnezia-client</title>
      <link>https://github.com/amnezia-vpn/amnezia-client</link>
      <description>&lt;p&gt;Amnezia VPN Client (Desktop+Mobile)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amnezia VPN&lt;/h1&gt; 
&lt;h3&gt;&lt;em&gt;The best client for self-hosted VPN&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml?query=branch:dev&quot;&gt;&lt;img src=&quot;https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml/badge.svg?branch=dev&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://gitpod.io/#https://github.com/amnezia-vpn/amnezia-client&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&quot; alt=&quot;Gitpod ready-to-code&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/amnezia-vpn/amnezia-client/dev/%5Bhttps://github.com/amnezia-vpn/amnezia-client/raw/dev/README_RU.md%5D(https://github.com/amnezia-vpn/amnezia-client/tree/dev?tab=readme-ov-file#)&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;https://github.com/amnezia-vpn/amnezia-client/raw/dev/README_RU.md&quot;&gt;Русский&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://amnezia.org?utm_source=github&amp;amp;utm_campaign=amnezia_website-readme-en&quot;&gt;Amnezia&lt;/a&gt; is an open-source VPN client, with a key feature that enables you to deploy your own VPN server on your server.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://amnezia.org&quot;&gt;&lt;img src=&quot;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/uipic4.png&quot; alt=&quot;Image&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://amnezia.org?utm_source=github&amp;amp;utm_campaign=amnezia_website-readme-en&quot;&gt;Website&lt;/a&gt; | &lt;a href=&quot;https://storage.googleapis.com/amnezia/amnezia.org?utm_source=github&amp;amp;utm_campaign=amnezia_website-readme-en-mirror&quot;&gt;Alt website link&lt;/a&gt; | &lt;a href=&quot;https://docs.amnezia.org&quot;&gt;Documentation&lt;/a&gt; | &lt;a href=&quot;https://docs.amnezia.org/troubleshooting&quot;&gt;Troubleshooting&lt;/a&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If the &lt;a href=&quot;https://amnezia.org?utm_source=github&amp;amp;utm_campaign=amnezia_website-readme-en&quot;&gt;Amnezia website&lt;/a&gt; is blocked in your region, you can use an &lt;a href=&quot;https://storage.googleapis.com/amnezia/amnezia.org?utm_source=github&amp;amp;utm_campaign=amnezia_website-readme-en-mirror&quot;&gt;Alternative website link&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://amnezia.org/en/downloads?utm_source=github&amp;amp;utm_campaign=amnezia_button-readme-en&quot;&gt;&lt;img src=&quot;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/download-website.svg?sanitize=true&quot; width=&quot;150&quot; style=&quot;max-width: 100%; margin-right: 10px&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://storage.googleapis.com/amnezia/amnezia.org?m-path=/en/downloads&amp;amp;utm_source=github&amp;amp;utm_campaign=amnezia_button-readme-en-mirrow&quot;&gt;&lt;img src=&quot;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/download-alt.svg?sanitize=true&quot; width=&quot;150&quot; style=&quot;max-width: 100%;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/amnezia-vpn/amnezia-client/releases&quot;&gt;All releases&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.testiny.io&quot;&gt;&lt;img src=&quot;https://github.com/amnezia-vpn/amnezia-client/raw/dev/metadata/img-readme/testiny.png&quot; height=&quot;28px&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Very easy to use - enter your IP address, SSH login, password and Amnezia will automatically install VPN docker containers to your server and connect to the VPN.&lt;/li&gt; 
 &lt;li&gt;Classic VPN-protocols: OpenVPN, WireGuard and IKEv2 protocols.&lt;/li&gt; 
 &lt;li&gt;Protocols with traffic Masking (Obfuscation): OpenVPN over &lt;a href=&quot;https://github.com/cbeuw/Cloak&quot;&gt;Cloak&lt;/a&gt; plugin, Shadowsocks (OpenVPN over Shadowsocks), &lt;a href=&quot;https://docs.amnezia.org/documentation/amnezia-wg/&quot;&gt;AmneziaWG&lt;/a&gt; and XRay.&lt;/li&gt; 
 &lt;li&gt;Split tunneling support - add any sites to the client to enable VPN only for them or add Apps (only for Android and Desktop).&lt;/li&gt; 
 &lt;li&gt;Windows, MacOS, Linux, Android, iOS releases.&lt;/li&gt; 
 &lt;li&gt;Support for AmneziaWG protocol configuration on &lt;a href=&quot;https://docs.keenetic.com/ua/air/kn-1611/en/6319-latest-development-release.html#UUID-186c4108-5afd-c10b-f38a-cdff6c17fab3_section-idm33192196168192-improved&quot;&gt;Keenetic beta firmware&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://amnezia.org&quot;&gt;https://amnezia.org&lt;/a&gt; - Project website | &lt;a href=&quot;https://storage.googleapis.com/kldscp/amnezia.org&quot;&gt;Alternative link (mirror)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.amnezia.org&quot;&gt;https://docs.amnezia.org&lt;/a&gt; - Documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.reddit.com/r/AmneziaVPN&quot;&gt;https://www.reddit.com/r/AmneziaVPN&lt;/a&gt; - Reddit&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://t.me/amnezia_vpn_en&quot;&gt;https://t.me/amnezia_vpn_en&lt;/a&gt; - Telegram support channel (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://t.me/amnezia_vpn_ir&quot;&gt;https://t.me/amnezia_vpn_ir&lt;/a&gt; - Telegram support channel (Farsi)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://t.me/amnezia_vpn_mm&quot;&gt;https://t.me/amnezia_vpn_mm&lt;/a&gt; - Telegram support channel (Myanmar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://t.me/amnezia_vpn&quot;&gt;https://t.me/amnezia_vpn&lt;/a&gt; - Telegram support channel (Russian)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vpnpay.io/en/amnezia-premium/&quot;&gt;https://vpnpay.io/en/amnezia-premium/&lt;/a&gt; - Amnezia Premium&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tech&lt;/h2&gt; 
&lt;p&gt;AmneziaVPN uses several open-source projects to work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.openssl.org/&quot;&gt;OpenSSL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openvpn.net/&quot;&gt;OpenVPN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://shadowsocks.org/&quot;&gt;Shadowsocks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.qt.io/&quot;&gt;Qt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://libssh.org&quot;&gt;LibSsh&lt;/a&gt; - forked from Qt Creator&lt;/li&gt; 
 &lt;li&gt;and more...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Checking out the source code&lt;/h2&gt; 
&lt;p&gt;Make sure to pull all submodules after checking out the repo.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Welcome!&lt;/p&gt; 
&lt;h3&gt;Help with translations&lt;/h3&gt; 
&lt;p&gt;Download the most actual translation files.&lt;/p&gt; 
&lt;p&gt;Go to &lt;a href=&quot;https://github.com/amnezia-vpn/amnezia-client/actions?query=is%3Asuccess+branch%3Adev&quot;&gt;&quot;Actions&quot; tab&lt;/a&gt;, click on the first line. Then scroll down to the &quot;Artifacts&quot; section and download &quot;AmneziaVPN_translations&quot;.&lt;/p&gt; 
&lt;p&gt;Unzip this file. Each *.ts file contains strings for one corresponding language.&lt;/p&gt; 
&lt;p&gt;Translate or correct some strings in one or multiple *.ts files and commit them back to this repository into the &lt;code&gt;client/translations&lt;/code&gt; folder. You can do it via a web-interface or any other method you&#39;re familiar with.&lt;/p&gt; 
&lt;h3&gt;Building sources and deployment&lt;/h3&gt; 
&lt;p&gt;Check deploy folder for build scripts.&lt;/p&gt; 
&lt;h3&gt;How to build an iOS app from source code on MacOS&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;First, make sure you have &lt;a href=&quot;https://developer.apple.com/xcode/&quot;&gt;XCode&lt;/a&gt; installed, at least version 14 or higher.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We use QT to generate the XCode project. We need QT version 6.6.2. Install QT for MacOS &lt;a href=&quot;https://doc.qt.io/qt-6/macos.html&quot;&gt;here&lt;/a&gt; or &lt;a href=&quot;https://www.qt.io/download-open-source&quot;&gt;QT Online Installer&lt;/a&gt;. Required modules:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MacOS&lt;/li&gt; 
   &lt;li&gt;iOS&lt;/li&gt; 
   &lt;li&gt;Qt 5 Compatibility Module&lt;/li&gt; 
   &lt;li&gt;Qt Shader Tools&lt;/li&gt; 
   &lt;li&gt;Additional Libraries: 
    &lt;ul&gt; 
     &lt;li&gt;Qt Image Formats&lt;/li&gt; 
     &lt;li&gt;Qt Multimedia&lt;/li&gt; 
     &lt;li&gt;Qt Remote Objects&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install CMake if required. We recommend CMake version 3.25. You can install CMake &lt;a href=&quot;https://cmake.org/download/&quot;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You also need to install go &amp;gt;= v1.16. If you don&#39;t have it installed already, download go from the &lt;a href=&quot;https://golang.org/dl/&quot;&gt;official website&lt;/a&gt; or use Homebrew. The latest version is recommended. Install gomobile&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export PATH=$PATH:~/go/bin
go install golang.org/x/mobile/cmd/gomobile@latest
gomobile init
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export QT_BIN_DIR=&quot;&amp;lt;PATH-TO-QT-FOLDER&amp;gt;/Qt/&amp;lt;QT-VERSION&amp;gt;/ios/bin&quot;
export QT_MACOS_ROOT_DIR=&quot;&amp;lt;PATH-TO-QT-FOLDER&amp;gt;/Qt/&amp;lt;QT-VERSION&amp;gt;/macos&quot;
export QT_IOS_BIN=$QT_BIN_DIR
export PATH=$PATH:~/go/bin
mkdir build-ios
$QT_IOS_BIN/qt-cmake . -B build-ios -GXcode -DQT_HOST_PATH=$QT_MACOS_ROOT_DIR
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace PATH-TO-QT-FOLDER and QT-VERSION to your environment&lt;/p&gt; 
&lt;p&gt;If you get &lt;code&gt;gomobile: command not found&lt;/code&gt; make sure to set PATH to the location of the bin folder where gomobile was installed. Usually, it&#39;s in &lt;code&gt;GOPATH&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export PATH=$(PATH):/path/to/GOPATH/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;6&quot;&gt; 
 &lt;li&gt;Open the XCode project. You can then run /test/archive/ship the app.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If the build fails with the following error&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make: *** 
[$(PROJECTDIR)/client/build/AmneziaVPN.build/Debug-iphoneos/wireguard-go-bridge/goroot/.prepared] 
Error 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add a user-defined variable to both AmneziaVPN and WireGuardNetworkExtension targets&#39; build settings with key &lt;code&gt;PATH&lt;/code&gt; and value &lt;code&gt;${PATH}/path/to/bin/folder/with/go/executable&lt;/code&gt;, e.g. &lt;code&gt;${PATH}:/usr/local/go/bin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;if the above error persists on your M1 Mac, then most probably you need to install arch based CMake&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;arch -arm64 brew install cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build might fail with the &quot;source files not found&quot; error the first time you try it, because the modern XCode build system compiles dependencies in parallel, and some dependencies end up being built after the ones that require them. In this case, simply restart the build.&lt;/p&gt; 
&lt;h2&gt;How to build the Android app&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Tested on Mac OS&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The Android app has the following requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JDK 11&lt;/li&gt; 
 &lt;li&gt;Android platform SDK 33&lt;/li&gt; 
 &lt;li&gt;CMake 3.25.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;After you have installed QT, QT Creator, and Android Studio, you need to configure QT Creator correctly.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Click in the top menu bar on &lt;code&gt;QT Creator&lt;/code&gt; -&amp;gt; &lt;code&gt;Preferences&lt;/code&gt; -&amp;gt; &lt;code&gt;Devices&lt;/code&gt; and select the tab &lt;code&gt;Android&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Set path to JDK 11&lt;/li&gt; 
 &lt;li&gt;Set path to Android SDK (&lt;code&gt;$ANDROID_HOME&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In case you get errors regarding missing SDK or &#39;SDK manager not running&#39;, you cannot fix them by correcting the paths. If you have some spare GBs on your disk, you can let QT Creator install all requirements by choosing an empty folder for &lt;code&gt;Android SDK location&lt;/code&gt; and clicking on &lt;code&gt;Set Up SDK&lt;/code&gt;. Be aware: This will install a second Android SDK and NDK on your machine!&amp;nbsp; Double-check that the right CMake version is configured: &amp;nbsp;Click on &lt;code&gt;QT Creator&lt;/code&gt; -&amp;gt; &lt;code&gt;Preferences&lt;/code&gt; and click on the side menu on &lt;code&gt;Kits&lt;/code&gt;. Under the center content view&#39;s &lt;code&gt;Kits&lt;/code&gt; tab, you&#39;ll find an entry for &lt;code&gt;CMake Tool&lt;/code&gt;. If the default selected CMake version is lower than 3.25.0, install on your system CMake &amp;gt;= 3.25.0 and choose &lt;code&gt;System CMake at &amp;lt;path&amp;gt;&lt;/code&gt; from the drop-down list. If this entry is missing, you either have not installed CMake yet or QT Creator hasn&#39;t found the path to it. In that case, click in the preferences window on the side menu item &lt;code&gt;CMake&lt;/code&gt;, then on the tab &lt;code&gt;Tools&lt;/code&gt; in the center content view, and finally on the button &lt;code&gt;Add&lt;/code&gt; to set the path to your installed CMake.&amp;nbsp; Please make sure that you have selected Android Platform SDK 33 for your project: click in the main view&#39;s side menu on &lt;code&gt;Projects&lt;/code&gt;, and on the left, you&#39;ll see a section &lt;code&gt;Build &amp;amp; Run&lt;/code&gt; showing different Android build targets. You can select any of them, Amnezia VPN&#39;s project setup is designed in a way that all Android targets will be built. Click on the targets submenu item &lt;code&gt;Build&lt;/code&gt; and scroll in the center content view to &lt;code&gt;Build Steps&lt;/code&gt;. Click on &lt;code&gt;Details&lt;/code&gt; at the end of the headline &lt;code&gt;Build Android APK&lt;/code&gt; (the &lt;code&gt;Details&lt;/code&gt; button might be hidden in case the QT Creator Window is not running in full screen!). Here we are: Choose &lt;code&gt;android-33&lt;/code&gt; as &lt;code&gt;Android Build Platform SDK&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;That&#39;s it! You should be ready to compile the project from QT Creator!&lt;/p&gt; 
&lt;h3&gt;Development flow&lt;/h3&gt; 
&lt;p&gt;After you&#39;ve hit the build button, QT-Creator copies the whole project to a folder in the repository parent directory. The folder should look something like &lt;code&gt;build-amnezia-client-Android_Qt_&amp;lt;version&amp;gt;_Clang_&amp;lt;architecture&amp;gt;-&amp;lt;BuildType&amp;gt;&lt;/code&gt;. If you want to develop Amnezia VPNs Android components written in Kotlin, such as components using system APIs, you need to import the generated project in Android Studio with &lt;code&gt;build-amnezia-client-Android_Qt_&amp;lt;version&amp;gt;_Clang_&amp;lt;architecture&amp;gt;-&amp;lt;BuildType&amp;gt;/client/android-build&lt;/code&gt; as the projects root directory. While you should be able to compile the generated project from Android Studio, you cannot work directly in the repository&#39;s Android project. So whenever you are confident with your work in the generated project, you&#39;ll need to copy and paste the affected files to the corresponding path in the repository&#39;s Android project so that you can add and commit your changes!&lt;/p&gt; 
&lt;p&gt;You may face compiling issues in QT Creator after you&#39;ve worked in Android Studio on the generated project. Just do a &lt;code&gt;./gradlew clean&lt;/code&gt; in the generated project&#39;s root directory (&lt;code&gt;&amp;lt;path&amp;gt;/client/android-build/.&lt;/code&gt;) and you should be good to go.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GPL v3.0&lt;/p&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;Patreon: &lt;a href=&quot;https://www.patreon.com/amneziavpn&quot;&gt;https://www.patreon.com/amneziavpn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Bitcoin: bc1qmhtgcf9637rl3kqyy22r2a8wa8laka4t9rx2mf &lt;br /&gt; USDT BEP20: 0x6abD576765a826f87D1D95183438f9408C901bE4 &lt;br /&gt; USDT TRC20: TELAitazF1MZGmiNjTcnxDjEiH5oe7LC9d &lt;br /&gt; XMR: 48spms39jt1L2L5vyw2RQW6CXD6odUd4jFu19GZcDyKKQV9U88wsJVjSbL4CfRys37jVMdoaWVPSvezCQPhHXUW5UKLqUp3 &lt;br /&gt; TON: UQDpU1CyKRmg7L8mNScKk9FRc2SlESuI7N-Hby4nX-CcVmns&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This project is tested with BrowserStack. We express our gratitude to &lt;a href=&quot;https://www.browserstack.com&quot;&gt;BrowserStack&lt;/a&gt; for supporting our project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>esphome/esphome</title>
      <link>https://github.com/esphome/esphome</link>
      <description>&lt;p&gt;ESPHome is a system to control your ESP8266/ESP32 by simple yet powerful configuration files and control them remotely through Home Automation systems.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ESPHome &lt;a href=&quot;https://discord.gg/KhAMKrd&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/429907082951524364.svg?sanitize=true&quot; alt=&quot;Discord Chat&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/esphome/esphome/releases/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/esphome/esphome.svg?sanitize=true&quot; alt=&quot;GitHub release&quot; /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;a href=&quot;https://esphome.io/&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://esphome.io/_static/logo-text-on-dark.svg&quot; , alt=&quot;ESPHome Logo&quot; /&gt; 
  &lt;img src=&quot;https://esphome.io/_static/logo-text-on-light.svg?sanitize=true&quot; alt=&quot;ESPHome Logo&quot; /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href=&quot;https://esphome.io&quot;&gt;Documentation&lt;/a&gt; -- &lt;a href=&quot;https://github.com/esphome/esphome/issues&quot;&gt;Issues&lt;/a&gt; -- &lt;a href=&quot;https://github.com/orgs/esphome/discussions&quot;&gt;Feature requests&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.openhomefoundation.org/&quot;&gt;&lt;img src=&quot;https://www.openhomefoundation.org/badges/esphome.png&quot; alt=&quot;ESPHome - A project from the Open Home Foundation&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>shadps4-emu/shadPS4</title>
      <link>https://github.com/shadps4-emu/shadPS4</link>
      <description>&lt;p&gt;PlayStation 4 emulator for Windows, Linux and macOS written in C++&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt; &lt;br /&gt; &lt;a href=&quot;https://shadps4.net/&quot;&gt;&lt;img src=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/.github/shadps4.png&quot; width=&quot;220&quot; /&gt;&lt;/a&gt; &lt;br /&gt; &lt;b&gt;shadPS4&lt;/b&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h1 align=&quot;center&quot;&gt; &lt;a href=&quot;https://discord.gg/bFJxfftGW6&quot;&gt; &lt;img src=&quot;https://img.shields.io/discord/1080089157554155590?color=5865F2&amp;amp;label=shadPS4%20Discord&amp;amp;logo=Discord&amp;amp;logoColor=white&quot; width=&quot;275&quot; /&gt; &lt;/a&gt;&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/releases/latest&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/downloads/shadps4-emu/shadPS4/total.svg?sanitize=true&quot; width=&quot;140&quot; /&gt; &lt;/a&gt;&lt;a href=&quot;https://shadps4.net/&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/shadPS4-website-8A2BE2&quot; width=&quot;150&quot; /&gt; &lt;/a&gt;&lt;a href=&quot;https://x.com/shadps4&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/-Join%20us-black?logo=X&amp;amp;logoColor=white&quot; width=&quot;100&quot; /&gt; &lt;/a&gt;&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/stargazers&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/stars/shadps4-emu/shadPS4&quot; width=&quot;120&quot; /&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/stargazers&quot;&gt; &lt;/a&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/stargazers&quot;&gt; &lt;/a&gt;&lt;a href=&quot;https://shadps4.net/&quot;&gt; &lt;img src=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/Screenshots/1.png&quot; width=&quot;400&quot; /&gt; &lt;img src=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/Screenshots/2.png&quot; width=&quot;400&quot; /&gt; &lt;img src=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/Screenshots/3.png&quot; width=&quot;400&quot; /&gt; &lt;img src=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/Screenshots/4.png&quot; width=&quot;400&quot; /&gt; &lt;/a&gt;&lt;/p&gt;
&lt;a href=&quot;https://shadps4.net/&quot;&gt; &lt;h1&gt;General information&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;shadPS4&lt;/strong&gt; is an early &lt;strong&gt;PlayStation 4&lt;/strong&gt; emulator for &lt;strong&gt;Windows&lt;/strong&gt;, &lt;strong&gt;Linux&lt;/strong&gt; and &lt;strong&gt;macOS&lt;/strong&gt; written in C++.&lt;/p&gt; &lt;/a&gt;
&lt;p&gt;&lt;a href=&quot;https://shadps4.net/&quot;&gt;If you encounter problems or have doubts, do not hesitate to look at the &lt;/a&gt;&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/wiki/I.-Quick-start-%5BUsers%5D&quot;&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/a&gt;.&lt;br /&gt; To verify that a game works, you can look at &lt;a href=&quot;https://github.com/shadps4-compatibility/shadps4-game-compatibility&quot;&gt;&lt;strong&gt;shadPS4 Game Compatibility&lt;/strong&gt;&lt;/a&gt;.&lt;br /&gt; To discuss shadPS4 development, suggest ideas or to ask for help, join our &lt;a href=&quot;https://discord.gg/bFJxfftGW6&quot;&gt;&lt;strong&gt;Discord server&lt;/strong&gt;&lt;/a&gt;.&lt;br /&gt; To get the latest news, go to our &lt;a href=&quot;https://x.com/shadps4&quot;&gt;&lt;strong&gt;X (Twitter)&lt;/strong&gt;&lt;/a&gt; or our &lt;a href=&quot;https://shadps4.net/&quot;&gt;&lt;strong&gt;website&lt;/strong&gt;&lt;/a&gt;.&lt;br /&gt; For those who&#39;d like to donate to the project, we now have a &lt;a href=&quot;https://ko-fi.com/shadps4&quot;&gt;&lt;strong&gt;Kofi page&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt; 
&lt;h1&gt;Status&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] shadPS4 is early in development, don&#39;t expect a flawless experience.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Currently, the emulator can successfully run games like &lt;a href=&quot;https://www.youtube.com/watch?v=wC6s0avpQRE&quot;&gt;&lt;strong&gt;Bloodborne&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=-3PA-Xwszts&quot;&gt;&lt;strong&gt;Dark Souls Remastered&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=Al7yz_5nLag&quot;&gt;&lt;strong&gt;Red Dead Redemption&lt;/strong&gt;&lt;/a&gt; and many other games.&lt;/p&gt; 
&lt;h1&gt;Why&lt;/h1&gt; 
&lt;p&gt;This project began as a fun project. Given our limited free time, it may take some time before shadPS4 can run more complex games, but we&#39;re committed to making small, regular updates.&lt;/p&gt; 
&lt;h1&gt;Building&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you want to use shadPS4 to play your games, you don&#39;t have to follow the build instructions, you can simply download the emulator from either the &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/releases&quot;&gt;&lt;strong&gt;release tab&lt;/strong&gt;&lt;/a&gt; or the &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/actions&quot;&gt;&lt;strong&gt;action tab&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Windows&lt;/h2&gt; 
&lt;p&gt;Check the build instructions for &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/building-windows.md&quot;&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Linux&lt;/h2&gt; 
&lt;p&gt;Check the build instructions for &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/building-linux.md&quot;&gt;&lt;strong&gt;Linux&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;macOS&lt;/h2&gt; 
&lt;p&gt;Check the build instructions for &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/building-macos.md&quot;&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] macOS users need at least macOS 15.4 to run shadPS4. Due to GPU issues there are currently heavy bugs on Intel Macs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Debugging and reporting issues&lt;/h1&gt; 
&lt;p&gt;For more information on how to test, debug and report issues with the emulator or games, read the &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/documents/Debugging/Debugging.md&quot;&gt;&lt;strong&gt;Debugging documentation&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Keyboard and Mouse Mappings&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Some keyboards may also require you to hold the Fn key to use the F* keys. Mac users should use the Command key instead of Control, and need to use Command+F11 for full screen to avoid conflicting with system key bindings.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Button&lt;/th&gt; 
   &lt;th&gt;Function&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;F10&lt;/td&gt; 
   &lt;td&gt;FPS Counter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ctrl+F10&lt;/td&gt; 
   &lt;td&gt;Video Debug Info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;F11&lt;/td&gt; 
   &lt;td&gt;Fullscreen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;F12&lt;/td&gt; 
   &lt;td&gt;Trigger RenderDoc Capture&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Xbox and DualShock controllers work out of the box.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Controller button&lt;/th&gt; 
   &lt;th&gt;Keyboard equivalent&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEFT AXIS UP&lt;/td&gt; 
   &lt;td&gt;W&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEFT AXIS DOWN&lt;/td&gt; 
   &lt;td&gt;S&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEFT AXIS LEFT&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEFT AXIS RIGHT&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RIGHT AXIS UP&lt;/td&gt; 
   &lt;td&gt;I&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RIGHT AXIS DOWN&lt;/td&gt; 
   &lt;td&gt;K&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RIGHT AXIS LEFT&lt;/td&gt; 
   &lt;td&gt;J&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RIGHT AXIS RIGHT&lt;/td&gt; 
   &lt;td&gt;L&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TRIANGLE&lt;/td&gt; 
   &lt;td&gt;Numpad 8 or C&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CIRCLE&lt;/td&gt; 
   &lt;td&gt;Numpad 6 or B&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CROSS&lt;/td&gt; 
   &lt;td&gt;Numpad 2 or N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SQUARE&lt;/td&gt; 
   &lt;td&gt;Numpad 4 or V&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PAD UP&lt;/td&gt; 
   &lt;td&gt;UP&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PAD DOWN&lt;/td&gt; 
   &lt;td&gt;DOWN&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PAD LEFT&lt;/td&gt; 
   &lt;td&gt;LEFT&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PAD RIGHT&lt;/td&gt; 
   &lt;td&gt;RIGHT&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OPTIONS&lt;/td&gt; 
   &lt;td&gt;RETURN&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BACK BUTTON / TOUCH PAD&lt;/td&gt; 
   &lt;td&gt;SPACE&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L1&lt;/td&gt; 
   &lt;td&gt;Q&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R1&lt;/td&gt; 
   &lt;td&gt;U&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L2&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R2&lt;/td&gt; 
   &lt;td&gt;O&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;L3&lt;/td&gt; 
   &lt;td&gt;X&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R3&lt;/td&gt; 
   &lt;td&gt;M&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Keyboard and mouse inputs can be customized in the settings menu by clicking the Controller button, and further details and help on controls are also found there. Custom bindings are saved per-game. Inputs support up to three keys per binding, mouse buttons, mouse movement mapped to joystick input, and more.&lt;/p&gt; 
&lt;h1&gt;Firmware files&lt;/h1&gt; 
&lt;p&gt;shadPS4 can load some PlayStation 4 firmware files, these must be dumped from your legally owned PlayStation 4 console. The following firmware modules are supported and must be placed in shadPS4&#39;s &lt;code&gt;sys_modules&lt;/code&gt; folder.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Modules&lt;/th&gt; 
    &lt;th&gt;Modules&lt;/th&gt; 
    &lt;th&gt;Modules&lt;/th&gt; 
    &lt;th&gt;Modules&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;libSceCesCs.sprx&lt;/td&gt; 
    &lt;td&gt;libSceFont.sprx&lt;/td&gt; 
    &lt;td&gt;libSceFontFt.sprx&lt;/td&gt; 
    &lt;td&gt;libSceFreeTypeOt.sprx&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;libSceJson.sprx&lt;/td&gt; 
    &lt;td&gt;libSceJson2.sprx&lt;/td&gt; 
    &lt;td&gt;libSceLibcInternal.sprx&lt;/td&gt; 
    &lt;td&gt;libSceNgs2.sprx&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;libSceUlt.sprx&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] The above modules are required to run the games properly and must be extracted from your PlayStation 4.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Main team&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/georgemoralis&quot;&gt;&lt;strong&gt;georgemoralis&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/psucien&quot;&gt;&lt;strong&gt;psucien&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/viniciuslrangel&quot;&gt;&lt;strong&gt;viniciuslrangel&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/roamic&quot;&gt;&lt;strong&gt;roamic&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/squidbus&quot;&gt;&lt;strong&gt;squidbus&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/baggins183&quot;&gt;&lt;strong&gt;frodo&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/StevenMiller123&quot;&gt;&lt;strong&gt;Stephen Miller&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kalaposfos13&quot;&gt;&lt;strong&gt;kalaposfos13&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Logo is done by &lt;a href=&quot;https://github.com/Xphalnos&quot;&gt;&lt;strong&gt;Xphalnos&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;If you want to contribute, please read the &lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/CONTRIBUTING.md&quot;&gt;&lt;strong&gt;CONTRIBUTING.md&lt;/strong&gt;&lt;/a&gt; file.&lt;br /&gt; Open a PR and we&#39;ll check it :)&lt;/p&gt; 
&lt;h1&gt;Translations&lt;/h1&gt; 
&lt;p&gt;If you want to translate shadPS4 to your language we use &lt;a href=&quot;https://crowdin.com/project/shadps4-emulator&quot;&gt;&lt;strong&gt;Crowdin&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=shadps4-emu/shadPS4&amp;amp;max=24&quot; /&gt; &lt;/a&gt; 
&lt;h1&gt;Special Thanks&lt;/h1&gt; 
&lt;p&gt;A few noteworthy teams/projects who&#39;ve helped us along the way are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/wheremyfoodat/Panda3DS&quot;&gt;&lt;strong&gt;Panda3DS&lt;/strong&gt;&lt;/a&gt;: A multiplatform 3DS emulator from our co-author wheremyfoodat. They have been incredibly helpful in understanding and solving problems that came up from natively executing the x64 code of PS4 binaries&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/red-prig/fpPS4&quot;&gt;&lt;strong&gt;fpPS4&lt;/strong&gt;&lt;/a&gt;: The fpPS4 team has assisted massively with understanding some of the more complex parts of the PS4 operating system and libraries, by helping with reverse engineering work and research.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;yuzu&lt;/strong&gt;: Our shader compiler has been designed with yuzu&#39;s Hades compiler as a blueprint. This allowed us to focus on the challenges of emulating a modern AMD GPU while having a high-quality optimizing shader compiler implementation as a base.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/OFFTKP/felix86&quot;&gt;&lt;strong&gt;felix86&lt;/strong&gt;&lt;/a&gt;: A new x86-64 → RISC-V Linux userspace emulator&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/shadps4-emu/shadPS4/raw/main/LICENSE&quot;&gt;&lt;strong&gt;GPL-2.0 license&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>stenzek/duckstation</title>
      <link>https://github.com/stenzek/duckstation</link>
      <description>&lt;p&gt;Fast PlayStation 1 emulator for x86-64/AArch32/AArch64/RV64&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DuckStation - PlayStation 1, aka. PSX Emulator&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#features&quot;&gt;Features&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#downloading-and-running&quot;&gt;Downloading and Running&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#building&quot;&gt;Building&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#disclaimers&quot;&gt;Disclaimers&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Latest Builds for Windows 10/11 (x64/ARM64), Linux (AppImage x64/ARM32/ARM64), and macOS (11.0+ Universal):&lt;/strong&gt; &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/tag/latest&quot;&gt;https://github.com/stenzek/duckstation/releases/tag/latest&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Game Compatibility List:&lt;/strong&gt; &lt;a href=&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vRE0jjiK_aldpICoy5kVQlpk2f81Vo6P4p9vfg4d7YoTOoDlH4PQHoXjTD2F7SdN8SSBLoEAItaIqQo/pubhtml&quot;&gt;https://docs.google.com/spreadsheets/d/e/2PACX-1vRE0jjiK_aldpICoy5kVQlpk2f81Vo6P4p9vfg4d7YoTOoDlH4PQHoXjTD2F7SdN8SSBLoEAItaIqQo/pubhtml&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Discord Server:&lt;/strong&gt; &lt;a href=&quot;https://www.duckstation.org/discord.html&quot;&gt;https://www.duckstation.org/discord.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DuckStation is an simulator/emulator of the Sony PlayStation(TM) console, focusing on playability, speed, and long-term maintainability. The goal is to be as accurate as possible while maintaining performance suitable for low-end devices. &quot;Hack&quot; options are discouraged, the default configuration should support all playable games with only some of the enhancements having compatibility issues.&lt;/p&gt; 
&lt;p&gt;A PS1 or PS2 &quot;BIOS&quot; ROM image is required to to start the emulator and to play games. You can use an image from any hardware version or region, although mismatching game regions and BIOS regions may have compatibility issues. A ROM image is not provided with the emulator for legal reasons, you should dump this from your own console using Caetla or other means.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;DuckStation features a fully-featured frontend built using Qt, as well as a fullscreen/TV UI based on Dear ImGui.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/stenzek/duckstation/md-images/main-qt.png&quot; alt=&quot;Main Window Screenshot&quot; /&gt; &lt;img src=&quot;https://raw.githubusercontent.com/stenzek/duckstation/md-images/bigduck.png&quot; alt=&quot;Fullscreen UI Screenshot&quot; /&gt; &lt;/p&gt; 
&lt;p&gt;Other features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU Recompiler/JIT (x86-64, armv7/AArch32, AArch64, RISC-V/RV64).&lt;/li&gt; 
 &lt;li&gt;Hardware renderer supporting D3D11, D3D12, OpenGL, Vulkan and Metal APIs.&lt;/li&gt; 
 &lt;li&gt;Upscaling, texture filtering, and true colour (24-bit) in hardware renderers.&lt;/li&gt; 
 &lt;li&gt;PGXP for geometry precision, texture correction, and depth buffer emulation.&lt;/li&gt; 
 &lt;li&gt;Accurate blending via Rasterizer Order Views/Fragment Shader Interlock.&lt;/li&gt; 
 &lt;li&gt;Texture replacement system in hardware renderers.&lt;/li&gt; 
 &lt;li&gt;Vectorized and multi-threaded software renderer.&lt;/li&gt; 
 &lt;li&gt;Motion adaptive deinterlacing.&lt;/li&gt; 
 &lt;li&gt;Adaptive downsampling filter.&lt;/li&gt; 
 &lt;li&gt;Screen rotation for vertical or &quot;TATE&quot; shmup games.&lt;/li&gt; 
 &lt;li&gt;Post processing shader chains (GLSL and Reshade FX).&lt;/li&gt; 
 &lt;li&gt;Border overlays/bezels displayed around game content.&lt;/li&gt; 
 &lt;li&gt;&quot;Fast boot&quot; for skipping BIOS splash/intro.&lt;/li&gt; 
 &lt;li&gt;Save state support, with runahead and rewind.&lt;/li&gt; 
 &lt;li&gt;Windows, Linux, macOS support.&lt;/li&gt; 
 &lt;li&gt;Supports reading directly from CD, bin/cue images, raw bin/img files, MAME CHD, single-track ECM, MDS/MDF, and unencrypted PBP formats.&lt;/li&gt; 
 &lt;li&gt;Preloading of disc images to RAM to avoid disk sleeping hitches.&lt;/li&gt; 
 &lt;li&gt;Merging of multi-disc games in game list/grid with memory cards shared between discs.&lt;/li&gt; 
 &lt;li&gt;Automatic loading/applying of PPF patches.&lt;/li&gt; 
 &lt;li&gt;Direct booting of homebrew executables.&lt;/li&gt; 
 &lt;li&gt;Direct loading of Portable Sound Format (psf) files.&lt;/li&gt; 
 &lt;li&gt;Time stretched audio when running outside of 100% speed.&lt;/li&gt; 
 &lt;li&gt;Digital and analog controllers for input (rumble is forwarded to host).&lt;/li&gt; 
 &lt;li&gt;GunCon and Justifier lightgun support (simulated with mouse).&lt;/li&gt; 
 &lt;li&gt;NeGcon support.&lt;/li&gt; 
 &lt;li&gt;Controller presets and per-game configuration.&lt;/li&gt; 
 &lt;li&gt;Qt and &quot;Big Picture&quot; UI.&lt;/li&gt; 
 &lt;li&gt;Automatic updates with preview and latest channels.&lt;/li&gt; 
 &lt;li&gt;Automatic content scanning - game titles/hashes are provided by redump.org.&lt;/li&gt; 
 &lt;li&gt;Optional automatic switching of memory cards for each game.&lt;/li&gt; 
 &lt;li&gt;Supports loading cheats from existing lists.&lt;/li&gt; 
 &lt;li&gt;Memory card editor and save importer.&lt;/li&gt; 
 &lt;li&gt;Emulated CPU overclocking.&lt;/li&gt; 
 &lt;li&gt;Integrated and remote debugging.&lt;/li&gt; 
 &lt;li&gt;Multitap controllers (up to 8 devices).&lt;/li&gt; 
 &lt;li&gt;RetroAchievements.&lt;/li&gt; 
 &lt;li&gt;Discord Rich Presence.&lt;/li&gt; 
 &lt;li&gt;Video capture with Media Foundation (Windows) and &lt;a href=&quot;https://www.ffmpeg.org/&quot;&gt;FFmpeg&lt;/a&gt; (All Platforms) backends.&lt;/li&gt; 
 &lt;li&gt;Free camera function.&lt;/li&gt; 
 &lt;li&gt;Parallel port cartridge emulation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A CPU faster than a potato. But it needs to be x86_64, AArch32/armv7, AArch64/ARMv8, or RISC-V/RV64.&lt;/li&gt; 
 &lt;li&gt;For the hardware renderers, a GPU capable of OpenGL 3.1/OpenGL ES 3.1/Direct3D 11 Feature Level 10.0 (or Vulkan 1.0) and above. So, basically anything made in the last 10 years or so.&lt;/li&gt; 
 &lt;li&gt;SDL, XInput or DInput compatible game controller (e.g. XB360/XBOne/XBSeries). DualShock 3 users on Windows will need to install the official DualShock 3 drivers included as part of PlayStation Now.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloading and running&lt;/h2&gt; 
&lt;p&gt;Binaries of DuckStation for Windows x64/ARM64, Linux x86_64/ARM32/ARM64 (in AppImage format), and macOS Universal Binaries are available via GitHub Releases and are automatically built with every commit/push.&lt;/p&gt; 
&lt;p&gt;As per the terms of CC-BY-NC-ND, redistribution of &lt;strong&gt;unmodified releases and code&lt;/strong&gt; is permitted. However, we would prefer if you linked to &lt;a href=&quot;https://www.duckstation.org/&quot;&gt;https://www.duckstation.org/&lt;/a&gt; instead. Please note that pre-configured settings and packages are considered modifications.&lt;/p&gt; 
&lt;p&gt;For x86 machines (most systems), you will need a CPU that supports the SSE4.1 instruction set for the &quot;normal&quot; build. This includes all Intel CPUs manufactured after 2007, and AMD CPUs manufactured after 2011. If you have a CPU that is older, you will need to download the &quot;SSE2&quot; build from the releases page, which has lower performance but still supports these CPUs.&lt;/p&gt; 
&lt;p&gt;The main releases page is limited to the last 30 releases due to automatic updater limitations. Older releases can be downloaded from &lt;a href=&quot;https://github.com/duckstation/old-releases/releases&quot;&gt;https://github.com/duckstation/old-releases/releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;DuckStation &lt;strong&gt;requires&lt;/strong&gt; Windows 10/11, specifically version 1809 or newer. If you are still using Windows 7/8/8.1, DuckStation &lt;strong&gt;will not run&lt;/strong&gt; on your operating system. Running these operating systems in 2023 should be considered a security risk, and I would recommend updating to something which receives vendor support. If you must use an older operating system, &lt;a href=&quot;https://github.com/duckstation/old-releases/releases/tag/v0.1-5624&quot;&gt;v0.1-5624&lt;/a&gt; is the last version which will run. But do not expect to recieve any assistance, these builds are no longer supported.&lt;/p&gt; 
&lt;p&gt;To download:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/tag/latest&quot;&gt;https://github.com/stenzek/duckstation/releases/tag/latest&lt;/a&gt;, and download the Windows x64 build. This is a zip archive containing the prebuilt binary. If you have an ARM64 Windows machine such as Snapdragon, download the Windows ARM64 build.&lt;/li&gt; 
 &lt;li&gt;Alternatively, direct download link: &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/download/latest/duckstation-windows-x64-release.zip&quot;&gt;https://github.com/stenzek/duckstation/releases/download/latest/duckstation-windows-x64-release.zip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Extract the archive &lt;strong&gt;to a subdirectory&lt;/strong&gt;. The archive has no root subdirectory, so extracting to the current directory will drop a bunch of files in your download directory if you do not extract to a subdirectory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once downloaded and extracted, you can launch the emulator with &lt;code&gt;duckstation-qt-x64-ReleaseLTCG.exe&lt;/code&gt;. Follow the Setup Wizard to get started.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you get an error about &lt;code&gt;vcruntime140_1.dll&lt;/code&gt; being missing, you will need to update your Visual C++ runtime.&lt;/strong&gt; You can do that from this page: &lt;a href=&quot;https://support.microsoft.com/en-au/help/2977003/the-latest-supported-visual-c-downloads&quot;&gt;https://support.microsoft.com/en-au/help/2977003/the-latest-supported-visual-c-downloads&lt;/a&gt;. Specifically, you want the x64 runtime, which can be downloaded from &lt;a href=&quot;https://aka.ms/vs/17/release/vc_redist.x64.exe&quot;&gt;https://aka.ms/vs/17/release/vc_redist.x64.exe&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;p&gt;DuckStation is provided for x86_64/ARM32/ARM64 Linux in AppImage (recommended) and Flatpak (not recommended) formats.&lt;/p&gt; 
&lt;h4&gt;AppImage&lt;/h4&gt; 
&lt;p&gt;The AppImages require a distribution equivalent to Ubuntu 22.04 or newer to run.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/tag/latest&quot;&gt;https://github.com/stenzek/duckstation/releases/tag/latest&lt;/a&gt;, and download &lt;code&gt;duckstation-x64.AppImage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;chmod a+x&lt;/code&gt; on the downloaded AppImage -- following this step, the AppImage can be run like a typical executable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Flatpak&lt;/h4&gt; 
&lt;p&gt;Due to various Flatpak limitations and Flathub randomly breaking regularly, &lt;strong&gt;the Flatpak package is not recommended&lt;/strong&gt;. &lt;strong&gt;We recommend that you use the AppImage instead.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/tag/latest&quot;&gt;https://github.com/stenzek/duckstation/releases/tag/latest&lt;/a&gt;, and download &lt;code&gt;duckstation-x64.flatpak&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;flatpak install ./duckstation-x64.flatpak&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or, if you have FlatHub set up:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;flatpak install org.duckstation.DuckStation&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Use &lt;code&gt;flatpak run org.duckstation.DuckStation&lt;/code&gt; to start, or select &lt;code&gt;DuckStation&lt;/code&gt; in the launcher of your desktop environment. Follow the Setup Wizard to get started.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;As of 2025/07/26, with the aforementioned issues and a lack of interest from users, the Flatpak package is deprecated. Future updates are not guaranteed.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To migrate your data from the Flatpak package to the AppImage, you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mv ~/.var/app/org.duckstation.DuckStation/config/duckstation ~/.local/share
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need to re-add your game directories after switching to the AppImage.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;Universal macOS builds are provided for both x86_64 (Intel) and ARM64 (Apple Silicon).&lt;/p&gt; 
&lt;p&gt;macOS Big Sur (11.0) is required, as this is also the minimum requirement for Qt.&lt;/p&gt; 
&lt;p&gt;To download:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href=&quot;https://github.com/stenzek/duckstation/releases/tag/latest&quot;&gt;https://github.com/stenzek/duckstation/releases/tag/latest&lt;/a&gt;, and download &lt;code&gt;duckstation-mac-release.zip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Extract the zip by double-clicking it.&lt;/li&gt; 
 &lt;li&gt;Open &lt;code&gt;DuckStation.app&lt;/code&gt;, optionally moving it to your desired location first.&lt;/li&gt; 
 &lt;li&gt;Depending on GateKeeper configuration, you may need to right click -&amp;gt; Open the first time you run it, as code signing certificates are out of the question for a project which brings in zero revenue.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;You will need a device with armv7 (32-bit ARM), AArch64 (64-bit ARM), or x86_64 (64-bit x86). 64-bit is preferred, the requirements are higher for 32-bit, you&#39;ll probably want at least a 1.5GHz CPU.&lt;/p&gt; 
&lt;p&gt;Download from Google Play: &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.github.stenzek.duckstation&quot;&gt;https://play.google.com/store/apps/details?id=com.github.stenzek.duckstation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;APK and Beta Downloads: &lt;a href=&quot;https://www.duckstation.org/android/&quot;&gt;https://www.duckstation.org/android/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;No support is provided for the Android app&lt;/strong&gt;, it is free and your expectations should be in line with that. Please &lt;strong&gt;do not&lt;/strong&gt; email me about issues about it, or ask for help, you will be ignored.&lt;/p&gt; 
&lt;p&gt;To use:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install and run the app for the first time.&lt;/li&gt; 
 &lt;li&gt;Follow the setup wizard.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you have an external controller, you will need to map the buttons and sticks in settings.&lt;/p&gt; 
&lt;h3&gt;LibCrypt protection and SBI files&lt;/h3&gt; 
&lt;p&gt;A number of PAL region games use LibCrypt protection, requiring additional CD subchannel information to run properly. libcrypt not functioning usually manifests as hanging or crashing, but can sometimes affect gameplay too, depending on how the game implemented it.&lt;/p&gt; 
&lt;p&gt;For these games, make sure that the CD image and its corresponding SBI (.sbi) file have the same name and are placed in the same directory. DuckStation will automatically load the SBI file when it is found next to the CD image.&lt;/p&gt; 
&lt;p&gt;For example, if your disc image was named &lt;code&gt;Spyro3.cue&lt;/code&gt;, you would place the SBI file in the same directory, and name it &lt;code&gt;Spyro3.sbi&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;CHD images with built-in subchannel information are also supported.&lt;/p&gt; 
&lt;p&gt;If you are playing directly from a disc and your CD/DVD drive does not support subchannel reading, or has a skew with the returned SubQ, you can place the SBI file in the &lt;code&gt;subchannel&lt;/code&gt; directory under the user directory, with the serial or title of the game.&lt;/p&gt; 
&lt;h3&gt;Cheats and patch database&lt;/h3&gt; 
&lt;p&gt;DuckStation ships with a built-in cheat and patch database, both provided by the community. Contributions to these are welcome at &lt;a href=&quot;https://github.com/duckstation/chtdb&quot;&gt;https://github.com/duckstation/chtdb&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Each release includes the latest version of the database, however you are free to manually update to the latest version as well.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual Studio 2022&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the respository: &lt;code&gt;git clone https://github.com/stenzek/duckstation.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the dependencies pack from &lt;a href=&quot;https://github.com/stenzek/duckstation-ext-qt-minimal/releases/download/latest/deps-x64.7z&quot;&gt;https://github.com/stenzek/duckstation-ext-qt-minimal/releases/download/latest/deps-x64.7z&lt;/a&gt;, and extract it to &lt;code&gt;dep\msvc&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Open the Visual Studio solution &lt;code&gt;duckstation.sln&lt;/code&gt; in the root, or &quot;Open Folder&quot; for cmake build.&lt;/li&gt; 
 &lt;li&gt;Build solution.&lt;/li&gt; 
 &lt;li&gt;Binaries are located in &lt;code&gt;bin/x64&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;duckstation-qt-x64-Release.exe&lt;/code&gt; or whichever config you used.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;h4&gt;Required Dependencies&lt;/h4&gt; 
&lt;p&gt;Ubuntu/Debian package names:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;autoconf automake build-essential clang cmake curl extra-cmake-modules git libasound2-dev libcurl4-openssl-dev libdbus-1-dev libdecor-0-dev libegl-dev libevdev-dev libfontconfig-dev libfreetype-dev libgtk-3-dev libgudev-1.0-dev libharfbuzz-dev libinput-dev libopengl-dev libpipewire-0.3-dev libpulse-dev libssl-dev libudev-dev libwayland-dev libx11-dev libx11-xcb-dev libxcb1-dev libxcb-composite0-dev libxcb-cursor-dev libxcb-damage0-dev libxcb-glx0-dev libxcb-icccm4-dev libxcb-image0-dev libxcb-keysyms1-dev libxcb-present-dev libxcb-randr0-dev libxcb-render0-dev libxcb-render-util0-dev libxcb-shape0-dev libxcb-shm0-dev libxcb-sync-dev libxcb-util-dev libxcb-xfixes0-dev libxcb-xinput-dev libxcb-xkb-dev libxext-dev libxkbcommon-x11-dev libxrandr-dev libtool lld llvm nasm ninja-build pkg-config zlib1g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Fedora package names:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;alsa-lib-devel autoconf automake brotli-devel clang cmake dbus-devel egl-wayland-devel extra-cmake-modules fontconfig-devel gcc-c++ gtk3-devel libavcodec-free-devel libavformat-free-devel libavutil-free-devel libcurl-devel libdecor-devel libevdev-devel libICE-devel libinput-devel libSM-devel libswresample-free-devel libswscale-free-devel libX11-devel libXau-devel libxcb-devel libXcomposite-devel libXcursor-devel libXext-devel libXfixes-devel libXft-devel libXi-devel libxkbcommon-devel libxkbcommon-x11-devel libXpresent-devel libXrandr-devel libXrender-devel libtool lld llvm make mesa-libEGL-devel mesa-libGL-devel nasm ninja-build openssl-devel patch pcre2-devel perl-Digest-SHA pipewire-devel pulseaudio-libs-devel systemd-devel wayland-devel xcb-util-cursor-devel xcb-util-devel xcb-util-errors-devel xcb-util-image-devel xcb-util-keysyms-devel xcb-util-renderutil-devel xcb-util-wm-devel xcb-util-xrm-devel zlib-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Arch package names:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;base-devel clang cmake curl dbus extra-cmake-modules freetype git libjpeg-turbo libpng libwebp libx11 libxrandr lld llvm ninja qt6-base qt6-imageformats qt6-svg qt6-tools wayland zstd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Building&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/stenzek/duckstation.git&lt;/code&gt;, &lt;code&gt;cd duckstation&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Build dependencies. You can save these outside of the tree if you like. This will take a while. &lt;code&gt;scripts/deps/build-dependencies-linux.sh deps&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run CMake to configure the build system. Assuming a build subdirectory of &lt;code&gt;build-release&lt;/code&gt;, run &lt;code&gt;cmake -B build-release -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_EXE_LINKER_FLAGS_INIT=&quot;-fuse-ld=lld&quot; -DCMAKE_MODULE_LINKER_FLAGS_INIT=&quot;-fuse-ld=lld&quot; -DCMAKE_SHARED_LINKER_FLAGS_INIT=&quot;-fuse-ld=lld&quot; -DCMAKE_PREFIX_PATH=&quot;$PWD/deps&quot; -G Ninja&lt;/code&gt;. If you want a release (optimized) build, include &lt;code&gt;-DCMAKE_BUILD_TYPE=Release -DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Compile the source code. For the example above, run &lt;code&gt;ninja -C build-release&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the binary, located in the build directory under &lt;code&gt;./build-release/bin/duckstation-qt&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CMake&lt;/li&gt; 
 &lt;li&gt;Xcode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/stenzek/duckstation.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Build the dependencies. This will take a while. &lt;code&gt;scripts/deps/build-dependencies-mac.sh deps&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run CMake to configure the build system: &lt;code&gt;cmake -Bbuild-release -DCMAKE_BUILD_TYPE=Release -DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON -DCMAKE_PREFIX_PATH=&quot;$PWD/deps&quot;&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Compile the source code: &lt;code&gt;cmake --build build-release --parallel&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the binary, located in the build directory under &lt;code&gt;bin/DuckStation.app&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;User Directories&lt;/h2&gt; 
&lt;p&gt;The &quot;User Directory&quot; is where you should place your BIOS images, where settings are saved to, and memory cards/save states are saved by default. An optional &lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#sdl-game-controller-database&quot;&gt;SDL game controller database file&lt;/a&gt; can be also placed here.&lt;/p&gt; 
&lt;p&gt;This is located in the following places depending on the platform you&#39;re using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows: My Documents\DuckStation&lt;/li&gt; 
 &lt;li&gt;Linux: &lt;code&gt;$XDG_DATA_HOME/duckstation&lt;/code&gt;, or &lt;code&gt;~/.local/share/duckstation&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/DuckStation&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;So, if you were using Linux, you would place your BIOS images in &lt;code&gt;~/.local/share/duckstation/bios&lt;/code&gt;. This directory will be created upon running DuckStation for the first time.&lt;/p&gt; 
&lt;p&gt;If you wish to use a &quot;portable&quot; build, where the user directory is the same as where the executable is located, create an empty file named &lt;code&gt;portable.txt&lt;/code&gt; in the same directory as the DuckStation executable.&lt;/p&gt; 
&lt;h2&gt;Bindings for Qt frontend&lt;/h2&gt; 
&lt;p&gt;Your keyboard or game controller can be used to simulate a variety of PlayStation controllers. Controller input is supported through DInput, XInput, and SDL backends and can be changed through &lt;code&gt;Settings -&amp;gt; Controllers&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To bind your input device, go to &lt;code&gt;Settings -&amp;gt; Controllers&lt;/code&gt;, and select the virtual controller you want to map. Automatic mapping handles the majority of controllers. However, if you need to manually bind a controller, click the box below the button/axis name, and press the key or button on your input device that you wish to bind to.&lt;/p&gt; 
&lt;h2&gt;SDL Game Controller Database&lt;/h2&gt; 
&lt;p&gt;DuckStation releases ship with a database of game controller mappings for the SDL controller backend, courtesy of &lt;a href=&quot;https://github.com/mdqinc/SDL_GameControllerDB&quot;&gt;https://github.com/mdqinc/SDL_GameControllerDB&lt;/a&gt;. The included &lt;code&gt;gamecontrollerdb.txt&lt;/code&gt; file can be found in the &lt;code&gt;resources&lt;/code&gt; subdirectory of the DuckStation program directory.&lt;/p&gt; 
&lt;p&gt;If you are experiencing issues binding your controller with the SDL controller backend, you may need to add a custom mapping to the database file. Make a copy of &lt;code&gt;gamecontrollerdb.txt&lt;/code&gt; and place it in your &lt;a href=&quot;https://raw.githubusercontent.com/stenzek/duckstation/master/#user-directories&quot;&gt;user directory&lt;/a&gt; (or directly in the program directory, if running in portable mode) and then follow the instructions in the &lt;a href=&quot;https://github.com/mdqinc/SDL_GameControllerDB&quot;&gt;SDL_GameControllerDB repository&lt;/a&gt; for creating a new mapping. Add this mapping to the new copy of &lt;code&gt;gamecontrollerdb.txt&lt;/code&gt; and your controller should then be recognized properly.&lt;/p&gt; 
&lt;h2&gt;Default bindings&lt;/h2&gt; 
&lt;p&gt;Bindings for controllers and hotkeys can be changed in &lt;code&gt;Settings -&amp;gt; Controllers&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Controller 1:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Left Stick:&lt;/strong&gt; W/A/S/D&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Right Stick:&lt;/strong&gt; T/F/G/H&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;D-Pad:&lt;/strong&gt; Up/Left/Down/Right&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Triangle/Square/Circle/Cross:&lt;/strong&gt; I/J/L/K&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;L1/R1:&lt;/strong&gt; Q/E&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;L2/R2:&lt;/strong&gt; 1/3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;L3/R3:&lt;/strong&gt; 2/4&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start:&lt;/strong&gt; Enter&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Select:&lt;/strong&gt; Backspace&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Hotkeys:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Escape:&lt;/strong&gt; Open Pause Menu&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F1:&lt;/strong&gt; Load State&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F2:&lt;/strong&gt; Save State&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F3:&lt;/strong&gt; Select Previous Save State&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F4:&lt;/strong&gt; Select Next Save State&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F10:&lt;/strong&gt; Save Screenshot&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;F11:&lt;/strong&gt; Toggle Fullscreen&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tab:&lt;/strong&gt; Temporarily Disable Speed Limiter&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Space:&lt;/strong&gt; Pause/Resume Emulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;Icon by icons8: &lt;a href=&quot;https://icons8.com/icon/74847/platforms.undefined.short-title&quot;&gt;https://icons8.com/icon/74847/platforms.undefined.short-title&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&quot;PlayStation&quot; and &quot;PSX&quot; are registered trademarks of Sony Interactive Entertainment Europe Limited. This project is not affiliated in any way with Sony Interactive Entertainment.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ikawrakow/ik_llama.cpp</title>
      <link>https://github.com/ikawrakow/ik_llama.cpp</link>
      <description>&lt;p&gt;llama.cpp fork with additional SOTA quants and improved performance&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ik_llama.cpp: llama.cpp fork with better CPU performance&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&quot; alt=&quot;License: MIT&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;TL;DR&lt;/h2&gt; 
&lt;p&gt;This repository is a fork of &lt;a href=&quot;https://github.com/ggerganov/llama.cpp&quot;&gt;llama.cpp&lt;/a&gt; with better CPU and hybrid GPU/CPU performance, new SOTA quantization types, first-class Bitnet support, better DeepSeek performance via MLA, FlashMLA, fused MoE operations and tensor overrides for hybrid GPU/CPU inference, row-interleaved quant packing, etc.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;h3&gt;Model Support&lt;/h3&gt; 
&lt;p&gt;LlaMA-3-Nemotron &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/377&quot;&gt;PR 377&lt;/a&gt;, Qwen3 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/355&quot;&gt;PR 355&lt;/a&gt;, GLM-4 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/344&quot;&gt;PR 344&lt;/a&gt;, Command-A &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/341&quot;&gt;PR 341&lt;/a&gt;, bitnet-b1.58-2B-4T &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/337&quot;&gt;PR 337&lt;/a&gt;, LLaMA-4 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/321&quot;&gt;PR 321&lt;/a&gt;, Gemma3 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/276&quot;&gt;PR 276&lt;/a&gt;, DeepSeek-V3 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/176&quot;&gt;PR 176&lt;/a&gt;, Kimi-2 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/609&quot;&gt;PR 609&lt;/a&gt;, dots.llm1 &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/573&quot;&gt;PR 573&lt;/a&gt;, Hunyuan &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/565&quot;&gt;PR 565&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quantization&lt;/h3&gt; 
&lt;h4&gt;Quantization additions&lt;/h4&gt; 
&lt;h5&gt;Trellis quants (&lt;code&gt;IQ1_KT&lt;/code&gt;, &lt;code&gt;IQ2_KT&lt;/code&gt;, &lt;code&gt;IQ3_KT&lt;/code&gt;, &lt;code&gt;IQ4_KT&lt;/code&gt;)&lt;/h5&gt; 
&lt;p&gt;Information and the original CUDA implementation in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/113&quot;&gt;PR 113&lt;/a&gt;. Additional implementations: Metal &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/475&quot;&gt;PR 475&lt;/a&gt;, Neon &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/471&quot;&gt;PR 471&lt;/a&gt;, CPU &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/441&quot;&gt;PR 441&lt;/a&gt;. &lt;code&gt;IQ1_KT&lt;/code&gt; was added more recently in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/616&quot;&gt;PR 616&lt;/a&gt;. Note: these are base on a novel, integer-base trellis, which allows to achieve reasonable CPU performance, see &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/529&quot;&gt;PR 529&lt;/a&gt; and PRs quoted there for details.&lt;/p&gt; 
&lt;h5&gt;IQK quants&lt;/h5&gt; 
&lt;p&gt;Information can be found in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/discussions/8&quot;&gt;Discussion 8&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Initial implementations (Zen4, AVX2, NEON): &lt;code&gt;IQ5_KS_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/426&quot;&gt;PR 426&lt;/a&gt;, &lt;code&gt;IQ5_KS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/422&quot;&gt;PR 422&lt;/a&gt;, &lt;code&gt;IQ4_KS_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/150&quot;&gt;PR 150&lt;/a&gt;, &lt;code&gt;IQ5_K_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/149&quot;&gt;PR 149&lt;/a&gt;, &lt;code&gt;IQ2_K_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/146&quot;&gt;PR 146&lt;/a&gt;, &lt;code&gt;IQ3_K_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/145&quot;&gt;PR 145&lt;/a&gt;, &lt;code&gt;IQ4_K_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/138&quot;&gt;PR 138&lt;/a&gt;, &lt;code&gt;IQ4_KSS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/89&quot;&gt;PR 89&lt;/a&gt;, &lt;code&gt;IQ2_KS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/85&quot;&gt;PR 85&lt;/a&gt;, &lt;code&gt;IQ4_KS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/83&quot;&gt;PR 83&lt;/a&gt;, &lt;code&gt;IQ6_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/14&quot;&gt;PR 14&lt;/a&gt;, &lt;code&gt;IQ2_K, IQ3_K and IQ5_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/7&quot;&gt;PR 7&lt;/a&gt;, &lt;code&gt;IQ4_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/6&quot;&gt;PR 6&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Cuda implementations: &lt;code&gt;IQ4_KS_R4&lt;/code&gt; and &lt;code&gt;IQ5_KS_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/493&quot;&gt;PR 493&lt;/a&gt;, &lt;code&gt;IQ1_S_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/492&quot;&gt;PR 492&lt;/a&gt;, &lt;code&gt;IQ1_M_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/494&quot;&gt;PR 494&lt;/a&gt;. &lt;code&gt;IQ4_KS_R4&lt;/code&gt; and &lt;code&gt;IQ5_KS_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/462&quot;&gt;PR 462&lt;/a&gt;, &lt;code&gt;IQ2_K_R4&lt;/code&gt;, &lt;code&gt;IQ3_K_R4&lt;/code&gt;, &lt;code&gt;IQ4_K_R4&lt;/code&gt;, &lt;code&gt;IQ5_K_R4&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/461&quot;&gt;PR 461&lt;/a&gt;, &lt;code&gt;IQ4_K, IQ5_K, IQ6_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/417&quot;&gt;PR 417&lt;/a&gt;, &lt;code&gt;IQ2_KS, IQ2_K, IQ3_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/417&quot;&gt;PR 418&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;IQ2_KL&lt;/code&gt; is a more recent addition in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/602&quot;&gt;PR 602&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Quantization improvements&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;IQ1_M&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/327&quot;&gt;PR 327&lt;/a&gt;, &lt;code&gt;IQ2_XS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/312&quot;&gt;PR 312&lt;/a&gt;, &lt;code&gt;Q2_K, Q4_K, Q5_K, Q4_1, Q5_1&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/302&quot;&gt;PR 302&lt;/a&gt;, &lt;code&gt;Q4_0, Q5_0, Q6_0, Q3_K, Q6_K, IQ4_XS, IQ4_NL&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/295&quot;&gt;PR 295&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Quantization performance improvements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Much faster CPU prompt processing for all non-interleaved quants. Initial idea in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/515&quot;&gt;PR 515&lt;/a&gt; and &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/531&quot;&gt;PR 531&lt;/a&gt;, with many follow up PRs to apply to all quantization types for the 3 supported CPU platforms.&lt;/li&gt; 
 &lt;li&gt;All quantization types now have quantized matrix multiplication CUDA kernels, see &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/515&quot;&gt;PR 557&lt;/a&gt; and several others&lt;/li&gt; 
 &lt;li&gt;Faster CPU prompt processing for Trellis quants and MoE models. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/488&quot;&gt;PR 488&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Trellis quants: faster CPU prompt processing &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/482&quot;&gt;PR 482&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Minor (~2%) &lt;code&gt;iq2_ks&lt;/code&gt; TG performance improvement on CUDA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/468&quot;&gt;PR 468&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Faster &lt;code&gt;IQ3_KT&lt;/code&gt; and &lt;code&gt;IQ4_KT&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/453&quot;&gt;PR 453&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Zen4: Faster PP for &lt;code&gt;IQ2_KS, IQ4_KS, IQ5_KS&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/428&quot;&gt;PR 428&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fast GEMM/GEMV for &lt;code&gt;IQ1_S&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/212&quot;&gt;PR 212&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Function call support &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/628&quot;&gt;PR 628&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Webui: New Features for Conversations, Settings, and Chat Messages &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/618&quot;&gt;PR 618&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Legacy quants conversion schemes in &lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/449&quot;&gt;PR 449&lt;/a&gt;, &lt;code&gt;Q6_0&lt;/code&gt; in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/483&quot;&gt;PR 483&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 8 2025: Webui updated (legacy still available when &lt;code&gt;--path ./examples/server/public_legacy&lt;/code&gt; is passed) &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/481&quot;&gt;PR 481&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 8 2025: RPC improvements &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/480&quot;&gt;PR 480&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 7 2025: Add an endpoint that lists all the saved prompt caches to server &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/502&quot;&gt;PR 502&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 6 2025: Make prompt cache saving and restoring MLA aware &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/497&quot;&gt;PR 497&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 3 2025: Added samplers, XTC &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/486&quot;&gt;PR 486&lt;/a&gt;, top-n σ &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/489&quot;&gt;PR 489&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 22 2025: Refactor &lt;code&gt;iqk_mul_mat.cpp&lt;/code&gt; which speeds up compilation time significantly. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/435&quot;&gt;PR 435&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 17 2025: Option to enable or disable the CPU FA kernels &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/429&quot;&gt;PR 429&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 12 2025: User can now control if/which operations with tensors held in RAM are offloaded to the GPU. See &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/405&quot;&gt;PR 405&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 12 2025: Compatibility issues with mainline &lt;code&gt;llama.cpp&lt;/code&gt; GGUFs for DeepSeek models with MLA enabled were resolved in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/394&quot;&gt;PR 394&lt;/a&gt;. The lower prompt processing performance resulting from using &lt;code&gt;llama.cpp&lt;/code&gt;-style MLA GGUFs was recovered in &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/409&quot;&gt;PR 409&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;April 21 2025: ik_llama.cpp builds and runs successfully on Android (using termux), see &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/336&quot;&gt;PR 336&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 1 2025: Smart Expert Reduction for faster DeepSeek inference &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/239&quot;&gt;PR 239&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 25 2025: Tensor overrides for better control where model weights are stored (GPU or CPU) &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/232&quot;&gt;PR 232&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 23 2025: &lt;code&gt;sweep-bench&lt;/code&gt; - better performance benchmarking &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/225&quot;&gt;PR 225&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 19 2025: &lt;code&gt;Q8_KV&lt;/code&gt; - new type for 8-bit KV-cache quantization &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/208&quot;&gt;PR 208&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 7 2025: Custom quantization mixes using regular expressions &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/244&quot;&gt;PR 244&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance improvements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Better GPU offload strategy for MoE models when using hybrid HPU/CPU inference, see &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/520&quot;&gt;PR 520&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 13 2025: Better CPU FA performance for DeepSeek-Lite. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/410&quot;&gt;PR 410&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 11 2025: Slightly faster flash attention for DeepSeek models on CUDA, along with extending compatibility to Touring or newer GPUs. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/408&quot;&gt;PR 408&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 4 2025: Significant token generation performance improvement on CUDA with Flash Attention for GQA models. For details and benchmarks. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/370&quot;&gt;PR 370&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 17 2025: Better CPU Flash Attention token generation performance. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/332&quot;&gt;PR 332&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 3 2025: Much faster MoE implementation on Metal. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/307&quot;&gt;PR 307&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 25 2025: Better MoE performance on CUDA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/283&quot;&gt;PR 283&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 23 2025: Better batched processing speed for DeepSeek models &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/282&quot;&gt;PR 282&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 18 2025: Reduce compute buffer size &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/237&quot;&gt;PR 237&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 10 2025: Better TG performance for MoE models on CUDA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/248&quot;&gt;PR 248&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 23 2025: Fused FFN ops for faster MoE inference &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/229&quot;&gt;PR 229&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Flash-MLA&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;May 7 2025: 🚀 FlashMLA-3 for DeepSeek models on CUDA. &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/386&quot;&gt;PR 386&lt;/a&gt;. Caveat: Ampere or newer Nvidia GPU required&lt;/li&gt; 
 &lt;li&gt;March 21 2025: 🚀 FlashMLA-3: fastest CPU-only inference for DeepSeek models &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/273&quot;&gt;PR 273&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 17 2025: 🚀 FlashMLA-2 performance improvements &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/253&quot;&gt;PR 253&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 12 2025: Allow &lt;code&gt;Q8_0&lt;/code&gt; KV cache with FlashMLA-2 on CUDA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/265&quot;&gt;PR 265&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 9 2025: 🚀 FlashMLA on CUDA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/247&quot;&gt;PR 247&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 8 2025: 🚀 Faster FlashMLA CPU implementation &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/243&quot;&gt;PR 243&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;March 3 2025: 🚀 Introducing FlashMLA - MLA with Flash Attention &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/240&quot;&gt;PR 240&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 27 2025: MLA without transposed cache &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/235&quot;&gt;PR 235&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 13 2025: Allow &lt;code&gt;Q8_0&lt;/code&gt; quantized cache with MLA &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/206&quot;&gt;PR 206&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 11 2025: 🚀 Flash Attention support for DeepSeek models &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/200&quot;&gt;PR 200&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feb 9 2025: 🚀 MLA for DeepSeek models &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/188&quot;&gt;PR 188&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix bug in MMVQ kernel &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/446&quot;&gt;PR 446&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fix AVX2 implementation of &lt;code&gt;IQ4_K, IQ4_KS, IQ5_K, IQ6_K&lt;/code&gt; &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/427&quot;&gt;PR 427&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fix standard attention on the CPU &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/421&quot;&gt;PR 421&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fix imatrix calculation for MLA models &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/411&quot;&gt;PR 411&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fix new CUDA FA on Touring &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/413&quot;&gt;PR 413&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fix SER. CPU: &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/415&quot;&gt;PR 415&lt;/a&gt; CUDA: &lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/pull/416&quot;&gt;PR 416&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;There is no single point of reference describing all new &lt;code&gt;ik_llama.cpp&lt;/code&gt; features. Pull requests often contain detailed information, so browsing the PRs is often the best way to learn about new features and how to use them. In addition&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/wiki&quot;&gt;The Wiki page&lt;/a&gt; has performance comparisons to mainline &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/discussions/258&quot;&gt;This guide&lt;/a&gt; is a good place to start if you came here because of DeepSeek models&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/discussions/266&quot;&gt;This discussion&lt;/a&gt; is about running DeepSeek-V3/R1 on a 16 x 3090 setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ikawrakow/ik_llama.cpp/discussions/8&quot;&gt;This discussion&lt;/a&gt; describes the new quantization types available in &lt;code&gt;ik_llama.cpp&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;h3&gt;Function Calls Tests&lt;/h3&gt; 
&lt;p&gt;To run the function calls test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd build
cmake --build . --target test-function-calls
./bin/test-function-calls
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The test suite covers parser functionality, streaming, error handling, content cleaning, and server integration. All tests should pass to ensure production readiness.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions in form of pull requests, issue submissions (bug reports, feature requests), or general discussions, are welcome.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nisargjhaveri/WirelessAndroidAutoDongle</title>
      <link>https://github.com/nisargjhaveri/WirelessAndroidAutoDongle</link>
      <description>&lt;p&gt;Use Wireless Android Auto with a car that supports only wired Android Auto using a Raspberry Pi.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Wireless Android Auto Dongle&lt;/h1&gt; 
&lt;p&gt;DIY Wireless Android Auto adapter to use with a car that supports only wired Android Auto using a Raspberry Pi.&lt;/p&gt; 
&lt;p&gt;This repository consists of the buildroot setup to generate an sd card image to create your own Wireless Android Auto adapter.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Native Wireless Android Auto connection to the phone, no extra app needed on the phone.&lt;/li&gt; 
 &lt;li&gt;Passes through all Android Auto traffic without any modifications to ensure seamless and safe experience.&lt;/li&gt; 
 &lt;li&gt;Fast bootup, connection under 30 seconds.&lt;/li&gt; 
 &lt;li&gt;Supports multiple boards (Currently multiple Raspberry Pi boards).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Hardware&lt;/h2&gt; 
&lt;p&gt;This is currently tested and built for the following Raspberry Pi boards supporting USB OTG.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Raspberry Pi Zero W&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Raspberry Pi Zero 2 W&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Raspberry Pi 3 A+&lt;/strong&gt; &lt;em&gt;(Raspberry Pi 3 B+ is not supported due to lack of USB OTG support.)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Raspberry Pi 4&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In theory, this can be extended to more hardware in future with these basic requirements.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The board should support USB OTG or Gadget mode.&lt;/li&gt; 
 &lt;li&gt;Has Wifi and Bluetooth. External should also work if not in-built.&lt;/li&gt; 
 &lt;li&gt;Should be able to operate on power provided by the car.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install and run&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/releases&quot;&gt;Download a pre-built sd card image&lt;/a&gt; for your board. You can also &lt;a href=&quot;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/BUILDING.md&quot;&gt;build one yourself&lt;/a&gt;. Install the image on the SD card using your favorite tool.&lt;/p&gt; 
&lt;p&gt;You may want to update the country code and other settings that works best for you. See &lt;a href=&quot;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/#Configurations&quot;&gt;Configurations&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;First-time connection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Connect the phone to headunit via USB cable, make sure Android Auto starts. Disconnect phone.&lt;/li&gt; 
 &lt;li&gt;Connect the board to the car. Make sure to use a data cable, with the USB OTG enabled port on the board. 
  &lt;ul&gt; 
   &lt;li&gt;On &lt;strong&gt;Raspberry Pi Zero W&lt;/strong&gt; and &lt;strong&gt;Raspberry Pi Zero 2 W&lt;/strong&gt;: Use the second micro-usb port marked &quot;USB&quot; and not &quot;PWR&quot;.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;Raspberry Pi 3 A+&lt;/strong&gt;: Use the only USB-A port with an USB-A to USB-A cable.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;Raspberry Pi 4&lt;/strong&gt;, use the USB-C port used for normally powering the board.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Open Bluetooth settings and pair the new device called &lt;code&gt;AndroidAuto-Dongle-*&lt;/code&gt; or &lt;code&gt;WirelessAADongle-*&lt;/code&gt; on your phone.&lt;/li&gt; 
 &lt;li&gt;After this phone should automatically connect via Wifi and the dongle will connect to the headunit via USB and start Android Auto on the car screen.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Subsequent connections&lt;/h3&gt; 
&lt;p&gt;From the next time, it should automatically connect to the phone and start Android Auto.&lt;/p&gt; 
&lt;p&gt;Make sure your Bluetooth and Wifi are enabled on the phone.&lt;/p&gt; 
&lt;h2&gt;Configurations&lt;/h2&gt; 
&lt;p&gt;Once the image is installed on the SD card, you can see the SD card as &lt;code&gt;WirelessAA&lt;/code&gt; drive.&lt;/p&gt; 
&lt;p&gt;Edit the &lt;code&gt;aawgd.conf&lt;/code&gt; file inside the &lt;code&gt;WirelessAA&lt;/code&gt; drive using a text editor to update the configurations. The file contains the possible configuration options with their explanations.&lt;/p&gt; 
&lt;h2&gt;Troubleshoot&lt;/h2&gt; 
&lt;h3&gt;Common issues&lt;/h3&gt; 
&lt;h4&gt;Bluetooth and Wifi seems connected, but the phone stuck at &quot;Looking for Android Auto&quot;&lt;/h4&gt; 
&lt;p&gt;The most common issue behind this is either bad USB cable or use of wrong USB port on the device. Make sure:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The cable is good quality data cable and not power-only cable&lt;/li&gt; 
 &lt;li&gt;You&#39;re using the OTG enabled usb port on the board, and not the power-only port.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&quot;Device not responding&quot; error on headunit&lt;/h4&gt; 
&lt;p&gt;Make sure that &quot;Wireless Android Auto&quot; is enabled in your phone&#39;s Andriod Auto settings. This option is only available and required on some older phones.&lt;/p&gt; 
&lt;h3&gt;Getting logs&lt;/h3&gt; 
&lt;p&gt;Once you&#39;ve already tried multiple times and it still does not work, you can ssh into the device and try to get some logs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set a static password by setting the &lt;code&gt;AAWG_WIFI_PASSWORD&lt;/code&gt; config, and enable SSH by setting the &lt;code&gt;AAWG_ENABLE_SSH&lt;/code&gt; config. See &lt;a href=&quot;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/#Configurations&quot;&gt;the instructions to update the configurations&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Connect the device to the headunit, let it boot and try to connect once. The logs are not persisted across reboots, so you need to get the logs in the same instance soon after you observe the issue.&lt;/li&gt; 
 &lt;li&gt;Connect to the device using wifi (SSID: AAWirelessDongle, Password: &amp;lt;as set in the first step&amp;gt;).&lt;/li&gt; 
 &lt;li&gt;SSH into the device (username: root, password: password, see relevant defconfigs e.g. &lt;a href=&quot;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/aa_wireless_dongle/configs/raspberrypi0w_defconfig&quot;&gt;raspberrypi0w_defconfig&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Once you&#39;re in, try to have a look at &lt;code&gt;/var/log/messages&lt;/code&gt; file, it should have most relevant logs to start with. You can also copy the file and attach to issues you create if any.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/issues&quot;&gt;Find or create a new issue&lt;/a&gt; for any bugs or improvements.&lt;/p&gt; 
&lt;p&gt;Feel free to &lt;a href=&quot;https://github.com/nisargjhaveri/WirelessAndroidAutoDongle/pulls&quot;&gt;Create a PR&lt;/a&gt; to fix any issues. Refer &lt;a href=&quot;https://raw.githubusercontent.com/nisargjhaveri/WirelessAndroidAutoDongle/main/BUILDING.md&quot;&gt;BUILDING.md&lt;/a&gt; for instructions on how to build locally.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Please &lt;a href=&quot;https://github.com/sponsors/nisargjhaveri&quot;&gt;consider sponsoring&lt;/a&gt; if you find the project useful. Even a small donation helps. This will help continuing fixing issues and getting support for more devices and headunit in future.&lt;/p&gt; 
&lt;p&gt;In any case, don&#39;t forget to star on github and spread the word if you think this project might be useful to someone else as well.&lt;/p&gt; 
&lt;h2&gt;Limitations&lt;/h2&gt; 
&lt;p&gt;This is currently tested with very limited set of headunits and cars. Let me know if it does not work with your headunit.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
