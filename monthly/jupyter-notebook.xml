<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Jupyter Notebook Monthly Trending</title>
    <description>Monthly Trending of Jupyter Notebook in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:54:03 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>aws/amazon-sagemaker-examples</title>
      <link>https://github.com/aws/amazon-sagemaker-examples</link>
      <description>&lt;p&gt;Example ğŸ““ Jupyter notebooks that demonstrate how to build, train, and deploy machine learning models using ğŸ§  Amazon SageMaker.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/aws/amazon-sagemaker-examples/raw/main/_static/sagemaker-banner.png&quot; alt=&quot;SageMaker&quot; /&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;â—&lt;/span&gt;&lt;span&gt;ğŸ”¥&lt;/span&gt; Announcing SageMaker-Core: A New Python SDK for Amazon SageMaker &lt;span&gt;ğŸ”¥&lt;/span&gt;&lt;span&gt;â—&lt;/span&gt;&lt;/h1&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Today, Amazon SageMaker is excited to announce the release of SageMaker-Core, a new Python SDK that provides an object-oriented interface for interacting with SageMaker resources such as TrainingJob, Model, and Endpoint. This SDK introduces the resource chaining feature, allowing developers to pass resource objects as parameters, eliminating manual parameter specification and simplifying code management. SageMaker-Core abstracts low-level details like resource state transitions and polling logic, achieving full parity with SageMaker APIs. It also includes usability improvements such as auto code completion, comprehensive documentation, and type hints, enhancing the overall developer experience.&lt;/p&gt; 
&lt;h2&gt;Use Case&lt;/h2&gt; 
&lt;p&gt;SageMaker-Core is ideal for ML practitioners who seek full customization of AWS primitives for their ML workloads. SageMaker-Core is an improvement over Boto3, providing a more intuitive and efficient way to manage SageMaker resources. By providing an intuitive object-oriented interface and resource chaining, the SDK allows for seamless integration and management of SageMaker resources. This flexibility, combined with intelligent defaults enables developers to tailor their ML workloads according to their needs. Comprehensive documentation, and type hints help developers write code faster and with fewer errors without navigating complex API documentation.&lt;/p&gt; 
&lt;h2&gt;Call to Action&lt;/h2&gt; 
&lt;p&gt;To learn more about SageMaker-Core, visit the &lt;a href=&quot;https://sagemaker-core.readthedocs.io&quot;&gt;documentation&lt;/a&gt; and &lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples/tree/default/sagemaker-core&quot;&gt;example notebooks&lt;/a&gt;. Get started today by integrating SageMaker-Core into your machine learning workflows and experience the benefits of a streamlined and efficient development process.&lt;/p&gt; 
&lt;h1&gt;Amazon SageMaker Examples&lt;/h1&gt; 
&lt;p&gt;Example Jupyter notebooks that demonstrate how to build, train, and deploy machine learning models using Amazon SageMaker.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“š&lt;/span&gt; Read this before you proceed further&lt;/h2&gt; 
&lt;p&gt;Amazon SageMaker examples are divided in two repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples&quot;&gt;SageMaker example notebooks&lt;/a&gt; is the official repository, containing examples that demonstrate the usage of Amazon SageMaker. This repository is entirely focussed on covering the breadth of features provided by SageMaker, and is maintained directly by the Amazon SageMaker team.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples-community&quot;&gt;Sagemaker Example Community repository&lt;/a&gt; is another SageMaker repository which contains additional examples and reference solutions, beyond the examples showcased in the &lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples&quot;&gt;official repository&lt;/a&gt;. This repository is maintained by community of engineers and solution architects at AWS.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Planning to submit a PR to this repository? Read this first:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;This repository will only accept notebooks/examples which demonstrate a feature of SageMaker, not yet covered anywhere in this repository. PR submitters are requested to check this before submitting the PR to avoid getting it rejected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you still would like to contribute your example, please submit a PR to &lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples-community&quot;&gt;Sagemaker Example Community repository&lt;/a&gt; instead.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ› &lt;/span&gt; Setup&lt;/h2&gt; 
&lt;p&gt;The quickest setup to run example notebooks includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An &lt;a href=&quot;http://docs.aws.amazon.com/sagemaker/latest/dg/gs-account.html&quot;&gt;AWS account&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Proper &lt;a href=&quot;http://docs.aws.amazon.com/sagemaker/latest/dg/authentication-and-access-control.html&quot;&gt;IAM User and Role&lt;/a&gt; setup&lt;/li&gt; 
 &lt;li&gt;An &lt;a href=&quot;http://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html&quot;&gt;Amazon SageMaker Notebook Instance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;An &lt;a href=&quot;http://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html&quot;&gt;S3 bucket&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ’»&lt;/span&gt; Usage&lt;/h2&gt; 
&lt;p&gt;These example notebooks are automatically loaded into SageMaker Notebook Instances. They can be accessed by clicking on the &lt;code&gt;SageMaker Examples&lt;/code&gt; tab in Jupyter or the SageMaker logo in JupyterLab.&lt;/p&gt; 
&lt;p&gt;Although most examples utilize key Amazon SageMaker functionality like distributed, managed training or real-time hosted endpoints, these notebooks can be run outside of Amazon SageMaker Notebook Instances with minimal modification (updating IAM role definition and installing the necessary libraries).&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ““&lt;/span&gt; Example Notebook Categories&lt;/h2&gt; 
&lt;h3&gt;End-to-End ML Lifecycle&lt;/h3&gt; 
&lt;p&gt;These examples are a diverse collection of end-to-end notebooks that demonstrate how to build, train, and deploy machine learning models using Amazon SageMaker. These notebooks cover a wide range of machine learning tasks and use cases, providing you with a comprehensive understanding of the SageMaker workflow. Each notebook in this folder is self-contained and includes detailed documentation, code samples, and instructions for running the examples on SageMaker. Whether you&#39;re a beginner or an experienced practitioner, this folder offers a comprehensive collection of end-to-end notebooks that will help you leverage the power of Amazon SageMaker for a wide range of machine learning tasks and use cases.&lt;/p&gt; 
&lt;h3&gt;Prepare Data&lt;/h3&gt; 
&lt;p&gt;The example notebooks within this folder showcase Sagemaker&#39;s data preparation capabilities. Data preparation in machine learning refers to the process of collecting, preprocessing, and organizing raw data to make it suitable for analysis and modeling. This step ensures that the data is in a format from which machine learning algorithms can effectively learn. Data preparation tasks may include handling missing values, removing outliers, scaling features, encoding categorical variables, assessing potential biases and taking steps to mitigate them, splitting data into training and testing sets, labeling, and other necessary transformations to optimize the quality and usability of the data for subsequent machine learning tasks.&lt;/p&gt; 
&lt;h3&gt;Build and Train Models&lt;/h3&gt; 
&lt;p&gt;Amazon SageMaker Training is a fully managed machine learning (ML) service offered by SageMaker that helps you efficiently build and train a wide range of ML models at scale. The core of SageMaker jobs is the containerization of ML workloads and the capability of managing AWS compute resources. The SageMaker Training platform takes care of the heavy lifting associated with setting up and managing infrastructure for ML training workloads. With SageMaker Training, you can focus on building, developing, training, and fine-tuning your model.&lt;/p&gt; 
&lt;h3&gt;Deploy and Monitor&lt;/h3&gt; 
&lt;p&gt;With Amazon SageMaker, you can start getting predictions, or inferences, from your trained machine learning models. SageMaker provides a broad selection of ML infrastructure and model deployment options to help meet all your ML inference needs. With SageMaker Inference, you can scale your model deployment, manage models more effectively in production, and reduce operational burden. SageMaker provides you with various inference options, such as real-time endpoints for getting low latency inference, serverless endpoints for fully managed infrastructure and auto-scaling, and asynchronous endpoints for batches of requests. By leveraging the appropriate inference option for your use case, you can ensure efficient and model deployment and inference.&lt;/p&gt; 
&lt;p&gt;After you deploy a model into your production environment, use Amazon SageMaker model monitor to continuously monitor the quality of your machine learning models in real time. Amazon SageMaker model monitor enables you to set up an automated alert triggering system when there are deviations in the model quality, such as data drift and anomalies. Amazon CloudWatch Logs collects log files of monitoring the model status and notifies when the quality of your model hits certain thresholds that you preset. CloudWatch stores the log files to an Amazon S3 bucket you specify. Early and pro-active detection of model deviations through AWS model monitor products enables you to take prompt actions to maintain and improve the quality of your deployed model.&lt;/p&gt; 
&lt;h3&gt;Generative AI&lt;/h3&gt; 
&lt;p&gt;These examples showcases Amazon SageMaker&#39;s capabilities in the exciting field of generative artificial intelligence (AI). Generative AI models are designed to create new, synthetic data across various modalities, such as text, images, audio, and video, based on the patterns and relationships learned from training data. These examples provide detailed documentation, code samples, and instructions for running the generative AI models on SageMaker. And demonstrate how to preprocess data, train models, fine-tune hyperparameters, and deploy the trained models for inference.&lt;/p&gt; 
&lt;p&gt;Whether you&#39;re interested in exploring the latest advancements in generative AI, or seeking to leverage these techniques for creative applications or content generation, this folder offers a comprehensive collection of examples that will help you unlock the power of SageMaker&#39;s generative AI capabilities and push the boundaries of what&#39;s possible with machine learning.&lt;/p&gt; 
&lt;h3&gt;ML Ops&lt;/h3&gt; 
&lt;p&gt;Amazon SageMaker supports features to implement machine learning models in production environments with continuous integration and deployment. MLOps accounts for the unique aspects of AI/ML projects in project management, CI/CD, and quality assurance, helping you improve delivery time, reduce defects, and make data science more productive. MLOps refers to a methodology that is built on applying DevOps practices to machine learning workloads.&lt;/p&gt; 
&lt;h3&gt;Responsible AI&lt;/h3&gt; 
&lt;p&gt;Amazon SageMaker offers features to improve your machine learning (ML) models by detecting potential bias and helping to explain the predictions that your models make from your tabular, computer vision, natural processing, or time series datasets. It helps you identify various types of bias in pre-training data and in post-training that can emerge during model training or when the model is in production. You can also evaluate a language model for model quality and responsibility metrics using foundation model evaluations.&lt;/p&gt; 
&lt;p&gt;Model governance is a framework that gives systematic visibility into machine learning (ML) model development, validation, and usage. Amazon SageMaker provides purpose-built ML governance tools for managing control access, activity tracking, and reporting across the ML lifecycle. Manage least-privilege permissions for ML practitioners using Amazon SageMaker Role Manager, create detailed model documentation using Amazon SageMaker Model Cards, and gain visibility into your models with centralized dashboards using Amazon SageMaker Model Dashboard.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;âš–&lt;/span&gt; License&lt;/h2&gt; 
&lt;p&gt;This library is licensed under the &lt;a href=&quot;http://aws.amazon.com/apache2.0/&quot;&gt;Apache 2.0 License&lt;/a&gt;. For more details, please take a look at the &lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples/raw/master/LICENSE.txt&quot;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ¤&lt;/span&gt; Contributing&lt;/h2&gt; 
&lt;p&gt;Although we&#39;re extremely excited to receive contributions from the community, we&#39;re still working on the best mechanism to take in examples from external sources. Please bear with us in the short-term if pull requests take longer than expected or are closed. Please read our &lt;a href=&quot;https://github.com/aws/amazon-sagemaker-examples/raw/default/CONTRIBUTING.md&quot;&gt;contributing guidelines&lt;/a&gt; if you&#39;d like to open an issue or submit a pull request.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jackfrued/Python-100-Days</title>
      <link>https://github.com/jackfrued/Python-100-Days</link>
      <description>&lt;p&gt;Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆ&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œè€…&lt;/strong&gt;ï¼šéª†æ˜Š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šå¦‚æœè®¿é—® GitHub æ¯”è¾ƒæ…¢çš„è¯ï¼Œå¯ä»¥å…³æ³¨æˆ‘çš„çŸ¥ä¹å·ï¼ˆ&lt;a href=&quot;https://www.zhihu.com/people/jackfrued&quot;&gt;&lt;strong&gt;Python-Jack&lt;/strong&gt;&lt;/a&gt;ï¼‰ï¼Œä¸Šé¢çš„&lt;a href=&quot;https://zhuanlan.zhihu.com/c_1216656665569013760&quot;&gt;â€œ&lt;strong&gt;ä»é›¶å¼€å§‹å­¦Python&lt;/strong&gt;â€&lt;/a&gt;ä¸“æ ï¼ˆå¯¹åº”æœ¬é¡¹ç›®å‰ 20 å¤©çš„å†…å®¹ï¼‰æ¯”è¾ƒé€‚åˆåˆå­¦è€…ï¼Œå…¶ä»–çš„ä¸“æ å¦‚â€œ&lt;a href=&quot;https://www.zhihu.com/column/c_1620074540456964096&quot;&gt;&lt;strong&gt;æ•°æ®æ€ç»´å’Œç»Ÿè®¡æ€ç»´&lt;/strong&gt;&lt;/a&gt;â€ã€â€œ&lt;a href=&quot;https://www.zhihu.com/column/c_1217746527315496960&quot;&gt;&lt;strong&gt;åŸºäºPythonçš„æ•°æ®åˆ†æ&lt;/strong&gt;&lt;/a&gt;â€ã€â€œ&lt;a href=&quot;https://www.zhihu.com/column/c_1628900668109946880&quot;&gt;&lt;strong&gt;è¯´èµ°å°±èµ°çš„AIä¹‹æ—…&lt;/strong&gt;&lt;/a&gt;â€ç­‰ä¹Ÿåœ¨æŒç»­åˆ›ä½œå’Œæ›´æ–°ä¸­ï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨ã€ç‚¹èµå’Œè¯„è®ºã€‚å¦‚æœå¸Œæœ›å…è´¹å­¦ä¹ æ‰“å¡æˆ–è€…å‚ä¸é—®é¢˜è®¨è®ºï¼Œå¯ä»¥åŠ å…¥ä¸‹é¢çš„ QQ äº¤æµç¾¤ï¼ˆä¸‰ä¸ªç¾¤åŠ ä¸€ä¸ªå³å¯ï¼‰ï¼Œè¯·ä¸è¦é‡å¤åŠ ç¾¤ï¼Œä¹Ÿä¸è¦åœ¨ç¾¤é‡Œå‘å¸ƒå¹¿å‘Šå’Œå…¶ä»–è‰²æƒ…ã€ä½ä¿—æˆ–æ•æ„Ÿå†…å®¹ã€‚å¦‚æœæœ‰ä»˜è´¹å­¦ä¹ æˆ–ä»˜è´¹å’¨è¯¢çš„éœ€æ±‚ï¼Œå¯ä»¥æ·»åŠ æˆ‘çš„ç§äººå¾®ä¿¡ï¼ˆå¾®ä¿¡å·ï¼š&lt;strong&gt;jackfrued&lt;/strong&gt;ï¼‰ï¼Œå¤‡æ³¨å¥½è‡ªå·±çš„ç§°å‘¼å’Œéœ€æ±‚ï¼Œæˆ‘ä¼šä¸ºå¤§å®¶æä¾›åŠ›æ‰€èƒ½åŠçš„å¸®åŠ©ã€‚&lt;/p&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/python_study_qq_group.png&quot; style=&quot;zoom:30%;&quot; /&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®å¯¹åº”çš„éƒ¨åˆ†è§†é¢‘å·²ç»åŒæ­¥åˆ° &lt;a href=&quot;https://space.bilibili.com/1177252794&quot;&gt;Bilibili&lt;/a&gt;ï¼Œæœ‰å…´è¶£çš„å°ä¼™ä¼´å¯ä»¥ç‚¹èµã€æŠ•å¸ã€å…³æ³¨ï¼Œä¸€é”®ä¸‰è¿æ”¯æŒä¸€ä¸‹ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pythonåº”ç”¨é¢†åŸŸå’ŒèŒä¸šå‘å±•åˆ†æ&lt;/h3&gt; 
&lt;p&gt;ç®€å•çš„è¯´ï¼ŒPythonæ˜¯ä¸€ä¸ªâ€œä¼˜é›…â€ã€â€œæ˜ç¡®â€ã€â€œç®€å•â€çš„ç¼–ç¨‹è¯­è¨€ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å­¦ä¹ æ›²çº¿ä½ï¼Œéä¸“ä¸šäººå£«ä¹Ÿèƒ½ä¸Šæ‰‹&lt;/li&gt; 
 &lt;li&gt;å¼€æºç³»ç»Ÿï¼Œæ‹¥æœ‰å¼ºå¤§çš„ç”Ÿæ€åœˆ&lt;/li&gt; 
 &lt;li&gt;è§£é‡Šå‹è¯­è¨€ï¼Œå®Œç¾çš„å¹³å°å¯ç§»æ¤æ€§&lt;/li&gt; 
 &lt;li&gt;åŠ¨æ€ç±»å‹è¯­è¨€ï¼Œæ”¯æŒé¢å‘å¯¹è±¡å’Œå‡½æ•°å¼ç¼–ç¨‹&lt;/li&gt; 
 &lt;li&gt;ä»£ç è§„èŒƒç¨‹åº¦é«˜ï¼Œå¯è¯»æ€§å¼º&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Pythonåœ¨ä»¥ä¸‹é¢†åŸŸéƒ½æœ‰ç”¨æ­¦ä¹‹åœ°ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;åç«¯å¼€å‘ - Python / Java / Go / PHP&lt;/li&gt; 
 &lt;li&gt;DevOps - Python / Shell / Ruby&lt;/li&gt; 
 &lt;li&gt;æ•°æ®é‡‡é›† - Python / C++ / Java&lt;/li&gt; 
 &lt;li&gt;é‡åŒ–äº¤æ˜“ - Python / C++ / R&lt;/li&gt; 
 &lt;li&gt;æ•°æ®ç§‘å­¦ - Python / R / Julia / Matlab&lt;/li&gt; 
 &lt;li&gt;æœºå™¨å­¦ä¹  - Python / R / C++ / Julia&lt;/li&gt; 
 &lt;li&gt;è‡ªåŠ¨åŒ–æµ‹è¯• - Python / Shell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œæ ¹æ®ä¸ªäººçš„å–œå¥½å’ŒèŒä¸šè§„åˆ’ï¼Œå¯ä»¥é€‰æ‹©çš„å°±ä¸šé¢†åŸŸä¹Ÿéå¸¸å¤šã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆæœåŠ¡å™¨ã€äº‘å¹³å°ã€æ•°æ®æ¥å£ï¼‰&lt;/li&gt; 
 &lt;li&gt;Pythonè¿ç»´å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–è¿ç»´ã€SREã€DevOpsï¼‰&lt;/li&gt; 
 &lt;li&gt;Pythonæ•°æ®åˆ†æå¸ˆï¼ˆæ•°æ®åˆ†æã€å•†ä¸šæ™ºèƒ½ã€æ•°å­—åŒ–è¿è¥ï¼‰&lt;/li&gt; 
 &lt;li&gt;Pythonæ•°æ®ç§‘å­¦å®¶ï¼ˆæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç®—æ³•ä¸“å®¶ï¼‰&lt;/li&gt; 
 &lt;li&gt;Pythonçˆ¬è™«å·¥ç¨‹å¸ˆï¼ˆä¸æ¨èæ­¤èµ›é“ï¼ï¼ï¼ï¼‰&lt;/li&gt; 
 &lt;li&gt;Pythonæµ‹è¯•å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–æµ‹è¯•ã€æµ‹è¯•å¼€å‘ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šç›®å‰ï¼Œ&lt;strong&gt;æ•°æ®ç§‘å­¦èµ›é“æ˜¯éå¸¸çƒ­é—¨çš„æ–¹å‘&lt;/strong&gt;ï¼Œå› ä¸ºä¸ç®¡æ˜¯äº’è”ç½‘è¡Œä¸šè¿˜æ˜¯ä¼ ç»Ÿè¡Œä¸šéƒ½å·²ç»ç§¯ç´¯äº†å¤§é‡çš„æ•°æ®ï¼Œå„è¡Œå„ä¸šéƒ½éœ€è¦æ•°æ®ç§‘å­¦å®¶ä»å·²æœ‰çš„æ•°æ®ä¸­å‘ç°æ›´å¤šçš„å•†ä¸šä»·å€¼ï¼Œä»è€Œä¸ºä¼ä¸šçš„å†³ç­–æä¾›æ•°æ®çš„æ”¯æ’‘ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æ•°æ®é©±åŠ¨å†³ç­–ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ç»™åˆå­¦è€…çš„å‡ ä¸ªå»ºè®®ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Make English as your working language.&lt;/strong&gt; ï¼ˆè®©è‹±è¯­æˆä¸ºä½ çš„å·¥ä½œè¯­è¨€ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Practice makes perfect.&lt;/strong&gt; ï¼ˆç†Ÿèƒ½ç”Ÿå·§ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;All experience comes from the mistakes you&#39;ve made.&lt;/strong&gt; ï¼ˆæ‰€æœ‰çš„ç»éªŒéƒ½æºäºä½ çŠ¯è¿‡çš„é”™è¯¯ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Don&#39;t be a freeloader.&lt;/strong&gt; ï¼ˆä¸è¦å½“ä¼¸æ‰‹å…šï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Either outstanding or out.&lt;/strong&gt; ï¼ˆè¦ä¹ˆå‡ºä¼—ï¼Œè¦ä¹ˆå‡ºå±€ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Day01~20 - Pythonè¯­è¨€åŸºç¡€&lt;/h3&gt; 
&lt;h4&gt;Day01 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/01.%E5%88%9D%E8%AF%86Python.md&quot;&gt;åˆè¯†Python&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pythonç®€ä»‹ 
  &lt;ul&gt; 
   &lt;li&gt;Pythonç¼–å¹´å²&lt;/li&gt; 
   &lt;li&gt;Pythonä¼˜ç¼ºç‚¹&lt;/li&gt; 
   &lt;li&gt;Pythonåº”ç”¨é¢†åŸŸ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å®‰è£…Pythonç¯å¢ƒ 
  &lt;ul&gt; 
   &lt;li&gt;Windowsç¯å¢ƒ&lt;/li&gt; 
   &lt;li&gt;macOSç¯å¢ƒ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day02 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/02.%E7%AC%AC%E4%B8%80%E4%B8%AAPython%E7%A8%8B%E5%BA%8F.md&quot;&gt;ç¬¬ä¸€ä¸ªPythonç¨‹åº&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç¼–å†™ä»£ç çš„å·¥å…·&lt;/li&gt; 
 &lt;li&gt;ä½ å¥½ä¸–ç•Œ&lt;/li&gt; 
 &lt;li&gt;æ³¨é‡Šä½ çš„ä»£ç &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day03 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/03.Python%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F.md&quot;&gt;Pythonè¯­è¨€ä¸­çš„å˜é‡&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä¸€äº›å¸¸è¯†&lt;/li&gt; 
 &lt;li&gt;å˜é‡å’Œç±»å‹&lt;/li&gt; 
 &lt;li&gt;å˜é‡å‘½å&lt;/li&gt; 
 &lt;li&gt;å˜é‡çš„ä½¿ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day04 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/04.Python%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6.md&quot;&gt;Pythonè¯­è¨€ä¸­çš„è¿ç®—ç¬¦&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç®—æœ¯è¿ç®—ç¬¦&lt;/li&gt; 
 &lt;li&gt;èµ‹å€¼è¿ç®—ç¬¦&lt;/li&gt; 
 &lt;li&gt;æ¯”è¾ƒè¿ç®—ç¬¦å’Œé€»è¾‘è¿ç®—ç¬¦&lt;/li&gt; 
 &lt;li&gt;è¿ç®—ç¬¦å’Œè¡¨è¾¾å¼åº”ç”¨ 
  &lt;ul&gt; 
   &lt;li&gt;åæ°å’Œæ‘„æ°æ¸©åº¦è½¬æ¢&lt;/li&gt; 
   &lt;li&gt;è®¡ç®—åœ†çš„å‘¨é•¿å’Œé¢ç§¯&lt;/li&gt; 
   &lt;li&gt;åˆ¤æ–­é—°å¹´&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day05 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/05.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84.md&quot;&gt;åˆ†æ”¯ç»“æ„&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä½¿ç”¨ifå’Œelseæ„é€ åˆ†æ”¯ç»“æ„&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨matchå’Œcaseæ„é€ åˆ†æ”¯ç»“æ„&lt;/li&gt; 
 &lt;li&gt;åˆ†æ”¯ç»“æ„çš„åº”ç”¨ 
  &lt;ul&gt; 
   &lt;li&gt;åˆ†æ®µå‡½æ•°æ±‚å€¼&lt;/li&gt; 
   &lt;li&gt;ç™¾åˆ†åˆ¶æˆç»©è½¬æ¢æˆç­‰çº§&lt;/li&gt; 
   &lt;li&gt;è®¡ç®—ä¸‰è§’å½¢çš„å‘¨é•¿å’Œé¢ç§¯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day06 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/06.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84.md&quot;&gt;å¾ªç¯ç»“æ„&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;for-inå¾ªç¯&lt;/li&gt; 
 &lt;li&gt;whileå¾ªç¯&lt;/li&gt; 
 &lt;li&gt;breakå’Œcontinue&lt;/li&gt; 
 &lt;li&gt;åµŒå¥—çš„å¾ªç¯ç»“æ„&lt;/li&gt; 
 &lt;li&gt;å¾ªç¯ç»“æ„çš„åº”ç”¨ 
  &lt;ul&gt; 
   &lt;li&gt;åˆ¤æ–­ç´ æ•°&lt;/li&gt; 
   &lt;li&gt;æœ€å¤§å…¬çº¦æ•°&lt;/li&gt; 
   &lt;li&gt;çŒœæ•°å­—æ¸¸æˆ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day07 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/07.%E5%88%86%E6%94%AF%E5%92%8C%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E5%AE%9E%E6%88%98.md&quot;&gt;åˆ†æ”¯å’Œå¾ªç¯ç»“æ„å®æˆ˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä¾‹å­1ï¼š100ä»¥å†…çš„ç´ æ•°&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­2ï¼šæ–æ³¢é‚£å¥‘æ•°åˆ—&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­3ï¼šå¯»æ‰¾æ°´ä»™èŠ±æ•°&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­4ï¼šç™¾é’±ç™¾é¸¡é—®é¢˜&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­5ï¼šCRAPSèµŒåšæ¸¸æˆ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day08 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/08.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8-1.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹åˆ—è¡¨-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºåˆ—è¡¨&lt;/li&gt; 
 &lt;li&gt;åˆ—è¡¨çš„è¿ç®—&lt;/li&gt; 
 &lt;li&gt;å…ƒç´ çš„éå†&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day09 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/09.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8-2.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹åˆ—è¡¨-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ—è¡¨çš„æ–¹æ³• 
  &lt;ul&gt; 
   &lt;li&gt;æ·»åŠ å’Œåˆ é™¤å…ƒç´ &lt;/li&gt; 
   &lt;li&gt;å…ƒç´ ä½ç½®å’Œé¢‘æ¬¡&lt;/li&gt; 
   &lt;li&gt;å…ƒç´ æ’åºå’Œåè½¬&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;åˆ—è¡¨ç”Ÿæˆå¼&lt;/li&gt; 
 &lt;li&gt;åµŒå¥—åˆ—è¡¨&lt;/li&gt; 
 &lt;li&gt;åˆ—è¡¨çš„åº”ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day10 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/10.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%83%E7%BB%84.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹å…ƒç»„&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å…ƒç»„çš„å®šä¹‰å’Œè¿ç®—&lt;/li&gt; 
 &lt;li&gt;æ‰“åŒ…å’Œè§£åŒ…æ“ä½œ&lt;/li&gt; 
 &lt;li&gt;äº¤æ¢å˜é‡çš„å€¼&lt;/li&gt; 
 &lt;li&gt;å…ƒç»„å’Œåˆ—è¡¨çš„æ¯”è¾ƒ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day11 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/11.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹å­—ç¬¦ä¸²&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å­—ç¬¦ä¸²çš„å®šä¹‰ 
  &lt;ul&gt; 
   &lt;li&gt;è½¬ä¹‰å­—ç¬¦&lt;/li&gt; 
   &lt;li&gt;åŸå§‹å­—ç¬¦ä¸²&lt;/li&gt; 
   &lt;li&gt;å­—ç¬¦çš„ç‰¹æ®Šè¡¨ç¤º&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å­—ç¬¦ä¸²çš„è¿ç®— 
  &lt;ul&gt; 
   &lt;li&gt;æ‹¼æ¥å’Œé‡å¤&lt;/li&gt; 
   &lt;li&gt;æ¯”è¾ƒè¿ç®—&lt;/li&gt; 
   &lt;li&gt;æˆå‘˜è¿ç®—&lt;/li&gt; 
   &lt;li&gt;è·å–å­—ç¬¦ä¸²é•¿åº¦&lt;/li&gt; 
   &lt;li&gt;ç´¢å¼•å’Œåˆ‡ç‰‡&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å­—ç¬¦çš„éå†&lt;/li&gt; 
 &lt;li&gt;å­—ç¬¦ä¸²çš„æ–¹æ³• 
  &lt;ul&gt; 
   &lt;li&gt;å¤§å°å†™ç›¸å…³æ“ä½œ&lt;/li&gt; 
   &lt;li&gt;æŸ¥æ‰¾æ“ä½œ&lt;/li&gt; 
   &lt;li&gt;æ€§è´¨åˆ¤æ–­&lt;/li&gt; 
   &lt;li&gt;æ ¼å¼åŒ–&lt;/li&gt; 
   &lt;li&gt;ä¿®å‰ªæ“ä½œ&lt;/li&gt; 
   &lt;li&gt;æ›¿æ¢æ“ä½œ&lt;/li&gt; 
   &lt;li&gt;æ‹†åˆ†ä¸åˆå¹¶&lt;/li&gt; 
   &lt;li&gt;ç¼–ç ä¸è§£ç &lt;/li&gt; 
   &lt;li&gt;å…¶ä»–æ–¹æ³•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day12 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/12.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%9B%86%E5%90%88.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹é›†åˆ&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºé›†åˆ&lt;/li&gt; 
 &lt;li&gt;å…ƒç´ çš„å˜é‡&lt;/li&gt; 
 &lt;li&gt;é›†åˆçš„è¿ç®— 
  &lt;ul&gt; 
   &lt;li&gt;æˆå‘˜è¿ç®—&lt;/li&gt; 
   &lt;li&gt;äºŒå…ƒè¿ç®—&lt;/li&gt; 
   &lt;li&gt;æ¯”è¾ƒè¿ç®—&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;é›†åˆçš„æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;ä¸å¯å˜é›†åˆ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day13 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/13.%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8.md&quot;&gt;å¸¸ç”¨æ•°æ®ç»“æ„ä¹‹å­—å…¸&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºå’Œä½¿ç”¨å­—å…¸&lt;/li&gt; 
 &lt;li&gt;å­—å…¸çš„è¿ç®—&lt;/li&gt; 
 &lt;li&gt;å­—å…¸çš„æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;å­—å…¸çš„åº”ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day14 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/14.%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E5%9D%97.md&quot;&gt;å‡½æ•°å’Œæ¨¡å—&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®šä¹‰å‡½æ•°&lt;/li&gt; 
 &lt;li&gt;å‡½æ•°çš„å‚æ•° 
  &lt;ul&gt; 
   &lt;li&gt;ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°&lt;/li&gt; 
   &lt;li&gt;å‚æ•°çš„é»˜è®¤å€¼&lt;/li&gt; 
   &lt;li&gt;å¯å˜å‚æ•°&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ç”¨æ¨¡å—ç®¡ç†å‡½æ•°&lt;/li&gt; 
 &lt;li&gt;æ ‡å‡†åº“ä¸­çš„æ¨¡å—å’Œå‡½æ•°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day15 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/15.%E5%87%BD%E6%95%B0%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98.md&quot;&gt;å‡½æ•°åº”ç”¨å®æˆ˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä¾‹å­1ï¼šéšæœºéªŒè¯ç &lt;/li&gt; 
 &lt;li&gt;ä¾‹å­2ï¼šåˆ¤æ–­ç´ æ•°&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­3ï¼šæœ€å¤§å…¬çº¦æ•°å’Œæœ€å°å…¬å€æ•°&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­4ï¼šæ•°æ®ç»Ÿè®¡&lt;/li&gt; 
 &lt;li&gt;ä¾‹å­5ï¼šåŒè‰²çƒéšæœºé€‰å·&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day16 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/16.%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6.md&quot;&gt;å‡½æ•°ä½¿ç”¨è¿›é˜¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;é«˜é˜¶å‡½æ•°&lt;/li&gt; 
 &lt;li&gt;Lambdaå‡½æ•°&lt;/li&gt; 
 &lt;li&gt;åå‡½æ•°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day17 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/17.%E5%87%BD%E6%95%B0%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8.md&quot;&gt;å‡½æ•°é«˜çº§åº”ç”¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è£…é¥°å™¨&lt;/li&gt; 
 &lt;li&gt;é€’å½’è°ƒç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day18 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/18.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8.md&quot;&gt;é¢å‘å¯¹è±¡ç¼–ç¨‹å…¥é—¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç±»å’Œå¯¹è±¡&lt;/li&gt; 
 &lt;li&gt;å®šä¹‰ç±»&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºå’Œä½¿ç”¨å¯¹è±¡&lt;/li&gt; 
 &lt;li&gt;åˆå§‹åŒ–æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;é¢å‘å¯¹è±¡çš„æ”¯æŸ±&lt;/li&gt; 
 &lt;li&gt;é¢å‘å¯¹è±¡æ¡ˆä¾‹ 
  &lt;ul&gt; 
   &lt;li&gt;ä¾‹å­1ï¼šæ•°å­—æ—¶é’Ÿ&lt;/li&gt; 
   &lt;li&gt;ä¾‹å­2ï¼šå¹³é¢ä¸Šçš„ç‚¹&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day19 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/19.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6.md&quot;&gt;é¢å‘å¯¹è±¡ç¼–ç¨‹è¿›é˜¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å¯è§æ€§å’Œå±æ€§è£…é¥°å™¨&lt;/li&gt; 
 &lt;li&gt;åŠ¨æ€å±æ€§&lt;/li&gt; 
 &lt;li&gt;é™æ€æ–¹æ³•å’Œç±»æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;ç»§æ‰¿å’Œå¤šæ€&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day20 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day01-20/20.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E5%BA%94%E7%94%A8.md&quot;&gt;é¢å‘å¯¹è±¡ç¼–ç¨‹åº”ç”¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ‰‘å…‹æ¸¸æˆ&lt;/li&gt; 
 &lt;li&gt;å·¥èµ„ç»“ç®—ç³»ç»Ÿ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day21~30 - Pythonè¯­è¨€åº”ç”¨&lt;/h3&gt; 
&lt;h4&gt;Day21 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/21.%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.md&quot;&gt;æ–‡ä»¶è¯»å†™å’Œå¼‚å¸¸å¤„ç†&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ‰“å¼€å’Œå…³é—­æ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;è¯»å†™æ–‡æœ¬æ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;å¼‚å¸¸å¤„ç†æœºåˆ¶&lt;/li&gt; 
 &lt;li&gt;ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¯­æ³•&lt;/li&gt; 
 &lt;li&gt;è¯»å†™äºŒè¿›åˆ¶æ–‡ä»¶&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day22 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/22.%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96.md&quot;&gt;å¯¹è±¡çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;JSONæ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;è¯»å†™JSONæ ¼å¼çš„æ•°æ®&lt;/li&gt; 
 &lt;li&gt;åŒ…ç®¡ç†å·¥å…·pip&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨ç½‘ç»œAPIè·å–æ•°æ®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day23 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/23.Python%E8%AF%BB%E5%86%99CSV%E6%96%87%E4%BB%B6.md&quot;&gt;Pythonè¯»å†™CSVæ–‡ä»¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;CSVæ–‡ä»¶ä»‹ç»&lt;/li&gt; 
 &lt;li&gt;å°†æ•°æ®å†™å…¥CSVæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;ä»CSVæ–‡ä»¶è¯»å–æ•°æ®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day24 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/24.%E7%94%A8Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-1.md&quot;&gt;Pythonè¯»å†™Excelæ–‡ä»¶-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Excelç®€ä»‹&lt;/li&gt; 
 &lt;li&gt;è¯»Excelæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;å†™Excelæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;è°ƒæ•´æ ·å¼&lt;/li&gt; 
 &lt;li&gt;å…¬å¼è®¡ç®—&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day25 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/25.Python%E8%AF%BB%E5%86%99Excel%E6%96%87%E4%BB%B6-2.md&quot;&gt;Pythonè¯»å†™Excelæ–‡ä»¶-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Excelç®€ä»‹&lt;/li&gt; 
 &lt;li&gt;è¯»Excelæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;å†™Excelæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;è°ƒæ•´æ ·å¼&lt;/li&gt; 
 &lt;li&gt;ç”Ÿæˆç»Ÿè®¡å›¾è¡¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day26 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/26.Python%E6%93%8D%E4%BD%9CWord%E5%92%8CPowerPoint%E6%96%87%E4%BB%B6.md&quot;&gt;Pythonæ“ä½œWordå’ŒPowerPointæ–‡ä»¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ“ä½œWordæ–‡æ¡£&lt;/li&gt; 
 &lt;li&gt;ç”ŸæˆPowerPoint&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day27 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/27.Python%E6%93%8D%E4%BD%9CPDF%E6%96%87%E4%BB%B6.md&quot;&gt;Pythonæ“ä½œPDFæ–‡ä»¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä»PDFä¸­æå–æ–‡æœ¬&lt;/li&gt; 
 &lt;li&gt;æ—‹è½¬å’Œå åŠ é¡µé¢&lt;/li&gt; 
 &lt;li&gt;åŠ å¯†PDFæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;æ‰¹é‡æ·»åŠ æ°´å°&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºPDFæ–‡ä»¶&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day28 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/28.Python%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F.md&quot;&gt;Pythonå¤„ç†å›¾åƒ&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å…¥é—¨çŸ¥è¯†&lt;/li&gt; 
 &lt;li&gt;ç”¨Pillowå¤„ç†å›¾åƒ&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨Pillowç»˜å›¾&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day29 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/29.Python%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%92%8C%E7%9F%AD%E4%BF%A1.md&quot;&gt;Pythonå‘é€é‚®ä»¶å’ŒçŸ­ä¿¡&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å‘é€ç”µå­é‚®ä»¶&lt;/li&gt; 
 &lt;li&gt;å‘é€çŸ­ä¿¡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day30 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day21-30/30.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8.md&quot;&gt;æ­£åˆ™è¡¨è¾¾å¼çš„åº”ç”¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ­£åˆ™è¡¨è¾¾å¼ç›¸å…³çŸ¥è¯†&lt;/li&gt; 
 &lt;li&gt;Pythonå¯¹æ­£åˆ™è¡¨è¾¾å¼çš„æ”¯æŒ 
  &lt;ul&gt; 
   &lt;li&gt;ä¾‹å­1ï¼šè¾“å…¥éªŒè¯&lt;/li&gt; 
   &lt;li&gt;ä¾‹å­2ï¼šå†…å®¹æå–&lt;/li&gt; 
   &lt;li&gt;ä¾‹å­3ï¼šå†…å®¹æ›¿æ¢&lt;/li&gt; 
   &lt;li&gt;ä¾‹å­4ï¼šé•¿å¥æ‹†åˆ†&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day31~35 - å…¶ä»–ç›¸å…³å†…å®¹&lt;/h3&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/31.Python%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6.md&quot;&gt;Pythonè¯­è¨€è¿›é˜¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;é‡è¦çŸ¥è¯†ç‚¹&lt;/li&gt; 
 &lt;li&gt;æ•°æ®ç»“æ„å’Œç®—æ³•&lt;/li&gt; 
 &lt;li&gt;å‡½æ•°çš„ä½¿ç”¨æ–¹å¼&lt;/li&gt; 
 &lt;li&gt;é¢å‘å¯¹è±¡ç›¸å…³çŸ¥è¯†&lt;/li&gt; 
 &lt;li&gt;è¿­ä»£å™¨å’Œç”Ÿæˆå™¨&lt;/li&gt; 
 &lt;li&gt;å¹¶å‘ç¼–ç¨‹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/32-33.Web%E5%89%8D%E7%AB%AF%E5%85%A5%E9%97%A8.md&quot;&gt;Webå‰ç«¯å…¥é—¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç”¨HTMLæ ‡ç­¾æ‰¿è½½é¡µé¢å†…å®¹&lt;/li&gt; 
 &lt;li&gt;ç”¨CSSæ¸²æŸ“é¡µé¢&lt;/li&gt; 
 &lt;li&gt;ç”¨JavaScriptå¤„ç†äº¤äº’å¼è¡Œä¸º&lt;/li&gt; 
 &lt;li&gt;Vue.jså…¥é—¨&lt;/li&gt; 
 &lt;li&gt;Elementçš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;Bootstrapçš„ä½¿ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day31-35/34-35.%E7%8E%A9%E8%BD%ACLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.md&quot;&gt;ç©è½¬Linuxæ“ä½œç³»ç»Ÿ&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ“ä½œç³»ç»Ÿå‘å±•å²å’ŒLinuxæ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;LinuxåŸºç¡€å‘½ä»¤&lt;/li&gt; 
 &lt;li&gt;Linuxä¸­çš„å®ç”¨ç¨‹åº&lt;/li&gt; 
 &lt;li&gt;Linuxçš„æ–‡ä»¶ç³»ç»Ÿ&lt;/li&gt; 
 &lt;li&gt;Vimç¼–è¾‘å™¨çš„åº”ç”¨&lt;/li&gt; 
 &lt;li&gt;ç¯å¢ƒå˜é‡å’ŒShellç¼–ç¨‹&lt;/li&gt; 
 &lt;li&gt;è½¯ä»¶çš„å®‰è£…å’ŒæœåŠ¡çš„é…ç½®&lt;/li&gt; 
 &lt;li&gt;ç½‘ç»œè®¿é—®å’Œç®¡ç†&lt;/li&gt; 
 &lt;li&gt;å…¶ä»–ç›¸å…³å†…å®¹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day36~45 - æ•°æ®åº“åŸºç¡€å’Œè¿›é˜¶&lt;/h3&gt; 
&lt;h4&gt;Day36 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/36.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8CMySQL%E6%A6%82%E8%BF%B0.md&quot;&gt;å…³ç³»å‹æ•°æ®åº“å’ŒMySQLæ¦‚è¿°&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å…³ç³»å‹æ•°æ®åº“æ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;MySQLç®€ä»‹&lt;/li&gt; 
 &lt;li&gt;å®‰è£…MySQL&lt;/li&gt; 
 &lt;li&gt;MySQLåŸºæœ¬å‘½ä»¤&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day37 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/37.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDDL.md&quot;&gt;SQLè¯¦è§£ä¹‹DDL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å»ºåº“å»ºè¡¨&lt;/li&gt; 
 &lt;li&gt;åˆ é™¤è¡¨å’Œä¿®æ”¹è¡¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day38 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/38.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDML.md&quot;&gt;SQLè¯¦è§£ä¹‹DML&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;insertæ“ä½œ&lt;/li&gt; 
 &lt;li&gt;deleteæ“ä½œ&lt;/li&gt; 
 &lt;li&gt;updateæ“ä½œ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day39 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/39.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDQL.md&quot;&gt;SQLè¯¦è§£ä¹‹DQL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æŠ•å½±å’Œåˆ«å&lt;/li&gt; 
 &lt;li&gt;ç­›é€‰æ•°æ®&lt;/li&gt; 
 &lt;li&gt;ç©ºå€¼å¤„ç†&lt;/li&gt; 
 &lt;li&gt;å»é‡&lt;/li&gt; 
 &lt;li&gt;æ’åº&lt;/li&gt; 
 &lt;li&gt;èšåˆå‡½æ•°&lt;/li&gt; 
 &lt;li&gt;åµŒå¥—æŸ¥è¯¢&lt;/li&gt; 
 &lt;li&gt;åˆ†ç»„æ“ä½œ&lt;/li&gt; 
 &lt;li&gt;è¡¨è¿æ¥ 
  &lt;ul&gt; 
   &lt;li&gt;ç¬›å¡å°”ç§¯&lt;/li&gt; 
   &lt;li&gt;å†…è¿æ¥&lt;/li&gt; 
   &lt;li&gt;è‡ªç„¶è¿æ¥&lt;/li&gt; 
   &lt;li&gt;å¤–è¿æ¥&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;çª—å£å‡½æ•° 
  &lt;ul&gt; 
   &lt;li&gt;å®šä¹‰çª—å£&lt;/li&gt; 
   &lt;li&gt;æ’åå‡½æ•°&lt;/li&gt; 
   &lt;li&gt;å–æ•°å‡½æ•°&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day40 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/40.SQL%E8%AF%A6%E8%A7%A3%E4%B9%8BDCL.md&quot;&gt;SQLè¯¦è§£ä¹‹DCL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºç”¨æˆ·&lt;/li&gt; 
 &lt;li&gt;æˆäºˆæƒé™&lt;/li&gt; 
 &lt;li&gt;å¬å›æƒé™&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day41 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/41.MySQL%E6%96%B0%E7%89%B9%E6%80%A7.md&quot;&gt;MySQLæ–°ç‰¹æ€§&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;JSONç±»å‹&lt;/li&gt; 
 &lt;li&gt;çª—å£å‡½æ•°&lt;/li&gt; 
 &lt;li&gt;å…¬å…±è¡¨è¡¨è¾¾å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Day42 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/42.%E8%A7%86%E5%9B%BE%E3%80%81%E5%87%BD%E6%95%B0%E5%92%8C%E8%BF%87%E7%A8%8B.md&quot;&gt;è§†å›¾ã€å‡½æ•°å’Œè¿‡ç¨‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è§†å›¾ 
  &lt;ul&gt; 
   &lt;li&gt;ä½¿ç”¨åœºæ™¯&lt;/li&gt; 
   &lt;li&gt;åˆ›å»ºè§†å›¾&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨é™åˆ¶&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å‡½æ•° 
  &lt;ul&gt; 
   &lt;li&gt;å†…ç½®å‡½æ•°&lt;/li&gt; 
   &lt;li&gt;ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ï¼ˆUDFï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;è¿‡ç¨‹ 
  &lt;ul&gt; 
   &lt;li&gt;åˆ›å»ºè¿‡ç¨‹&lt;/li&gt; 
   &lt;li&gt;è°ƒç”¨è¿‡ç¨‹&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day43 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/43.%E7%B4%A2%E5%BC%95.md&quot;&gt;ç´¢å¼•&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ‰§è¡Œè®¡åˆ’&lt;/li&gt; 
 &lt;li&gt;ç´¢å¼•çš„åŸç†&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºç´¢å¼• 
  &lt;ul&gt; 
   &lt;li&gt;æ™®é€šç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;å”¯ä¸€ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;å‰ç¼€ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;å¤åˆç´¢å¼•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ³¨æ„äº‹é¡¹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day44 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/44.Python%E6%8E%A5%E5%85%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93.md&quot;&gt;Pythonæ¥å…¥MySQLæ•°æ®åº“&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®‰è£…ä¸‰æ–¹åº“&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºè¿æ¥&lt;/li&gt; 
 &lt;li&gt;è·å–æ¸¸æ ‡&lt;/li&gt; 
 &lt;li&gt;æ‰§è¡ŒSQLè¯­å¥&lt;/li&gt; 
 &lt;li&gt;é€šè¿‡æ¸¸æ ‡æŠ“å–æ•°æ®&lt;/li&gt; 
 &lt;li&gt;äº‹åŠ¡æäº¤å’Œå›æ»š&lt;/li&gt; 
 &lt;li&gt;é‡Šæ”¾è¿æ¥&lt;/li&gt; 
 &lt;li&gt;ç¼–å†™ETLè„šæœ¬&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day45 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day36-45/45.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%92%8CHiveSQL.md&quot;&gt;å¤§æ•°æ®å¹³å°å’ŒHiveSQL&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Hadoopç”Ÿæ€åœˆ&lt;/li&gt; 
 &lt;li&gt;Hiveæ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;å‡†å¤‡å·¥ä½œ&lt;/li&gt; 
 &lt;li&gt;æ•°æ®ç±»å‹&lt;/li&gt; 
 &lt;li&gt;DDLæ“ä½œ&lt;/li&gt; 
 &lt;li&gt;DMLæ“ä½œ&lt;/li&gt; 
 &lt;li&gt;æ•°æ®æŸ¥è¯¢&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day46~60 - å®æˆ˜Django&lt;/h3&gt; 
&lt;h4&gt;Day46 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/46.Django%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.md&quot;&gt;Djangoå¿«é€Ÿä¸Šæ‰‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Webåº”ç”¨å·¥ä½œæœºåˆ¶&lt;/li&gt; 
 &lt;li&gt;HTTPè¯·æ±‚å’Œå“åº”&lt;/li&gt; 
 &lt;li&gt;Djangoæ¡†æ¶æ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day47 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/47.%E6%B7%B1%E5%85%A5%E6%A8%A1%E5%9E%8B.md&quot;&gt;æ·±å…¥æ¨¡å‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å…³ç³»å‹æ•°æ®åº“é…ç½®&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨ORMå®Œæˆå¯¹æ¨¡å‹çš„CRUDæ“ä½œ&lt;/li&gt; 
 &lt;li&gt;ç®¡ç†åå°çš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;Djangoæ¨¡å‹æœ€ä½³å®è·µ&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹å®šä¹‰å‚è€ƒ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day48 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/48.%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%92%8CAjax%E8%AF%B7%E6%B1%82.md&quot;&gt;é™æ€èµ„æºå’ŒAjaxè¯·æ±‚&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åŠ è½½é™æ€èµ„æº&lt;/li&gt; 
 &lt;li&gt;Ajaxæ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;ç”¨Ajaxå®ç°æŠ•ç¥¨åŠŸèƒ½&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day49 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/49.Cookie%E5%92%8CSession.md&quot;&gt;Cookieå’ŒSession&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®ç°ç”¨æˆ·è·Ÿè¸ª&lt;/li&gt; 
 &lt;li&gt;cookieå’Œsessionçš„å…³ç³»&lt;/li&gt; 
 &lt;li&gt;Djangoæ¡†æ¶å¯¹sessionçš„æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;è§†å›¾å‡½æ•°ä¸­çš„cookieè¯»å†™æ“ä½œ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day50 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/50.%E5%88%B6%E4%BD%9C%E6%8A%A5%E8%A1%A8.md&quot;&gt;æŠ¥è¡¨å’Œæ—¥å¿—&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;é€šè¿‡&lt;code&gt;HttpResponse&lt;/code&gt;ä¿®æ”¹å“åº”å¤´&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨&lt;code&gt;StreamingHttpResponse&lt;/code&gt;å¤„ç†å¤§æ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨&lt;code&gt;xlwt&lt;/code&gt;ç”ŸæˆExcelæŠ¥è¡¨&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨&lt;code&gt;reportlab&lt;/code&gt;ç”ŸæˆPDFæŠ¥è¡¨&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨EChartsç”Ÿæˆå‰ç«¯å›¾è¡¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day51 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/51.%E6%97%A5%E5%BF%97%E5%92%8C%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7%E6%A0%8F.md&quot;&gt;æ—¥å¿—å’Œè°ƒè¯•å·¥å…·æ &lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;é…ç½®æ—¥å¿—&lt;/li&gt; 
 &lt;li&gt;é…ç½®Django-Debug-Toolbar&lt;/li&gt; 
 &lt;li&gt;ä¼˜åŒ–ORMä»£ç &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day52 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/52.%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8.md&quot;&gt;ä¸­é—´ä»¶çš„åº”ç”¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä»€ä¹ˆæ˜¯ä¸­é—´ä»¶&lt;/li&gt; 
 &lt;li&gt;Djangoæ¡†æ¶å†…ç½®çš„ä¸­é—´ä»¶&lt;/li&gt; 
 &lt;li&gt;è‡ªå®šä¹‰ä¸­é—´ä»¶åŠå…¶åº”ç”¨åœºæ™¯&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day53 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/53.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%BC%80%E5%8F%91%E5%85%A5%E9%97%A8.md&quot;&gt;å‰åç«¯åˆ†ç¦»å¼€å‘å…¥é—¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è¿”å›JSONæ ¼å¼çš„æ•°æ®&lt;/li&gt; 
 &lt;li&gt;ç”¨Vue.jsæ¸²æŸ“é¡µé¢&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day54 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/54.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E5%85%A5%E9%97%A8.md&quot;&gt;RESTfulæ¶æ„å’ŒDRFå…¥é—¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;RESTæ¦‚è¿°&lt;/li&gt; 
 &lt;li&gt;DRFåº“ä½¿ç”¨å…¥é—¨&lt;/li&gt; 
 &lt;li&gt;å‰åç«¯åˆ†ç¦»å¼€å‘&lt;/li&gt; 
 &lt;li&gt;JWTçš„åº”ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day55 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/55.RESTful%E6%9E%B6%E6%9E%84%E5%92%8CDRF%E8%BF%9B%E9%98%B6.md&quot;&gt;RESTfulæ¶æ„å’ŒDRFè¿›é˜¶&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä½¿ç”¨CBV&lt;/li&gt; 
 &lt;li&gt;æ•°æ®åˆ†é¡µ&lt;/li&gt; 
 &lt;li&gt;æ•°æ®ç­›é€‰&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day56 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/56.%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98.md&quot;&gt;ä½¿ç”¨ç¼“å­˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç½‘ç«™ä¼˜åŒ–ç¬¬ä¸€å®šå¾‹&lt;/li&gt; 
 &lt;li&gt;åœ¨Djangoé¡¹ç›®ä¸­ä½¿ç”¨Redisæä¾›ç¼“å­˜æœåŠ¡&lt;/li&gt; 
 &lt;li&gt;åœ¨è§†å›¾å‡½æ•°ä¸­è¯»å†™ç¼“å­˜&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨è£…é¥°å™¨å®ç°é¡µé¢ç¼“å­˜&lt;/li&gt; 
 &lt;li&gt;ä¸ºæ•°æ®æ¥å£æä¾›ç¼“å­˜æœåŠ¡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day57 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/57.%E6%8E%A5%E5%85%A5%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0.md&quot;&gt;æ¥å…¥ä¸‰æ–¹å¹³å°&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ–‡ä»¶ä¸Šä¼ è¡¨å•æ§ä»¶å’Œå›¾ç‰‡æ–‡ä»¶é¢„è§ˆ&lt;/li&gt; 
 &lt;li&gt;æœåŠ¡å™¨ç«¯å¦‚ä½•å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day58 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/58.%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%92%8C%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.md&quot;&gt;å¼‚æ­¥ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç½‘ç«™ä¼˜åŒ–ç¬¬äºŒå®šå¾‹&lt;/li&gt; 
 &lt;li&gt;é…ç½®æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡&lt;/li&gt; 
 &lt;li&gt;åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°ä»»åŠ¡å¼‚æ­¥åŒ–&lt;/li&gt; 
 &lt;li&gt;åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°å®šæ—¶ä»»åŠ¡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day59 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/59.%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.md&quot;&gt;å•å…ƒæµ‹è¯•&lt;/a&gt;&lt;/h4&gt; 
&lt;h4&gt;Day60 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day46-60/60.%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF.md&quot;&gt;é¡¹ç›®ä¸Šçº¿&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pythonä¸­çš„å•å…ƒæµ‹è¯•&lt;/li&gt; 
 &lt;li&gt;Djangoæ¡†æ¶å¯¹å•å…ƒæµ‹è¯•çš„æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ&lt;/li&gt; 
 &lt;li&gt;é…ç½®å’Œä½¿ç”¨uWSGI&lt;/li&gt; 
 &lt;li&gt;åŠ¨é™åˆ†ç¦»å’ŒNginxé…ç½®&lt;/li&gt; 
 &lt;li&gt;é…ç½®HTTPS&lt;/li&gt; 
 &lt;li&gt;é…ç½®åŸŸåè§£æ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day61~65 - ç½‘ç»œæ•°æ®é‡‡é›†&lt;/h3&gt; 
&lt;h4&gt;Day61 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/61.%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A6%82%E8%BF%B0.md&quot;&gt;ç½‘ç»œæ•°æ®é‡‡é›†æ¦‚è¿°&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç½‘ç»œçˆ¬è™«çš„æ¦‚å¿µåŠå…¶åº”ç”¨é¢†åŸŸ&lt;/li&gt; 
 &lt;li&gt;ç½‘ç»œçˆ¬è™«çš„åˆæ³•æ€§æ¢è®¨&lt;/li&gt; 
 &lt;li&gt;å¼€å‘ç½‘ç»œçˆ¬è™«çš„ç›¸å…³å·¥å…·&lt;/li&gt; 
 &lt;li&gt;ä¸€ä¸ªçˆ¬è™«ç¨‹åºçš„æ„æˆ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day62 - æ•°æ®æŠ“å–å’Œè§£æ&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/62.%E7%94%A8Python%E8%8E%B7%E5%8F%96%E7%BD%91%E7%BB%9C%E8%B5%84%E6%BA%90-1.md&quot;&gt;ä½¿ç”¨&lt;code&gt;requests&lt;/code&gt;ä¸‰æ–¹åº“å®ç°æ•°æ®æŠ“å–&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/62.%E7%94%A8Python%E8%A7%A3%E6%9E%90HTML%E9%A1%B5%E9%9D%A2-2.md&quot;&gt;é¡µé¢è§£æçš„ä¸‰ç§æ–¹å¼&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æ­£åˆ™è¡¨è¾¾å¼è§£æ&lt;/li&gt; 
   &lt;li&gt;XPathè§£æ&lt;/li&gt; 
   &lt;li&gt;CSSé€‰æ‹©å™¨è§£æ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day63 - Pythonä¸­çš„å¹¶å‘ç¼–ç¨‹&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-1.md&quot;&gt;å¤šçº¿ç¨‹&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-2.md&quot;&gt;å¤šè¿›ç¨‹&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/63.Python%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-3.md&quot;&gt;å¼‚æ­¥I/O&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day64 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/64.%E4%BD%BF%E7%94%A8Selenium%E6%8A%93%E5%8F%96%E7%BD%91%E9%A1%B5%E5%8A%A8%E6%80%81%E5%86%85%E5%AE%B9.md&quot;&gt;ä½¿ç”¨SeleniumæŠ“å–ç½‘é¡µåŠ¨æ€å†…å®¹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®‰è£…Selenium&lt;/li&gt; 
 &lt;li&gt;åŠ è½½é¡µé¢&lt;/li&gt; 
 &lt;li&gt;æŸ¥æ‰¾å…ƒç´ å’Œæ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º&lt;/li&gt; 
 &lt;li&gt;éšå¼ç­‰å¾…å’Œæ˜¾ç¤ºç­‰å¾…&lt;/li&gt; 
 &lt;li&gt;æ‰§è¡ŒJavaScriptä»£ç &lt;/li&gt; 
 &lt;li&gt;Seleniumåçˆ¬ç ´è§£&lt;/li&gt; 
 &lt;li&gt;è®¾ç½®æ— å¤´æµè§ˆå™¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day65 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day61-65/65.%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%AE%80%E4%BB%8B.md&quot;&gt;çˆ¬è™«æ¡†æ¶Scrapyç®€ä»‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scrapyæ ¸å¿ƒç»„ä»¶&lt;/li&gt; 
 &lt;li&gt;Scrapyå·¥ä½œæµç¨‹&lt;/li&gt; 
 &lt;li&gt;å®‰è£…Scrapyå’Œåˆ›å»ºé¡¹ç›®&lt;/li&gt; 
 &lt;li&gt;ç¼–å†™èœ˜è››ç¨‹åº&lt;/li&gt; 
 &lt;li&gt;ç¼–å†™ä¸­é—´ä»¶å’Œç®¡é“ç¨‹åº&lt;/li&gt; 
 &lt;li&gt;Scrapyé…ç½®æ–‡ä»¶&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day66~80 - Pythonæ•°æ®åˆ†æ&lt;/h3&gt; 
&lt;h4&gt;Day66 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/66.%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A6%82%E8%BF%B0.md&quot;&gt;æ•°æ®åˆ†ææ¦‚è¿°&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°æ®åˆ†æå¸ˆçš„èŒè´£&lt;/li&gt; 
 &lt;li&gt;æ•°æ®åˆ†æå¸ˆçš„æŠ€èƒ½æ ˆ&lt;/li&gt; 
 &lt;li&gt;æ•°æ®åˆ†æç›¸å…³åº“&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day67 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/67.%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87.md&quot;&gt;ç¯å¢ƒå‡†å¤‡&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®‰è£…å’Œä½¿ç”¨anaconda 
  &lt;ul&gt; 
   &lt;li&gt;condaç›¸å…³å‘½ä»¤&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å®‰è£…å’Œä½¿ç”¨jupyter-lab 
  &lt;ul&gt; 
   &lt;li&gt;å®‰è£…å’Œå¯åŠ¨&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨å°æŠ€å·§&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day68 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/68.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-1.md&quot;&gt;NumPyçš„åº”ç”¨-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºæ•°ç»„å¯¹è±¡&lt;/li&gt; 
 &lt;li&gt;æ•°ç»„å¯¹è±¡çš„å±æ€§&lt;/li&gt; 
 &lt;li&gt;æ•°ç»„å¯¹è±¡çš„ç´¢å¼•è¿ç®— 
  &lt;ul&gt; 
   &lt;li&gt;æ™®é€šç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;èŠ±å¼ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;å¸ƒå°”ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;åˆ‡ç‰‡ç´¢å¼•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ¡ˆä¾‹ï¼šä½¿ç”¨æ•°ç»„å¤„ç†å›¾åƒ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day69 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/69.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-2.md&quot;&gt;NumPyçš„åº”ç”¨-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°ç»„å¯¹è±¡çš„ç›¸å…³æ–¹æ³• 
  &lt;ul&gt; 
   &lt;li&gt;è·å–æè¿°æ€§ç»Ÿè®¡ä¿¡æ¯&lt;/li&gt; 
   &lt;li&gt;å…¶ä»–ç›¸å…³æ–¹æ³•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day70 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/70.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-3.md&quot;&gt;NumPyçš„åº”ç”¨-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°ç»„çš„è¿ç®— 
  &lt;ul&gt; 
   &lt;li&gt;æ•°ç»„è·Ÿæ ‡é‡çš„è¿ç®—&lt;/li&gt; 
   &lt;li&gt;æ•°ç»„è·Ÿæ•°ç»„çš„è¿ç®—&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;é€šç”¨ä¸€å…ƒå‡½æ•°&lt;/li&gt; 
 &lt;li&gt;é€šç”¨äºŒå…ƒå‡½æ•°&lt;/li&gt; 
 &lt;li&gt;å¹¿æ’­æœºåˆ¶&lt;/li&gt; 
 &lt;li&gt;Numpyå¸¸ç”¨å‡½æ•°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day71 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/71.NumPy%E7%9A%84%E5%BA%94%E7%94%A8-4.md&quot;&gt;NumPyçš„åº”ç”¨-4&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å‘é‡&lt;/li&gt; 
 &lt;li&gt;è¡Œåˆ—å¼&lt;/li&gt; 
 &lt;li&gt;çŸ©é˜µ&lt;/li&gt; 
 &lt;li&gt;å¤šé¡¹å¼&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day72 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/72.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-1.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºSerieså¯¹è±¡&lt;/li&gt; 
 &lt;li&gt;Serieså¯¹è±¡çš„è¿ç®—&lt;/li&gt; 
 &lt;li&gt;Serieså¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day73 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/73.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-2.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åˆ›å»ºDataFrameå¯¹è±¡&lt;/li&gt; 
 &lt;li&gt;DataFrameå¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;è¯»å†™DataFrameä¸­çš„æ•°æ®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day74 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/74.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-3.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°æ®é‡å¡‘ 
  &lt;ul&gt; 
   &lt;li&gt;æ•°æ®æ‹¼æ¥&lt;/li&gt; 
   &lt;li&gt;æ•°æ®åˆå¹¶&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ•°æ®æ¸…æ´— 
  &lt;ul&gt; 
   &lt;li&gt;ç¼ºå¤±å€¼&lt;/li&gt; 
   &lt;li&gt;é‡å¤å€¼&lt;/li&gt; 
   &lt;li&gt;å¼‚å¸¸å€¼&lt;/li&gt; 
   &lt;li&gt;é¢„å¤„ç†&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day75 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/75.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-4.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-4&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°æ®é€è§† 
  &lt;ul&gt; 
   &lt;li&gt;è·å–æè¿°æ€§ç»Ÿè®¡ä¿¡æ¯&lt;/li&gt; 
   &lt;li&gt;æ’åºå’Œå¤´éƒ¨å€¼&lt;/li&gt; 
   &lt;li&gt;åˆ†ç»„èšåˆ&lt;/li&gt; 
   &lt;li&gt;é€è§†è¡¨å’Œäº¤å‰è¡¨&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ•°æ®å‘ˆç°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day76 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/76.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-5.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-5&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è®¡ç®—åŒæ¯”ç¯æ¯”&lt;/li&gt; 
 &lt;li&gt;çª—å£è®¡ç®—&lt;/li&gt; 
 &lt;li&gt;ç›¸å…³æ€§åˆ¤å®š&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day77 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/77.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApandas-6.md&quot;&gt;æ·±å…¥æµ…å‡ºpandas-6&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç´¢å¼•çš„ä½¿ç”¨ 
  &lt;ul&gt; 
   &lt;li&gt;èŒƒå›´ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;åˆ†ç±»ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;å¤šçº§ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;é—´éš”ç´¢å¼•&lt;/li&gt; 
   &lt;li&gt;æ—¥æœŸæ—¶é—´ç´¢å¼•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day78 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/78.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-1.md&quot;&gt;æ•°æ®å¯è§†åŒ–-1&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å®‰è£…å’Œå¯¼å…¥matplotlib&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºç”»å¸ƒ&lt;/li&gt; 
 &lt;li&gt;åˆ›å»ºåæ ‡ç³»&lt;/li&gt; 
 &lt;li&gt;ç»˜åˆ¶å›¾è¡¨ 
  &lt;ul&gt; 
   &lt;li&gt;æŠ˜çº¿å›¾&lt;/li&gt; 
   &lt;li&gt;æ•£ç‚¹å›¾&lt;/li&gt; 
   &lt;li&gt;æŸ±çŠ¶å›¾&lt;/li&gt; 
   &lt;li&gt;é¥¼çŠ¶å›¾&lt;/li&gt; 
   &lt;li&gt;ç›´æ–¹å›¾&lt;/li&gt; 
   &lt;li&gt;ç®±çº¿å›¾&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ˜¾ç¤ºå’Œä¿å­˜å›¾è¡¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day79 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/79.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-2.md&quot;&gt;æ•°æ®å¯è§†åŒ–-2&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;é«˜é˜¶å›¾è¡¨ 
  &lt;ul&gt; 
   &lt;li&gt;æ°”æ³¡å›¾&lt;/li&gt; 
   &lt;li&gt;é¢ç§¯å›¾&lt;/li&gt; 
   &lt;li&gt;é›·è¾¾å›¾&lt;/li&gt; 
   &lt;li&gt;ç«ç‘°å›¾&lt;/li&gt; 
   &lt;li&gt;3Då›¾è¡¨&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day80 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day66-80/80.%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-3.md&quot;&gt;æ•°æ®å¯è§†åŒ–-3&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Seaborn&lt;/li&gt; 
 &lt;li&gt;Pyecharts&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day81~90 - æœºå™¨å­¦ä¹ &lt;/h3&gt; 
&lt;h4&gt;Day81 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/81.%E6%B5%85%E8%B0%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md&quot;&gt;æµ…è°ˆæœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;äººå·¥æ™ºèƒ½å‘å±•å²&lt;/li&gt; 
 &lt;li&gt;ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ &lt;/li&gt; 
 &lt;li&gt;æœºå™¨å­¦ä¹ åº”ç”¨é¢†åŸŸ&lt;/li&gt; 
 &lt;li&gt;æœºå™¨å­¦ä¹ çš„åˆ†ç±»&lt;/li&gt; 
 &lt;li&gt;æœºå™¨å­¦ä¹ çš„æ­¥éª¤&lt;/li&gt; 
 &lt;li&gt;ç¬¬ä¸€æ¬¡æœºå™¨å­¦ä¹ &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day82 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/82.k%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.md&quot;&gt;kæœ€è¿‘é‚»ç®—æ³•&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è·ç¦»çš„åº¦é‡&lt;/li&gt; 
 &lt;li&gt;æ•°æ®é›†ä»‹ç»&lt;/li&gt; 
 &lt;li&gt;kNNåˆ†ç±»çš„å®ç°&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹è¯„ä¼°&lt;/li&gt; 
 &lt;li&gt;å‚æ•°è°ƒä¼˜&lt;/li&gt; 
 &lt;li&gt;kNNå›å½’çš„å®ç°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day83 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/83.%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97.md&quot;&gt;å†³ç­–æ ‘å’Œéšæœºæ£®æ—&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å†³ç­–æ ‘çš„æ„å»º 
  &lt;ul&gt; 
   &lt;li&gt;ç‰¹å¾é€‰æ‹©&lt;/li&gt; 
   &lt;li&gt;æ•°æ®åˆ†è£‚&lt;/li&gt; 
   &lt;li&gt;æ ‘çš„å‰ªæ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;å®ç°å†³ç­–æ ‘æ¨¡å‹&lt;/li&gt; 
 &lt;li&gt;éšæœºæ£®æ—æ¦‚è¿°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day84 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/84.%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95.md&quot;&gt;æœ´ç´ è´å¶æ–¯ç®—æ³•&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è´å¶æ–¯å®šç†&lt;/li&gt; 
 &lt;li&gt;æœ´ç´ è´å¶æ–¯&lt;/li&gt; 
 &lt;li&gt;ç®—æ³•åŸç† 
  &lt;ul&gt; 
   &lt;li&gt;è®­ç»ƒé˜¶æ®µ&lt;/li&gt; 
   &lt;li&gt;é¢„æµ‹é˜¶æ®µ&lt;/li&gt; 
   &lt;li&gt;ä»£ç å®ç°&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ç®—æ³•ä¼˜ç¼ºç‚¹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day85 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/85.%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B.md&quot;&gt;å›å½’æ¨¡å‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å›å½’æ¨¡å‹çš„åˆ†ç±»&lt;/li&gt; 
 &lt;li&gt;å›å½’ç³»æ•°çš„è®¡ç®—&lt;/li&gt; 
 &lt;li&gt;æ–°æ•°æ®é›†ä»‹ç»&lt;/li&gt; 
 &lt;li&gt;çº¿æ€§å›å½’ä»£ç å®ç°&lt;/li&gt; 
 &lt;li&gt;å›å½’æ¨¡å‹çš„è¯„ä¼°&lt;/li&gt; 
 &lt;li&gt;å¼•å…¥æ­£åˆ™åŒ–é¡¹&lt;/li&gt; 
 &lt;li&gt;çº¿æ€§å›å½’å¦ä¸€ç§å®ç°&lt;/li&gt; 
 &lt;li&gt;å¤šé¡¹å¼å›å½’&lt;/li&gt; 
 &lt;li&gt;é€»è¾‘å›å½’&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day86 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/86.K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.md&quot;&gt;K-Meansèšç±»ç®—æ³•&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç®—æ³•åŸç†&lt;/li&gt; 
 &lt;li&gt;æ•°å­¦æè¿°&lt;/li&gt; 
 &lt;li&gt;ä»£ç å®ç°&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day87 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/87.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95.md&quot;&gt;é›†æˆå­¦ä¹ ç®—æ³•&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;ç®—æ³•åˆ†ç±»&lt;/li&gt; 
 &lt;li&gt;AdaBoost&lt;/li&gt; 
 &lt;li&gt;GBDT&lt;/li&gt; 
 &lt;li&gt;XGBoost&lt;/li&gt; 
 &lt;li&gt;LightGBM&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day88 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/88.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.md&quot;&gt;ç¥ç»ç½‘ç»œæ¨¡å‹&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åŸºæœ¬æ„æˆ&lt;/li&gt; 
 &lt;li&gt;å·¥ä½œåŸç†&lt;/li&gt; 
 &lt;li&gt;ä»£ç å®ç°&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹ä¼˜ç¼ºç‚¹&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day89 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/89.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8.md&quot;&gt;è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è¯è¢‹æ¨¡å‹&lt;/li&gt; 
 &lt;li&gt;è¯å‘é‡&lt;/li&gt; 
 &lt;li&gt;NPLMå’ŒRNN&lt;/li&gt; 
 &lt;li&gt;Seq2Seq&lt;/li&gt; 
 &lt;li&gt;Transformer&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Day90 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day81-90/90.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.md&quot;&gt;æœºå™¨å­¦ä¹ å®æˆ˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°æ®æ¢ç´¢&lt;/li&gt; 
 &lt;li&gt;ç‰¹å¾å·¥ç¨‹&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹è®­ç»ƒ&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹è¯„ä¼°&lt;/li&gt; 
 &lt;li&gt;æ¨¡å‹éƒ¨ç½²&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Day91~99 - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100&quot;&gt;å›¢é˜Ÿé¡¹ç›®å¼€å‘&lt;/a&gt;&lt;/h3&gt; 
&lt;h4&gt;ç¬¬91å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md&quot;&gt;å›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;è½¯ä»¶è¿‡ç¨‹æ¨¡å‹&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ç»å…¸è¿‡ç¨‹æ¨¡å‹ï¼ˆç€‘å¸ƒæ¨¡å‹ï¼‰&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;å¯è¡Œæ€§åˆ†æï¼ˆç ”ç©¶åšè¿˜æ˜¯ä¸åšï¼‰ï¼Œè¾“å‡ºã€Šå¯è¡Œæ€§åˆ†ææŠ¥å‘Šã€‹ã€‚&lt;/li&gt; 
     &lt;li&gt;éœ€æ±‚åˆ†æï¼ˆç ”ç©¶åšä»€ä¹ˆï¼‰ï¼Œè¾“å‡ºã€Šéœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦ã€‹å’Œäº§å“ç•Œé¢åŸå‹å›¾ã€‚&lt;/li&gt; 
     &lt;li&gt;æ¦‚è¦è®¾è®¡å’Œè¯¦ç»†è®¾è®¡ï¼Œè¾“å‡ºæ¦‚å¿µæ¨¡å‹å›¾ï¼ˆERå›¾ï¼‰ã€ç‰©ç†æ¨¡å‹å›¾ã€ç±»å›¾ã€æ—¶åºå›¾ç­‰ã€‚&lt;/li&gt; 
     &lt;li&gt;ç¼–ç  / æµ‹è¯•ã€‚&lt;/li&gt; 
     &lt;li&gt;ä¸Šçº¿ / ç»´æŠ¤ã€‚&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt;ç€‘å¸ƒæ¨¡å‹æœ€å¤§çš„ç¼ºç‚¹æ˜¯æ— æ³•æ‹¥æŠ±éœ€æ±‚å˜åŒ–ï¼Œæ•´å¥—æµç¨‹ç»“æŸåæ‰èƒ½çœ‹åˆ°äº§å“ï¼Œå›¢é˜Ÿå£«æ°”ä½è½ã€‚&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;æ•æ·å¼€å‘ï¼ˆScrumï¼‰- äº§å“æ‰€æœ‰è€…ã€Scrum Masterã€ç ”å‘äººå‘˜ - Sprint&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;äº§å“çš„Backlogï¼ˆç”¨æˆ·æ•…äº‹ã€äº§å“åŸå‹ï¼‰ã€‚&lt;/li&gt; 
     &lt;li&gt;è®¡åˆ’ä¼šè®®ï¼ˆè¯„ä¼°å’Œé¢„ç®—ï¼‰ã€‚&lt;/li&gt; 
     &lt;li&gt;æ—¥å¸¸å¼€å‘ï¼ˆç«™ç«‹ä¼šè®®ã€ç•ªèŒ„å·¥ä½œæ³•ã€ç»“å¯¹ç¼–ç¨‹ã€æµ‹è¯•å…ˆè¡Œã€ä»£ç é‡æ„â€¦â€¦ï¼‰ã€‚&lt;/li&gt; 
     &lt;li&gt;ä¿®å¤bugï¼ˆé—®é¢˜æè¿°ã€é‡ç°æ­¥éª¤ã€æµ‹è¯•äººå‘˜ã€è¢«æŒ‡æ´¾äººï¼‰ã€‚&lt;/li&gt; 
     &lt;li&gt;å‘å¸ƒç‰ˆæœ¬ã€‚&lt;/li&gt; 
     &lt;li&gt;è¯„å®¡ä¼šè®®ï¼ˆShowcaseï¼Œç”¨æˆ·éœ€è¦å‚ä¸ï¼‰ã€‚&lt;/li&gt; 
     &lt;li&gt;å›é¡¾ä¼šè®®ï¼ˆå¯¹å½“å‰è¿­ä»£å‘¨æœŸåšä¸€ä¸ªæ€»ç»“ï¼‰ã€‚&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;è¡¥å……ï¼šæ•æ·è½¯ä»¶å¼€å‘å®£è¨€&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;ä¸ªä½“å’Œäº’åŠ¨&lt;/strong&gt; é«˜äº æµç¨‹å’Œå·¥å…·&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å·¥ä½œçš„è½¯ä»¶&lt;/strong&gt; é«˜äº è¯¦å°½çš„æ–‡æ¡£&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å®¢æˆ·åˆä½œ&lt;/strong&gt; é«˜äº åˆåŒè°ˆåˆ¤&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å“åº”å˜åŒ–&lt;/strong&gt; é«˜äº éµå¾ªè®¡åˆ’&lt;/li&gt; 
     &lt;/ul&gt; 
    &lt;/blockquote&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/agile-scrum-sprint-cycle.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;è§’è‰²ï¼šäº§å“æ‰€æœ‰è€…ï¼ˆå†³å®šåšä»€ä¹ˆï¼Œèƒ½å¯¹éœ€æ±‚æ‹æ¿çš„äººï¼‰ã€å›¢é˜Ÿè´Ÿè´£äººï¼ˆè§£å†³å„ç§é—®é¢˜ï¼Œä¸“æ³¨å¦‚ä½•æ›´å¥½çš„å·¥ä½œï¼Œå±è”½å¤–éƒ¨å¯¹å¼€å‘å›¢é˜Ÿçš„å½±å“ï¼‰ã€å¼€å‘å›¢é˜Ÿï¼ˆé¡¹ç›®æ‰§è¡Œäººå‘˜ï¼Œå…·ä½“æŒ‡å¼€å‘äººå‘˜å’Œæµ‹è¯•äººå‘˜ï¼‰ã€‚&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;å‡†å¤‡å·¥ä½œï¼šå•†ä¸šæ¡ˆä¾‹å’Œèµ„é‡‘ã€åˆåŒã€æ†§æ†¬ã€åˆå§‹äº§å“éœ€æ±‚ã€åˆå§‹å‘å¸ƒè®¡åˆ’ã€å…¥è‚¡ã€ç»„å»ºå›¢é˜Ÿã€‚&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;æ•æ·å›¢é˜Ÿé€šå¸¸äººæ•°ä¸º8-10äººã€‚&lt;/p&gt; 
    &lt;/blockquote&gt; 
    &lt;blockquote&gt; 
     &lt;p&gt;å·¥ä½œé‡ä¼°ç®—ï¼šå°†å¼€å‘ä»»åŠ¡é‡åŒ–ï¼ŒåŒ…æ‹¬åŸå‹ã€Logoè®¾è®¡ã€UIè®¾è®¡ã€å‰ç«¯å¼€å‘ç­‰ï¼Œå°½é‡æŠŠæ¯ä¸ªå·¥ä½œåˆ†è§£åˆ°æœ€å°ä»»åŠ¡é‡ï¼Œæœ€å°ä»»åŠ¡é‡æ ‡å‡†ä¸ºå·¥ä½œæ—¶é—´ä¸èƒ½è¶…è¿‡ä¸¤å¤©ï¼Œç„¶åä¼°ç®—æ€»ä½“é¡¹ç›®æ—¶é—´ã€‚æŠŠæ¯ä¸ªä»»åŠ¡éƒ½è´´åœ¨çœ‹æ¿ä¸Šé¢ï¼Œçœ‹æ¿ä¸Šåˆ†ä¸‰éƒ¨åˆ†ï¼što doï¼ˆå¾…å®Œæˆï¼‰ã€in progressï¼ˆè¿›è¡Œä¸­ï¼‰å’Œdoneï¼ˆå·²å®Œæˆï¼‰ã€‚&lt;/p&gt; 
    &lt;/blockquote&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;é¡¹ç›®å›¢é˜Ÿç»„å»º&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;å›¢é˜Ÿçš„æ„æˆå’Œè§’è‰²&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/company_architecture.png&quot; alt=&quot;company_architecture&quot; /&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ç¼–ç¨‹è§„èŒƒå’Œä»£ç å®¡æŸ¥ï¼ˆ&lt;code&gt;flake8&lt;/code&gt;ã€&lt;code&gt;pylint&lt;/code&gt;ï¼‰&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/pylint.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Pythonä¸­çš„ä¸€äº›â€œæƒ¯ä¾‹â€ï¼ˆè¯·å‚è€ƒ&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/%E7%95%AA%E5%A4%96%E7%AF%87/Python%E7%BC%96%E7%A8%8B%E6%83%AF%E4%BE%8B.md&quot;&gt;ã€ŠPythonæƒ¯ä¾‹-å¦‚ä½•ç¼–å†™Pythonicçš„ä»£ç ã€‹&lt;/a&gt;ï¼‰&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;å½±å“ä»£ç å¯è¯»æ€§çš„åŸå› ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ä»£ç æ³¨é‡Šå¤ªå°‘æˆ–è€…æ²¡æœ‰æ³¨é‡Š&lt;/li&gt; 
     &lt;li&gt;ä»£ç ç ´åäº†è¯­è¨€çš„æœ€ä½³å®è·µ&lt;/li&gt; 
     &lt;li&gt;åæ¨¡å¼ç¼–ç¨‹ï¼ˆæ„å¤§åˆ©é¢ä»£ç ã€å¤åˆ¶-é»è´´ç¼–ç¨‹ã€è‡ªè´Ÿç¼–ç¨‹ã€â€¦â€¦ï¼‰&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;å›¢é˜Ÿå¼€å‘å·¥å…·ä»‹ç»&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ç‰ˆæœ¬æ§åˆ¶ï¼šGitã€Mercury&lt;/li&gt; 
   &lt;li&gt;ç¼ºé™·ç®¡ç†ï¼š&lt;a href=&quot;https://about.gitlab.com/&quot;&gt;Gitlab&lt;/a&gt;ã€&lt;a href=&quot;http://www.redmine.org.cn/&quot;&gt;Redmine&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;æ•æ·é—­ç¯å·¥å…·ï¼š&lt;a href=&quot;https://www.zentao.net/&quot;&gt;ç¦…é“&lt;/a&gt;ã€&lt;a href=&quot;https://www.atlassian.com/software/jira/features&quot;&gt;JIRA&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;æŒç»­é›†æˆï¼š&lt;a href=&quot;https://jenkins.io/&quot;&gt;Jenkins&lt;/a&gt;ã€&lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis-CI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;è¯·å‚è€ƒ&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/91.%E5%9B%A2%E9%98%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md&quot;&gt;ã€Šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‹&lt;/a&gt;ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;é¡¹ç›®é€‰é¢˜å’Œç†è§£ä¸šåŠ¡&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;é€‰é¢˜èŒƒå›´è®¾å®š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;CMSï¼ˆç”¨æˆ·ç«¯ï¼‰ï¼šæ–°é—»èšåˆç½‘ç«™ã€é—®ç­”/åˆ†äº«ç¤¾åŒºã€å½±è¯„/ä¹¦è¯„ç½‘ç«™ç­‰ã€‚&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;MISï¼ˆç”¨æˆ·ç«¯+ç®¡ç†ç«¯ï¼‰ï¼šKMSã€KPIè€ƒæ ¸ç³»ç»Ÿã€HRSã€CRMç³»ç»Ÿã€ä¾›åº”é“¾ç³»ç»Ÿã€ä»“å‚¨ç®¡ç†ç³»ç»Ÿç­‰ã€‚&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Appåå°ï¼ˆç®¡ç†ç«¯+æ•°æ®æ¥å£ï¼‰ï¼šäºŒæ‰‹äº¤æ˜“ç±»ã€æŠ¥åˆŠæ‚å¿—ç±»ã€å°ä¼—ç”µå•†ç±»ã€æ–°é—»èµ„è®¯ç±»ã€æ—…æ¸¸ç±»ã€ç¤¾äº¤ç±»ã€é˜…è¯»ç±»ç­‰ã€‚&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;å…¶ä»–ç±»å‹ï¼šè‡ªèº«è¡Œä¸šèƒŒæ™¯å’Œå·¥ä½œç»éªŒã€ä¸šåŠ¡å®¹æ˜“ç†è§£å’ŒæŠŠæ§ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;éœ€æ±‚ç†è§£ã€æ¨¡å—åˆ’åˆ†å’Œä»»åŠ¡åˆ†é…&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;éœ€æ±‚ç†è§£ï¼šå¤´è„‘é£æš´å’Œç«å“åˆ†æã€‚&lt;/li&gt; 
   &lt;li&gt;æ¨¡å—åˆ’åˆ†ï¼šç”»æ€ç»´å¯¼å›¾ï¼ˆXMindï¼‰ï¼Œæ¯ä¸ªæ¨¡å—æ˜¯ä¸€ä¸ªæèŠ‚ç‚¹ï¼Œæ¯ä¸ªå…·ä½“çš„åŠŸèƒ½æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹ï¼ˆç”¨åŠ¨è¯è¡¨è¿°ï¼‰ï¼Œéœ€è¦ç¡®ä¿æ¯ä¸ªå¶èŠ‚ç‚¹æ— æ³•å†ç”Ÿå‡ºæ–°èŠ‚ç‚¹ï¼Œç¡®å®šæ¯ä¸ªå¶å­èŠ‚ç‚¹çš„é‡è¦æ€§ã€ä¼˜å…ˆçº§å’Œå·¥ä½œé‡ã€‚&lt;/li&gt; 
   &lt;li&gt;ä»»åŠ¡åˆ†é…ï¼šç”±é¡¹ç›®è´Ÿè´£äººæ ¹æ®ä¸Šé¢çš„æŒ‡æ ‡ä¸ºæ¯ä¸ªå›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡ã€‚&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/requirements_by_xmind.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;åˆ¶å®šé¡¹ç›®è¿›åº¦è¡¨ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;æ¨¡å—&lt;/th&gt; 
     &lt;th&gt;åŠŸèƒ½&lt;/th&gt; 
     &lt;th&gt;äººå‘˜&lt;/th&gt; 
     &lt;th&gt;çŠ¶æ€&lt;/th&gt; 
     &lt;th&gt;å®Œæˆ&lt;/th&gt; 
     &lt;th&gt;å·¥æ—¶&lt;/th&gt; 
     &lt;th&gt;è®¡åˆ’å¼€å§‹&lt;/th&gt; 
     &lt;th&gt;å®é™…å¼€å§‹&lt;/th&gt; 
     &lt;th&gt;è®¡åˆ’ç»“æŸ&lt;/th&gt; 
     &lt;th&gt;å®é™…ç»“æŸ&lt;/th&gt; 
     &lt;th&gt;å¤‡æ³¨&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;è¯„è®º&lt;/td&gt; 
     &lt;td&gt;æ·»åŠ è¯„è®º&lt;/td&gt; 
     &lt;td&gt;ç‹å¤§é”¤&lt;/td&gt; 
     &lt;td&gt;æ­£åœ¨è¿›è¡Œ&lt;/td&gt; 
     &lt;td&gt;50%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;åˆ é™¤è¯„è®º&lt;/td&gt; 
     &lt;td&gt;ç‹å¤§é”¤&lt;/td&gt; 
     &lt;td&gt;ç­‰å¾…&lt;/td&gt; 
     &lt;td&gt;0%&lt;/td&gt; 
     &lt;td&gt;2&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;æŸ¥çœ‹è¯„è®º&lt;/td&gt; 
     &lt;td&gt;ç™½å…ƒèŠ³&lt;/td&gt; 
     &lt;td&gt;æ­£åœ¨è¿›è¡Œ&lt;/td&gt; 
     &lt;td&gt;20%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/7&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;éœ€è¦è¿›è¡Œä»£ç å®¡æŸ¥&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;è¯„è®ºæŠ•ç¥¨&lt;/td&gt; 
     &lt;td&gt;ç™½å…ƒèŠ³&lt;/td&gt; 
     &lt;td&gt;ç­‰å¾…&lt;/td&gt; 
     &lt;td&gt;0%&lt;/td&gt; 
     &lt;td&gt;4&lt;/td&gt; 
     &lt;td&gt;2018/8/8&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;2018/8/8&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;OOADå’Œæ•°æ®åº“è®¾è®¡&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;UMLï¼ˆç»Ÿä¸€å»ºæ¨¡è¯­è¨€ï¼‰çš„ç±»å›¾&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/uml-class-diagram.png&quot; alt=&quot;uml&quot; /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;é€šè¿‡æ¨¡å‹åˆ›å»ºè¡¨ï¼ˆæ­£å‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºäºŒç»´è¡¨ã€‚&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;python manage.py makemigrations app
python manage.py migrate
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ä½¿ç”¨PowerDesignerç»˜åˆ¶ç‰©ç†æ¨¡å‹å›¾ã€‚&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/res/power-designer-pdm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;é€šè¿‡æ•°æ®è¡¨åˆ›å»ºæ¨¡å‹ï¼ˆåå‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ç”Ÿæˆæ¨¡å‹ã€‚&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-Shell&quot;&gt;python manage.py inspectdb &amp;gt; app/models.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ç¬¬92å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/92.Docker%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3.md&quot;&gt;Dockerå®¹å™¨æŠ€æœ¯è¯¦è§£&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Dockerç®€ä»‹&lt;/li&gt; 
 &lt;li&gt;å®‰è£…Docker&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨Dockeråˆ›å»ºå®¹å™¨ï¼ˆNginxã€MySQLã€Redisã€Gitlabã€Jenkinsï¼‰&lt;/li&gt; 
 &lt;li&gt;æ„å»ºDockeré•œåƒï¼ˆDockerfileçš„ç¼–å†™å’Œç›¸å…³æŒ‡ä»¤ï¼‰&lt;/li&gt; 
 &lt;li&gt;å®¹å™¨ç¼–æ’ï¼ˆDocker-composeï¼‰&lt;/li&gt; 
 &lt;li&gt;é›†ç¾¤ç®¡ç†ï¼ˆKubernetesï¼‰&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬93å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/93.MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md&quot;&gt;MySQLæ€§èƒ½ä¼˜åŒ–&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;åŸºæœ¬åŸåˆ™&lt;/li&gt; 
 &lt;li&gt;InnoDBå¼•æ“&lt;/li&gt; 
 &lt;li&gt;ç´¢å¼•çš„ä½¿ç”¨å’Œæ³¨æ„äº‹é¡¹&lt;/li&gt; 
 &lt;li&gt;æ•°æ®åˆ†åŒº&lt;/li&gt; 
 &lt;li&gt;SQLä¼˜åŒ–&lt;/li&gt; 
 &lt;li&gt;é…ç½®ä¼˜åŒ–&lt;/li&gt; 
 &lt;li&gt;æ¶æ„ä¼˜åŒ–&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬94å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/94.%E7%BD%91%E7%BB%9CAPI%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1.md&quot;&gt;ç½‘ç»œAPIæ¥å£è®¾è®¡&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è®¾è®¡åŸåˆ™ 
  &lt;ul&gt; 
   &lt;li&gt;å…³é”®é—®é¢˜&lt;/li&gt; 
   &lt;li&gt;å…¶ä»–é—®é¢˜&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æ–‡æ¡£æ’°å†™&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬95å¤©ï¼š[ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹ç›®](./Day91-100/95.ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹ ç›®.md)&lt;/h4&gt; 
&lt;h5&gt;é¡¹ç›®å¼€å‘ä¸­çš„å…¬å…±é—®é¢˜&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ•°æ®åº“çš„é…ç½®ï¼ˆå¤šæ•°æ®åº“ã€ä¸»ä»å¤åˆ¶ã€æ•°æ®åº“è·¯ç”±ï¼‰&lt;/li&gt; 
 &lt;li&gt;ç¼“å­˜çš„é…ç½®ï¼ˆåˆ†åŒºç¼“å­˜ã€é”®è®¾ç½®ã€è¶…æ—¶è®¾ç½®ã€ä¸»ä»å¤åˆ¶ã€æ•…éšœæ¢å¤ï¼ˆå“¨å…µï¼‰ï¼‰&lt;/li&gt; 
 &lt;li&gt;æ—¥å¿—çš„é…ç½®&lt;/li&gt; 
 &lt;li&gt;åˆ†æå’Œè°ƒè¯•ï¼ˆDjango-Debug-ToolBarï¼‰&lt;/li&gt; 
 &lt;li&gt;å¥½ç”¨çš„Pythonæ¨¡å—ï¼ˆæ—¥æœŸè®¡ç®—ã€å›¾åƒå¤„ç†ã€æ•°æ®åŠ å¯†ã€ä¸‰æ–¹APIï¼‰&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;REST APIè®¾è®¡&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;RESTfulæ¶æ„ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2011/09/restful.html&quot;&gt;ç†è§£RESTfulæ¶æ„&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2014/05/restful_api.html&quot;&gt;RESTful APIè®¾è®¡æŒ‡å—&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html&quot;&gt;RESTful APIæœ€ä½³å®è·µ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;APIæ¥å£æ–‡æ¡£çš„æ’°å†™ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;http://rap2.taobao.org/&quot;&gt;RAP2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;http://yapi.demo.qunar.com/&quot;&gt;YAPI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.django-rest-framework.org/&quot;&gt;django-REST-framework&lt;/a&gt;çš„åº”ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;é¡¹ç›®ä¸­çš„é‡ç‚¹éš¾ç‚¹å‰–æ&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä½¿ç”¨ç¼“å­˜ç¼“è§£æ•°æ®åº“å‹åŠ› - Redis&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—åšè§£è€¦åˆå’Œå‰Šå³° - Celery + RabbitMQ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬96å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/96.%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%92%8C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95.md&quot;&gt;è½¯ä»¶æµ‹è¯•å’Œè‡ªåŠ¨åŒ–æµ‹è¯•&lt;/a&gt;&lt;/h4&gt; 
&lt;h5&gt;å•å…ƒæµ‹è¯•&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;æµ‹è¯•çš„ç§ç±»&lt;/li&gt; 
 &lt;li&gt;ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆ&lt;code&gt;unittest&lt;/code&gt;ã€&lt;code&gt;pytest&lt;/code&gt;ã€&lt;code&gt;nose2&lt;/code&gt;ã€&lt;code&gt;tox&lt;/code&gt;ã€&lt;code&gt;ddt&lt;/code&gt;ã€â€¦â€¦ï¼‰&lt;/li&gt; 
 &lt;li&gt;æµ‹è¯•è¦†ç›–ç‡ï¼ˆ&lt;code&gt;coverage&lt;/code&gt;ï¼‰&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;Djangoé¡¹ç›®éƒ¨ç½²&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;éƒ¨ç½²å‰çš„å‡†å¤‡å·¥ä½œ 
  &lt;ul&gt; 
   &lt;li&gt;å…³é”®è®¾ç½®ï¼ˆSECRET_KEY / DEBUG / ALLOWED_HOSTS / ç¼“å­˜ / æ•°æ®åº“ï¼‰&lt;/li&gt; 
   &lt;li&gt;HTTPS / CSRF_COOKIE_SECUR / SESSION_COOKIE_SECURE&lt;/li&gt; 
   &lt;li&gt;æ—¥å¿—ç›¸å…³é…ç½®&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Linuxå¸¸ç”¨å‘½ä»¤å›é¡¾&lt;/li&gt; 
 &lt;li&gt;Linuxå¸¸ç”¨æœåŠ¡çš„å®‰è£…å’Œé…ç½®&lt;/li&gt; 
 &lt;li&gt;uWSGI/Gunicornå’ŒNginxçš„ä½¿ç”¨ 
  &lt;ul&gt; 
   &lt;li&gt;Gunicornå’ŒuWSGIçš„æ¯”è¾ƒ 
    &lt;ul&gt; 
     &lt;li&gt;å¯¹äºä¸éœ€è¦å¤§é‡å®šåˆ¶åŒ–çš„ç®€å•åº”ç”¨ç¨‹åºï¼ŒGunicornæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼ŒuWSGIçš„å­¦ä¹ æ›²çº¿æ¯”Gunicornè¦é™¡å³­å¾—å¤šï¼ŒGunicornçš„é»˜è®¤å‚æ•°å°±å·²ç»èƒ½å¤Ÿé€‚åº”å¤§å¤šæ•°åº”ç”¨ç¨‹åºã€‚&lt;/li&gt; 
     &lt;li&gt;uWSGIæ”¯æŒå¼‚æ„éƒ¨ç½²ã€‚&lt;/li&gt; 
     &lt;li&gt;ç”±äºNginxæœ¬èº«æ”¯æŒuWSGIï¼Œåœ¨çº¿ä¸Šä¸€èˆ¬éƒ½å°†Nginxå’ŒuWSGIæ†ç»‘åœ¨ä¸€èµ·éƒ¨ç½²ï¼Œè€Œä¸”uWSGIå±äºåŠŸèƒ½é½å…¨ä¸”é«˜åº¦å®šåˆ¶çš„WSGIä¸­é—´ä»¶ã€‚&lt;/li&gt; 
     &lt;li&gt;åœ¨æ€§èƒ½ä¸Šï¼ŒGunicornå’ŒuWSGIå…¶å®è¡¨ç°ç›¸å½“ã€‚&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨è™šæ‹ŸåŒ–æŠ€æœ¯ï¼ˆDockerï¼‰éƒ¨ç½²æµ‹è¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;æ€§èƒ½æµ‹è¯•&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;ABçš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;SQLslapçš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;sysbenchçš„ä½¿ç”¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h5&gt;è‡ªåŠ¨åŒ–æµ‹è¯•&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt;ä½¿ç”¨Shellå’ŒPythonè¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨Seleniumå®ç°è‡ªåŠ¨åŒ–æµ‹è¯• 
  &lt;ul&gt; 
   &lt;li&gt;Selenium IDE&lt;/li&gt; 
   &lt;li&gt;Selenium WebDriver&lt;/li&gt; 
   &lt;li&gt;Selenium Remote Control&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;æµ‹è¯•å·¥å…·Robot Frameworkä»‹ç»&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬97å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/97.%E7%94%B5%E5%95%86%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E5%89%96%E6%9E%90.md&quot;&gt;ç”µå•†ç½‘ç«™æŠ€æœ¯è¦ç‚¹å‰–æ&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;å•†ä¸šæ¨¡å¼å’Œéœ€æ±‚è¦ç‚¹&lt;/li&gt; 
 &lt;li&gt;ç‰©ç†æ¨¡å‹è®¾è®¡&lt;/li&gt; 
 &lt;li&gt;ç¬¬ä¸‰æ–¹ç™»å½•&lt;/li&gt; 
 &lt;li&gt;ç¼“å­˜é¢„çƒ­å’ŒæŸ¥è¯¢ç¼“å­˜&lt;/li&gt; 
 &lt;li&gt;è´­ç‰©è½¦çš„å®ç°&lt;/li&gt; 
 &lt;li&gt;æ”¯ä»˜åŠŸèƒ½é›†æˆ&lt;/li&gt; 
 &lt;li&gt;ç§’æ€å’Œè¶…å–é—®é¢˜&lt;/li&gt; 
 &lt;li&gt;é™æ€èµ„æºç®¡ç†&lt;/li&gt; 
 &lt;li&gt;å…¨æ–‡æ£€ç´¢æ–¹æ¡ˆ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬98å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/98.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E5%92%8C%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md&quot;&gt;é¡¹ç›®éƒ¨ç½²ä¸Šçº¿å’Œæ€§èƒ½è°ƒä¼˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;MySQLæ•°æ®åº“è°ƒä¼˜&lt;/li&gt; 
 &lt;li&gt;WebæœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ– 
  &lt;ul&gt; 
   &lt;li&gt;Nginxè´Ÿè½½å‡è¡¡é…ç½®&lt;/li&gt; 
   &lt;li&gt;Keepalivedå®ç°é«˜å¯ç”¨&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ä»£ç æ€§èƒ½è°ƒä¼˜ 
  &lt;ul&gt; 
   &lt;li&gt;å¤šçº¿ç¨‹&lt;/li&gt; 
   &lt;li&gt;å¼‚æ­¥åŒ–&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;é™æ€èµ„æºè®¿é—®ä¼˜åŒ– 
  &lt;ul&gt; 
   &lt;li&gt;äº‘å­˜å‚¨&lt;/li&gt; 
   &lt;li&gt;CDN&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ç¬¬99å¤©ï¼š&lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/99.%E9%9D%A2%E8%AF%95%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E9%97%AE%E9%A2%98.md&quot;&gt;é¢è¯•ä¸­çš„å…¬å…±é—®é¢˜&lt;/a&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;è®¡ç®—æœºåŸºç¡€&lt;/li&gt; 
 &lt;li&gt;PythonåŸºç¡€&lt;/li&gt; 
 &lt;li&gt;Webæ¡†æ¶ç›¸å…³&lt;/li&gt; 
 &lt;li&gt;çˆ¬è™«ç›¸å…³é—®é¢˜&lt;/li&gt; 
 &lt;li&gt;æ•°æ®åˆ†æ&lt;/li&gt; 
 &lt;li&gt;é¡¹ç›®ç›¸å…³&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ç¬¬100å¤© - &lt;a href=&quot;https://raw.githubusercontent.com/jackfrued/Python-100-Days/master/Day91-100/100.%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9.md&quot;&gt;è¡¥å……å†…å®¹&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;é¢è¯•å®å…¸&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python é¢è¯•å®å…¸&lt;/li&gt; 
   &lt;li&gt;SQL é¢è¯•å®å…¸ï¼ˆæ•°æ®åˆ†æå¸ˆï¼‰&lt;/li&gt; 
   &lt;li&gt;å•†ä¸šåˆ†æé¢è¯•å®å…¸&lt;/li&gt; 
   &lt;li&gt;æœºå™¨å­¦ä¹ é¢è¯•å®å…¸&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;æœºå™¨å­¦ä¹ æ•°å­¦åŸºç¡€&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;æ·±åº¦å­¦ä¹ &lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;è®¡ç®—æœºè§†è§‰&lt;/li&gt; 
   &lt;li&gt;å¤§è¯­è¨€æ¨¡å‹&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>facebookresearch/sam2</title>
      <link>https://github.com/facebookresearch/sam2</link>
      <description>&lt;p&gt;The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SAM 2: Segment Anything in Images and Videos&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ai.meta.com/research/&quot;&gt;AI at Meta, FAIR&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://nikhilaravi.com/&quot;&gt;Nikhila Ravi&lt;/a&gt;, &lt;a href=&quot;https://gabeur.github.io/&quot;&gt;Valentin Gabeur&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?user=E8DVVYQAAAAJ&amp;amp;hl=en&quot;&gt;Yuan-Ting Hu&lt;/a&gt;, &lt;a href=&quot;https://ronghanghu.com/&quot;&gt;Ronghang Hu&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?user=4LWx24UAAAAJ&amp;amp;hl=en&quot;&gt;Chaitanya Ryali&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?user=VeTSl0wAAAAJ&amp;amp;hl=en&quot;&gt;Tengyu Ma&lt;/a&gt;, &lt;a href=&quot;https://hkhedr.com/&quot;&gt;Haitham Khedr&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.de/citations?user=Tpt57v0AAAAJ&amp;amp;hl=en&quot;&gt;Roman RÃ¤dle&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?hl=fr&amp;amp;user=n-SnMhoAAAAJ&quot;&gt;Chloe Rolland&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?user=c8IpF9gAAAAJ&amp;amp;hl=en&quot;&gt;Laura Gustafson&lt;/a&gt;, &lt;a href=&quot;https://ericmintun.github.io/&quot;&gt;Eric Mintun&lt;/a&gt;, &lt;a href=&quot;https://junting.github.io/&quot;&gt;Junting Pan&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.co.in/citations?user=m34oaWEAAAAJ&amp;amp;hl=en&quot;&gt;Kalyan Vasudev Alwala&lt;/a&gt;, &lt;a href=&quot;https://www.nicolascarion.com/&quot;&gt;Nicolas Carion&lt;/a&gt;, &lt;a href=&quot;https://chaoyuan.org/&quot;&gt;Chao-Yuan Wu&lt;/a&gt;, &lt;a href=&quot;https://www.rossgirshick.info/&quot;&gt;Ross Girshick&lt;/a&gt;, &lt;a href=&quot;https://pdollar.github.io/&quot;&gt;Piotr DollÃ¡r&lt;/a&gt;, &lt;a href=&quot;https://feichtenhofer.github.io/&quot;&gt;Christoph Feichtenhofer&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[&lt;a href=&quot;https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/&quot;&gt;&lt;code&gt;Paper&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://ai.meta.com/sam2&quot;&gt;&lt;code&gt;Project&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://sam2.metademolab.com/&quot;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://ai.meta.com/datasets/segment-anything-video&quot;&gt;&lt;code&gt;Dataset&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://ai.meta.com/blog/segment-anything-2&quot;&gt;&lt;code&gt;Blog&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/#citing-sam-2&quot;&gt;&lt;code&gt;BibTeX&lt;/code&gt;&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/assets/model_diagram.png?raw=true&quot; alt=&quot;SAM 2 architecture&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Segment Anything Model 2 (SAM 2)&lt;/strong&gt; is a foundation model towards solving promptable visual segmentation in images and videos. We extend SAM to video by considering images as a video with a single frame. The model design is a simple transformer architecture with streaming memory for real-time video processing. We build a model-in-the-loop data engine, which improves model and data via user interaction, to collect &lt;a href=&quot;https://ai.meta.com/datasets/segment-anything-video&quot;&gt;&lt;strong&gt;our SA-V dataset&lt;/strong&gt;&lt;/a&gt;, the largest video segmentation dataset to date. SAM 2 trained on our data provides strong performance across a wide range of tasks and visual domains.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/assets/sa_v_dataset.jpg?raw=true&quot; alt=&quot;SA-V dataset&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Latest updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;12/11/2024 -- full model compilation for a major VOS speedup and a new &lt;code&gt;SAM2VideoPredictor&lt;/code&gt; to better handle multi-object tracking&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We now support &lt;code&gt;torch.compile&lt;/code&gt; of the entire SAM 2 model on videos, which can be turned on by setting &lt;code&gt;vos_optimized=True&lt;/code&gt; in &lt;code&gt;build_sam2_video_predictor&lt;/code&gt;, leading to a major speedup for VOS inference.&lt;/li&gt; 
 &lt;li&gt;We update the implementation of &lt;code&gt;SAM2VideoPredictor&lt;/code&gt; to support independent per-object inference, allowing us to relax the assumption of prompting for multi-object tracking and adding new objects after tracking starts.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/RELEASE_NOTES.md&quot;&gt;&lt;code&gt;RELEASE_NOTES.md&lt;/code&gt;&lt;/a&gt; for full details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;09/30/2024 -- SAM 2.1 Developer Suite (new checkpoints, training code, web demo) is released&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A new suite of improved model checkpoints (denoted as &lt;strong&gt;SAM 2.1&lt;/strong&gt;) are released. See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/#model-description&quot;&gt;Model Description&lt;/a&gt; for details. 
  &lt;ul&gt; 
   &lt;li&gt;To use the new SAM 2.1 checkpoints, you need the latest model code from this repo. If you have installed an earlier version of this repo, please first uninstall the previous version via &lt;code&gt;pip uninstall SAM-2&lt;/code&gt;, pull the latest code from this repo (with &lt;code&gt;git pull&lt;/code&gt;), and then reinstall the repo following &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/#installation&quot;&gt;Installation&lt;/a&gt; below.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The training (and fine-tuning) code has been released. See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/training/README.md&quot;&gt;&lt;code&gt;training/README.md&lt;/code&gt;&lt;/a&gt; on how to get started.&lt;/li&gt; 
 &lt;li&gt;The frontend + backend code for the SAM 2 web demo has been released. See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/demo/README.md&quot;&gt;&lt;code&gt;demo/README.md&lt;/code&gt;&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;SAM 2 needs to be installed first before use. The code requires &lt;code&gt;python&amp;gt;=3.10&lt;/code&gt;, as well as &lt;code&gt;torch&amp;gt;=2.5.1&lt;/code&gt; and &lt;code&gt;torchvision&amp;gt;=0.20.1&lt;/code&gt;. Please follow the instructions &lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;here&lt;/a&gt; to install both PyTorch and TorchVision dependencies. You can install SAM 2 on a GPU machine using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/facebookresearch/sam2.git &amp;amp;&amp;amp; cd sam2

pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are installing on Windows, it&#39;s strongly recommended to use &lt;a href=&quot;https://learn.microsoft.com/en-us/windows/wsl/install&quot;&gt;Windows Subsystem for Linux (WSL)&lt;/a&gt; with Ubuntu.&lt;/p&gt; 
&lt;p&gt;To use the SAM 2 predictor and run the example notebooks, &lt;code&gt;jupyter&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt; are required and can be installed by:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -e &quot;.[notebooks]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It&#39;s recommended to create a new Python environment via &lt;a href=&quot;https://www.anaconda.com/&quot;&gt;Anaconda&lt;/a&gt; for this installation and install PyTorch 2.5.1 (or higher) via &lt;code&gt;pip&lt;/code&gt; following &lt;a href=&quot;https://pytorch.org/&quot;&gt;https://pytorch.org/&lt;/a&gt;. If you have a PyTorch version lower than 2.5.1 in your current environment, the installation command above will try to upgrade it to the latest PyTorch version using &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;The step above requires compiling a custom CUDA kernel with the &lt;code&gt;nvcc&lt;/code&gt; compiler. If it isn&#39;t already available on your machine, please install the &lt;a href=&quot;https://developer.nvidia.com/cuda-toolkit-archive&quot;&gt;CUDA toolkits&lt;/a&gt; with a version that matches your PyTorch CUDA version.&lt;/li&gt; 
 &lt;li&gt;If you see a message like &lt;code&gt;Failed to build the SAM 2 CUDA extension&lt;/code&gt; during installation, you can ignore it and still use SAM 2 (some post-processing functionality may be limited, but it doesn&#39;t affect the results in most cases).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please see &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/INSTALL.md&quot;&gt;&lt;code&gt;INSTALL.md&lt;/code&gt;&lt;/a&gt; for FAQs on potential issues and solutions.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Download Checkpoints&lt;/h3&gt; 
&lt;p&gt;First, we need to download a model checkpoint. All the model checkpoints can be downloaded by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd checkpoints &amp;amp;&amp;amp; \
./download_ckpts.sh &amp;amp;&amp;amp; \
cd ..
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or individually from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt&quot;&gt;sam2.1_hiera_tiny.pt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt&quot;&gt;sam2.1_hiera_small.pt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt&quot;&gt;sam2.1_hiera_base_plus.pt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt&quot;&gt;sam2.1_hiera_large.pt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(note that these are the improved checkpoints denoted as SAM 2.1; see &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/#model-description&quot;&gt;Model Description&lt;/a&gt; for details.)&lt;/p&gt; 
&lt;p&gt;Then SAM 2 can be used in a few lines as follows for image and video prediction.&lt;/p&gt; 
&lt;h3&gt;Image prediction&lt;/h3&gt; 
&lt;p&gt;SAM 2 has all the capabilities of &lt;a href=&quot;https://github.com/facebookresearch/segment-anything&quot;&gt;SAM&lt;/a&gt; on static images, and we provide image prediction APIs that closely resemble SAM for image use cases. The &lt;code&gt;SAM2ImagePredictor&lt;/code&gt; class has an easy interface for image prompting.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import torch
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

checkpoint = &quot;./checkpoints/sam2.1_hiera_large.pt&quot;
model_cfg = &quot;configs/sam2.1/sam2.1_hiera_l.yaml&quot;
predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    predictor.set_image(&amp;lt;your_image&amp;gt;)
    masks, _, _ = predictor.predict(&amp;lt;input_prompts&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to the examples in &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/notebooks/image_predictor_example.ipynb&quot;&gt;image_predictor_example.ipynb&lt;/a&gt; (also in Colab &lt;a href=&quot;https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/image_predictor_example.ipynb&quot;&gt;here&lt;/a&gt;) for static image use cases.&lt;/p&gt; 
&lt;p&gt;SAM 2 also supports automatic mask generation on images just like SAM. Please see &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/notebooks/automatic_mask_generator_example.ipynb&quot;&gt;automatic_mask_generator_example.ipynb&lt;/a&gt; (also in Colab &lt;a href=&quot;https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/automatic_mask_generator_example.ipynb&quot;&gt;here&lt;/a&gt;) for automatic mask generation in images.&lt;/p&gt; 
&lt;h3&gt;Video prediction&lt;/h3&gt; 
&lt;p&gt;For promptable segmentation and tracking in videos, we provide a video predictor with APIs for example to add prompts and propagate masklets throughout a video. SAM 2 supports video inference on multiple objects and uses an inference state to keep track of the interactions in each video.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import torch
from sam2.build_sam import build_sam2_video_predictor

checkpoint = &quot;./checkpoints/sam2.1_hiera_large.pt&quot;
model_cfg = &quot;configs/sam2.1/sam2.1_hiera_l.yaml&quot;
predictor = build_sam2_video_predictor(model_cfg, checkpoint)

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    state = predictor.init_state(&amp;lt;your_video&amp;gt;)

    # add new prompts and instantly get the output on the same frame
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, &amp;lt;your_prompts&amp;gt;):

    # propagate the prompts to get masklets throughout the video
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to the examples in &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/notebooks/video_predictor_example.ipynb&quot;&gt;video_predictor_example.ipynb&lt;/a&gt; (also in Colab &lt;a href=&quot;https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/video_predictor_example.ipynb&quot;&gt;here&lt;/a&gt;) for details on how to add click or box prompts, make refinements, and track multiple objects in videos.&lt;/p&gt; 
&lt;h2&gt;Load from ğŸ¤— Hugging Face&lt;/h2&gt; 
&lt;p&gt;Alternatively, models can also be loaded from &lt;a href=&quot;https://huggingface.co/models?search=facebook/sam2&quot;&gt;Hugging Face&lt;/a&gt; (requires &lt;code&gt;pip install huggingface_hub&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;For image prediction:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import torch
from sam2.sam2_image_predictor import SAM2ImagePredictor

predictor = SAM2ImagePredictor.from_pretrained(&quot;facebook/sam2-hiera-large&quot;)

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    predictor.set_image(&amp;lt;your_image&amp;gt;)
    masks, _, _ = predictor.predict(&amp;lt;input_prompts&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For video prediction:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import torch
from sam2.sam2_video_predictor import SAM2VideoPredictor

predictor = SAM2VideoPredictor.from_pretrained(&quot;facebook/sam2-hiera-large&quot;)

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    state = predictor.init_state(&amp;lt;your_video&amp;gt;)

    # add new prompts and instantly get the output on the same frame
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, &amp;lt;your_prompts&amp;gt;):

    # propagate the prompts to get masklets throughout the video
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Description&lt;/h2&gt; 
&lt;h3&gt;SAM 2.1 checkpoints&lt;/h3&gt; 
&lt;p&gt;The table below shows the improved SAM 2.1 checkpoints released on September 29, 2024.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Size (M)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Speed (FPS)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;SA-V test (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;MOSE val (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;LVOS v2 (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2.1_hiera_tiny &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_t.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;38.9&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;91.2&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;76.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;71.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;77.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2.1_hiera_small &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_s.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;46&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;84.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;76.6&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;73.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;78.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2.1_hiera_base_plus &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_b+.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;80.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;64.1&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;78.2&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;73.7&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;78.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2.1_hiera_large &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2.1/sam2.1_hiera_l.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;224.4&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;39.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;79.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;74.6&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;80.6&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;SAM 2 checkpoints&lt;/h3&gt; 
&lt;p&gt;The previous SAM 2 checkpoints released on July 29, 2024 can be found as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Size (M)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Speed (FPS)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;SA-V test (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;MOSE val (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;LVOS v2 (J&amp;amp;F)&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2_hiera_tiny &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2/sam2_hiera_t.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;38.9&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;91.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;75.0&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;70.9&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;75.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2_hiera_small &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2/sam2_hiera_s.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;46&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;85.6&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;74.9&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;71.5&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;76.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2_hiera_base_plus &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2/sam2_hiera_b+.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;80.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;64.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;74.7&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;72.8&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;75.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;sam2_hiera_large &lt;br /&gt; (&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sam2/configs/sam2/sam2_hiera_l.yaml&quot;&gt;config&lt;/a&gt;, &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt&quot;&gt;checkpoint&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;224.4&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;39.7&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;76.0&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;74.6&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;79.8&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Speed measured on an A100 with &lt;code&gt;torch 2.5.1, cuda 12.4&lt;/code&gt;. See &lt;code&gt;benchmark.py&lt;/code&gt; for an example on benchmarking (compiling all the model components). Compiling only the image encoder can be more flexible and also provide (a smaller) speed-up (set &lt;code&gt;compile_image_encoder: True&lt;/code&gt; in the config).&lt;/p&gt; 
&lt;h2&gt;Segment Anything Video Dataset&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/sav_dataset/README.md&quot;&gt;sav_dataset/README.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Training SAM 2&lt;/h2&gt; 
&lt;p&gt;You can train or fine-tune SAM 2 on custom datasets of images, videos, or both. Please check the training &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/training/README.md&quot;&gt;README&lt;/a&gt; on how to get started.&lt;/p&gt; 
&lt;h2&gt;Web demo for SAM 2&lt;/h2&gt; 
&lt;p&gt;We have released the frontend + backend code for the SAM 2 web demo (a locally deployable version similar to &lt;a href=&quot;https://sam2.metademolab.com/demo&quot;&gt;https://sam2.metademolab.com/demo&lt;/a&gt;). Please see the web demo &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/demo/README.md&quot;&gt;README&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The SAM 2 model checkpoints, SAM 2 demo code (front-end and back-end), and SAM 2 training code are licensed under &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/LICENSE&quot;&gt;Apache 2.0&lt;/a&gt;, however the &lt;a href=&quot;https://github.com/rsms/inter?tab=OFL-1.1-1-ov-file&quot;&gt;Inter Font&lt;/a&gt; and &lt;a href=&quot;https://github.com/googlefonts/noto-emoji&quot;&gt;Noto Color Emoji&lt;/a&gt; used in the SAM 2 demo code are made available under the &lt;a href=&quot;https://openfontlicense.org/open-font-license-official-text/&quot;&gt;SIL Open Font License, version 1.1&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/CONTRIBUTING.md&quot;&gt;contributing&lt;/a&gt; and the &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/CODE_OF_CONDUCT.md&quot;&gt;code of conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;The SAM 2 project was made possible with the help of many contributors (alphabetical):&lt;/p&gt; 
&lt;p&gt;Karen Bergan, Daniel Bolya, Alex Bosenberg, Kai Brown, Vispi Cassod, Christopher Chedeau, Ida Cheng, Luc Dahlin, Shoubhik Debnath, Rene Martinez Doehner, Grant Gardner, Sahir Gomez, Rishi Godugu, Baishan Guo, Caleb Ho, Andrew Huang, Somya Jain, Bob Kamma, Amanda Kallet, Jake Kinney, Alexander Kirillov, Shiva Koduvayur, Devansh Kukreja, Robert Kuo, Aohan Lin, Parth Malani, Jitendra Malik, Mallika Malhotra, Miguel Martin, Alexander Miller, Sasha Mitts, William Ngan, George Orlin, Joelle Pineau, Kate Saenko, Rodrick Shepard, Azita Shokrpour, David Soofian, Jonathan Torres, Jenny Truong, Sagar Vaze, Meng Wang, Claudette Ward, Pengchuan Zhang.&lt;/p&gt; 
&lt;p&gt;Third-party code: we use a GPU-based connected component algorithm adapted from &lt;a href=&quot;https://github.com/zsef123/Connected_components_PyTorch&quot;&gt;&lt;code&gt;cc_torch&lt;/code&gt;&lt;/a&gt; (with its license in &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/sam2/main/LICENSE_cctorch&quot;&gt;&lt;code&gt;LICENSE_cctorch&lt;/code&gt;&lt;/a&gt;) as an optional post-processing step for the mask predictions.&lt;/p&gt; 
&lt;h2&gt;Citing SAM 2&lt;/h2&gt; 
&lt;p&gt;If you use SAM 2 or the SA-V dataset in your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\&quot;a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\&#39;a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  url={https://arxiv.org/abs/2408.00714},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>microsoft/ai-agents-for-beginners</title>
      <link>https://github.com/microsoft/ai-agents-for-beginners</link>
      <description>&lt;p&gt;11 Lessons to Get Started Building AI Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents for Beginners - A Course&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/images/repo-thumbnail.png&quot; alt=&quot;Generative AI For Beginners&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;11 Lessons teaching everything you need to know to start building AI Agents&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/issues/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/pulls/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/ai-agents-for-beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸŒ Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fr/README.md&quot;&gt;French&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/es/README.md&quot;&gt;Spanish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/de/README.md&quot;&gt;German&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ru/README.md&quot;&gt;Russian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ar/README.md&quot;&gt;Arabic&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fa/README.md&quot;&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ur/README.md&quot;&gt;Urdu&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/zh/README.md&quot;&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mo/README.md&quot;&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hk/README.md&quot;&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tw/README.md&quot;&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ja/README.md&quot;&gt;Japanese&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ko/README.md&quot;&gt;Korean&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hi/README.md&quot;&gt;Hindi&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bn/README.md&quot;&gt;Bengali&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mr/README.md&quot;&gt;Marathi&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ne/README.md&quot;&gt;Nepali&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pa/README.md&quot;&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pt/README.md&quot;&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/br/README.md&quot;&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/it/README.md&quot;&gt;Italian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pl/README.md&quot;&gt;Polish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tr/README.md&quot;&gt;Turkish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/el/README.md&quot;&gt;Greek&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/th/README.md&quot;&gt;Thai&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sv/README.md&quot;&gt;Swedish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/da/README.md&quot;&gt;Danish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/no/README.md&quot;&gt;Norwegian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fi/README.md&quot;&gt;Finnish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/nl/README.md&quot;&gt;Dutch&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/he/README.md&quot;&gt;Hebrew&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/vi/README.md&quot;&gt;Vietnamese&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/id/README.md&quot;&gt;Indonesian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ms/README.md&quot;&gt;Malay&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tl/README.md&quot;&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sw/README.md&quot;&gt;Swahili&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hu/README.md&quot;&gt;Hungarian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/cs/README.md&quot;&gt;Czech&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sk/README.md&quot;&gt;Slovak&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ro/README.md&quot;&gt;Romanian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bg/README.md&quot;&gt;Bulgarian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sr/README.md&quot;&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hr/README.md&quot;&gt;Croatian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sl/README.md&quot;&gt;Slovenian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/uk/README.md&quot;&gt;Ukrainian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/my/README.md&quot;&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href=&quot;https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md&quot;&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/watchers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/network/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/ai-agents-for-beginners/stargazers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/kzRShWzttr&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/kzRShWzttr&quot; alt=&quot;Azure AI Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒ± Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 11 lessons covering the fundamentals of building AI Agents. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;There is multi-language support for this course. Go to our &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/#-multi-language-support&quot;&gt;available languages here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If this is your first time building with Generative AI models, check out our &lt;a href=&quot;https://aka.ms/genai-beginners&quot;&gt;Generative AI For Beginners&lt;/a&gt; course, which includes 21 lessons on building with GenAI.&lt;/p&gt; 
&lt;p&gt;Don&#39;t forget to &lt;a href=&quot;https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst&quot;&gt;star (ğŸŒŸ) this repo&lt;/a&gt; and &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/fork&quot;&gt;fork this repo&lt;/a&gt; to run the code.&lt;/p&gt; 
&lt;h3&gt;What You Need&lt;/h3&gt; 
&lt;p&gt;Each lesson in this course includes code examples, which can be found in the code_samples folder. You can &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/fork&quot;&gt;fork this repo&lt;/a&gt; to create your own copy.&lt;/p&gt; 
&lt;p&gt;The code example in these exercises, utilize Azure AI Foundry and GitHub Model Catalogs for interacting with Language Models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/github-models&quot;&gt;Github Models&lt;/a&gt; - Free / Limited&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/ai-foundry&quot;&gt;Azure AI Foundry&lt;/a&gt; - Azure Account Required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This course also uses the following AI Agent frameworks and services from Microsoft:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/ai-agent-service&quot;&gt;Azure AI Agent Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/semantic-kernel&quot;&gt;Semantic Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-agents/autogen&quot;&gt;AutoGen&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information on running the code for this course, go to the &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/00-course-setup/README.md&quot;&gt;Course Setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ™ Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/issues?WT.mc_id=academic-105485-koreyst&quot;&gt;Raise an issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners/pulls?WT.mc_id=academic-105485-koreyst&quot;&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you get stuck or have any questions about building AI Agents, join our &lt;a href=&quot;https://discord.gg/kzRShWzttr&quot;&gt;Azure AI Foundry Community Discord&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you have product feedback or errors whilst building visit our &lt;a href=&quot;https://aka.ms/azureaifoundry/forum&quot;&gt;Azure AI Foundry Developer Forum&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“‚ Each lesson includes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A written lesson located in the README and a short video&lt;/li&gt; 
 &lt;li&gt;Python code samples supporting Azure AI Foundry and Github Models (Free)&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ—ƒï¸ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Text &amp;amp; Code&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Intro to AI Agents and Agent Use Cases&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/01-intro-to-ai-agents/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/3zgm60bXmQk?si=z8QygFvYQv-9WtO1&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exploring AI Agentic Frameworks&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/02-explore-agentic-frameworks/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/ODwF-EZo_O8?si=Vawth4hzVaHv-u0H&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Understanding AI Agentic Design Patterns&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/03-agentic-design-patterns/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/m9lM8qqoOEA?si=BIzHwzstTPL8o9GF&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tool Use Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/04-tool-use/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/vieRiPRx-gI?si=2z6O2Xu2cu_Jz46N&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agentic RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/05-agentic-rag/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/WcjAARvdL7I?si=gKPWsQpKiIlDH9A3&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Trustworthy AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/06-building-trustworthy-agents/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/iZKkMEGBCUQ?si=jZjpiMnGFOE9L8OK&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/07-planning-design/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/kPfJ2BrBCMY?si=6SC_iv_E5-mzucnC&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-Agent Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/08-multi-agent/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/V6HpE9hZEx0?si=rMgDhEu7wXo2uo6g&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metacognition Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/09-metacognition/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/His9R6gw6Ec?si=8gck6vvdSNCt6OcF&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AI Agents in Production&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/10-ai-agents-production/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/l4TP6IyJxmQ?si=31dnhexRo6yLRJDl&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AI Agents with MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/11-mcp/README.md&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/mcp-for-beginners&quot;&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ’ Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; Model Context Protocol (MCP) For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸŒŸ Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to &lt;a href=&quot;https://www.linkedin.com/in/shivam2003/&quot;&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples demonstrating Agentic RAG.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&quot;https://cla.opensource.microsoft.com&quot;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/&quot;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&quot;https://opensource.microsoft.com/codeofconduct/faq/&quot;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&quot;mailto:opencode@microsoft.com&quot;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&quot;https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general&quot;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties&#39; policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/rag-from-scratch</title>
      <link>https://github.com/langchain-ai/rag-from-scratch</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAG From Scratch&lt;/h1&gt; 
&lt;p&gt;LLMs are trained on a large but fixed corpus of data, limiting their ability to reason about private or recent information. Fine-tuning is one way to mitigate this, but is often &lt;a href=&quot;https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts&quot;&gt;not well-suited for factual recall&lt;/a&gt; and &lt;a href=&quot;https://www.glean.com/blog/how-to-build-an-ai-assistant-for-the-enterprise&quot;&gt;can be costly&lt;/a&gt;. Retrieval augmented generation (RAG) has emerged as a popular and powerful mechanism to expand an LLM&#39;s knowledge base, using documents retrieved from an external data source to ground the LLM generation via in-context learning. These notebooks accompany a &lt;a href=&quot;https://youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&amp;amp;feature=shared&quot;&gt;video playlist&lt;/a&gt; that builds up an understanding of RAG from scratch, starting with the basics of indexing, retrieval, and generation. &lt;img src=&quot;https://github.com/langchain-ai/rag-from-scratch/assets/122662504/54a2d76c-b07e-49e7-b4ce-fc45667360a1&quot; alt=&quot;rag_detail_v2&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&quot;&gt;Video playlist&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>karpathy/nn-zero-to-hero</title>
      <link>https://github.com/karpathy/nn-zero-to-hero</link>
      <description>&lt;p&gt;Neural Networks: Zero to Hero&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Neural Networks: Zero to Hero&lt;/h2&gt; 
&lt;p&gt;A course on neural networks that starts all the way at the basics. The course is a series of YouTube videos where we code and train neural networks together. The Jupyter notebooks we build in the videos are then captured here inside the &lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/&quot;&gt;lectures&lt;/a&gt; directory. Every lecture also has a set of exercises included in the video description. (This may grow into something more respectable).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 1: The spelled-out intro to neural networks and backpropagation: building micrograd&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Backpropagation and training of neural networks. Assumes basic knowledge of Python and a vague recollection of calculus from high school.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=VMj-3S1tku0&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/micrograd&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/micrograd&quot;&gt;micrograd Github repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 2: The spelled-out intro to language modeling: building makemore&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We implement a bigram character-level language model, which we will further complexify in followup videos into a modern Transformer language model, like GPT. In this video, the focus is on (1) introducing torch.Tensor and its subtleties and use in efficiently evaluating neural networks and (2) the overall framework of language modeling that includes model training, sampling, and the evaluation of a loss (e.g. the negative log likelihood for classification).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PaCmpygFfXo&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/makemore/makemore_part1_bigrams.ipynb&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/makemore&quot;&gt;makemore Github repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 3: Building makemore Part 2: MLP&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We implement a multilayer perceptron (MLP) character-level language model. In this video we also introduce many basics of machine learning (e.g. model training, learning rate tuning, hyperparameters, evaluation, train/dev/test splits, under/overfitting, etc.).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/TCH_1BHY58I&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/makemore/makemore_part2_mlp.ipynb&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/makemore&quot;&gt;makemore Github repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 4: Building makemore Part 3: Activations &amp;amp; Gradients, BatchNorm&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We dive into some of the internals of MLPs with multiple layers and scrutinize the statistics of the forward pass activations, backward pass gradients, and some of the pitfalls when they are improperly scaled. We also look at the typical diagnostic tools and visualizations you&#39;d want to use to understand the health of your deep network. We learn why training deep neural nets can be fragile and introduce the first modern innovation that made doing so much easier: Batch Normalization. Residual connections and the Adam optimizer remain notable todos for later video.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/P6sfmUTpUmc&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/makemore/makemore_part3_bn.ipynb&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/makemore&quot;&gt;makemore Github repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 5: Building makemore Part 4: Becoming a Backprop Ninja&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We take the 2-layer MLP (with BatchNorm) from the previous video and backpropagate through it manually without using PyTorch autograd&#39;s loss.backward(). That is, we backprop through the cross entropy loss, 2nd linear layer, tanh, batchnorm, 1st linear layer, and the embedding table. Along the way, we get an intuitive understanding about how gradients flow backwards through the compute graph and on the level of efficient Tensors, not just individual scalars like in micrograd. This helps build competence and intuition around how neural nets are optimized and sets you up to more confidently innovate on and debug modern neural networks.&lt;/p&gt; 
&lt;p&gt;I recommend you work through the exercise yourself but work with it in tandem and whenever you are stuck unpause the video and see me give away the answer. This video is not super intended to be simply watched. The exercise is &lt;a href=&quot;https://colab.research.google.com/drive/1WV2oi2fh9XXyldh02wupFQX0wh5ZC-z-?usp=sharing&quot;&gt;here as a Google Colab&lt;/a&gt;. Good luck :)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/q8SA3rM6ckI&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/makemore/makemore_part4_backprop.ipynb&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/makemore&quot;&gt;makemore Github repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 6: Building makemore Part 5: Building WaveNet&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We take the 2-layer MLP from previous video and make it deeper with a tree-like structure, arriving at a convolutional neural network architecture similar to the WaveNet (2016) from DeepMind. In the WaveNet paper, the same hierarchical architecture is implemented more efficiently using causal dilated convolutions (not yet covered). Along the way we get a better sense of torch.nn and what it is and how it works under the hood, and what a typical deep learning development process looks like (a lot of reading of documentation, keeping track of multidimensional tensor shapes, moving between jupyter notebooks and repository code, ...).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://youtu.be/t3YJ5hKiMQ0&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/karpathy/nn-zero-to-hero/master/lectures/makemore/makemore_part5_cnn1.ipynb&quot;&gt;Jupyter notebook files&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 7: Let&#39;s build GPT: from scratch, in code, spelled out.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We build a Generatively Pretrained Transformer (GPT), following the paper &quot;Attention is All You Need&quot; and OpenAI&#39;s GPT-2 / GPT-3. We talk about connections to ChatGPT, which has taken the world by storm. We watch GitHub Copilot, itself a GPT, help us write a GPT (meta :D!) . I recommend people watch the earlier makemore videos to get comfortable with the autoregressive language modeling framework and basics of tensors and PyTorch nn, which we take for granted in this video.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kCc8FmEb1nY&quot;&gt;YouTube video lecture&lt;/a&gt;. For all other links see the video description.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Lecture 8: Let&#39;s build the GPT Tokenizer&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The Tokenizer is a necessary and pervasive component of Large Language Models (LLMs), where it translates between strings and tokens (text chunks). Tokenizers are a completely separate stage of the LLM pipeline: they have their own training sets, training algorithms (Byte Pair Encoding), and after training implement two fundamental functions: encode() from strings to tokens, and decode() back from tokens to strings. In this lecture we build from scratch the Tokenizer used in the GPT series from OpenAI. In the process, we will see that a lot of weird behaviors and problems of LLMs actually trace back to tokenization. We&#39;ll go through a number of these issues, discuss why tokenization is at fault, and why someone out there ideally finds a way to delete this stage entirely.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=zduSFxRajkE&quot;&gt;YouTube video lecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/karpathy/minbpe&quot;&gt;minBPE code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://colab.research.google.com/drive/1y0KnCFZvGVf_odSfcNAws6kcDD7HsI0L?usp=sharing&quot;&gt;Google Colab&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;Ongoing...&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;License&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ed-donner/agents</title>
      <link>https://github.com/ed-donner/agents</link>
      <description>&lt;p&gt;Repo for the Complete Agentic AI Engineering Course&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Master AI Agentic Engineering - build autonomous AI Agents&lt;/h2&gt; 
&lt;h3&gt;6 week journey to code and deploy AI Agents with OpenAI Agents SDK, CrewAI, LangGraph, AutoGen and MCP&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/assets/autonomy.png&quot; alt=&quot;Autonomous Agent&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;If you&#39;re looking at this in Cursor, please right click on the filename in the Explorer on the left, and select &quot;Open preview&quot;, to view the formatted version.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I couldn&#39;t be more excited to welcome you! This is the start of your 6 week adventure into the powerful, astonishing and often surreal world of Agentic AI.&lt;/p&gt; 
&lt;h3&gt;Before you begin&lt;/h3&gt; 
&lt;p&gt;I&#39;m here to help you be most successful! Please do reach out if I can help, either in the platform or by emailing me direct (&lt;a href=&quot;mailto:ed@edwarddonner.com&quot;&gt;ed@edwarddonner.com&lt;/a&gt;). It&#39;s always great to connect with people on LinkedIn to build up the community - you&#39;ll find me here:&lt;br /&gt; &lt;a href=&quot;https://www.linkedin.com/in/eddonner/&quot;&gt;https://www.linkedin.com/in/eddonner/&lt;/a&gt;&lt;br /&gt; And this is new to me, but I&#39;m also trying out X/Twitter at &lt;a href=&quot;https://x.com/edwarddonner&quot;&gt;@edwarddonner&lt;/a&gt; - if you&#39;re on X, please show me how it&#39;s done ğŸ˜‚&lt;/p&gt; 
&lt;h3&gt;The not-so-dreaded setup instructions&lt;/h3&gt; 
&lt;p&gt;Perhaps famous last words: but I really, truly hope that I&#39;ve put together an environment that will be not too horrific to set up!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows people, your instructions are &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-PC.md&quot;&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Mac people, yours are &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-mac.md&quot;&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Linux people, yours are &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-linux.md&quot;&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any problems, please do contact me.&lt;/p&gt; 
&lt;h3&gt;Important notes for CrewAI week (Week 3)&lt;/h3&gt; 
&lt;p&gt;Windows PC users: you will need to have checked the &quot;gotcha #4&quot; at the top of the &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-PC.md&quot;&gt;SETUP-PC&lt;/a&gt; instructions -- installing Microsoft Build Tools.&lt;br /&gt; If you don&#39;t do this, then CrewAI will fail with an obscure error involving Chroma..&lt;/p&gt; 
&lt;p&gt;Then, you will need to run this command in a Cursor Terminal in the project root directory in order to run the Crew commands:&lt;br /&gt; &lt;code&gt;uv tool install crewai&lt;/code&gt;&lt;br /&gt; And in case you&#39;ve used Crew before, it might be worth doing this to make sure you have the latest:&lt;br /&gt; &lt;code&gt;uv tool upgrade crewai&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Then please keep in mind for Crew:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;There are two ways that you can work on the CrewAI project in week 3. Either review the code for each project while I build it, and then do &lt;code&gt;crewai run&lt;/code&gt; to see it in action. Or if you prefer to be more hands-on, then create your own Crew project from scratch to mirror mine; for example, create &lt;code&gt;my_debate&lt;/code&gt; to go alongside &lt;code&gt;debate&lt;/code&gt;, and write the code alongside me. Either approach works!&lt;/li&gt; 
 &lt;li&gt;Windows users: there&#39;s a new issue that was recently introduced by one of Crew&#39;s libraries. Until this is fixed, you might get a &quot;unicode&quot; error when you try to run &lt;code&gt;crewai create crew&lt;/code&gt;. If that happens, please try running this command in the Terminal first: &lt;code&gt;$env:PYTHONUTF8 = &quot;1&quot;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Gemini users: in addition to a key in your &lt;code&gt;.env&lt;/code&gt; file for &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;, you will need an identical key for &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Super useful resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The course &lt;a href=&quot;https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/&quot;&gt;resources&lt;/a&gt; with videos&lt;/li&gt; 
 &lt;li&gt;Many essential guides in the &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/guides/01_intro.ipynb&quot;&gt;guides&lt;/a&gt; section&lt;/li&gt; 
 &lt;li&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/setup/troubleshooting.ipynb&quot;&gt;troubleshooting&lt;/a&gt; notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API costs - please read me!&lt;/h3&gt; 
&lt;p&gt;This course does involve making calls to OpenAI and other frontier models, requiring an API key and a small spend, which we set up in the SETUP instructions. If you&#39;d prefer not to spend on API calls, there are cheaper alternatives like DeepSeek and free alternatives like using Ollama!&lt;/p&gt; 
&lt;p&gt;Details are &lt;a href=&quot;https://raw.githubusercontent.com/ed-donner/agents/main/guides/09_ai_apis_and_ollama.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Be sure to monitor your API costs to ensure you are totally happy with any spend. For OpenAI, the dashboard is &lt;a href=&quot;https://platform.openai.com/usage&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ABOVE ALL ELSE -&lt;/h3&gt; 
&lt;p&gt;Be sure to have fun with the course! You could not have picked a better time to be learning about Agentic AI. I hope you enjoy every single minute! And if you get stuck at any point - &lt;a href=&quot;https://www.linkedin.com/in/eddonner/&quot;&gt;contact me&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/openai-cookbook</title>
      <link>https://github.com/openai/openai-cookbook</link>
      <description>&lt;p&gt;Examples and guides for using the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;a href=&quot;https://cookbook.openai.com&quot; target=&quot;_blank&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/images/openai-cookbook-white.png&quot; style=&quot;max-width: 100%; width: 400px; margin-bottom: 20px&quot; /&gt; 
  &lt;img alt=&quot;OpenAI Cookbook Logo&quot; src=&quot;https://raw.githubusercontent.com/openai/openai-cookbook/main/images/openai-cookbook.png&quot; width=&quot;400px&quot; /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âœ¨ Navigate at &lt;a href=&quot;https://cookbook.openai.com&quot;&gt;cookbook.openai.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Example code and guides for accomplishing common tasks with the &lt;a href=&quot;https://platform.openai.com/docs/introduction&quot;&gt;OpenAI API&lt;/a&gt;. To run these examples, you&#39;ll need an OpenAI account and associated API key (&lt;a href=&quot;https://platform.openai.com/signup&quot;&gt;create a free account here&lt;/a&gt;). Set an environment variable called &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; with your API key. Alternatively, in most IDEs such as Visual Studio Code, you can create an &lt;code&gt;.env&lt;/code&gt; file at the root of your repo containing &lt;code&gt;OPENAI_API_KEY=&amp;lt;your API key&amp;gt;&lt;/code&gt;, which will be picked up by the notebooks.&lt;/p&gt; 
&lt;p&gt;Most code examples are written in Python, though the concepts can be applied in any language.&lt;/p&gt; 
&lt;p&gt;For other useful tools, guides and courses, check out these &lt;a href=&quot;https://cookbook.openai.com/related_resources&quot;&gt;related resources from around the web&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/OmniParser</title>
      <link>https://github.com/microsoft/OmniParser</link>
      <description>&lt;p&gt;A simple screen parsing tool towards pure vision based GUI agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/microsoft/OmniParser/master/imgs/logo.png&quot; alt=&quot;Logo&quot; /&gt; &lt;/p&gt; 
&lt;!-- &lt;a href=&quot;https://trendshift.io/repositories/12975&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12975&quot; alt=&quot;microsoft%2FOmniParser | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; --&gt; 
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Paper-green&quot; alt=&quot;arXiv&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ“¢ [&lt;a href=&quot;https://microsoft.github.io/OmniParser/&quot;&gt;Project Page&lt;/a&gt;] [&lt;a href=&quot;https://www.microsoft.com/en-us/research/articles/omniparser-v2-turning-any-llm-into-a-computer-use-agent/&quot;&gt;V2 Blog Post&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;Models V2&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Models V1.5&lt;/a&gt;] [&lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser-v2&quot;&gt;HuggingFace Space Demo&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OmniParser&lt;/strong&gt; is a comprehensive method for parsing user interface screenshots into structured and easy-to-understand elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface.&lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/3] We support local logging of trajecotry so that you can use OmniParser+OmniTool to build training data pipeline for your favorate agent in your domain. [Documentation WIP]&lt;/li&gt; 
 &lt;li&gt;[2025/3] We are gradually adding multi agents orchstration and improving user interface in OmniTool for better experience.&lt;/li&gt; 
 &lt;li&gt;[2025/2] We release OmniParser V2 &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser-v2.0&quot;&gt;checkpoints&lt;/a&gt;. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EWXbVESKWo9Buu6OYCwg06wBeoM97C6EOTG6RjvWLEN1Qg?e=alnHGC&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/2] We introduce OmniTool: Control a Windows 11 VM with OmniParser + your vision model of choice. OmniTool supports out of the box the following large language models - OpenAI (4o/o1/o3-mini), DeepSeek (R1), Qwen (2.5VL) or Anthropic Computer Use. &lt;a href=&quot;https://1drv.ms/v/c/650b027c18d5a573/EehZ7RzY69ZHn-MeQHrnnR4BCj3by-cLLpUVlxMjF4O65Q?e=8LxMgX&quot;&gt;Watch Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/1] V2 is coming. We achieve new state of the art results 39.5% on the new grounding benchmark &lt;a href=&quot;https://github.com/likaixin2000/ScreenSpot-Pro-GUI-Grounding/tree/main&quot;&gt;Screen Spot Pro&lt;/a&gt; with OmniParser v2 (will be released soon)! Read more details &lt;a href=&quot;https://github.com/microsoft/OmniParser/tree/master/docs/Evaluation.md&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2024/11] We release an updated version, OmniParser V1.5 which features 1) more fine grained/small icon detection, 2) prediction of whether each screen element is interactable or not. Examples in the demo.ipynb.&lt;/li&gt; 
 &lt;li&gt;[2024/10] OmniParser was the #1 trending model on huggingface model hub (starting 10/29/2024).&lt;/li&gt; 
 &lt;li&gt;[2024/10] Feel free to checkout our demo on &lt;a href=&quot;https://huggingface.co/spaces/microsoft/OmniParser&quot;&gt;huggingface space&lt;/a&gt;! (stay tuned for OmniParser + Claude Computer Use)&lt;/li&gt; 
 &lt;li&gt;[2024/10] Both Interactive Region Detection Model and Icon functional description model are released! &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;Hugginface models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2024/09] OmniParser achieves the best performance on &lt;a href=&quot;https://microsoft.github.io/WindowsAgentArena/&quot;&gt;Windows Agent Arena&lt;/a&gt;!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;First clone the repo, and then install environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;cd OmniParser
conda create -n &quot;omni&quot; python==3.12
conda activate omni
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you have the V2 weights downloaded in weights folder (ensure caption weights folder is called icon_caption_florence). If not download them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;   # download the model checkpoints to local directory OmniParser/weights/
   for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do huggingface-cli download microsoft/OmniParser-v2.0 &quot;$f&quot; --local-dir weights; done
   mv weights/icon_caption weights/icon_caption_florence
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- ## [deprecated]
Then download the model ckpts files in: https://huggingface.co/microsoft/OmniParser, and put them under weights/, default folder structure is: weights/icon_detect, weights/icon_caption_florence, weights/icon_caption_blip2. 

For v1: 
convert the safetensor to .pt file. 
```python
python weights/convert_safetensor_to_pt.py

For v1.5: 
download &#39;model_v1_5.pt&#39; from https://huggingface.co/microsoft/OmniParser/tree/main/icon_detect_v1_5, make a new dir: weights/icon_detect_v1_5, and put it inside the folder. No weight conversion is needed. 
``` --&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;We put together a few simple examples in the demo.ipynb.&lt;/p&gt; 
&lt;h2&gt;Gradio Demo&lt;/h2&gt; 
&lt;p&gt;To run gradio demo, simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;python gradio_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Weights License&lt;/h2&gt; 
&lt;p&gt;For the model checkpoints on huggingface model hub, please note that icon_detect model is under AGPL license since it is a license inherited from the original yolo model. And icon_caption_blip2 &amp;amp; icon_caption_florence is under MIT license. Please refer to the LICENSE file in the folder of each model: &lt;a href=&quot;https://huggingface.co/microsoft/OmniParser&quot;&gt;https://huggingface.co/microsoft/OmniParser&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Citation&lt;/h2&gt; 
&lt;p&gt;Our technical report can be found &lt;a href=&quot;https://arxiv.org/abs/2408.00203&quot;&gt;here&lt;/a&gt;. If you find our work useful, please consider citing our work:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{lu2024omniparserpurevisionbased,
      title={OmniParser for Pure Vision Based GUI Agent}, 
      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
      year={2024},
      eprint={2408.00203},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.00203}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>rasbt/LLMs-from-scratch</title>
      <link>https://github.com/rasbt/LLMs-from-scratch</link>
      <description>&lt;p&gt;Implement a ChatGPT-like LLM in PyTorch from scratch, step by step&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Build a Large Language Model (From Scratch)&lt;/h1&gt; 
&lt;p&gt;This repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book &lt;a href=&quot;https://amzn.to/4fqvn0D&quot;&gt;Build a Large Language Model (From Scratch)&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href=&quot;https://amzn.to/4fqvn0D&quot;&gt;&lt;img src=&quot;https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123&quot; width=&quot;250px&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;In &lt;a href=&quot;http://mng.bz/orYv&quot;&gt;&lt;em&gt;Build a Large Language Model (From Scratch)&lt;/em&gt;&lt;/a&gt;, you&#39;ll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I&#39;ll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.&lt;/p&gt; 
&lt;p&gt;The method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Link to the official &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch&quot;&gt;source code repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://mng.bz/orYv&quot;&gt;Link to the book at Manning (the publisher&#39;s website)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/gp/product/1633437167&quot;&gt;Link to the book page on Amazon.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ISBN 9781633437166&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;http://mng.bz/orYv#reviews&quot;&gt;&lt;img src=&quot;https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png&quot; width=&quot;220px&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;To download a copy of this repository, click on the &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip&quot;&gt;Download ZIP&lt;/a&gt; button or execute the following command in your terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch&quot;&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; for the latest updates.)&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;p&gt;Please note that this &lt;code&gt;README.md&lt;/code&gt; file is a Markdown (&lt;code&gt;.md&lt;/code&gt;) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven&#39;t installed a Markdown editor yet, &lt;a href=&quot;https://ghostwriter.kde.org&quot;&gt;Ghostwriter&lt;/a&gt; is a good free option.&lt;/p&gt; 
&lt;p&gt;You can alternatively view this and other files on GitHub at &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch&quot;&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; in your browser, which renders Markdown automatically.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip:&lt;/strong&gt; If you&#39;re seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md&quot;&gt;README.md&lt;/a&gt; file located in the &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup&quot;&gt;setup&lt;/a&gt; directory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml&quot;&gt;&lt;img src=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg?sanitize=true&quot; alt=&quot;Code tests Linux&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml&quot;&gt;&lt;img src=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg?sanitize=true&quot; alt=&quot;Code tests Windows&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml&quot;&gt;&lt;img src=&quot;https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg?sanitize=true&quot; alt=&quot;Code tests macOS&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chapter Title&lt;/th&gt; 
   &lt;th&gt;Main Code (for Quick Access)&lt;/th&gt; 
   &lt;th&gt;All Code + Supplementary&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup&quot;&gt;Setup recommendations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 1: Understanding Large Language Models&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 2: Working with Text Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/ch02.ipynb&quot;&gt;ch02.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/dataloader.ipynb&quot;&gt;dataloader.ipynb&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02&quot;&gt;./ch02&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 3: Coding Attention Mechanisms&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/ch03.ipynb&quot;&gt;ch03.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/multihead-attention.ipynb&quot;&gt;multihead-attention.ipynb&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03&quot;&gt;./ch03&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 4: Implementing a GPT Model from Scratch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/ch04.ipynb&quot;&gt;ch04.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/gpt.py&quot;&gt;gpt.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04&quot;&gt;./ch04&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 5: Pretraining on Unlabeled Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/ch05.ipynb&quot;&gt;ch05.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_train.py&quot;&gt;gpt_train.py&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_generate.py&quot;&gt;gpt_generate.py&lt;/a&gt; (summary) &lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05&quot;&gt;./ch05&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 6: Finetuning for Text Classification&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/ch06.ipynb&quot;&gt;ch06.ipynb&lt;/a&gt; &lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/gpt_class_finetune.py&quot;&gt;gpt_class_finetune.py&lt;/a&gt; &lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06&quot;&gt;./ch06&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 7: Finetuning to Follow Instructions&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ch07.ipynb&quot;&gt;ch07.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py&quot;&gt;gpt_instruction_finetuning.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ollama_evaluate.py&quot;&gt;ollama_evaluate.py&lt;/a&gt; (summary)&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07&quot;&gt;./ch07&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix A: Introduction to PyTorch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part1.ipynb&quot;&gt;code-part1.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part2.ipynb&quot;&gt;code-part2.ipynb&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/DDP-script.py&quot;&gt;DDP-script.py&lt;/a&gt;&lt;br /&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A&quot;&gt;./appendix-A&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix B: References and Further Reading&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix C: Exercise Solutions&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix D: Adding Bells and Whistles to the Training Loop&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D/01_main-chapter-code/appendix-D.ipynb&quot;&gt;appendix-D.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D&quot;&gt;./appendix-D&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix E: Parameter-efficient Finetuning with LoRA&lt;/td&gt; 
   &lt;td&gt;- &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E/01_main-chapter-code/appendix-E.ipynb&quot;&gt;appendix-E.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E&quot;&gt;./appendix-E&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;p&gt;The mental model below summarizes the contents covered in this book.&lt;/p&gt; 
&lt;img src=&quot;https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg&quot; width=&quot;650px&quot; /&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;The most important prerequisite is a strong foundation in Python programming. With this knowledge, you will be well prepared to explore the fascinating world of LLMs and understand the concepts and code examples presented in this book.&lt;/p&gt; 
&lt;p&gt;If you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.&lt;/p&gt; 
&lt;p&gt;This book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, &lt;a href=&quot;https://sebastianraschka.com/teaching/pytorch-1h/&quot;&gt;PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs&lt;/a&gt;, helpful for learning about the essentials.&lt;/p&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;p&gt;The code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/raw/main/setup/README.md&quot;&gt;setup&lt;/a&gt; doc for additional recommendations.)&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Video Course&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.manning.com/livevideo/master-and-build-large-language-models&quot;&gt;A 17-hour and 15-minute companion video course&lt;/a&gt; where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book&#39;s structure so that it can be used as a standalone alternative to the book or complementary code-along resource.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.manning.com/livevideo/master-and-build-large-language-models&quot;&gt;&lt;img src=&quot;https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123&quot; width=&quot;350px&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Exercises&lt;/h2&gt; 
&lt;p&gt;Each chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example, &lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb&quot;&gt;./ch02/01_main-chapter-code/exercise-solutions.ipynb&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to the code exercises, you can download a free 170-page PDF titled &lt;a href=&quot;https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch&quot;&gt;Test Yourself On Build a Large Language Model (From Scratch)&lt;/a&gt; from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch&quot;&gt;&lt;img src=&quot;https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123&quot; width=&quot;150px&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Bonus Material&lt;/h2&gt; 
&lt;p&gt;Several folders contain optional materials as a bonus for interested readers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Setup&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/01_optional-python-setup-preferences&quot;&gt;Python Setup Tips&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/02_installing-python-libraries&quot;&gt;Installing Python Packages and Libraries Used In This Book&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/03_optional-docker-environment&quot;&gt;Docker Environment Setup Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 2: Working with text data&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb&quot;&gt;Byte Pair Encoding (BPE) Tokenizer From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/02_bonus_bytepair-encoder&quot;&gt;Comparing Various Byte Pair Encoding (BPE) Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/03_bonus_embedding-vs-matmul&quot;&gt;Understanding the Difference Between Embedding Layers and Linear Layers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/04_bonus_dataloader-intuition&quot;&gt;Dataloader Intuition with Simple Numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 3: Coding attention mechanisms&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb&quot;&gt;Comparing Efficient Multi-Head Attention Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/03_understanding-buffers/understanding-buffers.ipynb&quot;&gt;Understanding PyTorch Buffers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 4: Implementing a GPT model from scratch&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/02_performance-analysis/flops-analysis.ipynb&quot;&gt;FLOPS Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/03_kv-cache&quot;&gt;KV Cache&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 5: Pretraining on unlabeled data:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/02_alternative_weight_loading/&quot;&gt;Alternative Weight Loading Methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/03_bonus_pretraining_on_gutenberg&quot;&gt;Pretraining GPT on the Project Gutenberg Dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/04_learning_rate_schedulers&quot;&gt;Adding Bells and Whistles to the Training Loop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/05_bonus_hparam_tuning&quot;&gt;Optimizing Hyperparameters for Pretraining&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/06_user_interface&quot;&gt;Building a User Interface to Interact With the Pretrained LLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama&quot;&gt;Converting GPT to Llama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama/standalone-llama32.ipynb&quot;&gt;Llama 3.2 From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/11_qwen3/&quot;&gt;Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb&quot;&gt;Memory-efficient Model Weight Loading&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/09_extending-tokenizers/extend-tiktoken.ipynb&quot;&gt;Extending the Tiktoken BPE Tokenizer with New Tokens&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/10_llm-training-speed&quot;&gt;PyTorch Performance Tips for Faster LLM Training&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 6: Finetuning for classification&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/02_bonus_additional-experiments&quot;&gt;Additional experiments finetuning different layers and using larger models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/03_bonus_imdb-classification&quot;&gt;Finetuning different models on 50k IMDB movie review dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/04_user_interface&quot;&gt;Building a User Interface to Interact With the GPT-based Spam Classifier&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 7: Finetuning to follow instructions&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/02_dataset-utilities&quot;&gt;Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/03_model-evaluation&quot;&gt;Evaluating Instruction Responses Using the OpenAI API and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/llama3-ollama.ipynb&quot;&gt;Generating a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/reflection-gpt4.ipynb&quot;&gt;Improving a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb&quot;&gt;Generating a Preference Dataset with Llama 3.1 70B and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb&quot;&gt;Direct Preference Optimization (DPO) for LLM Alignment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/06_user_interface&quot;&gt;Building a User Interface to Interact With the Instruction Finetuned GPT Model&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; &amp;nbsp; 
&lt;h2&gt;Questions, Feedback, and Contributing to This Repository&lt;/h2&gt; 
&lt;p&gt;I welcome all sorts of feedback, best shared via the &lt;a href=&quot;https://livebook.manning.com/forum?product=raschka&amp;amp;page=1&quot;&gt;Manning Forum&lt;/a&gt; or &lt;a href=&quot;https://github.com/rasbt/LLMs-from-scratch/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;. Likewise, if you have any questions or just want to bounce ideas off others, please don&#39;t hesitate to post these in the forum as well.&lt;/p&gt; 
&lt;p&gt;Please note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this book or code useful for your research, please consider citing it.&lt;/p&gt; 
&lt;p&gt;Chicago-style citation:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Raschka, Sebastian. &lt;em&gt;Build A Large Language Model (From Scratch)&lt;/em&gt;. Manning, 2024. ISBN: 978-1633437166.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;BibTeX entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>imanoop7/Ollama-OCR</title>
      <link>https://github.com/imanoop7/Ollama-OCR</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/imanoop7/Ollama-OCR&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/imanoop7/Ollama-OCR.svg?style=social&amp;amp;label=Star&quot; alt=&quot;Stargazers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/imanoop7/Ollama-OCR/graphs/commit-activity&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/commit-activity/m/imanoop7/Ollama-OCR.svg?sanitize=true&quot; alt=&quot;Commit Activity&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/imanoop7/Ollama-OCR&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/imanoop7/Ollama-OCR.svg?sanitize=true&quot; alt=&quot;Last Commit&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/logo_file.jpg&quot; alt=&quot;Ollama OCR Logo&quot; /&gt;&lt;/p&gt; 
&lt;h1 align=&quot;center&quot;&gt;Ollama OCR&lt;/h1&gt; 
&lt;p&gt;A powerful OCR (Optical Character Recognition) package that uses state-of-the-art vision language models through Ollama to extract text from images and PDF. Available both as a Python package and a Streamlit web application.&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Features&lt;/h2&gt; 
&lt;h3&gt;Supports PDF and Images (New! ğŸ†•)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple Vision Models Support&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://ollama.com/library/llava&quot;&gt;LLaVA&lt;/a&gt;: Efficient vision-language model for real-time processing (LLaVa model can generate wrong output sometimes)&lt;/li&gt; 
   &lt;li&gt;Llama 3.2 Vision: Advanced model with high accuracy for complex documents&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://ollama.com/library/granite3.2-vision&quot;&gt;Granite3.2-vision&lt;/a&gt;: A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://ollama.com/library/moondream&quot;&gt;Moondream&lt;/a&gt;: Small vision language model designed to run efficiently on edge devices.&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://ollama.com/library/minicpm-v&quot;&gt;Minicpm-v&lt;/a&gt;: MiniCPM-V 2.6 can process images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple Output Formats&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Markdown: Preserves text formatting with headers and lists&lt;/li&gt; 
   &lt;li&gt;Plain Text: Clean, simple text extraction&lt;/li&gt; 
   &lt;li&gt;JSON: Structured data format&lt;/li&gt; 
   &lt;li&gt;Structured: Tables and organized data&lt;/li&gt; 
   &lt;li&gt;Key-Value Pairs: Extracts labeled information&lt;/li&gt; 
   &lt;li&gt;Table: Extract all tabular data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Batch Processing&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Process multiple images in parallel&lt;/li&gt; 
   &lt;li&gt;Progress tracking for each image&lt;/li&gt; 
   &lt;li&gt;Image preprocessing (resize, normalize, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Custom Prompts&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Override default prompts with custom instructions for text extraction.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Package Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install ollama-ocr
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Ollama&lt;/li&gt; 
 &lt;li&gt;Pull the required model:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ollama pull llama3.2-vision:11b
ollama pull granite3.2-vision
ollama pull moondream
ollama pull minicpm-v
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using the Package&lt;/h2&gt; 
&lt;h3&gt;Single File Processing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from ollama_ocr import OCRProcessor

# Initialize OCR processor
ocr = OCRProcessor(model_name=&#39;llama3.2-vision:11b&#39;, base_url=&quot;http://host.docker.internal:11434/api/generate&quot;)  # You can use any vision model available on Ollama
# you can pass your custom ollama api

# Process an image
result = ocr.process_image(
    image_path=&quot;path/to/your/image.png&quot;, # path to your pdf files &quot;path/to/your/file.pdf&quot;
    format_type=&quot;markdown&quot;,  # Options: markdown, text, json, structured, key_value
    custom_prompt=&quot;Extract all text, focusing on dates and names.&quot;, # Optional custom prompt
    language=&quot;English&quot; # Specify the language of the text (New! ğŸ†•)
)
print(result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Batch File&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from ollama_ocr import OCRProcessor

# Initialize OCR processor
ocr = OCRProcessor(model_name=&#39;llama3.2-vision:11b&#39;, max_workers=4)  # max workers for parallel processing

# Process multiple images
# Process multiple images with progress tracking
batch_results = ocr.process_batch(
    input_path=&quot;path/to/images/folder&quot;,  # Directory or list of image paths
    format_type=&quot;markdown&quot;,
    recursive=True,  # Search subdirectories
    preprocess=True,  # Enable image preprocessing
    custom_prompt=&quot;Extract all text, focusing on dates and names.&quot;, # Optional custom prompt
    language=&quot;English&quot; # Specify the language of the text (New! ğŸ†•)
)
# Access results
for file_path, text in batch_results[&#39;results&#39;].items():
    print(f&quot;\nFile: {file_path}&quot;)
    print(f&quot;Extracted Text: {text}&quot;)

# View statistics
print(&quot;\nProcessing Statistics:&quot;)
print(f&quot;Total images: {batch_results[&#39;statistics&#39;][&#39;total&#39;]}&quot;)
print(f&quot;Successfully processed: {batch_results[&#39;statistics&#39;][&#39;successful&#39;]}&quot;)
print(f&quot;Failed: {batch_results[&#39;statistics&#39;][&#39;failed&#39;]}&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“‹ Output Format Details&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Markdown Format&lt;/strong&gt;: The output is a markdown string containing the extracted text from the image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Format&lt;/strong&gt;: The output is a plain text string containing the extracted text from the image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON Format&lt;/strong&gt;: The output is a JSON object containing the extracted text from the image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Format&lt;/strong&gt;: The output is a structured object containing the extracted text from the image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Key-Value Format&lt;/strong&gt;: The output is a dictionary containing the extracted text from the image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table Format&lt;/strong&gt;: Extract all tabular data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸŒ Streamlit Web Application(supports batch processing)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly Interface&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Drag-and-drop file upload&lt;/li&gt; 
   &lt;li&gt;Real-time processing&lt;/li&gt; 
   &lt;li&gt;Download extracted text&lt;/li&gt; 
   &lt;li&gt;Image preview with details&lt;/li&gt; 
   &lt;li&gt;Responsive design&lt;/li&gt; 
   &lt;li&gt;Language Selection: Specify the language for better OCR accuracy. (New! ğŸ†•)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/imanoop7/Ollama-OCR.git
cd Ollama-OCR
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Go to the directory where app.py is located:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd src/ollama_ocr      
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Run the Streamlit app:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;streamlit run app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“’ Example Notebooks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/example_notebooks%5Collama_ocr_on_colab.ipynb&quot;&gt;Ollama OCR on Colab&lt;/a&gt;: How to use Ollama-OCR on Google Colab.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/example_notebooks%5Cexample.ipynb&quot;&gt;Example Notebook&lt;/a&gt;: Example usage of Ollama OCR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/example_notebooks%5Collama-ocr-with-autogen.ipynb&quot;&gt;Ollama OCR with Autogen&lt;/a&gt;: Use Ollama-OCR with autogen.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/example_notebooks%5Collama-ocr-with-langgraph.ipynb&quot;&gt;Ollama OCR with LangGraph&lt;/a&gt;: Use Ollama-OCR with LangGraph.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples Output&lt;/h2&gt; 
&lt;h3&gt;Input Image&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/input/img.png&quot; alt=&quot;Input Image&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Sample Output&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/output/image.png&quot; alt=&quot;Sample Output&quot; /&gt; &lt;img src=&quot;https://raw.githubusercontent.com/imanoop7/Ollama-OCR/main/output/markdown.png&quot; alt=&quot;Sample Output&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Built with Ollama Powered by Vision Models&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href=&quot;https://www.star-history.com/#imanoop7/Ollama-OCR&amp;amp;Date&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=imanoop7/Ollama-OCR&amp;amp;type=Date&amp;amp;theme=dark&quot; /&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=imanoop7/Ollama-OCR&amp;amp;type=Date&quot; /&gt; 
  &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=imanoop7/Ollama-OCR&amp;amp;type=Date&quot; /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>mrdbourke/pytorch-deep-learning</title>
      <link>https://github.com/mrdbourke/pytorch-deep-learning</link>
      <description>&lt;p&gt;Materials for the Learn PyTorch for Deep Learning: Zero to Mastery course.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Learn PyTorch for Deep Learning&lt;/h1&gt; 
&lt;p&gt;Welcome to the &lt;a href=&quot;https://dbourke.link/ZTMPyTorch&quot;&gt;Zero to Mastery Learn PyTorch for Deep Learning course&lt;/a&gt;, the second best place to learn PyTorch on the internet (the first being the &lt;a href=&quot;https://pytorch.org/docs/stable/index.html&quot;&gt;PyTorch documentation&lt;/a&gt;).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Update April 2023:&lt;/strong&gt; New &lt;a href=&quot;https://www.learnpytorch.io/pytorch_2_intro/&quot;&gt;tutorial for PyTorch 2.0&lt;/a&gt; is live! And because PyTorch 2.0 is an additive (new features) and backward-compatible release, all previous course materials will &lt;em&gt;still&lt;/em&gt; work with PyTorch 2.0.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://learnpytorch.io&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/misc-pytorch-course-launch-cover-white-text-black-background.jpg&quot; width=&quot;750&quot; alt=&quot;pytorch deep learning by zero to mastery cover photo with different sections of the course&quot; /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Contents of this page&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning#course-materialsoutline&quot;&gt;Course materials/outline&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning#about-this-course&quot;&gt;About this course&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning#status&quot;&gt;Status&lt;/a&gt; (the progress of the course creation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning#log&quot;&gt;Log&lt;/a&gt; (a log of the course material creation process)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Course materials/outline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Online book version:&lt;/strong&gt; All of course materials are available in a readable online book at &lt;a href=&quot;https://learnpytorch.io&quot;&gt;learnpytorch.io&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ğŸ¥ &lt;strong&gt;First five sections on YouTube:&lt;/strong&gt; Learn Pytorch in a day by watching the &lt;a href=&quot;https://youtu.be/Z_ikDlimN6A&quot;&gt;first 25-hours of material&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ğŸ”¬ &lt;strong&gt;Course focus:&lt;/strong&gt; code, code, code, experiment, experiment, experiment.&lt;/li&gt; 
 &lt;li&gt;ğŸƒâ€â™‚ï¸ &lt;strong&gt;Teaching style:&lt;/strong&gt; &lt;a href=&quot;https://sive.rs/kimo&quot;&gt;https://sive.rs/kimo&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ğŸ¤” &lt;strong&gt;Ask a question:&lt;/strong&gt; See the &lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/discussions&quot;&gt;GitHub Discussions page&lt;/a&gt; for existing questions/ask your own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Section&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;What does it cover?&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Exercises &amp;amp; Extra-curriculum&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Slides&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/00_pytorch_fundamentals/&quot;&gt;00 - PyTorch Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Many fundamental PyTorch operations used for deep learning and neural networks.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/01_pytorch_workflow/&quot;&gt;01 - PyTorch Workflow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Provides an outline for approaching deep learning problems and building neural networks with PyTorch.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/01_pytorch_workflow/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/01_pytorch_workflow.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/02_pytorch_classification/&quot;&gt;02 - PyTorch Neural Network Classification&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Uses the PyTorch workflow from 01 to go through a neural network classification problem.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/02_pytorch_classification/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/02_pytorch_classification.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/03_pytorch_computer_vision/&quot;&gt;03 - PyTorch Computer Vision&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Let&#39;s see how PyTorch can be used for computer vision problems using the same workflow from 01 &amp;amp; 02.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/03_pytorch_computer_vision/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/03_pytorch_computer_vision.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/04_pytorch_custom_datasets/&quot;&gt;04 - PyTorch Custom Datasets&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;How do you load a custom dataset into PyTorch? Also we&#39;ll be laying the foundations in this notebook for our modular code (covered in 05).&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/04_pytorch_custom_datasets/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/04_pytorch_custom_datasets.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/05_pytorch_going_modular/&quot;&gt;05 - PyTorch Going Modular&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;PyTorch is designed to be modular, let&#39;s turn what we&#39;ve created into a series of Python scripts (this is how you&#39;ll often find PyTorch code in the wild).&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/05_pytorch_going_modular/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/05_pytorch_going_modular.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/06_pytorch_transfer_learning/&quot;&gt;06 - PyTorch Transfer Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Let&#39;s take a well performing pre-trained model and adjust it to one of our own problems.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/06_pytorch_transfer_learning/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/06_pytorch_transfer_learning.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/07_pytorch_experiment_tracking/&quot;&gt;07 - Milestone Project 1: PyTorch Experiment Tracking&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;We&#39;ve built a bunch of models... wouldn&#39;t it be good to track how they&#39;re all going?&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/07_pytorch_experiment_tracking/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/07_pytorch_experiment_tracking.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/08_pytorch_paper_replicating/&quot;&gt;08 - Milestone Project 2: PyTorch Paper Replicating&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;PyTorch is the most popular deep learning framework for machine learning research, let&#39;s see why by replicating a machine learning paper.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/08_pytorch_paper_replicating/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/08_pytorch_paper_replicating.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/09_pytorch_model_deployment/&quot;&gt;09 - Milestone Project 3: Model Deployment&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;So we&#39;ve built a working PyTorch model... how do we get it in the hands of others? Hint: deploy it to the internet.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/09_pytorch_model_deployment/#exercises&quot;&gt;Go to exercises &amp;amp; extra-curriculum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/slides/09_pytorch_model_deployment.pdf&quot;&gt;Go to slides&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/pytorch_extra_resources/&quot;&gt;PyTorch Extra Resources&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;This course covers a large amount of PyTorch and deep learning but the field of machine learning is vast, inside here you&#39;ll find recommended books and resources for: PyTorch and deep learning, ML engineering, NLP (natural language processing), time series data, where to find datasets and more.&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/pytorch_cheatsheet/&quot;&gt;PyTorch Cheatsheet&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A very quick overview of some of the main features of PyTorch plus links to various resources where more can be found in the course and in the PyTorch documentation.&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.learnpytorch.io/pytorch_2_intro/&quot;&gt;A Quick PyTorch 2.0 Tutorial&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A fasssssst introduction to PyTorch 2.0, what&#39;s new and how to get started along with resources to learn more.&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;All materials completed and videos published on Zero to Mastery!&lt;/p&gt; 
&lt;p&gt;See the project page for work-in-progress board - &lt;a href=&quot;https://github.com/users/mrdbourke/projects/1&quot;&gt;https://github.com/users/mrdbourke/projects/1&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total video count:&lt;/strong&gt; 321&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Done skeleton code for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08, 09&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Done annotations (text) for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08, 09&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Done images for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08, 09&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Done keynotes for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08, 09&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Done exercises and solutions for:&lt;/strong&gt; 00, 01, 02, 03, 04, 05, 06, 07, 08, 09&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning#log&quot;&gt;log&lt;/a&gt; for almost daily updates.&lt;/p&gt; 
&lt;h2&gt;About this course&lt;/h2&gt; 
&lt;h3&gt;Who is this course for?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;You:&lt;/strong&gt; Are a beginner in the field of machine learning or deep learning and would like to learn PyTorch.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This course:&lt;/strong&gt; Teaches you PyTorch and many machine learning concepts in a hands-on, code-first way.&lt;/p&gt; 
&lt;p&gt;If you already have 1-year+ experience in machine learning, this course may help but it is specifically designed to be beginner-friendly.&lt;/p&gt; 
&lt;h3&gt;What are the prerequisites?&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;3-6 months coding Python.&lt;/li&gt; 
 &lt;li&gt;At least one beginner machine learning course (however this might be able to be skipped, resources are linked for many different topics).&lt;/li&gt; 
 &lt;li&gt;Experience using Jupyter Notebooks or Google Colab (though you can pick this up as we go along).&lt;/li&gt; 
 &lt;li&gt;A willingness to learn (most important).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For 1 &amp;amp; 2, I&#39;d recommend the &lt;a href=&quot;https://dbourke.link/ZTMMLcourse&quot;&gt;Zero to Mastery Data Science and Machine Learning Bootcamp&lt;/a&gt;, it&#39;ll teach you the fundamentals of machine learning and Python (I&#39;m biased though, I also teach that course).&lt;/p&gt; 
&lt;h3&gt;How is the course taught?&lt;/h3&gt; 
&lt;p&gt;All of the course materials are available for free in an online book at &lt;a href=&quot;https://learnpytorch.io&quot;&gt;learnpytorch.io&lt;/a&gt;. If you like to read, I&#39;d recommend going through the resources there.&lt;/p&gt; 
&lt;p&gt;If you prefer to learn via video, the course is also taught in apprenticeship-style format, meaning I write PyTorch code, you write PyTorch code.&lt;/p&gt; 
&lt;p&gt;There&#39;s a reason the course motto&#39;s include &lt;em&gt;if in doubt, run the code&lt;/em&gt; and &lt;em&gt;experiment, experiment, experiment!&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;My whole goal is to help you to do one thing: learn machine learning by writing PyTorch code.&lt;/p&gt; 
&lt;p&gt;The code is all written via &lt;a href=&quot;https://colab.research.google.com&quot;&gt;Google Colab Notebooks&lt;/a&gt; (you could also use Jupyter Notebooks), an incredible free resource to experiment with machine learning.&lt;/p&gt; 
&lt;h3&gt;What will I get if I finish the course?&lt;/h3&gt; 
&lt;p&gt;There&#39;s certificates and all that jazz if you go through the videos.&lt;/p&gt; 
&lt;p&gt;But certificates are meh.&lt;/p&gt; 
&lt;p&gt;You can consider this course a machine learning momentum builder.&lt;/p&gt; 
&lt;p&gt;By the end, you&#39;ll have written hundreds of lines of PyTorch code.&lt;/p&gt; 
&lt;p&gt;And will have been exposed to many of the most important concepts in machine learning.&lt;/p&gt; 
&lt;p&gt;So when you go to build your own machine learning projects or inspect a public machine learning project made with PyTorch, it&#39;ll feel familiar and if it doesn&#39;t, at least you&#39;ll know where to look.&lt;/p&gt; 
&lt;h3&gt;What will I build in the course?&lt;/h3&gt; 
&lt;p&gt;We start with the barebone fundamentals of PyTorch and machine learning, so even if you&#39;re new to machine learning you&#39;ll be caught up to speed.&lt;/p&gt; 
&lt;p&gt;Then weâ€™ll explore more advanced areas including PyTorch neural network classification, PyTorch workflows, computer vision, custom datasets, experiment tracking, model deployment, and my personal favourite: transfer learning, a powerful technique for taking what one machine learning model has learned on another problem and applying it to your own!&lt;/p&gt; 
&lt;p&gt;Along the way, youâ€™ll build three milestone projects surrounding an overarching project called FoodVision, a neural network computer vision model to classify images of food.&lt;/p&gt; 
&lt;p&gt;These milestone projects will help you practice using PyTorch to cover important machine learning concepts and create a portfolio you can show employers and say &quot;here&#39;s what I&#39;ve done&quot;.&lt;/p&gt; 
&lt;h3&gt;How do I get started?&lt;/h3&gt; 
&lt;p&gt;You can read the materials on any device but this course is best viewed and coded along within a desktop browser.&lt;/p&gt; 
&lt;p&gt;The course uses a free tool called Google Colab. If you&#39;ve got no experience with it, I&#39;d go through the free &lt;a href=&quot;https://colab.research.google.com/notebooks/basic_features_overview.ipynb&quot;&gt;Introduction to Google Colab tutorial&lt;/a&gt; and then come back here.&lt;/p&gt; 
&lt;p&gt;To start:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Click on one of the notebook or section links above like &quot;&lt;a href=&quot;https://www.learnpytorch.io/00_pytorch_fundamentals/&quot;&gt;00. PyTorch Fundamentals&lt;/a&gt;&quot;.&lt;/li&gt; 
 &lt;li&gt;Click the &quot;Open in Colab&quot; button up the top.&lt;/li&gt; 
 &lt;li&gt;Press SHIFT+Enter a few times and see what happens.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;My question isn&#39;t answered&lt;/h3&gt; 
&lt;p&gt;Please leave a &lt;a href=&quot;https://github.com/mrdbourke/pytorch-deep-learning/discussions&quot;&gt;discussion&lt;/a&gt; or send me an email directly: daniel (at) mrdbourke (dot) com.&lt;/p&gt; 
&lt;h2&gt;Log&lt;/h2&gt; 
&lt;p&gt;Almost daily updates of what&#39;s happening.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;15 May 2023 - PyTorch 2.0 tutorial finished + videos added to ZTM/Udemy, see code: &lt;a href=&quot;https://www.learnpytorch.io/pytorch_2_intro/&quot;&gt;https://www.learnpytorch.io/pytorch_2_intro/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;13 Apr 2023 - update PyTorch 2.0 notebook&lt;/li&gt; 
 &lt;li&gt;30 Mar 2023 - update PyTorch 2.0 notebook with more info/clean code&lt;/li&gt; 
 &lt;li&gt;23 Mar 2023 - upgrade PyTorch 2.0 tutorial with annotations and images&lt;/li&gt; 
 &lt;li&gt;13 Mar 2023 - add starter code for PyTorch 2.0 tutorial&lt;/li&gt; 
 &lt;li&gt;18 Nov 2022 - add a reference for 3 most common errors in PyTorch + links to course sections for more: &lt;a href=&quot;https://www.learnpytorch.io/pytorch_most_common_errors/&quot;&gt;https://www.learnpytorch.io/pytorch_most_common_errors/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;9 Nov 2022 - add PyTorch cheatsheet for a very quick overview of the main features of PyTorch + links to course sections: &lt;a href=&quot;https://www.learnpytorch.io/pytorch_cheatsheet/&quot;&gt;https://www.learnpytorch.io/pytorch_cheatsheet/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;9 Nov 2022 - full course materials (300+ videos) are now live on Udemy! You can sign up here: &lt;a href=&quot;https://www.udemy.com/course/pytorch-for-deep-learning/?couponCode=ZTMGOODIES7&quot;&gt;https://www.udemy.com/course/pytorch-for-deep-learning/?couponCode=ZTMGOODIES7&lt;/a&gt; (launch deal code valid for 3-4 days from this line)&lt;/li&gt; 
 &lt;li&gt;4 Nov 2022 - add a notebook for PyTorch Cheatsheet in &lt;code&gt;extras/&lt;/code&gt; (a simple overview of many of the most important functionality of PyTorch)&lt;/li&gt; 
 &lt;li&gt;2 Oct 2022 - all videos for section 08 and 09 published (100+ videos for the last two sections)!&lt;/li&gt; 
 &lt;li&gt;30 Aug 2022 - recorded 15 videos for 09, total videos: 321, finished section 09 videos!!!! ... even bigger than 08!!&lt;/li&gt; 
 &lt;li&gt;29 Aug 2022 - recorded 16 videos for 09, total videos: 306&lt;/li&gt; 
 &lt;li&gt;28 Aug 2022 - recorded 11 videos for 09, total videos: 290&lt;/li&gt; 
 &lt;li&gt;27 Aug 2022 - recorded 16 videos for 09, total videos: 279&lt;/li&gt; 
 &lt;li&gt;26 Aug 2022 - add finishing touchs to notebook 09, add slides for 09, create solutions and exercises for 09&lt;/li&gt; 
 &lt;li&gt;25 Aug 2022 - add annotations and cleanup 09, remove TK&#39;s, cleanup images, make slides for 09&lt;/li&gt; 
 &lt;li&gt;24 Aug 2022 - add annotations to 09, main takeaways, exercises and extra-curriculum done&lt;/li&gt; 
 &lt;li&gt;23 Aug 2022 - add annotations to 09, add plenty of images/slides&lt;/li&gt; 
 &lt;li&gt;22 Aug 2022 - add annotations to 09, start working on slides/images&lt;/li&gt; 
 &lt;li&gt;20 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;19 Aug 2022 - add annotations to 09, check out the awesome demos!&lt;/li&gt; 
 &lt;li&gt;18 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;17 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;16 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;15 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;13 Aug 2022 - add annotations to 09&lt;/li&gt; 
 &lt;li&gt;12 Aug 2022 - add demo files for notebook 09 to &lt;code&gt;demos/&lt;/code&gt;, start annotating notebook 09 with explainer text&lt;/li&gt; 
 &lt;li&gt;11 Aug 2022 - finish skeleton code for notebook 09, course finishes deploying 2x models, one for FoodVision Mini &amp;amp; one for (secret)&lt;/li&gt; 
 &lt;li&gt;10 Aug 2022 - add section for PyTorch Extra Resources (places to learn more about PyTorch/deep learning): &lt;a href=&quot;https://www.learnpytorch.io/pytorch_extra_resources/&quot;&gt;https://www.learnpytorch.io/pytorch_extra_resources/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;09 Aug 2022 - add more skeleton code to notebook 09&lt;/li&gt; 
 &lt;li&gt;08 Aug 2022 - create draft notebook for 09, end goal to deploy FoodVision Mini model and make it publically accessible&lt;/li&gt; 
 &lt;li&gt;05 Aug 2022 - recorded 11 videos for 08, total videos: 263, section 08 videos finished!... the biggest section so far&lt;/li&gt; 
 &lt;li&gt;04 Aug 2022 - recorded 13 videos for 08, total videos: 252&lt;/li&gt; 
 &lt;li&gt;03 Aug 2022 - recorded 3 videos for 08, total videos: 239&lt;/li&gt; 
 &lt;li&gt;02 Aug 2022 - recorded 12 videos for 08, total videos: 236&lt;/li&gt; 
 &lt;li&gt;30 July 2022 - recorded 11 videos for 08, total videos: 224&lt;/li&gt; 
 &lt;li&gt;29 July 2022 - add exercises + solutions for 08, see live walkthrough on YouTube: &lt;a href=&quot;https://youtu.be/tjpW_BY8y3g&quot;&gt;https://youtu.be/tjpW_BY8y3g&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;28 July 2022 - add slides for 08&lt;/li&gt; 
 &lt;li&gt;27 July 2022 - cleanup much of 08, start on slides for 08, exercises and extra-curriculum next&lt;/li&gt; 
 &lt;li&gt;26 July 2022 - add annotations and images for 08&lt;/li&gt; 
 &lt;li&gt;25 July 2022 - add annotations for 08&lt;/li&gt; 
 &lt;li&gt;24 July 2022 - launched first half of course (notebooks 00-04) in a single video (25+ hours!!!) on YouTube: &lt;a href=&quot;https://youtu.be/Z_ikDlimN6A&quot;&gt;https://youtu.be/Z_ikDlimN6A&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;21 July 2022 - add annotations and images for 08&lt;/li&gt; 
 &lt;li&gt;20 July 2022 - add annotations and images for 08, getting so close! this is an epic section&lt;/li&gt; 
 &lt;li&gt;19 July 2022 - add annotations and images for 08&lt;/li&gt; 
 &lt;li&gt;15 July 2022 - add annotations and images for 08&lt;/li&gt; 
 &lt;li&gt;14 July 2022 - add annotations for 08&lt;/li&gt; 
 &lt;li&gt;12 July 2022 - add annotations for 08, woo woo this is bigggg section!&lt;/li&gt; 
 &lt;li&gt;11 July 2022 - add annotations for 08&lt;/li&gt; 
 &lt;li&gt;9 July 2022 - add annotations for 08&lt;/li&gt; 
 &lt;li&gt;8 July 2022 - add a bunch of annotations to 08&lt;/li&gt; 
 &lt;li&gt;6 July 2022 - course launched on ZTM Academy with videos for sections 00-07! ğŸš€ - &lt;a href=&quot;https://dbourke.link/ZTMPyTorch&quot;&gt;https://dbourke.link/ZTMPyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;1 July 2022 - add annotations and images for 08&lt;/li&gt; 
 &lt;li&gt;30 June 2022 - add annotations for 08&lt;/li&gt; 
 &lt;li&gt;28 June 2022 - recorded 11 videos for section 07, total video count 213, all videos for section 07 complete!&lt;/li&gt; 
 &lt;li&gt;27 June 2022 - recorded 11 videos for section 07, total video count 202&lt;/li&gt; 
 &lt;li&gt;25 June 2022 - recreated 7 videos for section 06 to include updated APIs, total video count 191&lt;/li&gt; 
 &lt;li&gt;24 June 2022 - recreated 12 videos for section 06 to include updated APIs&lt;/li&gt; 
 &lt;li&gt;23 June 2022 - finish annotations for 07, add exercise template and solutions for 07 + video walkthrough on YouTube: &lt;a href=&quot;https://youtu.be/cO_r2FYcAjU&quot;&gt;https://youtu.be/cO_r2FYcAjU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;21 June 2022 - make 08 runnable end-to-end, add images and annotations for 07&lt;/li&gt; 
 &lt;li&gt;17 June 2022 - fix up 06, 07 v2 for upcoming torchvision version upgrade, add plenty of annotations to 08&lt;/li&gt; 
 &lt;li&gt;13 June 2022 - add notebook 08 first version, starting to replicate the Vision Transformer paper&lt;/li&gt; 
 &lt;li&gt;10 June 2022 - add annotations for 07 v2&lt;/li&gt; 
 &lt;li&gt;09 June 2022 - create 07 v2 for &lt;code&gt;torchvision&lt;/code&gt; v0.13 (this will replace 07 v1 when &lt;code&gt;torchvision=0.13&lt;/code&gt; is released)&lt;/li&gt; 
 &lt;li&gt;08 June 2022 - adapt 06 v2 for &lt;code&gt;torchvision&lt;/code&gt; v0.13 (this will replace 06 v1 when &lt;code&gt;torchvision=0.13&lt;/code&gt; is released)&lt;/li&gt; 
 &lt;li&gt;07 June 2022 - create notebook 06 v2 for upcoming &lt;code&gt;torchvision&lt;/code&gt; v0.13 update (new transfer learning methods)&lt;/li&gt; 
 &lt;li&gt;04 June 2022 - add annotations for 07&lt;/li&gt; 
 &lt;li&gt;03 June 2022 - huuuuuuge amount of annotations added to 07&lt;/li&gt; 
 &lt;li&gt;31 May 2022 - add a bunch of annotations for 07, make code runnable end-to-end&lt;/li&gt; 
 &lt;li&gt;30 May 2022 - record 4 videos for 06, finished section 06, onto section 07, total videos 186&lt;/li&gt; 
 &lt;li&gt;28 May 2022 - record 10 videos for 06, total videos 182&lt;/li&gt; 
 &lt;li&gt;24 May 2022 - add solutions and exercises for 06&lt;/li&gt; 
 &lt;li&gt;23 May 2022 - finished annotations and images for 06, time to do exercises and solutions&lt;/li&gt; 
 &lt;li&gt;22 May 2202 - add plenty of images to 06&lt;/li&gt; 
 &lt;li&gt;18 May 2022 - add plenty of annotations to 06&lt;/li&gt; 
 &lt;li&gt;17 May 2022 - added a bunch of annotations for section 06&lt;/li&gt; 
 &lt;li&gt;16 May 2022 - recorded 10 videos for section 05, finish videos for section 05 âœ…&lt;/li&gt; 
 &lt;li&gt;12 May 2022 - added exercises and solutions for 05&lt;/li&gt; 
 &lt;li&gt;11 May 2022 - clean up part 1 and part 2 notebooks for 05, make slides for 05, start on exercises and solutions for 05&lt;/li&gt; 
 &lt;li&gt;10 May 2022 - huuuuge updates to the 05 section, see the website, it looks pretty: &lt;a href=&quot;https://www.learnpytorch.io/05_pytorch_going_modular/&quot;&gt;https://www.learnpytorch.io/05_pytorch_going_modular/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;09 May 2022 - add a bunch of materials for 05, cleanup docs&lt;/li&gt; 
 &lt;li&gt;08 May 2022 - add a bunch of materials for 05&lt;/li&gt; 
 &lt;li&gt;06 May 2022 - continue making materials for 05&lt;/li&gt; 
 &lt;li&gt;05 May 2022 - update section 05 with headings/outline&lt;/li&gt; 
 &lt;li&gt;28 Apr 2022 - recorded 13 videos for 04, finished videos for 04, now to make materials for 05&lt;/li&gt; 
 &lt;li&gt;27 Apr 2022 - recorded 3 videos for 04&lt;/li&gt; 
 &lt;li&gt;26 Apr 2022 - recorded 10 videos for 04&lt;/li&gt; 
 &lt;li&gt;25 Apr 2022 - recorded 11 videos for 04&lt;/li&gt; 
 &lt;li&gt;24 Apr 2022 - prepared slides for 04&lt;/li&gt; 
 &lt;li&gt;23 Apr 2022 - recorded 6 videos for 03, finished videos for 03, now to 04&lt;/li&gt; 
 &lt;li&gt;22 Apr 2022 - recorded 5 videos for 03&lt;/li&gt; 
 &lt;li&gt;21 Apr 2022 - recorded 9 videos for 03&lt;/li&gt; 
 &lt;li&gt;20 Apr 2022 - recorded 3 videos for 03&lt;/li&gt; 
 &lt;li&gt;19 Apr 2022 - recorded 11 videos for 03&lt;/li&gt; 
 &lt;li&gt;18 Apr 2022 - finish exercises/solutions for 04, added live-coding walkthrough of 04 exercises/solutions on YouTube: &lt;a href=&quot;https://youtu.be/vsFMF9wqWx0&quot;&gt;https://youtu.be/vsFMF9wqWx0&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;16 Apr 2022 - finish exercises/solutions for 03, added live-coding walkthrough of 03 exercises/solutions on YouTube: &lt;a href=&quot;https://youtu.be/_PibmqpEyhA&quot;&gt;https://youtu.be/_PibmqpEyhA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;14 Apr 2022 - add final images/annotations for 04, begin on exercises/solutions for 03 &amp;amp; 04&lt;/li&gt; 
 &lt;li&gt;13 Apr 2022 - add more images/annotations for 04&lt;/li&gt; 
 &lt;li&gt;3 Apr 2022 - add more annotations for 04&lt;/li&gt; 
 &lt;li&gt;2 Apr 2022 - add more annotations for 04&lt;/li&gt; 
 &lt;li&gt;1 Apr 2022 - add more annotations for 04&lt;/li&gt; 
 &lt;li&gt;31 Mar 2022 - add more annotations for 04&lt;/li&gt; 
 &lt;li&gt;29 Mar 2022 - add more annotations for 04&lt;/li&gt; 
 &lt;li&gt;27 Mar 2022 - starting to add annotations for 04&lt;/li&gt; 
 &lt;li&gt;26 Mar 2022 - making dataset for 04&lt;/li&gt; 
 &lt;li&gt;25 Mar 2022 - make slides for 03&lt;/li&gt; 
 &lt;li&gt;24 Mar 2022 - fix error for 03 not working in docs (finally)&lt;/li&gt; 
 &lt;li&gt;23 Mar 2022 - add more images for 03&lt;/li&gt; 
 &lt;li&gt;22 Mar 2022 - add images for 03&lt;/li&gt; 
 &lt;li&gt;20 Mar 2022 - add more annotations for 03&lt;/li&gt; 
 &lt;li&gt;18 Mar 2022 - add more annotations for 03&lt;/li&gt; 
 &lt;li&gt;17 Mar 2022 - add more annotations for 03&lt;/li&gt; 
 &lt;li&gt;16 Mar 2022 - add more annotations for 03&lt;/li&gt; 
 &lt;li&gt;15 Mar 2022 - add more annotations for 03&lt;/li&gt; 
 &lt;li&gt;14 Mar 2022 - start adding annotations for notebook 03, see the work in progress here: &lt;a href=&quot;https://www.learnpytorch.io/03_pytorch_computer_vision/&quot;&gt;https://www.learnpytorch.io/03_pytorch_computer_vision/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;12 Mar 2022 - recorded 12 videos for 02, finished section 02, now onto making materials for 03, 04, 05&lt;/li&gt; 
 &lt;li&gt;11 Mar 2022 - recorded 9 videos for 02&lt;/li&gt; 
 &lt;li&gt;10 Mar 2022 - recorded 10 videos for 02&lt;/li&gt; 
 &lt;li&gt;9 Mar 2022 - cleaning up slides/code for 02, getting ready for recording&lt;/li&gt; 
 &lt;li&gt;8 Mar 2022 - recorded 9 videos for section 01, finished section 01, now onto 02&lt;/li&gt; 
 &lt;li&gt;7 Mar 2022 - recorded 4 videos for section 01&lt;/li&gt; 
 &lt;li&gt;6 Mar 2022 - recorded 4 videos for section 01&lt;/li&gt; 
 &lt;li&gt;4 Mar 2022 - recorded 10 videos for section 01&lt;/li&gt; 
 &lt;li&gt;20 Feb 2022 - recorded 8 videos for section 00, finished section, now onto 01&lt;/li&gt; 
 &lt;li&gt;18 Feb 2022 - recorded 13 videos for section 00&lt;/li&gt; 
 &lt;li&gt;17 Feb 2022 - recorded 11 videos for section 00&lt;/li&gt; 
 &lt;li&gt;16 Feb 2022 - added setup guide&lt;/li&gt; 
 &lt;li&gt;12 Feb 2022 - tidy up README with table of course materials, finish images and slides for 01&lt;/li&gt; 
 &lt;li&gt;10 Feb 2022 - finished slides and images for 00, notebook is ready for publishing: &lt;a href=&quot;https://www.learnpytorch.io/00_pytorch_fundamentals/&quot;&gt;https://www.learnpytorch.io/00_pytorch_fundamentals/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;01-07 Feb 2022 - add annotations for 02, finished, still need images, going to work on exercises/solutions today&lt;/li&gt; 
 &lt;li&gt;31 Jan 2022 - start adding annotations for 02&lt;/li&gt; 
 &lt;li&gt;28 Jan 2022 - add exercies and solutions for 01&lt;/li&gt; 
 &lt;li&gt;26 Jan 2022 - lots more annotations to 01, should be finished tomorrow, will do exercises + solutions then too&lt;/li&gt; 
 &lt;li&gt;24 Jan 2022 - add a bunch of annotations to 01&lt;/li&gt; 
 &lt;li&gt;21 Jan 2022 - start adding annotations for 01&lt;/li&gt; 
 &lt;li&gt;20 Jan 2022 - finish annotations for 00 (still need to add images), add exercises and solutions for 00&lt;/li&gt; 
 &lt;li&gt;19 Jan 2022 - add more annotations for 00&lt;/li&gt; 
 &lt;li&gt;18 Jan 2022 - add more annotations for 00&lt;/li&gt; 
 &lt;li&gt;17 Jan 2022 - back from holidays, adding more annotations to 00&lt;/li&gt; 
 &lt;li&gt;10 Dec 2021 - start adding annotations for 00&lt;/li&gt; 
 &lt;li&gt;9 Dec 2021 - Created a website for the course (&lt;a href=&quot;https://learnpytorch.io&quot;&gt;learnpytorch.io&lt;/a&gt;) you&#39;ll see updates posted there as development continues&lt;/li&gt; 
 &lt;li&gt;8 Dec 2021 - Clean up notebook 07, starting to go back through code and add annotations&lt;/li&gt; 
 &lt;li&gt;26 Nov 2021 - Finish skeleton code for 07, added four different experiments, need to clean up and make more straightforward&lt;/li&gt; 
 &lt;li&gt;25 Nov 2021 - clean code for 06, add skeleton code for 07 (experiment tracking)&lt;/li&gt; 
 &lt;li&gt;24 Nov 2021 - Update 04, 05, 06 notebooks for easier digestion and learning, each section should cover a max of 3 big ideas, 05 is now dedicated to turning notebook code into modular code&lt;/li&gt; 
 &lt;li&gt;22 Nov 2021 - Update 04 train and test functions to make more straightforward&lt;/li&gt; 
 &lt;li&gt;19 Nov 2021 - Added 05 (transfer learning) notebook, update custom data loading code in 04&lt;/li&gt; 
 &lt;li&gt;18 Nov 2021 - Updated vision code for 03 and added custom dataset loading code in 04&lt;/li&gt; 
 &lt;li&gt;12 Nov 2021 - Added a bunch of skeleton code to notebook 04 for custom dataset loading, next is modelling with custom data&lt;/li&gt; 
 &lt;li&gt;10 Nov 2021 - researching best practice for custom datasets for 04&lt;/li&gt; 
 &lt;li&gt;9 Nov 2021 - Update 03 skeleton code to finish off building CNN model, onto 04 for loading custom datasets&lt;/li&gt; 
 &lt;li&gt;4 Nov 2021 - Add GPU code to 03 + train/test loops + &lt;code&gt;helper_functions.py&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;3 Nov 2021 - Add basic start for 03, going to finish by end of week&lt;/li&gt; 
 &lt;li&gt;29 Oct 2021 - Tidied up skeleton code for 02, still a few more things to clean/tidy, created 03&lt;/li&gt; 
 &lt;li&gt;28 Oct 2021 - Finished skeleton code for 02, going to clean/tidy tomorrow, 03 next week&lt;/li&gt; 
 &lt;li&gt;27 Oct 2021 - add a bunch of code for 02, going to finish tomorrow/by end of week&lt;/li&gt; 
 &lt;li&gt;26 Oct 2021 - update 00, 01, 02 with outline/code, skeleton code for 00 &amp;amp; 01 done, 02 next&lt;/li&gt; 
 &lt;li&gt;23, 24 Oct 2021 - update 00 and 01 notebooks with more outline/code&lt;/li&gt; 
 &lt;li&gt;20 Oct 2021 - add v0 outlines for 01 and 02, add rough outline of course to README, this course will focus on less but better&lt;/li&gt; 
 &lt;li&gt;19 Oct 2021 - Start repo ğŸ”¥, add fundamentals notebook draft v0&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>NirDiamant/GenAI_Agents</title>
      <link>https://github.com/NirDiamant/GenAI_Agents</link>
      <description>&lt;p&gt;This repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-Connect-blue&quot; alt=&quot;LinkedIn&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.reddit.com/r/EducationalAI/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Reddit-Join%20our%20subreddit-FF4500?style=flat-square&amp;amp;logo=reddit&amp;amp;logoColor=white&quot; alt=&quot;Reddit&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NirDiamantAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/NirDiamantAI?label=Follow%20@NirDiamantAI&amp;amp;style=social&quot; alt=&quot;Twitter&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20our%20community-7289da?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸŒŸ &lt;strong&gt;Support This Project:&lt;/strong&gt; Your sponsorship fuels innovation in GenAI agent development. &lt;strong&gt;&lt;a href=&quot;https://github.com/sponsors/NirDiamant&quot;&gt;Become a sponsor&lt;/a&gt;&lt;/strong&gt; to help maintain and expand this valuable resource!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;GenAI Agents: Comprehensive Repository for Development and Implementation ğŸš€&lt;/h1&gt; 
&lt;p&gt;Welcome to one of the most extensive and dynamic collections of Generative AI (GenAI) agent tutorials and implementations available today. This repository serves as a comprehensive resource for learning, building, and sharing GenAI agents, ranging from simple conversational bots to complex, multi-agent systems.&lt;/p&gt; 
&lt;h2&gt;ğŸ“« Stay Updated!&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸš€&lt;br /&gt;&lt;b&gt;Cutting-edge&lt;br /&gt;Updates&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ’¡&lt;br /&gt;&lt;b&gt;Expert&lt;br /&gt;Insights&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ¯&lt;br /&gt;&lt;b&gt;Top 0.1%&lt;br /&gt;Content&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/subscribe-button.svg?sanitize=true&quot; alt=&quot;Subscribe to DiamantAI Newsletter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!&lt;/em&gt; &lt;em&gt;&lt;strong&gt;Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/images/substack_image.png&quot; alt=&quot;DiamantAI&#39;s newsletter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Generative AI agents are at the forefront of artificial intelligence, revolutionizing the way we interact with and leverage AI technologies. This repository is designed to guide you through the development journey, from basic agent implementations to advanced, cutting-edge systems.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;h3&gt;ğŸ“š Learn to Build Your First AI Agent&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://diamantai.substack.com/p/your-first-ai-agent-simpler-than&quot;&gt;Your First AI Agent: Simpler Than You Think&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This detailed blog post complements the repository by providing a complete A-Z walkthrough with in-depth explanations of core concepts, step-by-step implementation, and the theory behind AI agents. It&#39;s designed to be incredibly simple to follow while covering everything you need to know to build your first working agent from scratch.&lt;/p&gt; &lt;p&gt;&lt;em&gt;ğŸ’¡ Plus: Subscribe to the newsletter for exclusive early access to tutorials and special discounts on upcoming courses and books!&lt;/em&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;Our goal is to provide a valuable resource for everyone - from beginners taking their first steps in AI to seasoned practitioners pushing the boundaries of what&#39;s possible. By offering a range of examples from foundational to complex, we aim to facilitate learning, experimentation, and innovation in the rapidly evolving field of GenAI agents.&lt;/p&gt; 
&lt;p&gt;Furthermore, this repository serves as a platform for showcasing innovative agent creations. Whether you&#39;ve developed a novel agent architecture or found an innovative application for existing techniques, we encourage you to share your work with the community.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;ğŸš€ Level up with my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/agents-towards-production&quot;&gt;Agents Towards Production&lt;/a&gt;&lt;/strong&gt; repository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you&#39;re serious about shipping agents to production.&lt;/p&gt; 
&lt;p&gt;ğŸ“š Dive into my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques&quot;&gt;comprehensive guide on RAG techniques&lt;/a&gt;&lt;/strong&gt; to learn about integrating external knowledge into AI systems, enhancing their capabilities with up-to-date and relevant information retrieval.&lt;/p&gt; 
&lt;p&gt;ğŸ–‹ï¸ Explore my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Prompt_Engineering&quot;&gt;Prompt Engineering Techniques guide&lt;/a&gt;&lt;/strong&gt; for an extensive collection of prompting strategies, from fundamental concepts to advanced methods, improving your ability to communicate effectively with AI language models.&lt;/p&gt; 
&lt;h2&gt;A Community-Driven Knowledge Hub&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This repository grows stronger with your contributions!&lt;/strong&gt; Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.reddit.com/r/EducationalAI/&quot;&gt;Educational AI Subreddit&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;GenAI Agents Discord Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Whether you&#39;re a novice eager to learn or an expert ready to share your knowledge, your insights can shape the future of GenAI agents. Join us to propose ideas, get feedback, and collaborate on innovative implementations. For contribution guidelines, please refer to our &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/strong&gt; file. Let&#39;s advance GenAI agent technology together!&lt;/p&gt; 
&lt;p&gt;ğŸ”— For discussions on GenAI, agents, or to explore knowledge-sharing opportunities, feel free to &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;connect on LinkedIn&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“ Learn to build GenAI agents from beginner to advanced levels&lt;/li&gt; 
 &lt;li&gt;ğŸ§  Explore a wide range of agent architectures and applications&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Step-by-step tutorials and comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Practical, ready-to-use agent implementations&lt;/li&gt; 
 &lt;li&gt;ğŸŒŸ Regular updates with the latest advancements in GenAI&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ Share your own agent creations with the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GenAI Agent Implementations&lt;/h2&gt; 
&lt;p&gt;Below is a comprehensive overview of our GenAI agent implementations, organized by category and functionality. Each implementation is designed to showcase different aspects of AI agent development, from basic conversational agents to complex multi-agent systems.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Agent Name&lt;/th&gt; 
   &lt;th&gt;Framework&lt;/th&gt; 
   &lt;th&gt;Key Features&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;ğŸŒ± &lt;strong&gt;Beginner&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/simple_conversational_agent.ipynb&quot;&gt;Simple Conversational Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain/PydanticAI&lt;/td&gt; 
   &lt;td&gt;Context-aware conversations, history management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;ğŸŒ± &lt;strong&gt;Beginner&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/simple_question_answering_agent.ipynb&quot;&gt;Simple Question Answering&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Query understanding, concise answers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;ğŸŒ± &lt;strong&gt;Beginner&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb&quot;&gt;Simple Data Analysis&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain/PydanticAI&lt;/td&gt; 
   &lt;td&gt;Dataset interpretation, natural language queries&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;ğŸ”§ &lt;strong&gt;Framework&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/langgraph-tutorial.ipynb&quot;&gt;Introduction to LangGraph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Modular AI workflows, state management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;ğŸ”§ &lt;strong&gt;Framework&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/mcp-tutorial.ipynb&quot;&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP&lt;/td&gt; 
   &lt;td&gt;AI-external resource integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;ğŸ“ &lt;strong&gt;Educational&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb&quot;&gt;ATLAS: Academic Task System&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Multi-agent academic planning, note-taking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;ğŸ“ &lt;strong&gt;Educational&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb&quot;&gt;Scientific Paper Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Literature review automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;ğŸ“ &lt;strong&gt;Educational&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb&quot;&gt;Chiron - Feynman Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Adaptive learning, checkpoint system&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb&quot;&gt;Customer Support Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Query categorization, sentiment analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb&quot;&gt;Essay Grading Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Automated grading, multiple criteria&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb&quot;&gt;Travel Planning Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Personalized itineraries&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb&quot;&gt;GenAI Career Assistant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Career guidance, learning paths&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/project_manager_assistant_agent.ipynb&quot;&gt;Project Manager Assistant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Task generation, risk assessment&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/ClauseAI.ipynb&quot;&gt;Contract Analysis Assistant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Clause analysis, compliance checking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;ğŸ’¼ &lt;strong&gt;Business&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/e2e_testing_agent.ipynb&quot;&gt;E2E Testing Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Test automation, browser control&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb&quot;&gt;GIF Animation Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Text-to-animation pipeline&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb&quot;&gt;TTS Poem Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Text classification, speech synthesis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb&quot;&gt;Music Compositor&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;AI music composition&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/ContentIntelligence.ipynb&quot;&gt;Content Intelligence&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Multi-platform content generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/business_meme_generator.ipynb&quot;&gt;Business Meme Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Brand-aligned meme creation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;ğŸ¨ &lt;strong&gt;Creative&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb&quot;&gt;Murder Mystery Game&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Procedural story generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb&quot;&gt;Memory-Enhanced Conversational&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Short/long-term memory integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb&quot;&gt;Multi-Agent Collaboration&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Historical research, data analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/self_improving_agent.ipynb&quot;&gt;Self-Improving Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Learning from interactions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/task_oriented_agent.ipynb&quot;&gt;Task-Oriented Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Text summarization, translation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb&quot;&gt;Internet Search Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangChain&lt;/td&gt; 
   &lt;td&gt;Web research, summarization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/research_team_autogen.ipynb&quot;&gt;Research Team - Autogen&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen&lt;/td&gt; 
   &lt;td&gt;Multi-agent research collaboration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb&quot;&gt;Sales Call Analyzer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Audio transcription, NLP analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb&quot;&gt;Weather Emergency System&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Real-time data processing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/self_healing_code.ipynb&quot;&gt;Self-Healing Codebase&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Error detection, automated fixes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;31&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/database_discovery_fleet.ipynb&quot;&gt;DataScribe&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Database exploration, query planning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/memory-agent-tutorial.ipynb&quot;&gt;Memory-Enhanced Email&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Email triage, response generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;33&lt;/td&gt; 
   &lt;td&gt;ğŸ“° &lt;strong&gt;News&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/news_tldr_langgraph.ipynb&quot;&gt;News TL;DR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;News summarization, API integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;34&lt;/td&gt; 
   &lt;td&gt;ğŸ“° &lt;strong&gt;News&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/ainsight_langgraph.ipynb&quot;&gt;AInsight&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;AI/ML news aggregation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;35&lt;/td&gt; 
   &lt;td&gt;ğŸ“° &lt;strong&gt;News&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb&quot;&gt;Journalism Assistant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Fact-checking, bias detection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;36&lt;/td&gt; 
   &lt;td&gt;ğŸ“° &lt;strong&gt;News&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/blog_writer_swarm.ipynb&quot;&gt;Blog Writer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Swarm&lt;/td&gt; 
   &lt;td&gt;Collaborative content creation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;37&lt;/td&gt; 
   &lt;td&gt;ğŸ“° &lt;strong&gt;News&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb&quot;&gt;Podcast Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Content search, audio generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;38&lt;/td&gt; 
   &lt;td&gt;ğŸ›ï¸ &lt;strong&gt;Shopping&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/ShopGenie.ipynb&quot;&gt;ShopGenie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Product comparison, recommendations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;39&lt;/td&gt; 
   &lt;td&gt;ğŸ›ï¸ &lt;strong&gt;Shopping&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb&quot;&gt;Car Buyer Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Web scraping, decision support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;40&lt;/td&gt; 
   &lt;td&gt;ğŸ¯ &lt;strong&gt;Task Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/taskifier.ipynb&quot;&gt;Taskifier&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Work style analysis, task breakdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;41&lt;/td&gt; 
   &lt;td&gt;ğŸ¯ &lt;strong&gt;Task Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/grocery_management_agents_system.ipynb&quot;&gt;Grocery Management&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CrewAI&lt;/td&gt; 
   &lt;td&gt;Inventory tracking, recipe suggestions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;42&lt;/td&gt; 
   &lt;td&gt;ğŸ” &lt;strong&gt;QA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb&quot;&gt;LangGraph Inspector&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;System testing, vulnerability detection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;43&lt;/td&gt; 
   &lt;td&gt;ğŸ” &lt;strong&gt;QA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb&quot;&gt;EU Green Deal Bot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Regulatory compliance, FAQ system&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;44&lt;/td&gt; 
   &lt;td&gt;ğŸ” &lt;strong&gt;QA&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb&quot;&gt;Systematic Review&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;LangGraph&lt;/td&gt; 
   &lt;td&gt;Academic paper processing, draft generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;45&lt;/td&gt; 
   &lt;td&gt;ğŸŒŸ &lt;strong&gt;Advanced&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;Controllable RAG Agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Custom&lt;/td&gt; 
   &lt;td&gt;Complex question answering, deterministic graph&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Explore our extensive list of GenAI agent implementations, sorted by categories:&lt;/p&gt; 
&lt;h3&gt;ğŸŒ± Beginner-Friendly Agents&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Conversational Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_conversational_agent-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A context-aware conversational AI maintains information across interactions, enabling more natural dialogues.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model, prompt template, and history manager to generate contextual responses and track conversation sessions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_question_answering_agent.ipynb&quot;&gt;Simple Question Answering Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Answering (QA) agent using LangChain and OpenAI&#39;s language model understands user queries and provides relevant, concise answers.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Combines OpenAI&#39;s GPT model, a prompt template, and an LLMChain to process user questions and generate AI-driven responses in a streamlined manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simple Data Analysis Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb&quot;&gt;LangChain&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_data_analysis_agent_notebook-pydanticai.ipynb&quot;&gt;PydanticAI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI-powered data analysis agent interprets and answers questions about datasets using natural language, combining language models with data manipulation tools for intuitive data exploration.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model, data manipulation framework, and agent framework to process natural language queries and perform data analysis on a synthetic dataset, enabling accessible insights for non-technical users.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ”§ Framework Tutorial&lt;/h3&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/langgraph-tutorial.ipynb&quot;&gt;Introduction to LangGraph: Building Modular AI Workflows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;This tutorial introduces LangGraph, a powerful framework for creating modular, graph-based AI workflows. Learn how to leverage LangGraph to build more complex and flexible AI agents that can handle multi-step processes efficiently.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Step-by-step guide on using LangGraph to create a StateGraph workflow. The tutorial covers key concepts such as state management, node creation, and graph compilation. It demonstrates these principles by constructing a simple text analysis pipeline, serving as a foundation for more advanced agent architectures.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/your-first-ai-agent-simpler-than?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/mcp-tutorial.ipynb&quot;&gt;Model Context Protocol (MCP): Seamless Integration of AI and External Resources&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;This tutorial introduces the Model Context Protocol (MCP), an open standard for connecting AI models with external data sources and tools. Learn how MCP serves as a universal bridge between GenAI agents and the wider digital ecosystem, enabling more capable and context-aware AI applications.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Provides a hands-on guide to implementing MCP servers and clients, demonstrating how to connect language models with external tools and data sources. The tutorial covers server setup, tool definition, and integration with AI clients, with practical examples of building useful agent capabilities through the protocol.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/model-context-protocol-mcp-explained?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot;&gt;Official MCP Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/modelcontextprotocol&quot;&gt;MCP GitHub Repository&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“ Educational and Research Agents&lt;/h3&gt; 
&lt;ol start=&quot;6&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb&quot;&gt;ATLAS: Academic Task and Learning Agent System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;ATLAS demonstrates how to build an intelligent multi-agent system that transforms academic support through AI-powered assistance. The system leverages LangGraph&#39;s workflow framework to coordinate multiple specialized agents that provide personalized academic planning, note-taking, and advisory support.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent architecture using four specialized agents (Coordinator, Planner, Notewriter, and Advisor) working in concert through LangGraph&#39;s workflow framework. The system features sophisticated workflows for profile analysis and academic support, with continuous adaptation based on student performance and feedback.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yxowMLL2dDI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/atlas-when-artificial-intelligence?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb&quot;&gt;Scientific Paper Agent - Literature Review&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent research assistant that helps users navigate, understand, and analyze scientific literature through an orchestrated workflow. The system combines academic APIs with sophisticated paper processing techniques to automate literature review tasks, enabling researchers to efficiently extract insights from academic papers while maintaining research rigor and quality control.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to create a five-node workflow system including decision making, planning, tool execution, and quality validation nodes. The system integrates the CORE API for paper access, PDFplumber for document processing, and advanced language models for analysis. Key features include a retry mechanism for robust paper downloads, structured data handling through Pydantic models, and quality-focused improvement cycles with human-in-the-loop validation options.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/Bc4YtpHY6Ws&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/nexus-ai-the-revolutionary-research?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb&quot;&gt;Chiron - A Feynman-Enhanced Learning Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An adaptive learning agent that guides users through educational content using a structured checkpoint system and Feynman-style teaching. The system processes learning materials (either user-provided or web-retrieved), verifies understanding through interactive checkpoints, and provides simplified explanations when needed, creating a personalized learning experience that mimics one-on-one tutoring.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a learning workflow that includes checkpoint definition, context building, understanding verification, and Feynman teaching nodes. The system integrates web search for dynamic content retrieval, employs semantic chunking for context processing, and manages embeddings for relevant information retrieval. Key features include a 70% understanding threshold for progression, interactive human-in-the-loop validation, and structured output through Pydantic models for consistent data handling.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qsdiTGkB8mk&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ’¼ Business and Professional Agents&lt;/h3&gt; 
&lt;ol start=&quot;9&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb&quot;&gt;Customer Support Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent customer support agent using LangGraph categorizes queries, analyzes sentiment, and provides appropriate responses or escalates issues.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to create a workflow combining state management, query categorization, sentiment analysis, and response generation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb&quot;&gt;Essay Grading Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An automated essay grading system using LangGraph and an LLM model evaluates essays based on relevance, grammar, structure, and depth of analysis.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state graph to define the grading workflow, incorporating separate grading functions for each criterion.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb&quot;&gt;Travel Planning Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A Travel Planner using LangGraph demonstrates how to build a stateful, multi-step conversational AI application that collects user input and generates personalized travel itineraries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes StateGraph to define the application flow, incorporates custom PlannerState for process management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb&quot;&gt;GenAI Career Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The GenAI Career Assistant demonstrates how to create a multi-agent system that provides personalized guidance for careers in Generative AI. Using LangGraph and Gemini LLM, the system delivers customized learning paths, resume assistance, interview preparation, and job search support.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages a multi-agent architecture using LangGraph to coordinate specialized agents (Learning, Resume, Interview, Job Search) through TypedDict-based state management. The system employs sophisticated query categorization and routing while integrating with external tools like DuckDuckGo for job searches and dynamic content generation.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=IcKh0ltXO_8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/project_manager_assistant_agent.ipynb&quot;&gt;Project Manager Assistant Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI agent designed to assist in project management tasks by automating the process of creating actionable tasks from project descriptions, identifying dependencies, scheduling work, and assigning tasks to team members based on expertise. The system includes risk assessment and self-reflection capabilities to optimize project plans through multiple iterations, aiming to minimize overall project risk.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized nodes including task generation, dependency mapping, scheduling, allocation, and risk assessment. Each node uses GPT-4o-mini for structured outputs following Pydantic models. The system implements a feedback loop for self-improvement, where risk scores trigger reflection cycles that generate insights to optimize the project plan. Visualization tools display Gantt charts of the generated schedules across iterations.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=R7YWjzg3LpI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ClauseAI.ipynb&quot;&gt;Contract Analysis Assistant (ClauseAI)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;ClauseAI demonstrates how to build an AI-powered contract analysis system using a multi-agent approach. The system employs specialized AI agents for different aspects of contract review, from clause analysis to compliance checking, and leverages LangGraph for workflow orchestration and Pinecone for efficient clause retrieval and comparison.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated state-based workflow using LangGraph to coordinate multiple AI agents through contract analysis stages. The system features Pydantic models for data validation, vector storage with Pinecone for clause comparison, and LLM-based analysis for generating comprehensive contract reports. The implementation includes parallel processing capabilities and customizable report generation based on user requirements.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=rP8uv_tXuSI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/e2e_testing_agent.ipynb&quot;&gt;E2E Testing Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The E2E Testing Agent demonstrates how to build an AI-powered system that converts natural language test instructions into executable end-to-end web tests. Using LangGraph for workflow orchestration and Playwright for browser automation, the system enables users to specify test cases in plain English while handling the complexity of test generation and execution.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a structured workflow using LangGraph to coordinate test generation, validation, and execution. The system features TypedDict state management, integration with Playwright for browser automation, and LLM-based code generation for converting natural language instructions into executable test scripts. The implementation includes DOM state analysis, error handling, and comprehensive test reporting.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=jPXtpzcCtyA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ¨ Creative and Content Generation Agents&lt;/h3&gt; 
&lt;ol start=&quot;16&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb&quot;&gt;GIF Animation Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A GIF animation generator that integrates LangGraph for workflow management, GPT-4 for text generation, and DALL-E for image creation, producing custom animations from user prompts.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that generates character descriptions, plots, and image prompts using GPT-4, creates images with DALL-E 3, and assembles them into GIFs using PIL. Employs asynchronous programming for efficient parallel processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb&quot;&gt;TTS Poem Generator Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An advanced text-to-speech (TTS) agent using LangGraph and OpenAI&#39;s APIs classifies input text, processes it based on content type, and generates corresponding speech output.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow that classifies input text using GPT models, applies content-specific processing, and converts the processed text to speech using OpenAI&#39;s TTS API. The system adapts its output based on the identified content type (general, poem, news, or joke).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb&quot;&gt;Music Compositor Agent (LangGraph)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI Music Compositor using LangGraph and OpenAI&#39;s language models generates custom musical compositions based on user input. The system processes the input through specialized components, each contributing to the final musical piece, which is then converted to a playable MIDI file.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;LangGraph orchestrates a workflow that transforms user input into a musical composition, using ChatOpenAI (GPT-4) to generate melody, harmony, and rhythm, which are then style-adapted. The final AI-generated composition is converted to a MIDI file using music21 and can be played back using pygame.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ContentIntelligence.ipynb&quot;&gt;Content Intelligence: Multi-Platform Content Generation Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Content Intelligence demonstrates how to build an advanced content generation system that transforms input text into platform-optimized content across multiple social media channels. The system employs LangGraph for workflow orchestration to analyze content, conduct research, and generate tailored content while maintaining brand consistency across different platforms.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated workflow using LangGraph to coordinate multiple specialized nodes (Summary, Research, Platform-Specific) through the content generation process. The system features TypedDict and Pydantic models for state management, integration with Tavily Search for research enhancement, and platform-specific content generation using GPT-4. The implementation includes parallel processing for multiple platforms and customizable content templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=DPMtPbKmWnU&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/business_meme_generator.ipynb&quot;&gt;Business Meme Generator Using LangGraph and Memegen.link&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The Business Meme Generator demonstrates how to create an AI-powered system that generates contextually relevant memes based on company website analysis. Using LangGraph for workflow orchestration, the system combines Groq&#39;s Llama model for text analysis and the Memegen.link API to automatically produce brand-aligned memes for digital marketing.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed workflow using LangGraph to coordinate website content analysis, meme concept generation, and image creation. The system features Pydantic models for data validation, asynchronous processing with aiohttp, and integration with external APIs (Groq, Memegen.link) to create a complete meme generation pipeline with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://youtu.be/lsdDaGmkSCw?si=oF3CGfhbRqz1_Vm8&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb&quot;&gt;Murder Mystery Game with LLM Agents&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A text-based detective game that utilizes autonomous LLM agents as interactive characters in a procedurally generated murder mystery. Drawing inspiration from the UNBOUNDED paper, the system creates unique scenarios each time, with players taking on the role of Sherlock Holmes to solve the case through character interviews and deductive reasoning.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages two LangGraph workflows - a main game loop for story/character generation and game progression, and a conversation sub-graph for character interactions. The system uses a combination of LLM-powered narrative generation, character AI, and structured game mechanics to create an immersive investigative experience with replayable storylines.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_3cJYlk2EmA&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“Š Analysis and Information Processing Agents&lt;/h3&gt; 
&lt;ol start=&quot;22&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb&quot;&gt;Memory-Enhanced Conversational Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A memory-enhanced conversational AI agent incorporates short-term and long-term memory systems to maintain context within conversations and across multiple sessions, improving interaction quality and personalization.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model with separate short-term and long-term memory stores, utilizes a prompt template incorporating both memory types, and employs a memory manager for storage and retrieval. The system includes an interaction loop that updates and utilizes memories for each response.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb&quot;&gt;Multi-Agent Collaboration System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent collaboration system combining historical research with data analysis, leveraging large language models to simulate specialized agents working together to answer complex historical questions.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a base Agent class to create specialized HistoryResearchAgent and DataAnalysisAgent, orchestrated by a HistoryDataCollaborationSystem. The system follows a five-step process: historical context provision, data needs identification, historical data provision, data analysis, and final synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_improving_agent.ipynb&quot;&gt;Self-Improving Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A Self-Improving Agent using LangChain engages in conversations, learns from interactions, and continuously improves its performance over time through reflection and adaptation.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a language model with chat history management, response generation, and a reflection mechanism. The system employs a learning system that incorporates insights from reflection to enhance future performance, creating a continuous improvement loop.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/task_oriented_agent.ipynb&quot;&gt;Task-Oriented Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A language model application using LangChain that summarizes text and translates the summary to Spanish, combining custom functions, structured tools, and an agent for efficient text processing.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes custom functions for summarization and translation, wrapped as structured tools. Employs a prompt template to guide the agent, which orchestrates the use of tools. An agent executor manages the process, taking input text and producing both an English summary and its Spanish translation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb&quot;&gt;Internet Search and Summarize Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent web research assistant that combines web search capabilities with AI-powered summarization, automating the process of gathering information from the internet and distilling it into concise, relevant summaries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates a web search module using DuckDuckGo&#39;s API, a result parser, and a text summarization engine leveraging OpenAI&#39;s language models. The system performs site-specific or general searches, extracts relevant content, generates concise summaries, and compiles attributed results for efficient information retrieval and synthesis.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/research_team_autogen.ipynb&quot;&gt;Multi agent research team - Autogen&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;This technique explores a multi-agent system for collaborative research using the AutoGen library. It employs agents to solve tasks collaboratively, focusing on efficient execution and quality assurance. The system enhances research by distributing tasks among specialized agents.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Agents are configured with specific roles using the GPT-4 model, including admin, developer, planner, executor, and quality assurance. Interaction management ensures orderly communication with defined transitions. Task execution involves collaborative planning, coding, execution, and quality checking, demonstrating a scalable framework for various domains.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/yanivvak/dream-team&quot;&gt;comprehensive solution with UI&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/build-your-dream-team-with-autogen/ba-p/4157961&quot;&gt;Blogpost&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb&quot;&gt;Sales Call Analyzer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent system that automates the analysis of sales call recordings by combining audio transcription with advanced natural language processing. The analyzer transcribes audio using OpenAI&#39;s Whisper, processes the text using NLP techniques, and generates comprehensive reports including sentiment analysis, key phrases, pain points, and actionable recommendations to improve sales performance.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes multiple components in a structured workflow: OpenAI Whisper for audio transcription, CrewAI for task automation and agent management, and LangChain for orchestrating the analysis pipeline. The system processes audio through a series of steps from transcription to detailed analysis, leveraging custom agents and tasks to generate structured JSON reports containing insights about customer sentiment, sales opportunities, and recommended improvements.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=SKAt_PvznDw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb&quot;&gt;Weather Emergency &amp;amp; Response System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive system demonstrating two agent graph implementations for weather emergency response: a real-time graph processing live weather data, and a hybrid graph combining real and simulated data for testing high-severity scenarios. The system handles complete workflow from data gathering through emergency plan generation, with automated notifications and human verification steps.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph for orchestrating complex workflows with state management, integrating OpenWeatherMap API for real-time data, and Gemini for analysis and response generation. The system incorporates email notifications, social media monitoring simulation, and severity-based routing with configurable human verification for low/medium severity events.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AgiOAJl_apw&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/self_healing_code.ipynb&quot;&gt;Self-Healing Codebase System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent system that automatically detects, diagnoses, and fixes runtime code errors using LangGraph workflow orchestration and ChromaDB vector storage. The system maintains a memory of encountered bugs and their fixes through vector embeddings, enabling pattern recognition for similar errors across the codebase.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that processes function definitions and runtime arguments through specialized nodes for error detection, code analysis, and fix generation. Incorporates ChromaDB for vector-based storage of bug patterns and fixes, with automated search and retrieval capabilities for similar error patterns, while maintaining code execution safety through structured validation steps.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ga7ShvIXOvE&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/database_discovery_fleet.ipynb&quot;&gt;DataScribe: AI-Powered Schema Explorer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent agent system that enables intuitive exploration and querying of relational databases through natural language interactions. The system utilizes a fleet of specialized agents, coordinated by a stateful Supervisor, to handle schema discovery, query planning, and data analysis tasks while maintaining contextual understanding through vector-based relationship graphs.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-agent workflow including discovery, inference, and planning agents, with NetworkX for relationship graph visualization and management. The system incorporates dynamic state management through TypedDict classes, maintains database context between sessions using a db_graph attribute, and includes safety measures to prevent unauthorized database modifications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/memory-agent-tutorial.ipynb&quot;&gt;Memory-Enhanced Email Agent (LangGraph &amp;amp; LangMem)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent email assistant that combines three types of memory (semantic, episodic, and procedural) to create a system that improves over time. The agent can triage incoming emails, draft contextually appropriate responses using stored knowledge, and enhance its performance based on user feedback.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for workflow orchestration and LangMem for sophisticated memory management across multiple memory types. The system implements a triage workflow with memory-enhanced decision making, specialized tools for email composition and calendar management, and a self-improvement mechanism that updates its own prompts based on feedback and past performance.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;**&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/building-an-ai-agent-with-memory?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“° News and Information Agents&lt;/h3&gt; 
&lt;ol start=&quot;33&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/news_tldr_langgraph.ipynb&quot;&gt;News TL;DR using LangGraph&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A news summarization system that generates concise TL;DR summaries of current events based on user queries. The system leverages large language models for decision making and summarization while integrating with news APIs to access up-to-date content, allowing users to quickly catch up on topics of interest through generated bullet-point summaries.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a workflow combining multiple components: GPT-4o-mini for generating search terms and article summaries, NewsAPI for retrieving article metadata, BeautifulSoup for web scraping article content, and Asyncio for concurrent processing. The system follows a structured pipeline from query processing through article selection and summarization, managing the flow between components to produce relevant TL;DRs of current news articles.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0fRxW6miybI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/stop-reading-start-understanding?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ainsight_langgraph.ipynb&quot;&gt;AInsight: AI/ML Weekly News Reporter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;AInsight demonstrates how to build an intelligent news aggregation and summarization system using a multi-agent architecture. The system employs three specialized agents (NewsSearcher, Summarizer, Publisher) to automatically collect, process and summarize AI/ML news for general audiences through LangGraph-based workflow orchestration.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-managed multi-agent system using LangGraph to coordinate the news collection (Tavily API), technical content summarization (GPT-4), and report generation processes. The system features modular architecture with TypedDict-based state management, external API integration, and markdown report generation with customizable templates.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kH5S1is2D_0&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb&quot;&gt;Journalism-Focused AI Assistant&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A specialized AI assistant that helps journalists tackle modern journalistic challenges like misinformation, bias, and information overload. The system integrates fact-checking, tone analysis, summarization, and grammar review tools to enhance the accuracy and efficiency of journalistic work while maintaining ethical reporting standards.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph to orchestrate a workflow of specialized components including language models for analysis and generation, web search integration via DuckDuckGo&#39;s API, document parsing tools like PyMuPDFLoader and WebBaseLoader, text splitting with RecursiveCharacterTextSplitter, and structured JSON outputs. Each component works together through a unified workflow to analyze content, verify facts, detect bias, extract quotes, and generate comprehensive reports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/blog_writer_swarm.ipynb&quot;&gt;Blog Writer (Open AI Swarm)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent system for collaborative blog post creation using OpenAI&#39;s Swarm package. It leverages specialized agents to perform research, planning, writing, and editing tasks efficiently.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes OpenAI&#39;s Swarm Package to manage agent interactions. Includes an admin, researcher, planner, writer, and editor, each with specific roles. The system follows a structured workflow: topic setting, outlining, research, drafting, and editing. This approach enhances content creation through task distribution, specialization, and collaborative problem-solving.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;Swarm Repo&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb&quot;&gt;Podcast Internet Search and Generate Agent ğŸ™ï¸&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A two step agent that first searches the internet for a given topic and then generates a podcast on the topic found. The search step uses a search agent and search function to find the most relevant information. The second step uses a podcast generation agent and generation function to create a podcast on the topic found.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes LangGraph to orchestrate a two-step workflow. The first step involves a search agent and function to gather information from the internet. The second step uses a podcast generation agent and function to create a podcast based on the gathered information.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ›ï¸ Shopping and Product Analysis Agents&lt;/h3&gt; 
&lt;ol start=&quot;38&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/ShopGenie.ipynb&quot;&gt;ShopGenie - Redefining Online Shopping Customer Experience&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An AI-powered shopping assistant that helps customers make informed purchasing decisions even without domain expertise. The system analyzes product information from multiple sources, compares specifications and reviews, identifies the best option based on user needs, and delivers recommendations through email with supporting video reviews, creating a comprehensive shopping experience.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Uses LangGraph to orchestrate a workflow combining Tavily for web search, Llama-3.1-70B for structured data analysis and product comparison, and YouTube API for review video retrieval. The system processes search results through multiple nodes including schema mapping, product comparison, review identification, and email generation. Key features include structured Pydantic models for consistent data handling, retry mechanisms for robust API interactions, and email delivery through SMTP for sharing recommendations.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Js0sK0u53dQ&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb&quot;&gt;Car Buyer AI Agent&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The Smart Product Buyer AI Agent demonstrates how to build an intelligent system that assists users in making informed purchasing decisions. Using LangGraph and LLM-based intelligence, the system processes user requirements, scrapes product listings from websites like AutoTrader, and provides detailed analysis and recommendations for car purchases.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a state-based workflow using LangGraph to coordinate user interaction, web scraping, and decision support. The system features TypedDict state management, async web scraping with Playwright, and integrates with external APIs for comprehensive product analysis. The implementation includes a Gradio interface for real-time chat interaction and modular scraper architecture for easy extension to additional product categories.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=I61I1fp0qys&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ¯ Task Management and Productivity Agents&lt;/h3&gt; 
&lt;ol start=&quot;40&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/taskifier.ipynb&quot;&gt;Taskifier - Intelligent Task Allocation &amp;amp; Management&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An intelligent task management system that analyzes user work styles and creates personalized task breakdown strategies, born from the observation that procrastination often stems from task ambiguity among students and early-career professionals. The system evaluates historical work patterns, gathers relevant task information through web search, and generates customized step-by-step approaches to optimize productivity and reduce workflow paralysis.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Leverages LangGraph for orchestrating a multi-step workflow including work style analysis, information gathering via Tavily API, and customized plan generation. The system maintains state through the process, integrating historical work pattern data with fresh task research to output detailed, personalized task execution plans aligned with the user&#39;s natural working style.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=1W_p_RVi9KE&amp;amp;t=25s&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/grocery_management_agents_system.ipynb&quot;&gt;Grocery Management Agents System&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A multi-agent system built with CrewAI that automates grocery management tasks including receipt interpretation, expiration date tracking, inventory management, and recipe recommendations. The system uses specialized agents to extract data from receipts, estimate product shelf life, track consumption, and suggest recipes to minimize food waste.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements four specialized agents using CrewAI - a Receipt Interpreter that extracts item details from receipts, an Expiration Date Estimator that determines shelf life using online sources, a Grocery Tracker that maintains inventory based on consumption, and a Recipe Recommender that suggests meals using available ingredients. Each agent has specific tools and tasks orchestrated through a crew workflow.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=FlMu5pKSaHI&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ” Quality Assurance and Testing Agents&lt;/h3&gt; 
&lt;ol start=&quot;42&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb&quot;&gt;LangGraph-Based Systems Inspector&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive testing and validation tool for LangGraph-based applications that automatically analyzes system architecture, generates test cases, and identifies potential vulnerabilities through multi-agent inspection. The inspector employs specialized AI testers to evaluate different aspects of the system, from basic functionality to security concerns and edge cases.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Integrates LangGraph for workflow orchestration, multiple LLM-powered testing agents, and a structured evaluation pipeline that includes static analysis, test case generation, and results verification. The system uses Pydantic for data validation, NetworkX for graph representation, and implements a modular architecture that allows for parallel test execution and comprehensive result analysis.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=fQd6lXc-Y9A&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=false&quot;&gt;Blog Post&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb&quot;&gt;EU Green Deal FAQ Bot&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;The EU Green Deal FAQ Bot demonstrates how to build a RAG-based AI agent that helps businesses understand EU green deal policies. The system processes complex regulatory documents into manageable chunks and provides instant, accurate answers to common questions about environmental compliance, emissions reporting, and waste management requirements.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implements a sophisticated RAG pipeline using FAISS vectorstore for document storage, semantic chunking for preprocessing, and multiple specialized agents (Retriever, Summarizer, Evaluator) for query processing. The system features query rephrasing for improved accuracy, cross-reference with gold Q&amp;amp;A datasets for answer validation, and comprehensive evaluation metrics to ensure response quality and relevance.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Av0kBQjwU-Y&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/raw/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb&quot;&gt;Systematic Review Automation System + Paper Draft Creation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A comprehensive system for automating academic systematic reviews using a directed graph architecture and LangChain components. The system generates complete, publication-ready systematic review papers, automatically processing everything from literature search through final draft generation with multiple revision cycles.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Utilizes a state-based graph workflow that handles paper search and selection (up to 3 papers), PDF processing, and generates a complete academic paper with all standard sections (abstract, introduction, methods, results, conclusions, references). The system incorporates multiple revision cycles with automated critique and improvement phases, all orchestrated through LangGraph state management.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qi35mGGkCtg&quot;&gt;YouTube Explanation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸŒŸ Special Advanced Technique ğŸŒŸ&lt;/h3&gt; 
&lt;ol start=&quot;45&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;Sophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the &quot;brain&quot; ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To begin exploring and building GenAI agents:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/NirDiamant/GenAI_Agents.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to the technique you&#39;re interested in: &lt;pre&gt;&lt;code&gt;cd all_agents_tutorials/technique-name
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the detailed implementation guide in each technique&#39;s notebook.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have a new technique or improvement to suggest:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch: &lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Commit your changes: &lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Push to the branch: &lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Open a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=NirDiamant/GenAI_Agents&quot; alt=&quot;Contributors&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under a custom non-commercial license - see the &lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/GenAI_Agents/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;â­ï¸ If you find this repository helpful, please consider giving it a star!&lt;/p&gt; 
&lt;p&gt;Keywords: GenAI, Generative AI, Agents, NLP, AI, Machine Learning, Natural Language Processing, LLM, Conversational AI, Task-Oriented AI&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/AI-For-Beginners</title>
      <link>https://github.com/microsoft/AI-For-Beginners</link>
      <description>&lt;p&gt;12 Weeks, 24 Lessons, AI for All!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/graphs/contributors/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/issues/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/pulls/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/watchers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/network/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/AI-For-Beginners/stargazers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/AI-For-Beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://mybinder.org/v2/gh/microsoft/ai-for-beginners/HEAD&quot;&gt;&lt;img src=&quot;https://mybinder.org/badge_logo.svg?sanitize=true&quot; alt=&quot;Binder&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://gitter.im/Microsoft/ai-for-beginners?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&quot;&gt;&lt;img src=&quot;https://badges.gitter.im/Microsoft/ai-for-beginners.svg?sanitize=true&quot; alt=&quot;Gitter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/zxKYvhSnVp?WT.mc_id=academic-000002-leestott&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/ByRwuEEgH4&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Artificial Intelligence for Beginners - A Curriculum&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/sketchnotes/ai-overview.png&quot; alt=&quot; Sketchnote by (@girlie_mac) &quot; /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;AI For Beginners - &lt;em&gt;Sketchnote by &lt;a href=&quot;https://twitter.com/girlie_mac&quot;&gt;@girlie_mac&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Explore the world of &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; (AI) with our 12-week, 24-lesson curriculum! It includes practical lessons, quizzes, and labs. The curriculum is beginner-friendly and covers tools like TensorFlow and PyTorch, as well as ethics in AI&lt;/p&gt; 
&lt;h2&gt;What you will learn&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://soshnikov.com/courses/ai-for-beginners/mindmap.html&quot;&gt;Mindmap of the Course&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this curriculum, you will learn:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Different approaches to Artificial Intelligence, including the &quot;good old&quot; symbolic approach with &lt;strong&gt;Knowledge Representation&lt;/strong&gt; and reasoning (&lt;a href=&quot;https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence&quot;&gt;GOFAI&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt; and &lt;strong&gt;Deep Learning&lt;/strong&gt;, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - &lt;a href=&quot;http://Tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&quot;http://pytorch.org&quot;&gt;PyTorch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural Architectures&lt;/strong&gt; for working with images and text. We will cover recent models but may be a bit lacking in the state-of-the-art.&lt;/li&gt; 
 &lt;li&gt;Less popular AI approaches, such as &lt;strong&gt;Genetic Algorithms&lt;/strong&gt; and &lt;strong&gt;Multi-Agent Systems&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What we will not cover in this curriculum:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href=&quot;https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Find all additional resources for this course in our Microsoft Learn collection&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Business cases of using &lt;strong&gt;AI in Business&lt;/strong&gt;. Consider taking &lt;a href=&quot;https://docs.microsoft.com/learn/paths/introduction-ai-for-business-users/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Introduction to AI for business users&lt;/a&gt; learning path on Microsoft Learn, or &lt;a href=&quot;https://www.microsoft.com/ai/ai-business-school/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;AI Business School&lt;/a&gt;, developed in cooperation with &lt;a href=&quot;https://www.insead.edu/&quot;&gt;INSEAD&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classic Machine Learning&lt;/strong&gt;, which is well described in our &lt;a href=&quot;http://github.com/Microsoft/ML-for-Beginners&quot;&gt;Machine Learning for Beginners Curriculum&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Practical AI applications built using &lt;strong&gt;&lt;a href=&quot;https://azure.microsoft.com/services/cognitive-services/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Cognitive Services&lt;/a&gt;&lt;/strong&gt;. For this, we recommend that you start with modules Microsoft Learn for &lt;a href=&quot;https://docs.microsoft.com/learn/paths/create-computer-vision-solutions-azure-cognitive-services/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;vision&lt;/a&gt;, &lt;a href=&quot;https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;natural language processing&lt;/a&gt;, &lt;strong&gt;&lt;a href=&quot;https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Generative AI with Azure OpenAI Service&lt;/a&gt;&lt;/strong&gt; and others.&lt;/li&gt; 
 &lt;li&gt;Specific ML &lt;strong&gt;Cloud Frameworks&lt;/strong&gt;, such as &lt;a href=&quot;https://azure.microsoft.com/services/machine-learning/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Azure Machine Learning&lt;/a&gt;, &lt;a href=&quot;https://learn.microsoft.com/en-us/training/paths/get-started-fabric/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Microsoft Fabric&lt;/a&gt;, or &lt;a href=&quot;https://docs.microsoft.com/learn/paths/data-engineer-azure-databricks?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Azure Databricks&lt;/a&gt;. Consider using &lt;a href=&quot;https://docs.microsoft.com/learn/paths/build-ai-solutions-with-azure-ml-service/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Build and operate machine learning solutions with Azure Machine Learning&lt;/a&gt; and &lt;a href=&quot;https://docs.microsoft.com/learn/paths/build-operate-machine-learning-solutions-azure-databricks/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Build and Operate Machine Learning Solutions with Azure Databricks&lt;/a&gt; learning paths.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversational AI&lt;/strong&gt; and &lt;strong&gt;Chat Bots&lt;/strong&gt;. There is a separate &lt;a href=&quot;https://docs.microsoft.com/learn/paths/create-conversational-ai-solutions/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Create conversational AI solutions&lt;/a&gt; learning path, and you can also refer to &lt;a href=&quot;https://soshnikov.com/azure/hello-bot-conversational-ai-on-microsoft-platform/&quot;&gt;this blog post&lt;/a&gt; for more detail.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Mathematics&lt;/strong&gt; behind deep learning. For this, we would recommend &lt;a href=&quot;https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618&quot;&gt;Deep Learning&lt;/a&gt; by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at &lt;a href=&quot;https://www.deeplearningbook.org/&quot;&gt;https://www.deeplearningbook.org/&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a gentle introduction to &lt;em&gt;AI in the Cloud&lt;/em&gt; topics you may consider taking the &lt;a href=&quot;https://docs.microsoft.com/learn/paths/get-started-with-artificial-intelligence-on-azure/?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Get started with artificial intelligence on Azure&lt;/a&gt; Learning Path.&lt;/p&gt; 
&lt;h1&gt;Content&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Lesson Link&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;PyTorch/Keras/TensorFlow&lt;/th&gt; 
   &lt;th&gt;Lab&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;0&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/setup.md&quot;&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/0-course-setup/how-to-run.md&quot;&gt;Setup Your Development Environment&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;I&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md&quot;&gt;&lt;strong&gt;Introduction to AI&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;01&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/1-Intro/README.md&quot;&gt;Introduction and History of AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;II&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;Symbolic AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;02&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/2-Symbolic/README.md&quot;&gt;Knowledge Representation and Expert Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/2-Symbolic/Animals.ipynb&quot;&gt;Expert Systems&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/2-Symbolic/FamilyOntology.ipynb&quot;&gt;Ontology&lt;/a&gt; /&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/2-Symbolic/MSConceptGraph.ipynb&quot;&gt;Concept Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;III&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/README.md&quot;&gt;&lt;strong&gt;Introduction to Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;03&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/README.md&quot;&gt;Perceptron&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb&quot;&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/03-Perceptron/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;04&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/README.md&quot;&gt;Multi-Layered Perceptron and Creating our own Framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb&quot;&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;05&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/README.md&quot;&gt;Intro to Frameworks (PyTorch/TensorFlow) and Overfitting&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb&quot;&gt;Keras&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/3-NeuralNetworks/05-Frameworks/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;IV&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/README.md&quot;&gt;&lt;strong&gt;Computer Vision&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.microsoft.com/learn/modules/intro-computer-vision-pytorch/?WT.mc_id=academic-77998-cacaste&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://docs.microsoft.com/learn/modules/intro-computer-vision-TensorFlow/?WT.mc_id=academic-77998-cacaste&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Explore Computer Vision on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;06&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/README.md&quot;&gt;Intro to Computer Vision. OpenCV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/06-IntroCV/OpenCV.ipynb&quot;&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/06-IntroCV/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;07&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/README.md&quot;&gt;Convolutional Neural Networks&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md&quot;&gt;CNN Architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/07-ConvNets/ConvNetsPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; /&lt;a href=&quot;https://microsoft.github.io/AI-For-Beginners/lessons/4-ComputerVision/07-ConvNets/ConvNetsTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/07-ConvNets/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;08&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/README.md&quot;&gt;Pre-trained Networks and Transfer Learning&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/TrainingTricks.md&quot;&gt;Training Tricks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/08-TransferLearning/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;09&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/09-Autoencoders/README.md&quot;&gt;Autoencoders and VAEs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;10&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/10-GANs/README.md&quot;&gt;Generative Adversarial Networks &amp;amp; Artistic Style Transfer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/10-GANs/GANTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;11&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/README.md&quot;&gt;Object Detection&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/11-ObjectDetection/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;12&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/4-ComputerVision/12-Segmentation/README.md&quot;&gt;Semantic Segmentation. U-Net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/(https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb)&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;V&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/README.md&quot;&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste&quot;&gt;PyTorch&lt;/a&gt; /&lt;a href=&quot;https://docs.microsoft.com/learn/modules/intro-natural-language-processing-TensorFlow/?WT.mc_id=academic-77998-cacaste&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum&quot;&gt;Explore Natural Language Processing on Microsoft Azure&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;13&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/13-TextRep/README.md&quot;&gt;Text Representation. Bow/TF-IDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/13-TextRep/TextRepresentationTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;14&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/14-Embeddings/README.md&quot;&gt;Semantic word embeddings. Word2Vec and GloVe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/14-Embeddings/EmbeddingsTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;15&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/README.md&quot;&gt;Language Modeling. Training your own embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-PyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/15-LanguageModeling/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;16&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/16-RNN/README.md&quot;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/16-RNN/RNNTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;17&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/README.md&quot;&gt;Generative Recurrent Networks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/17-GenerativeNetworks/GenerativePyTorch.md&quot;&gt;PyTorch&lt;/a&gt; / &lt;a href=&quot;https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.md&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/17-GenerativeNetworks/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;18&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/18-Transformers/READMEtransformers.md&quot;&gt;Transformers. BERT.&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; /&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/5-NLP/18-Transformers/TransformersTF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;19&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/README.md&quot;&gt;Named Entity Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/19-NER/NER-TF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/19-NER/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;20&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/5-NLP/20-LangModels/READMELargeLang.md&quot;&gt;Large Language Models, Prompt Programming and Few-Shot Tasks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://microsoft.github.io/AI-For-Beginners/lessons/5-NLP/20-LangModels/GPT-PyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;VI&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;Other AI Techniques&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;21&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/21-GeneticAlgorithms/README.md&quot;&gt;Genetic Algorithms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/6-Other/21-GeneticAlgorithms/Genetic.ipynb&quot;&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;22&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/README.md&quot;&gt;Deep Reinforcement Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/6-Other/22-DeepRL/CartPole-RL-PyTorch.ipynb&quot;&gt;PyTorch&lt;/a&gt; /&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/6-Other/22-DeepRL/CartPole-RL-TF.ipynb&quot;&gt;TensorFlow&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/22-DeepRL/lab/README.md&quot;&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;23&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/6-Other/23-MultiagentSystems/README.md&quot;&gt;Multi-Agent Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;VII&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;AI Ethics&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;24&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/7-Ethics/README.md&quot;&gt;AI Ethics and Responsible AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.microsoft.com/learn/paths/responsible-ai-business-principles/?WT.mc_id=academic-77998-cacaste&quot;&gt;Microsoft Learn: Responsible AI Principles&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;IX&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;strong&gt;Extras&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;25&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/lessons/X-Extras/X1-MultiModal/README.md&quot;&gt;Multi-Modal Networks, CLIP and VQGAN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/X-Extras/X1-MultiModal/Clip.ipynb&quot;&gt;Notebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Each lesson contains&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pre-reading material&lt;/li&gt; 
 &lt;li&gt;Executable Jupyter Notebooks, which are often specific to the framework (&lt;strong&gt;PyTorch&lt;/strong&gt; or &lt;strong&gt;TensorFlow&lt;/strong&gt;). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebook (either PyTorch or TensorFlow).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Labs&lt;/strong&gt; available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.&lt;/li&gt; 
 &lt;li&gt;Some sections contain links to &lt;a href=&quot;https://learn.microsoft.com/en-us/collections/7w28iy2xrqzdj0?WT.mc_id=academic-77998-bethanycheum&quot;&gt;&lt;strong&gt;MS Learn&lt;/strong&gt;&lt;/a&gt; modules that cover related topics.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We have created a &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/0-course-setup/setup.md&quot;&gt;setup lesson&lt;/a&gt; to help you with setting up your development environment. - For Educators, we have created a &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/0-course-setup/for-teachers.md&quot;&gt;curricula setup lesson&lt;/a&gt; for you too!&lt;/li&gt; 
 &lt;li&gt;How to &lt;a href=&quot;https://github.com/microsoft/AI-For-Beginners/raw/main/lessons/0-course-setup/how-to-run.md&quot;&gt;Run the code in a VSCode or a Codepace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Follow these steps:&lt;/p&gt; 
&lt;p&gt;Fork the Repository: Click on the &quot;Fork&quot; button at the top-right corner of this page.&lt;/p&gt; 
&lt;p&gt;Clone the Repository: &lt;code&gt;git clone https://github.com/microsoft/AI-For-Beginners.git&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Don&#39;t forget to star (ğŸŒŸ) this repo to find it easier later.&lt;/p&gt; 
&lt;h2&gt;Meet other Learners&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href=&quot;https://aka.ms/genai-discord?WT.mc_id=academic-105485-bethanycheum&quot;&gt;official AI Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;If you have product feedback or questions whilst building visit our &lt;a href=&quot;https://aka.ms/foundry/forum&quot;&gt;Azure AI Foundry Developer Forum&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quizzes&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained in the Quiz-app folder in etc\quiz-app, They are linked from within the lessons the quiz app can be run locally or deployed to Azure; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder. They are gradually being localized.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Help Wanted&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? Raise an issue or create a pull request.&lt;/p&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âœï¸ Primary Author:&lt;/strong&gt; &lt;a href=&quot;http://soshnikov.com&quot;&gt;Dmitry Soshnikov&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”¥ Editor:&lt;/strong&gt; &lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen Looper&lt;/a&gt;, PhD&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Sketchnote illustrator:&lt;/strong&gt; &lt;a href=&quot;https://twitter.com/girlie_mac&quot;&gt;Tomomi Imura&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âœ… Quiz Creator:&lt;/strong&gt; &lt;a href=&quot;https://github.com/CinnamonXI&quot;&gt;Lateefah Bello&lt;/a&gt;, &lt;a href=&quot;https://studentambassadors.microsoft.com/&quot;&gt;MLSA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ™ Core Contributors:&lt;/strong&gt; &lt;a href=&quot;https://github.com/Pe4enIks&quot;&gt;Evgenii Pishchik&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Curricula&lt;/h2&gt; 
&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/genai-beginners&quot;&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet&quot;&gt;Generative AI for Beginners .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/generative-ai-with-javascript&quot;&gt;Generative AI with JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-java&quot;&gt;Generative AI with Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming&quot;&gt;Mastering GitHub Copilot for Agentic use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>patchy631/ai-engineering-hub</title>
      <link>https://github.com/patchy631/ai-engineering-hub</link>
      <description>&lt;p&gt;In-depth tutorials on LLMs, RAGs and real-world AI agent applications.&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://trendshift.io/repositories/12800&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/assets/TRENDING-BADGE.png&quot; alt=&quot;Trending Badge&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/assets/ai-eng-hub.gif&quot; alt=&quot;AI Engineering Hub Banner&quot; /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;AI Engineering Hub ğŸš€&lt;/h1&gt; 
&lt;p&gt;Welcome to the &lt;strong&gt;AI Engineering Hub&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Why This Repo?&lt;/h2&gt; 
&lt;p&gt;AI Engineering is advancing rapidly, and staying at the forefront requires both deep understanding and hands-on experience. Here, you will find:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In-depth tutorials on &lt;strong&gt;LLMs and RAGs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Real-world &lt;strong&gt;AI agent&lt;/strong&gt; applications&lt;/li&gt; 
 &lt;li&gt;Examples to implement, adapt, and scale in your projects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Whether youâ€™re a beginner, practitioner, or researcher, this repo provides resources for all skill levels to experiment and succeed in AI engineering.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“¬ Stay Updated with Our Newsletter!&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Get a FREE Data Science eBook&lt;/strong&gt; ğŸ“– with 150+ essential lessons in Data Science when you subscribe to our newsletter! Stay in the loop with the latest tutorials, insights, and exclusive resources. &lt;a href=&quot;https://join.dailydoseofds.com&quot;&gt;Subscribe now!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://join.dailydoseofds.com&quot;&gt;&lt;img src=&quot;https://github.com/patchy631/ai-engineering/raw/main/resources/join_ddods.png&quot; alt=&quot;Daily Dose of Data Science Newsletter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“¢ Contribute to the AI Engineering Hub!&lt;/h2&gt; 
&lt;p&gt;We welcome contributors! Whether you want to add new tutorials, improve existing code, or report issues, your contributions make this community thrive. Hereâ€™s how to get involved:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork&lt;/strong&gt; the repository.&lt;/li&gt; 
 &lt;li&gt;Create a new branch for your contribution.&lt;/li&gt; 
 &lt;li&gt;Submit a &lt;strong&gt;Pull Request&lt;/strong&gt; and describe the improvements.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“œ License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the MIT License - see the &lt;a href=&quot;https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ’¬ Connect&lt;/h2&gt; 
&lt;p&gt;For discussions, suggestions, and more, feel free to &lt;a href=&quot;https://github.com/patchy631/ai-engineering/issues&quot;&gt;create an issue&lt;/a&gt; or reach out directly!&lt;/p&gt; 
&lt;p&gt;Happy Coding! ğŸ‰&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>facebookresearch/segment-anything</title>
      <link>https://github.com/facebookresearch/segment-anything</link>
      <description>&lt;p&gt;The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Latest updates -- SAM 2: Segment Anything in Images and Videos&lt;/h2&gt; 
&lt;p&gt;Please check out our new release on &lt;a href=&quot;https://github.com/facebookresearch/segment-anything-2&quot;&gt;&lt;strong&gt;Segment Anything Model 2 (SAM 2)&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SAM 2 code: &lt;a href=&quot;https://github.com/facebookresearch/segment-anything-2&quot;&gt;https://github.com/facebookresearch/segment-anything-2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SAM 2 demo: &lt;a href=&quot;https://sam2.metademolab.com/&quot;&gt;https://sam2.metademolab.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SAM 2 paper: &lt;a href=&quot;https://arxiv.org/abs/2408.00714&quot;&gt;https://arxiv.org/abs/2408.00714&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/facebookresearch/segment-anything-2/raw/main/assets/model_diagram.png?raw=true&quot; alt=&quot;SAM 2 architecture&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Segment Anything Model 2 (SAM 2)&lt;/strong&gt; is a foundation model towards solving promptable visual segmentation in images and videos. We extend SAM to video by considering images as a video with a single frame. The model design is a simple transformer architecture with streaming memory for real-time video processing. We build a model-in-the-loop data engine, which improves model and data via user interaction, to collect &lt;a href=&quot;https://ai.meta.com/datasets/segment-anything-video&quot;&gt;&lt;strong&gt;our SA-V dataset&lt;/strong&gt;&lt;/a&gt;, the largest video segmentation dataset to date. SAM 2 trained on our data provides strong performance across a wide range of tasks and visual domains.&lt;/p&gt; 
&lt;h1&gt;Segment Anything&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ai.facebook.com/research/&quot;&gt;Meta AI Research, FAIR&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://alexander-kirillov.github.io/&quot;&gt;Alexander Kirillov&lt;/a&gt;, &lt;a href=&quot;https://ericmintun.github.io/&quot;&gt;Eric Mintun&lt;/a&gt;, &lt;a href=&quot;https://nikhilaravi.com/&quot;&gt;Nikhila Ravi&lt;/a&gt;, &lt;a href=&quot;https://hanzimao.me/&quot;&gt;Hanzi Mao&lt;/a&gt;, Chloe Rolland, Laura Gustafson, &lt;a href=&quot;https://tetexiao.com&quot;&gt;Tete Xiao&lt;/a&gt;, &lt;a href=&quot;https://www.spencerwhitehead.com/&quot;&gt;Spencer Whitehead&lt;/a&gt;, Alex Berg, Wan-Yen Lo, &lt;a href=&quot;https://pdollar.github.io/&quot;&gt;Piotr Dollar&lt;/a&gt;, &lt;a href=&quot;https://www.rossgirshick.info/&quot;&gt;Ross Girshick&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[&lt;a href=&quot;https://ai.facebook.com/research/publications/segment-anything/&quot;&gt;&lt;code&gt;Paper&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://segment-anything.com/&quot;&gt;&lt;code&gt;Project&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://segment-anything.com/demo&quot;&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://segment-anything.com/dataset/index.html&quot;&gt;&lt;code&gt;Dataset&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/&quot;&gt;&lt;code&gt;Blog&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/#citing-segment-anything&quot;&gt;&lt;code&gt;BibTeX&lt;/code&gt;&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/assets/model_diagram.png?raw=true&quot; alt=&quot;SAM design&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Segment Anything Model (SAM)&lt;/strong&gt; produces high quality object masks from input prompts such as points or boxes, and it can be used to generate masks for all objects in an image. It has been trained on a &lt;a href=&quot;https://segment-anything.com/dataset/index.html&quot;&gt;dataset&lt;/a&gt; of 11 million images and 1.1 billion masks, and has strong zero-shot performance on a variety of segmentation tasks.&lt;/p&gt; 
&lt;p float=&quot;left&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/assets/masks1.png?raw=true&quot; width=&quot;37.25%&quot; /&gt; &lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/assets/masks2.jpg?raw=true&quot; width=&quot;61.5%&quot; /&gt; &lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The code requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;, as well as &lt;code&gt;pytorch&amp;gt;=1.7&lt;/code&gt; and &lt;code&gt;torchvision&amp;gt;=0.8&lt;/code&gt;. Please follow the instructions &lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;here&lt;/a&gt; to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.&lt;/p&gt; 
&lt;p&gt;Install Segment Anything:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install git+https://github.com/facebookresearch/segment-anything.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or clone the repository locally and install with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone git@github.com:facebookresearch/segment-anything.git
cd segment-anything; pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following optional dependencies are necessary for mask post-processing, saving masks in COCO format, the example notebooks, and exporting the model in ONNX format. &lt;code&gt;jupyter&lt;/code&gt; is also required to run the example notebooks.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install opencv-python pycocotools matplotlib onnxruntime onnx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;a name=&quot;GettingStarted&quot;&gt;&lt;/a&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;First download a &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/#model-checkpoints&quot;&gt;model checkpoint&lt;/a&gt;. Then the model can be used in just a few lines to get masks from a given prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from segment_anything import SamPredictor, sam_model_registry
sam = sam_model_registry[&quot;&amp;lt;model_type&amp;gt;&quot;](checkpoint=&quot;&amp;lt;path/to/checkpoint&amp;gt;&quot;)
predictor = SamPredictor(sam)
predictor.set_image(&amp;lt;your_image&amp;gt;)
masks, _, _ = predictor.predict(&amp;lt;input_prompts&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or generate masks for an entire image:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from segment_anything import SamAutomaticMaskGenerator, sam_model_registry
sam = sam_model_registry[&quot;&amp;lt;model_type&amp;gt;&quot;](checkpoint=&quot;&amp;lt;path/to/checkpoint&amp;gt;&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
masks = mask_generator.generate(&amp;lt;your_image&amp;gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, masks can be generated for images from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/amg.py --checkpoint &amp;lt;path/to/checkpoint&amp;gt; --model-type &amp;lt;model_type&amp;gt; --input &amp;lt;image_or_folder&amp;gt; --output &amp;lt;path/to/output&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the examples notebooks on &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/predictor_example.ipynb&quot;&gt;using SAM with prompts&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/automatic_mask_generator_example.ipynb&quot;&gt;automatically generating masks&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p float=&quot;left&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/assets/notebook1.png?raw=true&quot; width=&quot;49.1%&quot; /&gt; &lt;img src=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/assets/notebook2.png?raw=true&quot; width=&quot;48.9%&quot; /&gt; &lt;/p&gt; 
&lt;h2&gt;ONNX Export&lt;/h2&gt; 
&lt;p&gt;SAM&#39;s lightweight mask decoder can be exported to ONNX format so that it can be run in any environment that supports ONNX runtime, such as in-browser as showcased in the &lt;a href=&quot;https://segment-anything.com/demo&quot;&gt;demo&lt;/a&gt;. Export the model with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python scripts/export_onnx_model.py --checkpoint &amp;lt;path/to/checkpoint&amp;gt; --model-type &amp;lt;model_type&amp;gt; --output &amp;lt;path/to/output&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://github.com/facebookresearch/segment-anything/raw/main/notebooks/onnx_model_example.ipynb&quot;&gt;example notebook&lt;/a&gt; for details on how to combine image preprocessing via SAM&#39;s backbone with mask prediction using the ONNX model. It is recommended to use the latest stable version of PyTorch for ONNX export.&lt;/p&gt; 
&lt;h3&gt;Web demo&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;demo/&lt;/code&gt; folder has a simple one page React app which shows how to run mask prediction with the exported ONNX model in a web browser with multithreading. Please see &lt;a href=&quot;https://github.com/facebookresearch/segment-anything/raw/main/demo/README.md&quot;&gt;&lt;code&gt;demo/README.md&lt;/code&gt;&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;&lt;a name=&quot;Models&quot;&gt;&lt;/a&gt;Model Checkpoints&lt;/h2&gt; 
&lt;p&gt;Three model versions of the model are available with different backbone sizes. These models can be instantiated by running&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from segment_anything import sam_model_registry
sam = sam_model_registry[&quot;&amp;lt;model_type&amp;gt;&quot;](checkpoint=&quot;&amp;lt;path/to/checkpoint&amp;gt;&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Click the links below to download the checkpoint for the corresponding model type.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;default&lt;/code&gt; or &lt;code&gt;vit_h&lt;/code&gt;: &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth&quot;&gt;ViT-H SAM model.&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vit_l&lt;/code&gt;: &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth&quot;&gt;ViT-L SAM model.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vit_b&lt;/code&gt;: &lt;a href=&quot;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth&quot;&gt;ViT-B SAM model.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Dataset&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://ai.facebook.com/datasets/segment-anything/&quot;&gt;here&lt;/a&gt; for an overview of the datastet. The dataset can be downloaded &lt;a href=&quot;https://ai.facebook.com/datasets/segment-anything-downloads/&quot;&gt;here&lt;/a&gt;. By downloading the datasets you agree that you have read and accepted the terms of the SA-1B Dataset Research License.&lt;/p&gt; 
&lt;p&gt;We save masks per image as a json file. It can be loaded as a dictionary in python in the below format.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;{
    &quot;image&quot;                 : image_info,
    &quot;annotations&quot;           : [annotation],
}

image_info {
    &quot;image_id&quot;              : int,              # Image id
    &quot;width&quot;                 : int,              # Image width
    &quot;height&quot;                : int,              # Image height
    &quot;file_name&quot;             : str,              # Image filename
}

annotation {
    &quot;id&quot;                    : int,              # Annotation id
    &quot;segmentation&quot;          : dict,             # Mask saved in COCO RLE format.
    &quot;bbox&quot;                  : [x, y, w, h],     # The box around the mask, in XYWH format
    &quot;area&quot;                  : int,              # The area in pixels of the mask
    &quot;predicted_iou&quot;         : float,            # The model&#39;s own prediction of the mask&#39;s quality
    &quot;stability_score&quot;       : float,            # A measure of the mask&#39;s quality
    &quot;crop_box&quot;              : [x, y, w, h],     # The crop of the image used to generate the mask, in XYWH format
    &quot;point_coords&quot;          : [[x, y]],         # The point coordinates input to the model to generate the mask
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Image ids can be found in sa_images_ids.txt which can be downloaded using the above &lt;a href=&quot;https://ai.facebook.com/datasets/segment-anything-downloads/&quot;&gt;link&lt;/a&gt; as well.&lt;/p&gt; 
&lt;p&gt;To decode a mask in COCO RLE format into binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from pycocotools import mask as mask_utils
mask = mask_utils.decode(annotation[&quot;segmentation&quot;])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/cocodataset/cocoapi/raw/master/PythonAPI/pycocotools/mask.py&quot;&gt;here&lt;/a&gt; for more instructions to manipulate masks stored in RLE format.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The model is licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/LICENSE&quot;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/CONTRIBUTING.md&quot;&gt;contributing&lt;/a&gt; and the &lt;a href=&quot;https://raw.githubusercontent.com/facebookresearch/segment-anything/main/CODE_OF_CONDUCT.md&quot;&gt;code of conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;The Segment Anything project was made possible with the help of many contributors (alphabetical):&lt;/p&gt; 
&lt;p&gt;Aaron Adcock, Vaibhav Aggarwal, Morteza Behrooz, Cheng-Yang Fu, Ashley Gabriel, Ahuva Goldstand, Allen Goodman, Sumanth Gurram, Jiabo Hu, Somya Jain, Devansh Kukreja, Robert Kuo, Joshua Lane, Yanghao Li, Lilian Luong, Jitendra Malik, Mallika Malhotra, William Ngan, Omkar Parkhi, Nikhil Raina, Dirk Rowe, Neil Sejoor, Vanessa Stark, Bala Varadarajan, Bram Wasti, Zachary Winstrom&lt;/p&gt; 
&lt;h2&gt;Citing Segment Anything&lt;/h2&gt; 
&lt;p&gt;If you use SAM or SA-1B in your research, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{kirillov2023segany,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\&#39;a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>microsoft/Data-Science-For-Beginners</title>
      <link>https://github.com/microsoft/Data-Science-For-Beginners</link>
      <description>&lt;p&gt;10 Weeks, 20 Lessons, Data Science for All!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Science for Beginners - A Curriculum&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=main&amp;amp;repo=344191198&quot;&gt;&lt;img src=&quot;https://github.com/codespaces/badge.svg?sanitize=true&quot; alt=&quot;Open in GitHub Codespaces&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/Data-Science-For-Beginners/raw/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/Data-Science-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/graphs/contributors/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/Data-Science-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/issues/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/Data-Science-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/pulls/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/Data-Science-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/watchers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/Data-Science-For-Beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/network/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/Data-Science-For-Beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Data-Science-For-Beginners/stargazers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/Data-Science-For-Beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/zxKYvhSnVp?WT.mc_id=academic-000002-leestott&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/ByRwuEEgH4&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://aka.ms/foundry/forum&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-Azure_AI_Foundry_Developer_Forum-blue?style=for-the-badge&amp;amp;logo=github&amp;amp;color=000000&amp;amp;logoColor=fff&quot; alt=&quot;Azure AI Foundry Developer Forum&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Azure Cloud Advocates at Microsoft are pleased to offer a 10-week, 20-lesson curriculum all about Data Science. Each lesson includes pre-lesson and post-lesson quizzes, written instructions to complete the lesson, a solution, and an assignment. Our project-based pedagogy allows you to learn while building, a proven way for new skills to &#39;stick&#39;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hearty thanks to our authors:&lt;/strong&gt; &lt;a href=&quot;https://www.twitter.com/paladique&quot;&gt;Jasmine Greenaway&lt;/a&gt;, &lt;a href=&quot;http://soshnikov.com&quot;&gt;Dmitry Soshnikov&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/nitya&quot;&gt;Nitya Narasimhan&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/JalenMcG&quot;&gt;Jalen McGee&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen Looper&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/maudstweets&quot;&gt;Maud Levy&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/TiffanySouterre&quot;&gt;Tiffany Souterre&lt;/a&gt;, &lt;a href=&quot;https://www.twitter.com/geektrainer&quot;&gt;Christopher Harrison&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ™ Special thanks ğŸ™ to our &lt;a href=&quot;https://studentambassadors.microsoft.com/&quot;&gt;Microsoft Student Ambassador&lt;/a&gt; authors, reviewers and content contributors,&lt;/strong&gt; notably Aaryan Arora, &lt;a href=&quot;https://github.com/AdityaGarg00&quot;&gt;Aditya Garg&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/alondra-sanchez-molina/&quot;&gt;Alondra Sanchez&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/ankitasingh007&quot;&gt;Ankita Singh&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/anupam--mishra/&quot;&gt;Anupam Mishra&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/arpitadas01/&quot;&gt;Arpita Das&lt;/a&gt;, ChhailBihari Dubey, &lt;a href=&quot;https://www.linkedin.com/in/dibrinsofor&quot;&gt;Dibri Nsofor&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/dishita-bhasin-7065281bb&quot;&gt;Dishita Bhasin&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/majd-s/&quot;&gt;Majd Safi&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/max-blum-6036a1186/&quot;&gt;Max Blum&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/miguelmque/&quot;&gt;Miguel Correa&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/iftu119&quot;&gt;Mohamma Iftekher (Iftu) Ebne Jalal&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/nawrin-tabassum&quot;&gt;Nawrin Tabassum&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/raymond-wp/&quot;&gt;Raymond Wangsa Putra&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/rty2423&quot;&gt;Rohit Yadav&lt;/a&gt;, Samridhi Sharma, &lt;a href=&quot;https://www.linkedin.com/mwlite/in/sanya-sinha-13aab1200&quot;&gt;Sanya Sinha&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/sheena-narua-n/&quot;&gt;Sheena Narula&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/tauqeerahmad5201/&quot;&gt;Tauqeer Ahmad&lt;/a&gt;, Yogendrasingh Pawar , &lt;a href=&quot;https://www.linkedin.com/in/vidushi-gupta07/&quot;&gt;Vidushi Gupta&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/jasleen-sondhi/&quot;&gt;Jasleen Sondhi&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/sketchnotes/00-Title.png&quot; alt=&quot; Sketchnote by (@sketchthedocs) &quot; /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science For Beginners - &lt;em&gt;Sketchnote by &lt;a href=&quot;https://twitter.com/nitya&quot;&gt;@nitya&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Announcement - New Curriculum on Generative AI was just released!&lt;/h2&gt; 
&lt;p&gt;We just released a 12 lesson curriculum on generative AI. Come learn things like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;prompting and prompt engineering&lt;/li&gt; 
 &lt;li&gt;text and image app generation&lt;/li&gt; 
 &lt;li&gt;search apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As usual, there&#39;s a lesson, assignments to complete, knowledge checks and challenges.&lt;/p&gt; 
&lt;p&gt;Check it out:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-beginners&quot;&gt;https://aka.ms/genai-beginners&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Are you a student?&lt;/h1&gt; 
&lt;p&gt;Get started with the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-gb/learn/student-hub?WT.mc_id=academic-77958-bethanycheum&quot;&gt;Student Hub page&lt;/a&gt; In this page, you will find beginner resources, Student packs and even ways to get a free cert voucher. This is one page you want to bookmark and check from time to time as we switch out content at least monthly.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://studentambassadors.microsoft.com?WT.mc_id=academic-77958-bethanycheum&quot;&gt;Microsoft Learn Student Ambassadors&lt;/a&gt; Join a global community of student ambassadors, this could be your way into Microsoft.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Teachers&lt;/strong&gt;: we have &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/for-teachers.md&quot;&gt;included some suggestions&lt;/a&gt; on how to use this curriculum. We&#39;d love your feedback &lt;a href=&quot;https://github.com/microsoft/Data-Science-For-Beginners/discussions&quot;&gt;in our discussion forum&lt;/a&gt;!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aka.ms/student-page&quot;&gt;Students&lt;/a&gt;&lt;/strong&gt;: to use this curriculum on your own, fork the entire repo and complete the exercises on your own, starting with a pre-lecture quiz. Then read the lecture and complete the rest of the activities. Try to create the projects by comprehending the lessons rather than copying the solution code; however, that code is available in the /solutions folders in each project-oriented lesson. Another idea would be to form a study group with friends and go through the content together. For further study, we recommend &lt;a href=&quot;https://docs.microsoft.com/en-us/users/jenlooper-2911/collections/qprpajyoy3x0g7?WT.mc_id=academic-77958-bethanycheum&quot;&gt;Microsoft Learn&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Meet the Team&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://youtu.be/8mzavjQSMM4&quot; title=&quot;Promo video&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/ds-for-beginners.gif&quot; alt=&quot;Promo video&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gif by&lt;/strong&gt; &lt;a href=&quot;https://www.linkedin.com/in/mohitjaisal&quot;&gt;Mohit Jaisal&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ¥ Click the image above for a video about the project the folks who created it!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Pedagogy&lt;/h2&gt; 
&lt;p&gt;We have chosen two pedagogical tenets while building this curriculum: ensuring that it is project-based and that it includes frequent quizzes. By the end of this series, students will have learned basic principles of data science, including ethical concepts, data preparation, different ways of working with data, data visualization, data analysis, real-world use cases of data science, and more.&lt;/p&gt; 
&lt;p&gt;In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 10 week cycle.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Find our &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/CODE_OF_CONDUCT.md&quot;&gt;Code of Conduct&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/CONTRIBUTING.md&quot;&gt;Contributing&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/TRANSLATIONS.md&quot;&gt;Translation&lt;/a&gt; guidelines. We welcome your constructive feedback!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Each lesson includes:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optional sketchnote&lt;/li&gt; 
 &lt;li&gt;Optional supplemental video&lt;/li&gt; 
 &lt;li&gt;Pre-lesson warmup quiz&lt;/li&gt; 
 &lt;li&gt;Written lesson&lt;/li&gt; 
 &lt;li&gt;For project-based lessons, step-by-step guides on how to build the project&lt;/li&gt; 
 &lt;li&gt;Knowledge checks&lt;/li&gt; 
 &lt;li&gt;A challenge&lt;/li&gt; 
 &lt;li&gt;Supplemental reading&lt;/li&gt; 
 &lt;li&gt;Assignment&lt;/li&gt; 
 &lt;li&gt;Post-lesson quiz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;A note about quizzes&lt;/strong&gt;: All quizzes are contained in the Quiz-App folder, for 40 total quizzes of three questions each. They are linked from within the lessons, but the quiz app can be run locally or deployed to Azure; follow the instruction in the &lt;code&gt;quiz-app&lt;/code&gt; folder. They are gradually being localized.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/sketchnotes/00-Roadmap.png&quot; alt=&quot; Sketchnote by (@sketchthedocs) &quot; /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science For Beginners: Roadmap - &lt;em&gt;Sketchnote by &lt;a href=&quot;https://twitter.com/nitya&quot;&gt;@nitya&lt;/a&gt;&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;center&quot;&gt;Lesson Number&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Topic&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Lesson Grouping&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Learning Objectives&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Linked Lesson&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;Author&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;01&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Defining Data Science&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/README.md&quot;&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Learn the basic concepts behind data science and how itâ€™s related to artificial intelligence, machine learning, and big data.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/01-defining-data-science/README.md&quot;&gt;lesson&lt;/a&gt; &lt;a href=&quot;https://youtu.be/beZ7Mb_oz9I&quot;&gt;video&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;http://soshnikov.com&quot;&gt;Dmitry&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;02&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science Ethics&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/README.md&quot;&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Ethics Concepts, Challenges &amp;amp; Frameworks.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/02-ethics/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/nitya&quot;&gt;Nitya&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;03&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Defining Data&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/README.md&quot;&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;How data is classified and its common sources.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/03-defining-data/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.twitter.com/paladique&quot;&gt;Jasmine&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;04&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Introduction to Statistics &amp;amp; Probability&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/README.md&quot;&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;The mathematical techniques of probability and statistics to understand data.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/1-Introduction/04-stats-and-probability/README.md&quot;&gt;lesson&lt;/a&gt; &lt;a href=&quot;https://youtu.be/Z5Zy85g4Yjw&quot;&gt;video&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;http://soshnikov.com&quot;&gt;Dmitry&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;05&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Working with Relational Data&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/README.md&quot;&gt;Working With Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Introduction to relational data and the basics of exploring and analyzing relational data with the Structured Query Language, also known as SQL (pronounced â€œsee-quellâ€).&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/05-relational-databases/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.twitter.com/geektrainer&quot;&gt;Christopher&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;06&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Working with NoSQL Data&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/README.md&quot;&gt;Working With Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Introduction to non-relational data, its various types and the basics of exploring and analyzing document databases.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/06-non-relational/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/paladique&quot;&gt;Jasmine&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;07&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Working with Python&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/README.md&quot;&gt;Working With Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Basics of using Python for data exploration with libraries such as Pandas. Foundational understanding of Python programming is recommended.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/07-python/README.md&quot;&gt;lesson&lt;/a&gt; &lt;a href=&quot;https://youtu.be/dZjWOGbsN4Y&quot;&gt;video&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;http://soshnikov.com&quot;&gt;Dmitry&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;08&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Preparation&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/README.md&quot;&gt;Working With Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Topics on data techniques for cleaning and transforming the data to handle challenges of missing, inaccurate, or incomplete data.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/2-Working-With-Data/08-data-preparation/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.twitter.com/paladique&quot;&gt;Jasmine&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;09&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing Quantities&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/README.md&quot;&gt;Data Visualization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Learn how to use Matplotlib to visualize bird data ğŸ¦†&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/09-visualization-quantities/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;10&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing Distributions of Data&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/README.md&quot;&gt;Data Visualization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing observations and trends within an interval.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/10-visualization-distributions/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;11&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing Proportions&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/README.md&quot;&gt;Data Visualization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing discrete and grouped percentages.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/11-visualization-proportions/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;12&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing Relationships&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/README.md&quot;&gt;Data Visualization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Visualizing connections and correlations between sets of data and their variables.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/12-visualization-relationships/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;13&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Meaningful Visualizations&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/README.md&quot;&gt;Data Visualization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Techniques and guidance for making your visualizations valuable for effective problem solving and insights.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/3-Data-Visualization/13-meaningful-visualizations/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/jenlooper&quot;&gt;Jen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;14&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Introduction to the Data Science lifecycle&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/README.md&quot;&gt;Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Introduction to the data science lifecycle and its first step of acquiring and extracting data.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/14-Introduction/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/paladique&quot;&gt;Jasmine&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;15&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Analyzing&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/README.md&quot;&gt;Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;This phase of the data science lifecycle focuses on techniques to analyze data.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/15-analyzing/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/paladique&quot;&gt;Jasmine&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;16&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Communication&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/README.md&quot;&gt;Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;This phase of the data science lifecycle focuses on presenting the insights from the data in a way that makes it easier for decision makers to understand.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/4-Data-Science-Lifecycle/16-communication/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/JalenMcG&quot;&gt;Jalen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;17&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science in the Cloud&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/README.md&quot;&gt;Cloud Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;This series of lessons introduces data science in the cloud and its benefits.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/17-Introduction/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/TiffanySouterre&quot;&gt;Tiffany&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/maudstweets&quot;&gt;Maud&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;18&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science in the Cloud&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/README.md&quot;&gt;Cloud Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Training models using Low Code tools.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/18-Low-Code/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/TiffanySouterre&quot;&gt;Tiffany&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/maudstweets&quot;&gt;Maud&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;19&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science in the Cloud&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/README.md&quot;&gt;Cloud Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Deploying models with Azure Machine Learning Studio.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/5-Data-Science-In-Cloud/19-Azure/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/TiffanySouterre&quot;&gt;Tiffany&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/maudstweets&quot;&gt;Maud&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;20&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data Science in the Wild&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/6-Data-Science-In-Wild/README.md&quot;&gt;In the Wild&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Data science driven projects in the real world.&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/6-Data-Science-In-Wild/20-Real-World-Examples/README.md&quot;&gt;lesson&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://twitter.com/nitya&quot;&gt;Nitya&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;GitHub Codespaces&lt;/h2&gt; 
&lt;p&gt;Follow these steps to open this sample in a Codespace:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Click the Code drop-down menu and select the Open with Codespaces option.&lt;/li&gt; 
 &lt;li&gt;Select + New codespace at the bottom on the pane. For more info, check out the &lt;a href=&quot;https://docs.github.com/en/codespaces/developing-in-codespaces/creating-a-codespace-for-a-repository#creating-a-codespace&quot;&gt;GitHub documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;VSCode Remote - Containers&lt;/h2&gt; 
&lt;p&gt;Follow these steps to open this repo in a container using your local machine and VSCode using the VS Code Remote - Containers extension:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;If this is your first time using a development container, please ensure your system meets the pre-reqs (i.e. have Docker installed) in &lt;a href=&quot;https://code.visualstudio.com/docs/devcontainers/containers#_getting-started&quot;&gt;the getting started documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To use this repository, you can either open the repository in an isolated Docker volume:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Under the hood, this will use the Remote-Containers: &lt;strong&gt;Clone Repository in Container Volume...&lt;/strong&gt; command to clone the source code in a Docker volume instead of the local filesystem. &lt;a href=&quot;https://docs.docker.com/storage/volumes/&quot;&gt;Volumes&lt;/a&gt; are the preferred mechanism for persisting container data.&lt;/p&gt; 
&lt;p&gt;Or open a locally cloned or downloaded version of the repository:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone this repository to your local filesystem.&lt;/li&gt; 
 &lt;li&gt;Press F1 and select the &lt;strong&gt;Remote-Containers: Open Folder in Container...&lt;/strong&gt; command.&lt;/li&gt; 
 &lt;li&gt;Select the cloned copy of this folder, wait for the container to start, and try things out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Offline access&lt;/h2&gt; 
&lt;p&gt;You can run this documentation offline by using &lt;a href=&quot;https://docsify.js.org/#/&quot;&gt;Docsify&lt;/a&gt;. Fork this repo, &lt;a href=&quot;https://docsify.js.org/#/quickstart&quot;&gt;install Docsify&lt;/a&gt; on your local machine, then in the root folder of this repo, type &lt;code&gt;docsify serve&lt;/code&gt;. The website will be served on port 3000 on your localhost: &lt;code&gt;localhost:3000&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note, notebooks will not be rendered via Docsify, so when you need to run a notebook, do that separately in VS Code running a Python kernel.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Help Wanted!&lt;/h2&gt; 
&lt;p&gt;If you would like to translate all or part of the curriculum, please follow our &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/Data-Science-For-Beginners/main/TRANSLATIONS.md&quot;&gt;Translations&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Other Curricula&lt;/h2&gt; 
&lt;p&gt;Our team produces other curricula! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/genai-beginners&quot;&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet&quot;&gt;Generative AI for Beginners .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/generative-ai-with-javascript&quot;&gt;Generative AI with JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/genaijava&quot;&gt;Generative AI with Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming&quot;&gt;Mastering GitHub Copilot for Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ageron/handson-ml3</title>
      <link>https://github.com/ageron/handson-ml3</link>
      <description>&lt;p&gt;A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning Notebooks, 3rd edition&lt;/h1&gt; 
&lt;p&gt;This project aims at teaching you the fundamentals of Machine Learning in python. It contains the example code and solutions to the exercises in the third edition of my O&#39;Reilly book &lt;a href=&quot;https://homl.info/er3&quot;&gt;Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow (3rd edition)&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://homl.info/er3&quot;&gt;&lt;img src=&quot;https://learning.oreilly.com/library/cover/9781098125967/300w/&quot; title=&quot;book&quot; width=&quot;150&quot; border=&quot;0&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are looking for the second edition notebooks, check out &lt;a href=&quot;https://github.com/ageron/handson-ml2&quot;&gt;ageron/handson-ml2&lt;/a&gt;. For the first edition, see &lt;a href=&quot;https://github.com/ageron/handson-ml&quot;&gt;ageron/handson-ml&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Want to play with these notebooks online without having to install anything?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://colab.research.google.com/github/ageron/handson-ml3/blob/main/&quot; target=&quot;_parent&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot; /&gt;&lt;/a&gt; (recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;âš  &lt;em&gt;Colab provides a temporary environment: anything you do will be deleted after a while, so make sure you download any data you care about.&lt;/em&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;Other services may work as well, but I have not fully tested them:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://homl.info/kaggle3/&quot;&gt;&lt;img src=&quot;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&quot; alt=&quot;Open in Kaggle&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://mybinder.org/v2/gh/ageron/handson-ml3/HEAD?filepath=%2Findex.ipynb&quot;&gt;&lt;img src=&quot;https://mybinder.org/badge_logo.svg?sanitize=true&quot; alt=&quot;Launch binder&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://homl.info/deepnote3/&quot;&gt;&lt;img src=&quot;https://deepnote.com/buttons/launch-in-deepnote-small.svg?sanitize=true&quot; alt=&quot;Launch in Deepnote&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Just want to quickly look at some notebooks, without executing any code?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://nbviewer.jupyter.org/github/ageron/handson-ml3/blob/main/index.ipynb&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg?sanitize=true&quot; alt=&quot;Render nbviewer&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ageron/handson-ml3/raw/main/index.ipynb&quot;&gt;github.com&#39;s notebook viewer&lt;/a&gt; also works but it&#39;s not ideal: it&#39;s slower, the math equations are not always displayed correctly, and large notebooks often fail to open.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Want to run this project using a Docker image?&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href=&quot;https://github.com/ageron/handson-ml3/tree/main/docker&quot;&gt;Docker instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Want to install this project on your own machine?&lt;/h3&gt; 
&lt;p&gt;Start by installing &lt;a href=&quot;https://www.anaconda.com/products/distribution&quot;&gt;Anaconda&lt;/a&gt; (or &lt;a href=&quot;https://docs.conda.io/en/latest/miniconda.html&quot;&gt;Miniconda&lt;/a&gt;), &lt;a href=&quot;https://git-scm.com/downloads&quot;&gt;git&lt;/a&gt;, and if you have a TensorFlow-compatible GPU, install the &lt;a href=&quot;https://www.nvidia.com/Download/index.aspx&quot;&gt;GPU driver&lt;/a&gt;, as well as the appropriate version of CUDA and cuDNN (see TensorFlow&#39;s documentation for more details).&lt;/p&gt; 
&lt;p&gt;Next, clone this project by opening a terminal and typing the following commands (do not type the first &lt;code&gt;$&lt;/code&gt; signs on each line, they just indicate that these are terminal commands):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ageron/handson-ml3.git
$ cd handson-ml3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ conda env create -f environment.yml
$ conda activate homl3
$ python -m ipykernel install --user --name=python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, start Jupyter:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need further instructions, read the &lt;a href=&quot;https://raw.githubusercontent.com/ageron/handson-ml3/main/INSTALL.md&quot;&gt;detailed installation instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Which Python version should I use?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I recommend Python 3.10. If you follow the installation instructions above, that&#39;s the version you will get. Any version â‰¥3.7 should work as well.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I&#39;m getting an error when I call &lt;code&gt;load_housing_data()&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you&#39;re getting an HTTP error, make sure you&#39;re running the exact same code as in the notebook (copy/paste it if needed). If the problem persists, please check your network configuration. If it&#39;s an SSL error, see the next question.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I&#39;m getting an SSL error on MacOSX&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You probably need to install the SSL certificates (see this &lt;a href=&quot;https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error&quot;&gt;StackOverflow question&lt;/a&gt;). If you downloaded Python from the official website, then run &lt;code&gt;/Applications/Python\ 3.10/Install\ Certificates.command&lt;/code&gt; in a terminal (change &lt;code&gt;3.10&lt;/code&gt; to whatever version you installed). If you installed Python using MacPorts, run &lt;code&gt;sudo port install curl-ca-bundle&lt;/code&gt; in a terminal.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I&#39;ve installed this project locally. How do I update it to the latest version?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/ageron/handson-ml3/main/INSTALL.md&quot;&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How do I update my Python libraries to the latest versions, when using Anaconda?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/ageron/handson-ml3/main/INSTALL.md&quot;&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;I would like to thank everyone &lt;a href=&quot;https://github.com/ageron/handson-ml3/graphs/contributors&quot;&gt;who contributed to this project&lt;/a&gt;, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park and Ian Beauregard who reviewed every notebook and submitted many PRs, including help on some of the exercise solutions. Thanks as well to Steven Bunkley and Ziembla who created the &lt;code&gt;docker&lt;/code&gt; directory, and to github user SuperYorio who helped on some exercise solutions. Thanks a lot to Victor Khaustov who submitted plenty of excellent PRs, fixing many errors. And lastly, thanks to Google ML Developer Programs team who supported this work by providing Google Cloud Credit.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NirDiamant/RAG_Techniques</title>
      <link>https://github.com/NirDiamant/RAG_Techniques</link>
      <description>&lt;p&gt;This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;http://makeapullrequest.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/LinkedIn-Connect-blue&quot; alt=&quot;LinkedIn&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NirDiamantAI&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/NirDiamantAI?label=Follow%20@NirDiamantAI&amp;amp;style=social&quot; alt=&quot;Twitter&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.reddit.com/r/EducationalAI/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Reddit-Join%20our%20subreddit-FF4500?style=flat-square&amp;amp;logo=reddit&amp;amp;logoColor=white&quot; alt=&quot;Reddit&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20our%20community-7289da?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/sponsors/NirDiamant&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;color=ff69b4&quot; alt=&quot;Sponsor&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸŒŸ &lt;strong&gt;Support This Project:&lt;/strong&gt; Your sponsorship fuels innovation in RAG technologies. &lt;strong&gt;&lt;a href=&quot;https://github.com/sponsors/NirDiamant&quot;&gt;Become a sponsor&lt;/a&gt;&lt;/strong&gt; to help maintain and expand this valuable resource!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Sponsors â¤ï¸&lt;/h2&gt; 
&lt;p&gt;We gratefully acknowledge the organizations and individuals who have made significant contributions to this project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Company Sponsors&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://zilliz.com&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/ziliz_logo.png&quot; style=&quot;border-radius: 12px; margin-right: 24px; vertical-align: middle;&quot; height=&quot;96&quot; alt=&quot;Zilliz: Key Collaborator&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Individual Sponsors&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sponsors/Eisenh&quot;&gt;&lt;img src=&quot;https://github.com/Eisenh.png&quot; style=&quot;border-radius: 50%;&quot; width=&quot;64&quot; height=&quot;64&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ğŸš€&lt;/h1&gt; 
&lt;p&gt;Welcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.&lt;/p&gt; 
&lt;h2&gt;ğŸ“« Stay Updated!&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸš€&lt;br /&gt;&lt;b&gt;Cutting-edge&lt;br /&gt;Updates&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ’¡&lt;br /&gt;&lt;b&gt;Expert&lt;br /&gt;Insights&lt;/b&gt;&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;ğŸ¯&lt;br /&gt;&lt;b&gt;Top 0.1%&lt;br /&gt;Content&lt;/b&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/subscribe-button.svg?sanitize=true&quot; alt=&quot;Subscribe to DiamantAI Newsletter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!&lt;/em&gt; &lt;em&gt;&lt;strong&gt;Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href=&quot;https://diamantai.substack.com/?r=336pe4&amp;amp;utm_campaign=pub-share-checklist&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/images/substack_image.png&quot; alt=&quot;DiamantAI&#39;s newsletter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Retrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.&lt;/p&gt; 
&lt;p&gt;Our goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what&#39;s possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;ğŸš€ Level up with my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/agents-towards-production&quot;&gt;Agents Towards Production&lt;/a&gt;&lt;/strong&gt; repository. It delivers horizontal, code-first tutorials that cover every tool and step in the lifecycle of building production-grade GenAI agents, guiding you from spark to scale with proven patterns and reusable blueprints for real-world launches, making it the smartest place to start if you&#39;re serious about shipping agents to production.&lt;/p&gt; 
&lt;p&gt;ğŸ¤– Explore my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/GenAI_Agents&quot;&gt;GenAI Agents Repository&lt;/a&gt;&lt;/strong&gt; to discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.&lt;/p&gt; 
&lt;p&gt;ğŸ–‹ï¸ Check out my &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Prompt_Engineering&quot;&gt;Prompt Engineering Techniques guide&lt;/a&gt;&lt;/strong&gt; for a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.&lt;/p&gt; 
&lt;h2&gt;A Community-Driven Knowledge Hub&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This repository grows stronger with your contributions!&lt;/strong&gt; Join our vibrant communities - the central hubs for shaping and advancing this project together ğŸ¤&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.reddit.com/r/EducationalAI/&quot;&gt;Educational AI Subreddit&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://discord.gg/cA6Aa4uyDX&quot;&gt;RAG Techniques Discord Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Whether you&#39;re an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to our &lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/strong&gt; file. Let&#39;s advance RAG technology together!&lt;/p&gt; 
&lt;p&gt;ğŸ”— For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free to &lt;strong&gt;&lt;a href=&quot;https://www.linkedin.com/in/nir-diamant-759323134/&quot;&gt;connect on LinkedIn&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ§  State-of-the-art RAG enhancements&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Comprehensive documentation for each technique&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Practical implementation guidelines&lt;/li&gt; 
 &lt;li&gt;ğŸŒŸ Regular updates with the latest advancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Advanced Techniques&lt;/h2&gt; 
&lt;p&gt;Explore our extensive list of cutting-edge RAG techniques:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Technique&lt;/th&gt; 
   &lt;th&gt;View&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;â­ Key Collaboration&lt;/td&gt; 
   &lt;td&gt;Graph RAG with Milvus Vector DB&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;Foundational ğŸŒ±&lt;/td&gt; 
   &lt;td&gt;Basic RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/simple_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;Foundational ğŸŒ±&lt;/td&gt; 
   &lt;td&gt;RAG with CSV Files&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/simple_csv_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;Foundational ğŸŒ±&lt;/td&gt; 
   &lt;td&gt;Reliable RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/reliable_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;Foundational ğŸŒ±&lt;/td&gt; 
   &lt;td&gt;Optimizing Chunk Sizes&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/choose_chunk_size.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;Foundational ğŸŒ±&lt;/td&gt; 
   &lt;td&gt;Proposition Chunking&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/proposition_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;Query Enhancement ğŸ”&lt;/td&gt; 
   &lt;td&gt;Query Transformations&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/query_transformations.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;Query Enhancement ğŸ”&lt;/td&gt; 
   &lt;td&gt;HyDE (Hypothetical Document Embedding)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9&lt;/td&gt; 
   &lt;td&gt;Query Enhancement ğŸ”&lt;/td&gt; 
   &lt;td&gt;HyPE (Hypothetical Prompt Embedding)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Contextual Chunk Headers&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/contextual_chunk_headers.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Relevant Segment Extraction&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/relevant_segment_extraction.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Context Window Enhancement&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Semantic Chunking&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/semantic_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Contextual Compression&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/contextual_compression.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;Context Enrichment ğŸ“š&lt;/td&gt; 
   &lt;td&gt;Document Augmentation&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/document_augmentation.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Fusion Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/fusion_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Reranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/reranking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Multi-faceted Filtering&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/multi_faceted_filtering.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_faceted_filtering.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Hierarchical Indices&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/hierarchical_indices.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Ensemble Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/ensemble_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/ensemble_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Dartboard Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/dartboard.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;Advanced Retrieval ğŸš€&lt;/td&gt; 
   &lt;td&gt;Multi-modal RAG with Captioning&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;Iterative Techniques ğŸ”&lt;/td&gt; 
   &lt;td&gt;Retrieval with Feedback Loop&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;Iterative Techniques ğŸ”&lt;/td&gt; 
   &lt;td&gt;Adaptive Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/adaptive_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;Iterative Retrieval ğŸ”„&lt;/td&gt; 
   &lt;td&gt;Iterative Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/iterative_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/iterative_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;Evaluation ğŸ“Š&lt;/td&gt; 
   &lt;td&gt;DeepEval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/evaluation/evaluation_deep_eval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;Evaluation ğŸ“Š&lt;/td&gt; 
   &lt;td&gt;GroUSE&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/evaluation/evaluation_grouse.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;Explainability ğŸ”¬&lt;/td&gt; 
   &lt;td&gt;Explainable Retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/explainable_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;Advanced Architecture ğŸ—ï¸&lt;/td&gt; 
   &lt;td&gt;Graph RAG with LangChain&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/graph_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;Advanced Architecture ğŸ—ï¸&lt;/td&gt; 
   &lt;td&gt;Microsoft GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/Microsoft_GraphRag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;31&lt;/td&gt; 
   &lt;td&gt;Advanced Architecture ğŸ—ï¸&lt;/td&gt; 
   &lt;td&gt;RAPTOR&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/raptor.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;Advanced Architecture ğŸ—ï¸&lt;/td&gt; 
   &lt;td&gt;Self-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/self_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;33&lt;/td&gt; 
   &lt;td&gt;Advanced Architecture ğŸ—ï¸&lt;/td&gt; 
   &lt;td&gt;Corrective RAG (CRAG)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/crag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;34&lt;/td&gt; 
   &lt;td&gt;Special Technique ğŸŒŸ&lt;/td&gt; 
   &lt;td&gt;Sophisticated Controllable Agent&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸŒ± Foundational RAG Techniques&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Simple RAG ğŸŒ±&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques/raw/main/all_rag_techniques_runnable_scripts/simple_rag.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Introducing basic RAG techniques ideal for newcomers.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Start with basic retrieval queries and integrate incremental learning mechanisms.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Simple RAG using a CSV file ğŸ§©&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Introducing basic RAG using CSV files.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;This uses CSV files to create basic retrieval and integrates with openai to create question and answering system.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliable RAG ğŸ·ï¸&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Enhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Check for retrieved document relevancy and highlight the segment of docs used for answering.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose Chunk Size ğŸ“&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/choose_chunk_size.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Selecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Experiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Proposition Chunking â›“ï¸â€ğŸ’¥&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Breaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ’ª &lt;strong&gt;Proposition Generation:&lt;/strong&gt; The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.&lt;/li&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;Quality Checking:&lt;/strong&gt; The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/the-propositions-method-enhancing?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;The Propositions Method: Enhancing Information Retrieval for AI Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ” Query Enhancement&lt;/h3&gt; 
&lt;ol start=&quot;6&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Query Transformations ğŸ”„&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/query_transformations.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Modifying and expanding queries to improve retrieval effectiveness.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;âœï¸ &lt;strong&gt;Query Rewriting:&lt;/strong&gt; Reformulate queries to improve retrieval.&lt;/li&gt; 
   &lt;li&gt;ğŸ”™ &lt;strong&gt;Step-back Prompting:&lt;/strong&gt; Generate broader queries for better context retrieval.&lt;/li&gt; 
   &lt;li&gt;ğŸ§© &lt;strong&gt;Sub-query Decomposition:&lt;/strong&gt; Break complex queries into simpler sub-queries.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hypothetical Questions (HyDE Approach) â“&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/HyDe_Hypothetical_Document_Embedding.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Generating hypothetical questions to improve alignment between queries and data.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Create hypothetical questions that point to relevant locations in the data, enhancing query-data matching.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/hyde-exploring-hypothetical-document?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;HyDE: Exploring Hypothetical Document Embeddings for AI Retrieval&lt;/a&gt;&lt;/strong&gt; - A short blog post explaining this method clearly.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“š Context and Content Enrichment&lt;/h3&gt; 
&lt;ol start=&quot;8&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Hypothetical Prompt Embeddings (HyPE) â“ğŸš€&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/HyPE_Hypothetical_Prompt_Embeddings.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;HyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval that &lt;strong&gt;precomputes hypothetical prompts at the indexing stage&lt;/strong&gt;, but inseting the chunk in their place. This transforms retrieval into a &lt;strong&gt;question-question matching task&lt;/strong&gt;. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead while &lt;strong&gt;improving retrieval alignment&lt;/strong&gt;.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ“– &lt;strong&gt;Precomputed Questions:&lt;/strong&gt; Instead of embedding document chunks, HyPE &lt;strong&gt;generates multiple hypothetical queries per chunk&lt;/strong&gt; at indexing time.&lt;/li&gt; 
   &lt;li&gt;ğŸ” &lt;strong&gt;Question-Question Matching:&lt;/strong&gt; User queries are matched against stored hypothetical questions, leading to &lt;strong&gt;better retrieval alignment&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;âš¡ &lt;strong&gt;No Runtime Overhead:&lt;/strong&gt; Unlike HyDE, HyPE does &lt;strong&gt;not require LLM calls at query time&lt;/strong&gt;, making retrieval &lt;strong&gt;faster and cheaper&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;ğŸ“ˆ &lt;strong&gt;Higher Precision &amp;amp; Recall:&lt;/strong&gt; Improves retrieval &lt;strong&gt;context precision by up to 42 percentage points&lt;/strong&gt; and &lt;strong&gt;claim recall by up to 45 percentage points&lt;/strong&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5139335&quot;&gt;Preprint: Hypothetical Prompt Embeddings (HyPE)&lt;/a&gt;&lt;/strong&gt; - Research paper detailing the method, evaluation, and benchmarks.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contextual Chunk Headers &lt;span&gt;ğŸ·&lt;/span&gt;&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Contextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Create a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/D-Star-AI/dsRAG&quot;&gt;dsRAG&lt;/a&gt;&lt;/strong&gt;: open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Relevant Segment Extraction ğŸ§©&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Relevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Perform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Context Enrichment Techniques ğŸ“&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/context_enrichment_window_around_chunk.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Overview ğŸ”&lt;/h4&gt; 
&lt;p&gt;Enhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.&lt;/p&gt; 
&lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
&lt;p&gt;Retrieve the most relevant sentence while also accessing the sentences before and after it in the original text.&lt;/p&gt; 
&lt;ol start=&quot;12&quot;&gt; 
 &lt;li&gt;Semantic Chunking ğŸ§ &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques/raw/main/all_rag_techniques_runnable_scripts/semantic_chunking.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Overview ğŸ”&lt;/h4&gt; 
&lt;p&gt;Dividing documents based on semantic coherence rather than fixed sizes.&lt;/p&gt; 
&lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
&lt;p&gt;Use NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.&lt;/p&gt; 
&lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/semantic-chunking-improving-ai-information?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;Semantic Chunking: Improving AI Information Retrieval&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start=&quot;13&quot;&gt; 
 &lt;li&gt;Contextual Compression ğŸ—œï¸&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/contextual_compression.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Overview ğŸ”&lt;/h4&gt; 
&lt;p&gt;Compressing retrieved information while preserving query-relevant content.&lt;/p&gt; 
&lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
&lt;p&gt;Use an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.&lt;/p&gt; 
&lt;ol start=&quot;14&quot;&gt; 
 &lt;li&gt;Document Augmentation through Question Generation for Enhanced Retrieval&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/document_augmentation.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Overview ğŸ”&lt;/h4&gt; 
&lt;p&gt;This implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.&lt;/p&gt; 
&lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
&lt;p&gt;Use an LLM to augment text dataset with all possible questions that can be asked to each document.&lt;/p&gt; 
&lt;h3&gt;ğŸš€ Advanced Retrieval Methods&lt;/h3&gt; 
&lt;ol start=&quot;15&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Fusion Retrieval ğŸ”—&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/fusion_retrieval.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Optimizing search results by combining different retrieval methods.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Combine keyword-based search with vector-based search for more comprehensive and accurate retrieval.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Intelligent Reranking ğŸ“ˆ&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LlamaIndex&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/reranking.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Applying advanced scoring mechanisms to improve the relevance ranking of retrieved results.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ§  &lt;strong&gt;LLM-based Scoring:&lt;/strong&gt; Use a language model to score the relevance of each retrieved chunk.&lt;/li&gt; 
   &lt;li&gt;ğŸ”€ &lt;strong&gt;Cross-Encoder Models:&lt;/strong&gt; Re-encode both the query and retrieved documents jointly for similarity scoring.&lt;/li&gt; 
   &lt;li&gt;ğŸ† &lt;strong&gt;Metadata-enhanced Ranking:&lt;/strong&gt; Incorporate metadata into the scoring process for more nuanced ranking.&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/relevance-revolution-how-re-ranking?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;Relevance Revolution: How Re-ranking Transforms RAG Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-faceted Filtering ğŸ”&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Applying various filtering techniques to refine and improve the quality of retrieved results.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ·ï¸ &lt;strong&gt;Metadata Filtering:&lt;/strong&gt; Apply filters based on attributes like date, source, author, or document type.&lt;/li&gt; 
   &lt;li&gt;ğŸ“Š &lt;strong&gt;Similarity Thresholds:&lt;/strong&gt; Set thresholds for relevance scores to keep only the most pertinent results.&lt;/li&gt; 
   &lt;li&gt;ğŸ“„ &lt;strong&gt;Content Filtering:&lt;/strong&gt; Remove results that don&#39;t match specific content criteria or essential keywords.&lt;/li&gt; 
   &lt;li&gt;ğŸŒˆ &lt;strong&gt;Diversity Filtering:&lt;/strong&gt; Ensure result diversity by filtering out near-duplicate entries.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hierarchical Indices ğŸ—‚ï¸&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/hierarchical_indices.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Creating a multi-tiered system for efficient information navigation and retrieval.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Implement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.&lt;/p&gt; &lt;h4&gt;Additional Resources ğŸ“š&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://open.substack.com/pub/diamantai/p/hierarchical-indices-enhancing-rag?r=336pe4&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;Hierarchical Indices: Enhancing RAG Systems&lt;/a&gt;&lt;/strong&gt; - A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensemble Retrieval ğŸ­&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Combining multiple retrieval models or techniques for more robust and accurate results.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Apply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Dartboard Retrieval ğŸ¯&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Optimizing over Relevant Information Gain in Retrieval&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Combine both relevance and diversity into a single scoring function and directly optimize for it.&lt;/li&gt; 
   &lt;li&gt;POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-modal Retrieval ğŸ“½ï¸&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Extending RAG capabilities to handle diverse data types for richer responses.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Multi-model RAG with Multimedia Captioning&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; - Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Multi-model RAG with Colpali&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; - Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ” Iterative and Adaptive Techniques&lt;/h3&gt; 
&lt;ol start=&quot;22&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Retrieval with Feedback Loops ğŸ”&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/retrieval_with_feedback_loop.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Implementing mechanisms to learn from user interactions and improve future retrievals.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Collect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Adaptive Retrieval ğŸ¯&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/adaptive_retrieval.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Dynamically adjusting retrieval strategies based on query types and user contexts.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Classify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Iterative Retrieval ğŸ”„&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Performing multiple rounds of retrieval to refine and enhance result quality.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Use the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ“Š Evaluation&lt;/h3&gt; 
&lt;ol start=&quot;25&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DeepEval Evaluation&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; | Comprehensive RAG system evaluation |&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Performing evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Use the &lt;code&gt;deepeval&lt;/code&gt; library to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GroUSE Evaluation&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; | Contextually-grounded LLM evaluation |&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Evaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Use the &lt;code&gt;grouse&lt;/code&gt; package to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ”¬ Explainability and Transparency&lt;/h3&gt; 
&lt;ol start=&quot;27&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Explainable Retrieval ğŸ”&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/explainable_retrieval.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Providing transparency in the retrieval process to enhance user trust and system refinement.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Explain why certain pieces of information were retrieved and how they relate to the query.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ—ï¸ Advanced Architectures&lt;/h3&gt; 
&lt;ol start=&quot;28&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Graph RAG with Milvus Vector Database ğŸ”&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Graph RAG with Milvus&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graphrag_with_milvus_vectordb.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A simple yet powerful approach to implement Graph RAG using Milvus vector databases. This technique significantly improves performance on complex multi-hop questions by combining relationship-based retrieval with vector search and reranking.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Store both text passages and relationship triplets (subject-predicate-object) in separate Milvus collections&lt;/li&gt; 
   &lt;li&gt;Perform multi-way retrieval by querying both collections&lt;/li&gt; 
   &lt;li&gt;Use an LLM to rerank retrieved relationships based on their relevance to the query&lt;/li&gt; 
   &lt;li&gt;Retrieve the final passages based on the most relevant relationships&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Knowledge Graph Integration (Graph RAG) ğŸ•¸ï¸&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/graph_rag.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Incorporating structured data from knowledge graphs to enrich context and improve retrieval.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Retrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GraphRag (Microsoft) ğŸ¯&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;GraphRag&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Microsoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMs&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ğŸŒ³&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/raptor.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;Implementing a recursive approach to process and organize retrieved information in a tree structure.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;Use abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Self RAG ğŸ”&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/self_rag.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Corrective RAG ğŸ”§&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LangChain&lt;/strong&gt;: &lt;a href=&quot;https://github.com/NirDiamant/RAG_TECHNIQUES/raw/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-View-blue&quot; height=&quot;20&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; height=&quot;20&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/all_rag_techniques_runnable_scripts/crag.py&quot;&gt;Runnable Script&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;A sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸŒŸ Special Advanced Technique ğŸŒŸ&lt;/h2&gt; 
&lt;ol start=&quot;34&quot;&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/NirDiamant/Controllable-RAG-Agent&quot;&gt;Sophisticated Controllable Agent for Complex RAG Tasks ğŸ¤–&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h4&gt;Overview ğŸ”&lt;/h4&gt; &lt;p&gt;An advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the &quot;brain&quot; ğŸ§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.&lt;/p&gt; &lt;h4&gt;Implementation ğŸ› ï¸&lt;/h4&gt; &lt;p&gt;â€¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To begin implementing these advanced RAG techniques in your projects:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository: &lt;pre&gt;&lt;code&gt;git clone https://github.com/NirDiamant/RAG_Techniques.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to the technique you&#39;re interested in: &lt;pre&gt;&lt;code&gt;cd all_rag_techniques/technique-name
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the detailed implementation guide in each technique&#39;s directory.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have a new technique or improvement to suggest:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch: &lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Commit your changes: &lt;code&gt;git commit -m &#39;Add some AmazingFeature&#39;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Push to the branch: &lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Open a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NirDiamant/RAG_Techniques/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=NirDiamant/RAG_Techniques&quot; alt=&quot;Contributors&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under a custom non-commercial license - see the &lt;a href=&quot;https://raw.githubusercontent.com/NirDiamant/RAG_Techniques/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;â­ï¸ If you find this repository helpful, please consider giving it a star!&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=main-readme&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Keywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/generative-ai-for-beginners</title>
      <link>https://github.com/microsoft/generative-ai-for-beginners</link>
      <description>&lt;p&gt;21 Lessons, Get Started Building with Generative AI ğŸ”— https://microsoft.github.io/generative-ai-for-beginners/&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/images/repo-thumbnailv4-fixed.png?WT.mc_id=academic-105485-koreyst&quot; alt=&quot;Generative AI For Beginners&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;21 Lessons teaching everything you need to know to start building Generative AI applications&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-For-Beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub license&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub contributors&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub issues&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg?sanitize=true&quot; alt=&quot;GitHub pull-requests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Watch&quot; alt=&quot;GitHub watchers&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Fork&quot; alt=&quot;GitHub forks&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Star&quot; alt=&quot;GitHub stars&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;img src=&quot;https://dcbadge.limes.pink/api/server/ByRwuEEgH4&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸŒ Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fr/README.md&quot;&gt;French&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/es/README.md&quot;&gt;Spanish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/de/README.md&quot;&gt;German&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ru/README.md&quot;&gt;Russian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ar/README.md&quot;&gt;Arabic&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fa/README.md&quot;&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ur/README.md&quot;&gt;Urdu&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/zh/README.md&quot;&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mo/README.md&quot;&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hk/README.md&quot;&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tw/README.md&quot;&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ja/README.md&quot;&gt;Japanese&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ko/README.md&quot;&gt;Korean&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hi/README.md&quot;&gt;Hindi&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bn/README.md&quot;&gt;Bengali&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mr/README.md&quot;&gt;Marathi&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ne/README.md&quot;&gt;Nepali&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pa/README.md&quot;&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pt/README.md&quot;&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/br/README.md&quot;&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/it/README.md&quot;&gt;Italian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pl/README.md&quot;&gt;Polish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tr/README.md&quot;&gt;Turkish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/el/README.md&quot;&gt;Greek&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/th/README.md&quot;&gt;Thai&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sv/README.md&quot;&gt;Swedish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/da/README.md&quot;&gt;Danish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/no/README.md&quot;&gt;Norwegian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fi/README.md&quot;&gt;Finnish&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/nl/README.md&quot;&gt;Dutch&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/he/README.md&quot;&gt;Hebrew&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/vi/README.md&quot;&gt;Vietnamese&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/id/README.md&quot;&gt;Indonesian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ms/README.md&quot;&gt;Malay&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tl/README.md&quot;&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sw/README.md&quot;&gt;Swahili&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hu/README.md&quot;&gt;Hungarian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/cs/README.md&quot;&gt;Czech&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sk/README.md&quot;&gt;Slovak&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ro/README.md&quot;&gt;Romanian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bg/README.md&quot;&gt;Bulgarian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sr/README.md&quot;&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hr/README.md&quot;&gt;Croatian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sl/README.md&quot;&gt;Slovenian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/uk/README.md&quot;&gt;Ukrainian&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/my/README.md&quot;&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Generative AI for Beginners (Version 3) - A Course&lt;/h1&gt; 
&lt;p&gt;Learn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.&lt;/p&gt; 
&lt;h2&gt;ğŸŒ± Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 21 lessons. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;Lessons are labeled either &quot;Learn&quot; lessons explaining a Generative AI concept or &quot;Build&quot; lessons that explain a concept and code examples in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt; when possible.&lt;/p&gt; 
&lt;p&gt;For .NET Developers checkout &lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners (.NET Edition)&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Each lesson also includes a &quot;Keep Learning&quot; section with additional learning tools.&lt;/p&gt; 
&lt;h2&gt;What You Need&lt;/h2&gt; 
&lt;h3&gt;To run the code of this course, you can use either:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-beginners/azure-open-ai?WT.mc_id=academic-105485-koreyst&quot;&gt;Azure OpenAI Service&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;aoai-assignment&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-beginners/gh-models?WT.mc_id=academic-105485-koreyst&quot;&gt;GitHub Marketplace Model Catalog&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;githubmodels&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://aka.ms/genai-beginners/open-ai?WT.mc_id=academic-105485-koreyst&quot;&gt;OpenAI API&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; &quot;oai-assignment&quot;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these &lt;a href=&quot;https://aka.ms/genai-beginners/python?WT.mc_id=academic-105485-koreyst&quot;&gt;Python&lt;/a&gt; and &lt;a href=&quot;https://aka.ms/genai-beginners/typescript?WT.mc_id=academic-105485-koreyst&quot;&gt;TypeScript&lt;/a&gt; courses&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A GitHub account to &lt;a href=&quot;https://aka.ms/genai-beginners/github?WT.mc_id=academic-105485-koreyst&quot;&gt;fork this entire repo&lt;/a&gt; to your own GitHub account&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We have created a &lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Course Setup&lt;/a&gt;&lt;/strong&gt; lesson to help you with setting up your development environment.&lt;/p&gt; 
&lt;p&gt;Don&#39;t forget to &lt;a href=&quot;https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst&quot;&gt;star (ğŸŒŸ) this repo&lt;/a&gt; to find it easier later.&lt;/p&gt; 
&lt;h2&gt;ğŸ§  Ready to Deploy?&lt;/h2&gt; 
&lt;p&gt;If you are looking for more advanced code samples, check out our &lt;a href=&quot;https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst&quot;&gt;collection of Generative AI Code Samples&lt;/a&gt; in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ—£ï¸ Meet Other Learners, Get Support&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href=&quot;https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst&quot;&gt;official Azure AI Foundry Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;Ask questions or share product feedback in our &lt;a href=&quot;https://aka.ms/azureaifoundry/forum&quot;&gt;Azure AI Foundry Developer Forum&lt;/a&gt; on Github.&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Building a Startup?&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href=&quot;https://www.microsoft.com/startups&quot;&gt;Microsoft for Startups&lt;/a&gt; to find out how to get started building with Azure credits today.&lt;/p&gt; 
&lt;h2&gt;ğŸ™ Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst&quot;&gt;Raise an issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst&quot;&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“‚ Each lesson includes:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A short video introduction to the topic&lt;/li&gt; 
 &lt;li&gt;A written lesson located in the README&lt;/li&gt; 
 &lt;li&gt;Python and TypeScript code samples supporting Azure OpenAI and OpenAI API&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ—ƒï¸ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson Link&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to Setup Your Development Environment&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Introduction to Generative AI and LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Understanding what Generative AI is and how Large Language Models (LLMs) work.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Exploring and comparing different LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to select the right model for your use case&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Using Generative AI Responsibly&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to build Generative AI Applications responsibly&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Understanding Prompt Engineering Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Hands-on Prompt Engineering Best Practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Creating Advanced Prompts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply prompt engineering techniques that improve the outcome of your prompts.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Text Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A text generation app using Azure OpenAI / OpenAI API&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Chat Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; Techniques for efficiently building and integrating chat applications.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Search Apps Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A search application that uses Embeddings to search for data.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Image Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An image generation application&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building Low Code AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A Generative AI application using Low Code tools&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Integrating External Applications with Function Calling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; What is function calling and its use cases for applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Designing UX for AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply UX design principles when developing Generative AI Applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Securing Your Generative AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The threats and risks to AI systems and methods to secure these systems.&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;The Generative AI Application Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The tools and metrics to manage the LLM Lifecycle and LLMOps&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Retrieval Augmented Generation (RAG) and Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using a RAG Framework to retrieve embeddings from a Vector Databases&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Open Source Models and Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using open source models available on Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;AI Agents&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using an AI Agent Framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Fine-Tuning LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The what, why and how of fine-tuning LLMs&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst&quot;&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/19-slm/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with SLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The benefits of building with Small Language Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/20-mistral/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with Mistral Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Mistral Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/21-meta/README.md?WT.mc_id=academic-105485-koreyst&quot;&gt;Building with Meta Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Meta Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst&quot;&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸŒŸ Special thanks&lt;/h3&gt; 
&lt;p&gt;Special thanks to &lt;a href=&quot;https://www.linkedin.com/in/john0isaac/&quot;&gt;&lt;strong&gt;John Aziz&lt;/strong&gt;&lt;/a&gt; for creating all of the GitHub Actions and workflows&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/bernhard-merkle-738b73/&quot;&gt;&lt;strong&gt;Bernhard Merkle&lt;/strong&gt;&lt;/a&gt; for making key contributions to each lesson to improve the learner and code experience.&lt;/p&gt; 
&lt;h2&gt;ğŸ’ Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;&lt;strong&gt;NEW&lt;/strong&gt; Model Context Protocol for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;AI Agents for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/genai-js-course?WT.mc_id=academic-105485-koreyst&quot;&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung&quot;&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst&quot;&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst&quot;&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst&quot;&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>
