<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Scala Weekly Trending</title>
    <description>Weekly Trending of Scala in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:49:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>scala/scala3</title>
      <link>https://github.com/scala/scala3</link>
      <description>&lt;p&gt;The Scala 3 compiler, also known as Dotty.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dotty&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/scala/scala3/actions?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://github.com/scala/scala3/workflows/Dotty/badge.svg?branch=main&quot; alt=&quot;Dotty CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.com/invite/scala&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/632150470000902164&quot; alt=&quot;Join the chat at https://discord.com/invite/scala&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://develocity.scala-lang.org&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&amp;amp;labelColor=02303A&quot; alt=&quot;Revved up by Develocity&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.scala-lang.org/scala3/&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Try it out&lt;/h1&gt; 
&lt;p&gt;To try it in your project see also the &lt;a href=&quot;https://docs.scala-lang.org/scala3/getting-started.html&quot;&gt;Getting Started User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Building a Local Distribution&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;sbt dist/Universal/packageBin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Find the newly-built distributions in &lt;code&gt;dist/target/&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Code of Conduct&lt;/h1&gt; 
&lt;p&gt;Dotty uses the &lt;a href=&quot;https://www.scala-lang.org/conduct.html&quot;&gt;Scala Code of Conduct&lt;/a&gt; for all communication and discussion. This includes both GitHub, Discord and other more direct lines of communication such as email.&lt;/p&gt; 
&lt;h1&gt;How to Contribute&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.scala-lang.org/scala3/guides/contribution/contribution-intro.html&quot;&gt;Getting Started as Contributor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/scala/scala3/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&quot;&gt;Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Dotty is licensed under the &lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;Apache License Version 2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>digital-asset/daml</title>
      <link>https://github.com/digital-asset/daml</link>
      <description>&lt;p&gt;The Daml smart contract language&lt;/p&gt;&lt;hr&gt;&lt;p&gt;See full README at &lt;a href=&quot;https://raw.githubusercontent.com/digital-asset/daml/main/sdk/README.md&quot;&gt;sdk/README.md&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rtyley/bfg-repo-cleaner</title>
      <link>https://github.com/rtyley/bfg-repo-cleaner</link>
      <description>&lt;p&gt;Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BFG Repo-Cleaner&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/rtyley/bfg-repo-cleaner/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/rtyley/bfg-repo-cleaner/actions/workflows/ci.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/rtyley/bfg-repo-cleaner/actions/workflows/release.yml&quot;&gt;&lt;img src=&quot;https://github.com/rtyley/bfg-repo-cleaner/actions/workflows/release.yml/badge.svg?sanitize=true&quot; alt=&quot;Release&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Removes large or troublesome blobs like git-filter-branch does, but faster - and written in Scala&lt;/em&gt; - &lt;a href=&quot;https://j.mp/fund-bfg&quot;&gt;Fund the BFG&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ bfg --strip-blobs-bigger-than 1M --replace-text banned.txt repo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The BFG is a simpler, faster (&lt;a href=&quot;https://docs.google.com/spreadsheet/ccc?key=0AsR1d5Zpes8HdER3VGU1a3dOcmVHMmtzT2dsS2xNenc&quot;&gt;10 - 720x&lt;/a&gt; faster) alternative to &lt;code&gt;git-filter-branch&lt;/code&gt; for cleansing bad data out of your Git repository:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Removing &lt;strong&gt;Crazy Big Files&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Removing &lt;strong&gt;Passwords, Credentials&lt;/strong&gt; &amp;amp; other &lt;strong&gt;Private data&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Main documentation for The BFG is here : &lt;strong&gt;&lt;a href=&quot;https://rtyley.github.io/bfg-repo-cleaner/&quot;&gt;https://rtyley.github.io/bfg-repo-cleaner/&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>scalameta/metals</title>
      <link>https://github.com/scalameta/metals</link>
      <description>&lt;p&gt;Scala language server with rich IDE features ðŸš€&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Metals&lt;/h1&gt; 
&lt;a href=&quot;https://discord.gg/FaVDrJegEh&quot;&gt; &lt;img alt=&quot;Chat with us on discord&quot; src=&quot;https://img.shields.io/discord/632642981228314653&quot; /&gt; &lt;/a&gt; 
&lt;a href=&quot;https://twitter.com/scalameta&quot;&gt; &lt;img alt=&quot;Follow scalameta on Twitter&quot; src=&quot;https://img.shields.io/twitter/follow/scalameta.svg?logo=twitter&amp;amp;color=blue&quot; /&gt; &lt;/a&gt; 
&lt;a href=&quot;https://index.scala-lang.org/scalameta/metals/metals&quot;&gt; &lt;img alt=&quot;Find us on scaladex&quot; src=&quot;https://index.scala-lang.org/scalameta/metals/metals/latest.svg?sanitize=true&quot; /&gt; &lt;/a&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the website: &lt;a href=&quot;https://scalameta.org/metals/&quot;&gt;https://scalameta.org/metals/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We organize regular online events for anyone interested in contributing to Scala tooling, everyone is invited to join us! You can find more information on the &lt;a href=&quot;https://scalameta.org/scala-tooling-spree/&quot;&gt;Scala Tooling Spree&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;See the contributing guide: &lt;a href=&quot;https://scalameta.org/metals/docs/contributors/getting-started.html&quot;&gt;https://scalameta.org/metals/docs/contributors/getting-started.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To learn more about how Metals works, see &lt;a href=&quot;https://raw.githubusercontent.com/scalameta/metals/main/architecture.md&quot;&gt;./architecture.md&lt;/a&gt;. It explains the high-level layout of the source code. Do skim through that document.&lt;/p&gt; 
&lt;h3&gt;Acknowledgements and Development&lt;/h3&gt; 
&lt;p&gt;For more information on the current maintainers, companies that have/are sponsoring the development of Metals, and acknowledgements of previous work, please see &lt;a href=&quot;https://scalameta.org/metals/docs/acknowledgements/development.html&quot;&gt;https://scalameta.org/metals/docs/acknowledgements/development.html&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/help/idea/discover-intellij-idea-for-scala.html&quot;&gt;IntelliJ IDEA&lt;/a&gt;: the most widely used IDE for Scala using a re-implementation of the Scala typechecker.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Metals?&lt;/h2&gt; 
&lt;p&gt;Metals = Meta (from Scalameta) + LS (from Language Server)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>delta-io/delta-sharing</title>
      <link>https://github.com/delta-io/delta-sharing</link>
      <description>&lt;p&gt;An open protocol for secure data sharing&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://user-images.githubusercontent.com/1446829/144671151-b095e1b9-2d24-4d3b-b3c6-a7041e491077.png&quot; alt=&quot;Delta Sharing Logo&quot; width=&quot;200&quot; /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Delta Sharing: An Open Protocol for Secure Data Sharing&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/delta-io/delta-sharing/actions/workflows/build-and-test.yml&quot;&gt;&lt;img src=&quot;https://github.com/delta-io/delta-sharing/actions/workflows/build-and-test.yml/badge.svg?sanitize=true&quot; alt=&quot;Build and Test&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/delta-io/delta-sharing/raw/main/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?sanitize=true&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/delta-sharing/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/delta-sharing.svg?sanitize=true&quot; alt=&quot;PyPI&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://delta.io/sharing&quot;&gt;Delta Sharing&lt;/a&gt; is an open protocol for secure real-time exchange of large datasets, which enables organizations to share data in real time regardless of which computing platforms they use. It is a simple &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;REST protocol&lt;/a&gt; that securely shares access to part of a cloud dataset and leverages modern cloud storage systems, such as S3, ADLS, or GCS, to reliably transfer data.&lt;/p&gt; 
&lt;p&gt;With Delta Sharing, a user accessing shared data can directly connect to it through pandas, Tableau, Apache Spark, Rust, or other systems that support the open protocol, without having to deploy a specific compute platform first. Data providers can share a dataset once to reach a broad range of consumers, while consumers can begin using the data in minutes.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/images/delta-sharing.png&quot; width=&quot;85%&quot; /&gt; &lt;/p&gt; 
&lt;p&gt;This repo includes the following components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Delta Sharing &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;protocol specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Python Connector: A Python library that implements the Delta Sharing Protocol to read shared tables as &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; DataFrame or &lt;a href=&quot;http://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; DataFrames.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; Connector: An Apache Spark connector that implements the Delta Sharing Protocol to read shared tables from a Delta Sharing Server. The tables can then be accessed in SQL, Python, Java, Scala, or R.&lt;/li&gt; 
 &lt;li&gt;Delta Sharing Server: A reference implementation server for the Delta Sharing Protocol for development purposes. Users can deploy this server to share existing tables in Delta Lake and Apache Parquet format on modern cloud storage systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Python Connector&lt;/h1&gt; 
&lt;p&gt;The Delta Sharing Python Connector is a Python library that implements the &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol&lt;/a&gt; to read tables from a Delta Sharing Server. You can load shared tables as a &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; DataFrame, or as an &lt;a href=&quot;http://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt; DataFrame if running in PySpark with the Apache Spark Connector installed.&lt;/p&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;p&gt;Python 3.8+ for delta-sharing version 1.1+, Python 3.6+ for older versions If running Linux, glibc version &amp;gt;= 2.31 (for automatic delta-kernel-rust-sharing-wrapper package installation, please see next section for more details)&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip3 install delta-sharing
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using &lt;a href=&quot;https://docs.databricks.com/runtime/dbr.html&quot;&gt;Databricks Runtime&lt;/a&gt;, you can follow &lt;a href=&quot;https://docs.databricks.com/libraries/index.html&quot;&gt;Databricks Libraries doc&lt;/a&gt; to install the library on your clusters.&lt;/p&gt; 
&lt;p&gt;If this doesnâ€™t work because of an issue downloading delta-kernel-rust-sharing-wrapper try the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check python3 version &amp;gt;= 3.8&lt;/li&gt; 
 &lt;li&gt;Upgrade your pip3 to the latest version&lt;/li&gt; 
 &lt;li&gt;Check the linux glibc version &amp;gt;= 2.31&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.rust-lang.org/tools/install&quot;&gt;Install Rust&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you cannot upgrade glibc or PyPI does not have a pre-built wheel for delta-kernel-rust-sharing-wrapper for your environment, pip will have to build the package from source, which requires Rust to be installed. See &lt;a href=&quot;https://pypi.org/project/delta-kernel-rust-sharing-wrapper/0.2.1/#files&quot;&gt;https://pypi.org/project/delta-kernel-rust-sharing-wrapper/0.2.1/#files&lt;/a&gt; for environments that have a pre-built wheel.&lt;/p&gt; 
&lt;p&gt;You can also use an older version of the delta-sharing package which did not bake delta-kernel-rust-sharing-wrapper into the installation with the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip3 install delta-sharing==1.0.5
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install the delta-kernel-rust-sharing-wrapper package manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd [delta-sharing-root]/python/delta-kernel-rust-sharing-wrapper
python3 -m venv .venv
source .venv/bin/activate
pip3 install maturin
maturin develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Accessing Shared Data&lt;/h2&gt; 
&lt;p&gt;The connector accesses shared tables based on &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md#profile-file-format&quot;&gt;profile files&lt;/a&gt;, which are JSON files containing a user&#39;s credentials to access a Delta Sharing Server. We have several ways to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the profile file to access an open, example Delta Sharing Server that we&#39;re hosting &lt;a href=&quot;https://databricks-datasets-oregon.s3-us-west-2.amazonaws.com/delta-sharing/share/open-datasets.share&quot;&gt;here&lt;/a&gt;. You can try the connectors with this sample data.&lt;/li&gt; 
 &lt;li&gt;Start your own &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#delta-sharing-reference-server&quot;&gt;Delta Sharing Server&lt;/a&gt; and create your own profile file following &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md#profile-file-format&quot;&gt;profile file format&lt;/a&gt; to connect to this server.&lt;/li&gt; 
 &lt;li&gt;Download a profile file from your data provider.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;After you save the profile file, you can use it in the connector to access shared tables.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import delta_sharing

# Point to the profile file. It can be a file on the local file system or a file on a remote storage.
profile_file = &quot;&amp;lt;profile-file-path&amp;gt;&quot;

# Create a SharingClient.
client = delta_sharing.SharingClient(profile_file)

# List all shared tables.
client.list_all_tables()

# Create a url to access a shared table.
# A table path is the profile file path following with `#` and the fully qualified name of a table 
# (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
table_url = profile_file + &quot;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;

# Fetch 10 rows from a table and convert it to a Pandas DataFrame. This can be used to read sample data 
# from a table that cannot fit in the memory.
delta_sharing.load_as_pandas(table_url, limit=10)

# Load a table as a Pandas DataFrame. This can be used to process tables that can fit in the memory.
delta_sharing.load_as_pandas(table_url)

# Load a table as a Pandas DataFrame explicitly using Delta Format
delta_sharing.load_as_pandas(table_url, use_delta_format=True)

# Load a table as a Pandas DataFrame, using batch conversion to potentially reduce memory usage.
delta_sharing.load_as_pandas(table_url, convert_in_batches=True)

# Load a table as a Pandas DataFrame explicitly using jsonPredicateHints
hintOnHireDate = &#39;&#39;&#39;{
  &quot;op&quot;: &quot;equal&quot;,
  &quot;children&quot;: [
    {&quot;op&quot;: &quot;column&quot;, &quot;name&quot;:&quot;hireDate&quot;, &quot;valueType&quot;:&quot;date&quot;},
    {&quot;op&quot;:&quot;literal&quot;,&quot;value&quot;:&quot;2021-04-29&quot;,&quot;valueType&quot;:&quot;date&quot;}
  ]
}&#39;&#39;&#39;
delta_sharing.load_as_pandas(table_url, jsonPredicateHints = hintOnHireDate)

# If the code is running with PySpark, you can use `load_as_spark` to load the table as a Spark DataFrame.
delta_sharing.load_as_spark(table_url)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the table supports history sharing(&lt;code&gt;tableConfig.cdfEnabled=true&lt;/code&gt; in the OSS Delta Sharing Server), the connector can query table changes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;# Load table changes from version 0 to version 5, as a Pandas DataFrame.
delta_sharing.load_table_changes_as_pandas(table_url, starting_version=0, ending_version=5)

# Load table changes from version 0 to version 5 as a Pandas DataFrame, explicitly using Delta Format.
delta_sharing.load_table_changes_as_pandas(table_url, starting_version=0, ending_version=5, use_delta_format=True)

# Load table changes from version 0 to version 5, as a Pandas DataFrame, with batch conversion for potentially lower memory usage.
delta_sharing.load_table_changes_as_pandas(table_url, starting_version=0, ending_version=5, convert_in_batches=True)

# If the code is running with PySpark, you can load table changes as Spark DataFrame.
delta_sharing.load_table_changes_as_spark(table_url, starting_version=0, ending_version=5)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can try this by running our &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/examples/README.md&quot;&gt;examples&lt;/a&gt; with the open, example Delta Sharing Server.&lt;/p&gt; 
&lt;h3&gt;Details on Profile Paths&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The profile file path for &lt;code&gt;SharingClient&lt;/code&gt; and &lt;code&gt;load_as_pandas&lt;/code&gt; can be any URL supported by &lt;a href=&quot;https://filesystem-spec.readthedocs.io/en/latest/index.html&quot;&gt;FSSPEC&lt;/a&gt; (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;). If you are using &lt;a href=&quot;https://docs.databricks.com/data/databricks-file-system.html&quot;&gt;Databricks File System&lt;/a&gt;, you can also &lt;a href=&quot;https://docs.databricks.com/data/databricks-file-system.html#dbfs-and-local-driver-node-paths&quot;&gt;preface the path with &lt;code&gt;/dbfs/&lt;/code&gt;&lt;/a&gt; to access the profile file as if it were a local file.&lt;/li&gt; 
 &lt;li&gt;The profile file path for &lt;code&gt;load_as_spark&lt;/code&gt; can be any URL supported by Hadoop FileSystem (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;A table path is the profile file path following with &lt;code&gt;#&lt;/code&gt; and the fully qualified name of a table (&lt;code&gt;&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Apache Spark Connector&lt;/h1&gt; 
&lt;p&gt;The Apache Spark Connector implements the &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol&lt;/a&gt; to read shared tables from a Delta Sharing Server. It can be used in SQL, Python, Java, Scala and R.&lt;/p&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java 8+&lt;/li&gt; 
 &lt;li&gt;Scala 2.12.x&lt;/li&gt; 
 &lt;li&gt;Apache Spark 3+ or &lt;a href=&quot;https://docs.databricks.com/runtime/dbr.html&quot;&gt;Databricks Runtime&lt;/a&gt; 9+&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Accessing Shared Data&lt;/h2&gt; 
&lt;p&gt;The connector loads user credentials from profile files. Please see &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#accessing-shared-data&quot;&gt;Accessing Shared Data&lt;/a&gt; to download a profile file for our example server or for your own data sharing server.&lt;/p&gt; 
&lt;h2&gt;Configuring Apache Spark&lt;/h2&gt; 
&lt;p&gt;You can set up Apache Spark to load the Delta Sharing connector in the following two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run interactively: Start the Spark shell (Scala or Python) with the Delta Sharing connector and run the code snippets interactively in the shell.&lt;/li&gt; 
 &lt;li&gt;Run as a project: Set up a Maven or SBT project (Scala or Java) with the Delta Sharing connector, copy the code snippets into a source file, and run the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using &lt;a href=&quot;https://docs.databricks.com/runtime/dbr.html&quot;&gt;Databricks Runtime&lt;/a&gt;, you can skip this section and follow &lt;a href=&quot;https://docs.databricks.com/libraries/index.html&quot;&gt;Databricks Libraries doc&lt;/a&gt; to install the connector on your clusters.&lt;/p&gt; 
&lt;h3&gt;Set up an interactive shell&lt;/h3&gt; 
&lt;p&gt;To use Delta Sharing connector interactively within the Sparkâ€™s Scala/Python shell, you can launch the shells as follows.&lt;/p&gt; 
&lt;h4&gt;PySpark shell&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;pyspark --packages io.delta:delta-sharing-spark_2.12:3.1.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Scala Shell&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;bin/spark-shell --packages io.delta:delta-sharing-spark_2.12:3.1.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Set up a standalone project&lt;/h3&gt; 
&lt;p&gt;If you want to build a Java/Scala project using Delta Sharing connector from Maven Central Repository, you can use the following Maven coordinates.&lt;/p&gt; 
&lt;h4&gt;Maven&lt;/h4&gt; 
&lt;p&gt;You include Delta Sharing connector in your Maven project by adding it as a dependency in your POM file. Delta Sharing connector is compiled with Scala 2.12.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;io.delta&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;delta-sharing-spark_2.12&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.1.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;SBT&lt;/h4&gt; 
&lt;p&gt;You include Delta Sharing connector in your SBT project by adding the following line to your &lt;code&gt;build.sbt&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-scala&quot;&gt;libraryDependencies += &quot;io.delta&quot; %% &quot;delta-sharing-spark&quot; % &quot;3.1.0&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;After you save the profile file and launch Spark with the connector library, you can access shared tables using any language.&lt;/p&gt; 
&lt;h3&gt;SQL&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- A table path is the profile file path following with `#` and the fully qualified name 
-- of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
CREATE TABLE mytable USING deltaSharing LOCATION &#39;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&#39;;
SELECT * FROM mytable;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;# A table path is the profile file path following with `#` and the fully qualified name 
# of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
table_path = &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;
df = spark.read.format(&quot;deltaSharing&quot;).load(table_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scala&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-scala&quot;&gt;// A table path is the profile file path following with `#` and the fully qualified name 
// of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
val tablePath = &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;
val df = spark.read.format(&quot;deltaSharing&quot;).load(tablePath)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Java&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// A table path is the profile file path following with `#` and the fully qualified name 
// of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
String tablePath = &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;;
Dataset&amp;lt;Row&amp;gt; df = spark.read.format(&quot;deltaSharing&quot;).load(tablePath);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;R&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# A table path is the profile file path following with `#` and the fully qualified name 
# of a table (`&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;`).
table_path &amp;lt;- &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;
df &amp;lt;- read.df(table_path, &quot;deltaSharing&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can try this by running our &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/examples/README.md&quot;&gt;examples&lt;/a&gt; with the open, example Delta Sharing Server.&lt;/p&gt; 
&lt;h3&gt;CDF&lt;/h3&gt; 
&lt;p&gt;Starting from release 0.5.0, querying &lt;a href=&quot;https://docs.databricks.com/delta/delta-change-data-feed.html&quot;&gt;Change Data Feed&lt;/a&gt; is supported with Delta Sharing. Once the provider turns on CDF on the original delta table and shares it through Delta Sharing, the recipient can query CDF of a Delta Sharing table similar to CDF of a delta table.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-scala&quot;&gt;val tablePath = &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;
val df = spark.read.format(&quot;deltaSharing&quot;)
  .option(&quot;readChangeFeed&quot;, &quot;true&quot;)
  .option(&quot;startingVersion&quot;, &quot;3&quot;)
  .load(tablePath)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Streaming&lt;/h3&gt; 
&lt;p&gt;Starting from release 0.6.0, Delta Sharing table can be used as a data source for &lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&quot;&gt;Spark Structured Streaming&lt;/a&gt;. Once the provider shares a table with history, the recipient can perform a streaming query on the table.&lt;/p&gt; 
&lt;p&gt;Note: Trigger.AvailableNow is not supported in delta sharing streaming because it&#39;s supported since spark 3.3.0, while delta sharing is still using spark 3.1.1.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-scala&quot;&gt;val tablePath = &quot;&amp;lt;profile-file-path&amp;gt;#&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&quot;
val df = spark.readStream.format(&quot;deltaSharing&quot;)
  .option(&quot;startingVersion&quot;, &quot;1&quot;)
  .option(&quot;skipChangeCommits&quot;, &quot;true&quot;)
  .load(tablePath)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Table paths&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A profile file path can be any URL supported by Hadoop FileSystem (such as &lt;code&gt;s3a://my_bucket/my/profile/file&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;A table path is the profile file path following with &lt;code&gt;#&lt;/code&gt; and the fully qualified name of a table (&lt;code&gt;&amp;lt;share-name&amp;gt;.&amp;lt;schema-name&amp;gt;.&amp;lt;table-name&amp;gt;&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;The Community&lt;/h1&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/images/the-community.png&quot; alt=&quot;Delta Sharing OSS Connectors&quot; width=&quot;400&quot; /&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th&gt;Connector&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Supported Features&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Power BI&lt;/td&gt; 
   &lt;td&gt;Databricks owned&lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Clojure&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/amperity/delta-sharing-client-clj&quot;&gt;amperity/delta-sharing-client-clj&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;br /&gt;QueryTableChanges(CDF)&lt;br /&gt;Time Travel Queries&lt;br /&gt;Query Changes between Versions&lt;br /&gt;Delta Format Queries&lt;br /&gt;Limit and Predicate Pushdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
  &lt;/tr&gt;
  &lt;tr&gt; 
   &lt;td&gt;Node.js&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/goodwillpunning/nodejs-sharing-client&quot;&gt;goodwillpunning/nodejs-sharing-client&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/databrickslabs/delta-sharing-java-connector&quot;&gt;databrickslabs/delta-sharing-java-connector&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arcuate&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/databrickslabs/arcuate&quot;&gt;databrickslabs/arcuate&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/r3stl355/delta-sharing-rust-client&quot;&gt;r3stl355/delta-sharing-rust-client&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Go&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/magpierre/delta-sharing/tree/golangdev/golang/delta_sharing_go&quot;&gt;magpierre/delta-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C++&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/magpierre/delta-sharing/tree/cppdev/cpp/DeltaSharingClient&quot;&gt;magpierre/delta-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/zacdav-db/delta-sharing-r&quot;&gt;zacdav-db/delta-sharing-r&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Released&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google Spreadsheet&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/delta-incubator/delta-sharing-connectors/tree/main/google_workspace_add_on&quot;&gt;delta-incubator/delta-sharing-connectors&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Beta&lt;/td&gt; 
   &lt;td&gt;QueryTableVersion&lt;br /&gt;QueryTableMetadata&lt;br /&gt;QueryTableLatestSnapshot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Airflow&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/apache/airflow/pull/22692&quot;&gt;apache/airflow&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Un-released&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Excel-Connector&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://www.exponam.com/solutions/&quot;&gt;https://www.exponam.com/solutions/&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;limited-release&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Lakehouse Sharing&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/rajagurunath/lakehouse-sharing&quot;&gt;rajagurunath/lakehouse-sharing&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td&gt;Preview&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;a href=&quot;https://guruengineering.substack.com/p/lakehouse-sharing&quot;&gt;Demonstrates&lt;/a&gt; a table format agnostic data sharing&lt;br /&gt; server (based on delta-sharing protocol) implemented in python for both Delta Lake and Iceberg formats.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h1&gt;Delta Sharing Reference Server&lt;/h1&gt; 
&lt;p&gt;The Delta Sharing Reference Server is a reference implementation server for the &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol&lt;/a&gt;. This can be used to set up a small service to test your own connector that implements the &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol&lt;/a&gt;. Please note that this is not a completed implementation of secure web server. We highly recommend you to put this behind a secure proxy if you would like to expose it to public.&lt;/p&gt; 
&lt;p&gt;Some vendors offer managed services for Delta Sharing too (for example, &lt;a href=&quot;https://databricks.com/product/delta-sharing&quot;&gt;Databricks&lt;/a&gt;). Please refer to your vendor&#39;s website for how to set up sharing there. Vendors that are interested in being listed as a service provider should open an issue on GitHub to be added to this README and our project&#39;s website.&lt;/p&gt; 
&lt;p&gt;Here are the steps to setup the reference server to share your own data.&lt;/p&gt; 
&lt;h2&gt;Get the pre-built package&lt;/h2&gt; 
&lt;p&gt;Download the pre-built package &lt;code&gt;delta-sharing-server-x.y.z.zip&lt;/code&gt; from &lt;a href=&quot;https://github.com/delta-io/delta-sharing/releases&quot;&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Server configuration and adding Shared Data&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Unpack the pre-built package and copy the server config template file &lt;code&gt;conf/delta-sharing-server.yaml.template&lt;/code&gt; to create your own server yaml file, such as &lt;code&gt;conf/delta-sharing-server.yaml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Make changes to your yaml file. You may also need to update some server configs for special requirements.&lt;/li&gt; 
 &lt;li&gt;To add Shared Data, add reference to Delta Lake tables you would like to share from this server in this config file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Config the server to access tables on cloud storage&lt;/h2&gt; 
&lt;p&gt;We support sharing Delta Lake tables on S3, Azure Blob Storage and Azure Data Lake Storage Gen2.&lt;/p&gt; 
&lt;h3&gt;S3&lt;/h3&gt; 
&lt;p&gt;The server is using &lt;code&gt;hadoop-aws&lt;/code&gt; to access S3. Table paths in the server config file should use &lt;code&gt;s3a://&lt;/code&gt; paths rather than &lt;code&gt;s3://&lt;/code&gt; paths. There are multiple ways to config S3 authentication.&lt;/p&gt; 
&lt;h4&gt;EC2 IAM Metadata Authentication (Recommended)&lt;/h4&gt; 
&lt;p&gt;Applications running in EC2 may associate an IAM role with the VM and query the &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html&quot;&gt;EC2 Instance Metadata Service&lt;/a&gt; for credentials to access S3.&lt;/p&gt; 
&lt;h4&gt;Authenticating via the AWS Environment Variables&lt;/h4&gt; 
&lt;p&gt;We support configuration via &lt;a href=&quot;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html#cli-environment&quot;&gt;the standard AWS environment variables&lt;/a&gt;. The core environment variables are for the access key and associated secret:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=my.aws.key
export AWS_SECRET_ACCESS_KEY=my.secret.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Other S3 authentication methods&lt;/h4&gt; 
&lt;p&gt;You can find other approaches in &lt;a href=&quot;https://hadoop.apache.org/docs/r2.10.1/hadoop-aws/tools/hadoop-aws/index.html#S3A_Authentication_methods&quot;&gt;hadoop-aws doc&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Blob Storage&lt;/h3&gt; 
&lt;p&gt;The server is using &lt;code&gt;hadoop-azure&lt;/code&gt; to read Azure Blob Storage. Using Azure Blob Storage requires &lt;a href=&quot;https://hadoop.apache.org/docs/current/hadoop-azure/index.html#Configuring_Credentials&quot;&gt;configuration of credentials&lt;/a&gt;. You can create a Hadoop configuration file named &lt;code&gt;core-site.xml&lt;/code&gt; and add it to the server&#39;s &lt;code&gt;conf&lt;/code&gt; directory. Then add the following content to the xml file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.azure.account.key.YOUR-ACCOUNT-NAME.blob.core.windows.net&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;YOUR-ACCOUNT-KEY&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;YOUR-ACCOUNT-NAME&lt;/code&gt; is your Azure storage account and &lt;code&gt;YOUR-ACCOUNT-KEY&lt;/code&gt; is your account key.&lt;/p&gt; 
&lt;h3&gt;Azure Data Lake Storage Gen2&lt;/h3&gt; 
&lt;p&gt;The server is using &lt;code&gt;hadoop-azure&lt;/code&gt; to read Azure Data Lake Storage Gen2. We support &lt;a href=&quot;https://hadoop.apache.org/docs/stable/hadoop-azure/abfs.html#Default:_Shared_Key&quot;&gt;the Shared Key authentication&lt;/a&gt;. You can create a Hadoop configuration file named &lt;code&gt;core-site.xml&lt;/code&gt; and add it to the server&#39;s &lt;code&gt;conf&lt;/code&gt; directory. Then add the following content to the xml file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.azure.account.auth.type.YOUR-ACCOUNT-NAME.dfs.core.windows.net&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;SharedKey&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.azure.account.key.YOUR-ACCOUNT-NAME.dfs.core.windows.net&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;YOUR-ACCOUNT-KEY&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;
    The secret password. Never share these.
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;YOUR-ACCOUNT-NAME&lt;/code&gt; is your Azure storage account and &lt;code&gt;YOUR-ACCOUNT-KEY&lt;/code&gt; is your account key.&lt;/p&gt; 
&lt;h3&gt;Google Cloud Storage&lt;/h3&gt; 
&lt;p&gt;We support using &lt;a href=&quot;https://cloud.google.com/iam/docs/service-accounts&quot;&gt;Service Account&lt;/a&gt; to read Google Cloud Storage. You can find more details in &lt;a href=&quot;https://cloud.google.com/docs/authentication/getting-started&quot;&gt;GCP Authentication Doc&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To set up the Service Account credentials, you can specify the environment GOOGLE_APPLICATION_CREDENTIALS before starting the Delta Sharing Server.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export GOOGLE_APPLICATION_CREDENTIALS=&quot;KEY_PATH&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;KEY_PATH&lt;/code&gt; with path of the JSON file that contains your service account key.&lt;/p&gt; 
&lt;h3&gt;Cloudflare R2&lt;/h3&gt; 
&lt;p&gt;We use an R2 implementation of the &lt;a href=&quot;https://developers.cloudflare.com/r2/api/s3/api/&quot;&gt;S3 API&lt;/a&gt; and &lt;code&gt;hadoop-aws&lt;/code&gt; to read Cloudflare R2. Table paths in the server config file should use the &lt;code&gt;s3a://&lt;/code&gt; scheme. You must &lt;a href=&quot;https://developers.cloudflare.com/r2/api/s3/tokens/&quot;&gt;generate an API token&lt;/a&gt; for usage with existing S3-compatible SDKs. These credentials can be specified in substitute of the S3 credentials in a Hadoop configuration file named &lt;code&gt;core-site.xml&lt;/code&gt; within the server&#39;s &lt;code&gt;conf&lt;/code&gt; directory. For R2 to work, you also need to directly specify the S3 endpoint and reduce &lt;code&gt;fs.s3a.paging.maximum&lt;/code&gt; from Hadoop&#39;s default of 5000 to 1000 since R2 only supports &lt;code&gt;MaxKeys&lt;/code&gt; &amp;lt;= 1000.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.s3a.access.key&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;YOUR-ACCESS-KEY&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.s3a.secret.key&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;YOUR-SECRET-KEY&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.s3a.endpoint&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;https://YOUR-ACCOUNT-ID.r2.cloudflarestorage.com&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.s3a.paging.maximum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;1000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;YOUR-ACCESS-KEY&lt;/code&gt; with your generated API token&#39;s R2 access key ID, &lt;code&gt;YOUR-SECRET-KEY&lt;/code&gt; with your generated API token&#39;s secret access key, and &lt;code&gt;YOUR-ACCOUNT-ID&lt;/code&gt; with your Cloudflare account ID.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: S3 and R2 credentials cannot be configured simultaneously.&lt;/p&gt; 
&lt;h2&gt;Authorization&lt;/h2&gt; 
&lt;p&gt;The server supports a basic authorization with pre-configed bearer token. You can add the following config to your server yaml file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;authorization:
  bearerToken: &amp;lt;token&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then any request should send with the above token, otherwise, the server will refuse the request.&lt;/p&gt; 
&lt;p&gt;If you don&#39;t config the bearer token in the server yaml file, all requests will be accepted without authorization.&lt;/p&gt; 
&lt;p&gt;To be more secure, you recommend you to put the server behind a secure proxy such as &lt;a href=&quot;https://www.nginx.com/&quot;&gt;NGINX&lt;/a&gt; to set up &lt;a href=&quot;https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-jwt-authentication/&quot;&gt;JWT Authentication&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Start the server&lt;/h2&gt; 
&lt;p&gt;Run the following shell command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bin/delta-sharing-server -- --config &amp;lt;the-server-config-yaml-file&amp;gt; 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;&amp;lt;the-server-config-yaml-file&amp;gt;&lt;/code&gt; should be the path of the yaml file you created in the previous step. You can find options to config JVM in &lt;a href=&quot;https://www.scala-sbt.org/sbt-native-packager/archetypes/java_app/index.html#start-script-options&quot;&gt;sbt-native-packager&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use the pre-built Docker image&lt;/h2&gt; 
&lt;p&gt;You can use the pre-built docker image from &lt;a href=&quot;https://hub.docker.com/r/deltaio/delta-sharing-server&quot;&gt;https://hub.docker.com/r/deltaio/delta-sharing-server&lt;/a&gt; by running the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -p &amp;lt;host-port&amp;gt;:&amp;lt;container-port&amp;gt; \
  --mount type=bind,source=&amp;lt;the-server-config-yaml-file&amp;gt;,target=/config/delta-sharing-server-config.yaml \
  deltaio/delta-sharing-server:0.7.8 -- --config /config/delta-sharing-server-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;&amp;lt;container-port&amp;gt;&lt;/code&gt; should be the same as the port defined inside the config file.&lt;/p&gt; 
&lt;h2&gt;API Compatibility&lt;/h2&gt; 
&lt;p&gt;The REST APIs provided by Delta Sharing Server are stable public APIs. They are defined by &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol&lt;/a&gt; and we will follow the entire protocol strictly.&lt;/p&gt; 
&lt;p&gt;The interfaces inside Delta Sharing Server are not public APIs. They are considered internal, and they are subject to change across minor/patch releases.&lt;/p&gt; 
&lt;h1&gt;Delta Sharing Protocol&lt;/h1&gt; 
&lt;p&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/PROTOCOL.md&quot;&gt;Delta Sharing Protocol specification&lt;/a&gt; details the protocol.&lt;/p&gt; 
&lt;h1&gt;Building this Project&lt;/h1&gt; 
&lt;h2&gt;Python Connector&lt;/h2&gt; 
&lt;p&gt;To execute tests, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python/dev/pytest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install in develop mode, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd python/
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install locally, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd python/
pip install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To generate a wheel file, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd python/
python setup.py sdist bdist_wheel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will generate &lt;code&gt;python/dist/delta_sharing-x.y.z-py3-none-any.whl&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Apache Spark Connector and Delta Sharing Server&lt;/h2&gt; 
&lt;p&gt;Apache Spark Connector and Delta Sharing Server are compiled using &lt;a href=&quot;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&quot;&gt;SBT&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To compile, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt compile
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To execute tests, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To generate the Apache Spark Connector, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt spark/package
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will generate &lt;code&gt;spark/target/scala-2.12/delta-sharing-spark_2.12-x.y.z.jar&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To generate the pre-built Delta Sharing Server package, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt server/universal:packageBin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will generate &lt;code&gt;server/target/universal/delta-sharing-server-x.y.z.zip&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To build the Docker image for Delta Sharing Server, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt server/docker:publishLocal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will build a Docker image tagged &lt;code&gt;delta-sharing-server:x.y.z&lt;/code&gt;, which you can run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -p &amp;lt;host-port&amp;gt;:&amp;lt;container-port&amp;gt; \
  --mount type=bind,source=&amp;lt;the-server-config-yaml-file&amp;gt;,target=/config/delta-sharing-server-config.yaml \
  delta-sharing-server:x.y.z -- --config /config/delta-sharing-server-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;&amp;lt;container-port&amp;gt;&lt;/code&gt; should be the same as the port defined inside the config file.&lt;/p&gt; 
&lt;p&gt;Refer to &lt;a href=&quot;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&quot;&gt;SBT docs&lt;/a&gt; for more commands.&lt;/p&gt; 
&lt;h1&gt;Reporting Issues&lt;/h1&gt; 
&lt;p&gt;We use &lt;a href=&quot;https://github.com/delta-io/delta-sharing/issues&quot;&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/#community&quot;&gt;contact&lt;/a&gt; the community for getting answers.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to Delta Sharing. See our &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;We also adhere to the &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/CODE_OF_CONDUCT.md&quot;&gt;Delta Lake Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta-sharing/main/LICENSE.txt&quot;&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;p&gt;We use the same community resources as the Delta Lake project:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Public Slack Channel&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://go.delta.io/slack&quot;&gt;Register here&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://delta-users.slack.com/&quot;&gt;Login here&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Public &lt;a href=&quot;https://groups.google.com/forum/#!forum/delta-users&quot;&gt;Mailing list&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ucb-bar/berkeley-hardfloat</title>
      <link>https://github.com/ucb-bar/berkeley-hardfloat</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Berkeley Hardware Floating-Point Units&lt;/h1&gt; 
&lt;p&gt;This repository contains hardware floating-point units written in Chisel. This library contains parameterized floating-point units for fused multiply-add operations, conversions between integer and floating-point numbers, and conversions between floating-point conversions with different precision.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: These units are works in progress. They may not be yet completely free of bugs, nor are they fully optimized.&lt;/p&gt; 
&lt;h2&gt;Recoded Format&lt;/h2&gt; 
&lt;p&gt;The floating-point units in this repository work on an internal recoded format (exponent has an additional bit) to handle subnormal numbers more efficiently in a microprocessor. A more detailed explanation will come soon, but in the mean time here are some example mappings for single-precision numbers.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;IEEE format                           Recoded format
----------------------------------    -----------------------------------
s 00000000 00000000000000000000000    s 000------ 00000000000000000000000
s 00000000 00000000000000000000001    s 001101011 00000000000000000000000
s 00000000 0000000000000000000001f    s 001101100 f0000000000000000000000
s 00000000 000000000000000000001ff    s 001101101 ff000000000000000000000
    ...              ...                   ...              ... 
s 00000000 001ffffffffffffffffffff    s 001111111 ffffffffffffffffffff000
s 00000000 01fffffffffffffffffffff    s 010000000 fffffffffffffffffffff00
s 00000000 1ffffffffffffffffffffff    s 010000001 ffffffffffffffffffffff0
s 00000001 fffffffffffffffffffffff    s 010000010 fffffffffffffffffffffff
s 00000010 fffffffffffffffffffffff    s 010000011 fffffffffffffffffffffff
    ...              ...                   ...              ... 
s 11111101 fffffffffffffffffffffff    s 101111110 fffffffffffffffffffffff
s 11111110 fffffffffffffffffffffff    s 101111111 fffffffffffffffffffffff
s 11111111 00000000000000000000000    s 110------ -----------------------
s 11111111 fffffffffffffffffffffff    s 111------ fffffffffffffffffffffff
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Unit-Testing&lt;/h2&gt; 
&lt;p&gt;To unit-test these floating-point units, you need the berkeley-testfloat-3 package.&lt;/p&gt; 
&lt;p&gt;To test floating-point units with the C simulator:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>apache/spark</title>
      <link>https://github.com/apache/spark</link>
      <description>&lt;p&gt;Apache Spark - A unified analytics engine for large-scale data processing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Spark&lt;/h1&gt; 
&lt;p&gt;Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Scala, Java, Python, and R (Deprecated), and an optimized engine that supports general computation graphs for data analysis. It also supports a rich set of higher-level tools including Spark SQL for SQL and DataFrames, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for stream processing.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Official version: &lt;a href=&quot;https://spark.apache.org/&quot;&gt;https://spark.apache.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Development version: &lt;a href=&quot;https://apache.github.io/spark/&quot;&gt;https://apache.github.io/spark/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_main.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_main.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/apache/spark&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg?sanitize=true&quot; alt=&quot;PySpark Coverage&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/pyspark/&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/personalized-badge/pyspark?period=month&amp;amp;units=international_system&amp;amp;left_color=black&amp;amp;right_color=orange&amp;amp;left_text=PyPI%20downloads&quot; alt=&quot;PyPI Downloads&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Online Documentation&lt;/h2&gt; 
&lt;p&gt;You can find the latest Spark documentation, including a programming guide, on the &lt;a href=&quot;https://spark.apache.org/documentation.html&quot;&gt;project web page&lt;/a&gt;. This README file only contains basic setup instructions.&lt;/p&gt; 
&lt;h2&gt;Build Pipeline Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Branch&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;master&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/release.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/release.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_java21.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_java21.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_non_ansi.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_non_ansi.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_uds.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_uds.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_rockdb_as_ui_backend.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_rockdb_as_ui_backend.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_maven.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_maven.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21_macos15.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21_macos15.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21_arm.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_maven_java21_arm.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_coverage.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_coverage.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_pypy3.10.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_pypy3.10.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.10.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.10.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_classic_only.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_classic_only.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_arm.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_arm.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_macos.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.11_macos.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_numpy_2.1.3.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_numpy_2.1.3.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.12.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.12.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.13.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.13.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.13_nogil.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_3.13_nogil.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_minimum.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_minimum.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_ps_minimum.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_ps_minimum.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_connect35.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_connect35.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_python_connect.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_python_connect.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_sparkr_window.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_sparkr_window.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/publish_snapshot.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/publish_snapshot.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;branch-4.0&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_java21.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_java21.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_non_ansi.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_non_ansi.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_maven.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_maven.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_maven_java21.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_maven_java21.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_python.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_python.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_python_pypy3.10.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch40_python_pypy3.10.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;branch-3.5&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch35.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch35.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/apache/spark/actions/workflows/build_branch35_python.yml&quot;&gt;&lt;img src=&quot;https://github.com/apache/spark/actions/workflows/build_branch35_python.yml/badge.svg?sanitize=true&quot; alt=&quot;GitHub Actions Build&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Building Spark&lt;/h2&gt; 
&lt;p&gt;Spark is built using &lt;a href=&quot;https://maven.apache.org/&quot;&gt;Apache Maven&lt;/a&gt;. To build Spark and its example programs, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./build/mvn -DskipTests clean package
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(You do not need to do this if you downloaded a pre-built package.)&lt;/p&gt; 
&lt;p&gt;More detailed documentation is available from the project site, at &lt;a href=&quot;https://spark.apache.org/docs/latest/building-spark.html&quot;&gt;&quot;Building Spark&quot;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For general development tips, including info on developing Spark using an IDE, see &lt;a href=&quot;https://spark.apache.org/developer-tools.html&quot;&gt;&quot;Useful Developer Tools&quot;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Interactive Scala Shell&lt;/h2&gt; 
&lt;p&gt;The easiest way to start using Spark is through the Scala shell:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./bin/spark-shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try the following command, which should return 1,000,000,000:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-scala&quot;&gt;scala&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Interactive Python Shell&lt;/h2&gt; 
&lt;p&gt;Alternatively, if you prefer Python, you can use the Python shell:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./bin/pyspark
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And run the following command, which should also return 1,000,000,000:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; spark.range(1000 * 1000 * 1000).count()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example Programs&lt;/h2&gt; 
&lt;p&gt;Spark also comes with several sample programs in the &lt;code&gt;examples&lt;/code&gt; directory. To run one of them, use &lt;code&gt;./bin/run-example &amp;lt;class&amp;gt; [params]&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will run the Pi example locally.&lt;/p&gt; 
&lt;p&gt;You can set the MASTER environment variable when running examples to submit examples to a cluster. This can be spark:// URL, &quot;yarn&quot; to run on YARN, and &quot;local&quot; to run locally with one thread, or &quot;local[N]&quot; to run locally with N threads. You can also use an abbreviated class name if the class is in the &lt;code&gt;examples&lt;/code&gt; package. For instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;MASTER=spark://host:7077 ./bin/run-example SparkPi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Many of the example programs print usage help if no params are given.&lt;/p&gt; 
&lt;h2&gt;Running Tests&lt;/h2&gt; 
&lt;p&gt;Testing first requires &lt;a href=&quot;https://raw.githubusercontent.com/apache/spark/master/#building-spark&quot;&gt;building Spark&lt;/a&gt;. Once Spark is built, tests can be run using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;./dev/run-tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please see the guidance on how to &lt;a href=&quot;https://spark.apache.org/developer-tools.html#individual-tests&quot;&gt;run tests for a module, or individual tests&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;There is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md&lt;/p&gt; 
&lt;h2&gt;A Note About Hadoop Versions&lt;/h2&gt; 
&lt;p&gt;Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported storage systems. Because the protocols have changed in different versions of Hadoop, you must build Spark against the same version that your cluster runs.&lt;/p&gt; 
&lt;p&gt;Please refer to the build documentation at &lt;a href=&quot;https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn&quot;&gt;&quot;Specifying the Hadoop Version and Enabling YARN&quot;&lt;/a&gt; for detailed guidance on building for a particular distribution of Hadoop, including building for particular Hive and Hive Thriftserver distributions.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href=&quot;https://spark.apache.org/docs/latest/configuration.html&quot;&gt;Configuration Guide&lt;/a&gt; in the online documentation for an overview on how to configure Spark.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please review the &lt;a href=&quot;https://spark.apache.org/contributing.html&quot;&gt;Contribution to Spark guide&lt;/a&gt; for information on how to get started contributing to the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lichess-org/lila</title>
      <link>https://github.com/lichess-org/lila</link>
      <description>&lt;p&gt;â™ž lichess.org: the forever free, adless and open source chess server â™ž&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&quot;https://lichess.org&quot;&gt;lichess.org&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/lichess-org/lila/actions/workflows/server.yml&quot;&gt;&lt;img src=&quot;https://github.com/lichess-org/lila/actions/workflows/server.yml/badge.svg?sanitize=true&quot; alt=&quot;Build server&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/lichess-org/lila/actions/workflows/assets.yml&quot;&gt;&lt;img src=&quot;https://github.com/lichess-org/lila/actions/workflows/assets.yml/badge.svg?sanitize=true&quot; alt=&quot;Build assets&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://crowdin.com/project/lichess&quot;&gt;&lt;img src=&quot;https://d322cqt584bo4o.cloudfront.net/lichess/localized.svg?sanitize=true&quot; alt=&quot;Crowdin&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://mastodon.online/@lichess&quot;&gt;&lt;img src=&quot;https://img.shields.io/mastodon/follow/109298525492334687?domain=mastodon.online&quot; alt=&quot;Mastodon&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bsky.app/profile/lichess.org&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;amp;logoColor=fff&quot; alt=&quot;Bluesky&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/lichess&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/280713822073913354?label=Discord&amp;amp;logo=discord&amp;amp;style=flat&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/lichess-org/lila/master/public/images/home-bicolor.png&quot; alt=&quot;Lichess homepage&quot; title=&quot;Lichess comes with light and dark theme, this screenshot shows both.&quot; /&gt; 
&lt;p&gt;Lila (li[chess in sca]la) is a free online chess game server focused on &lt;a href=&quot;https://lichess.org/games&quot;&gt;realtime&lt;/a&gt; gameplay and ease of use.&lt;/p&gt; 
&lt;p&gt;It features a &lt;a href=&quot;https://lichess.org/games/search&quot;&gt;search engine&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/ief49lif&quot;&gt;computer analysis&lt;/a&gt; distributed with &lt;a href=&quot;https://github.com/lichess-org/fishnet&quot;&gt;fishnet&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/tournament&quot;&gt;tournaments&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/simul&quot;&gt;simuls&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/forum&quot;&gt;forums&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/team&quot;&gt;teams&lt;/a&gt;, &lt;a href=&quot;https://lichess.org/training&quot;&gt;tactic trainer&lt;/a&gt;, a &lt;a href=&quot;https://lichess.org/mobile&quot;&gt;mobile app&lt;/a&gt;, and a &lt;a href=&quot;https://lichess.org/study&quot;&gt;shared analysis board&lt;/a&gt;. The UI is available in more than &lt;a href=&quot;https://crowdin.com/project/lichess&quot;&gt;140 languages&lt;/a&gt; thanks to the community.&lt;/p&gt; 
&lt;p&gt;Lichess is written in &lt;a href=&quot;https://www.scala-lang.org/&quot;&gt;Scala 3&lt;/a&gt;, and relies on the &lt;a href=&quot;https://www.playframework.com/&quot;&gt;Play 2.8&lt;/a&gt; framework. &lt;a href=&quot;https://com-lihaoyi.github.io/scalatags/&quot;&gt;scalatags&lt;/a&gt; is used for templating. Pure chess logic is contained in the &lt;a href=&quot;https://github.com/lichess-org/scalachess&quot;&gt;scalachess&lt;/a&gt; submodule. The server is fully asynchronous, making heavy use of Scala Futures and &lt;a href=&quot;https://akka.io&quot;&gt;Akka streams&lt;/a&gt;. WebSocket connections are handled by a &lt;a href=&quot;https://github.com/lichess-org/lila-ws&quot;&gt;separate server&lt;/a&gt; that communicates using &lt;a href=&quot;https://redis.io/&quot;&gt;redis&lt;/a&gt;. Lichess talks to &lt;a href=&quot;https://stockfishchess.org/&quot;&gt;Stockfish&lt;/a&gt; deployed in an &lt;a href=&quot;https://github.com/lichess-org/fishnet&quot;&gt;AI cluster&lt;/a&gt; of donated servers. It uses &lt;a href=&quot;https://www.mongodb.com&quot;&gt;MongoDB&lt;/a&gt; to store more than 4.7 billion games, which are indexed by &lt;a href=&quot;https://github.com/elastic/elasticsearch&quot;&gt;elasticsearch&lt;/a&gt;. HTTP requests and WebSocket connections can be proxied by &lt;a href=&quot;https://nginx.org&quot;&gt;nginx&lt;/a&gt;. The web client is written in &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt; and &lt;a href=&quot;https://github.com/snabbdom/snabbdom&quot;&gt;snabbdom&lt;/a&gt;, using &lt;a href=&quot;https://sass-lang.com/&quot;&gt;Sass&lt;/a&gt; to generate CSS. All rated games are published in a &lt;a href=&quot;https://database.lichess.org&quot;&gt;free PGN database&lt;/a&gt;. Browser testing done with &lt;a href=&quot;https://www.browserstack.com&quot;&gt;Browserstack&lt;/a&gt;. Proxy detection done with &lt;a href=&quot;https://www.ip2location.com/database/ip2proxy&quot;&gt;IP2Proxy database&lt;/a&gt;. Please help us &lt;a href=&quot;https://crowdin.com/project/lichess&quot;&gt;translate Lichess with Crowdin&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://lichess.org/source&quot;&gt;lichess.org/source&lt;/a&gt; for a list of repositories.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/lichess&quot;&gt;Join us on Discord&lt;/a&gt; for more info. Use &lt;a href=&quot;https://github.com/lichess-org/lila/issues&quot;&gt;GitHub issues&lt;/a&gt; for bug reports and feature requests.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;./lila.sh # thin wrapper around sbt
run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Wiki describes &lt;a href=&quot;https://github.com/lichess-org/lila/wiki/Lichess-Development-Onboarding&quot;&gt;how to setup a development environment&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;HTTP API&lt;/h2&gt; 
&lt;p&gt;Feel free to use the &lt;a href=&quot;https://lichess.org/api&quot;&gt;Lichess API&lt;/a&gt; in your applications and websites.&lt;/p&gt; 
&lt;h2&gt;Supported browsers&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chromium / Chrome&lt;/td&gt; 
   &lt;td&gt;last 10&lt;/td&gt; 
   &lt;td&gt;Full support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Firefox&lt;/td&gt; 
   &lt;td&gt;75+&lt;/td&gt; 
   &lt;td&gt;Full support (fastest local analysis since FF 79)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Edge&lt;/td&gt; 
   &lt;td&gt;91+&lt;/td&gt; 
   &lt;td&gt;Full support (reasonable support for 79+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Opera&lt;/td&gt; 
   &lt;td&gt;66+&lt;/td&gt; 
   &lt;td&gt;Reasonable support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Safari&lt;/td&gt; 
   &lt;td&gt;11.1+&lt;/td&gt; 
   &lt;td&gt;Reasonable support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Older browsers (including any version of Internet Explorer) will not work. For your own sake, please upgrade. Security and performance, think about it!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Lila is licensed under the GNU Affero General Public License 3 or any later version at your choice. See &lt;a href=&quot;https://github.com/lichess-org/lila/raw/master/COPYING.md&quot;&gt;copying&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Production architecture (as of July 2022)&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/lichess-org/lila/master/public/images/architecture.png&quot; alt=&quot;Lichess production server architecture diagram&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://lichess.org/thanks&quot;&gt;lichess.org/thanks&lt;/a&gt; and the contributors here:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/lichess-org/lila/graphs/contributors&quot;&gt;&lt;img src=&quot;https://contrib.rocks/image?repo=lichess-org/lila&quot; alt=&quot;GitHub contributors&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Competence development program&lt;/h2&gt; 
&lt;p&gt;Lichess would like to support its contributors in their competence development by covering costs of relevant training materials and activities. This is a small way to further empower contributors who have given their time to Lichess and to enable or improve additional contributions to Lichess in the future. For more information, including how to apply, check &lt;a href=&quot;https://lichess.org/page/competence-development&quot;&gt;Competence Development for Lichess contributors&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>akka/akka</title>
      <link>https://github.com/akka/akka</link>
      <description>&lt;p&gt;A platform to build and run apps that are elastic, agile, and resilient. SDK, libraries, and hosted environments.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Akka&lt;/h1&gt; 
&lt;p&gt;The Akka family of projects is managed by teams at &lt;a href=&quot;https://akka.io/&quot;&gt;Akka&lt;/a&gt; with help from the community.&lt;/p&gt; 
&lt;p&gt;We believe that writing correct concurrent &amp;amp; distributed, resilient and elastic applications is too hard. Most of the time it&#39;s because we are using the wrong tools and the wrong level of abstraction.&lt;/p&gt; 
&lt;p&gt;Akka is here to change that.&lt;/p&gt; 
&lt;p&gt;Using the Actor Model we raise the abstraction level and provide a better platform to build correct concurrent and scalable applications. This model is a perfect match for the principles laid out in the &lt;a href=&quot;https://www.reactivemanifesto.org/&quot;&gt;Reactive Manifesto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For resilience, we adopt the &quot;Let it crash&quot; model which the telecom industry has used with great success to build applications that self-heal and systems that never stop.&lt;/p&gt; 
&lt;p&gt;Actors also provide the abstraction for transparent distribution and the basis for truly scalable and fault-tolerant applications.&lt;/p&gt; 
&lt;p&gt;Learn more at &lt;a href=&quot;https://akka.io/&quot;&gt;akka.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Reference Documentation&lt;/h2&gt; 
&lt;p&gt;The reference documentation is available at &lt;a href=&quot;https://doc.akka.io&quot;&gt;doc.akka.io&lt;/a&gt;, for &lt;a href=&quot;https://doc.akka.io/libraries/akka-core/current/?language=scala&quot;&gt;Scala&lt;/a&gt; and &lt;a href=&quot;https://doc.akka.io/libraries/akka-core/current/?language=java&quot;&gt;Java&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Current versions of all Akka libraries&lt;/h2&gt; 
&lt;p&gt;The current versions of all Akka libraries are listed on the &lt;a href=&quot;https://doc.akka.io/libraries/akka-dependencies/current/&quot;&gt;Akka Dependencies&lt;/a&gt; page. Releases of the Akka core libraries in this repository are listed on the &lt;a href=&quot;https://github.com/akka/akka/releases&quot;&gt;GitHub releases&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;You can join these groups and chats to discuss and ask Akka related questions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Forums: &lt;a href=&quot;https://discuss.akka.io&quot;&gt;discuss.akka.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Issue tracker: &lt;a href=&quot;https://github.com/akka/akka/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/github%3A-issues-blue.svg?style=flat-square&quot; alt=&quot;github: akka/akka&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to that, you may enjoy following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Questions tagged &lt;a href=&quot;https://stackoverflow.com/questions/tagged/akka&quot;&gt;#akka on StackOverflow&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Contributions are &lt;em&gt;very&lt;/em&gt; welcome!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you see an issue that you&#39;d like to see fixed, or want to shape out some ideas, the best way to make it happen is to help out by submitting a pull request implementing it. We welcome contributions from all, even you are not yet familiar with this project, We are happy to get you started, and will guide you through the process once you&#39;ve submitted your PR.&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href=&quot;https://github.com/akka/akka/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; file for more details about the workflow, and general hints on how to prepare your pull request. You can also ask for clarifications or guidance in GitHub issues directly, or in the akka/dev chat if a more real time communication would be of benefit.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Akka is licensed under the Business Source License 1.1, please see the &lt;a href=&quot;https://akka.io/bsl-license-faq&quot;&gt;Akka License FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Tests and documentation are under a separate license, see the LICENSE file in each documentation and test root directory for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheHive-Project/TheHive</title>
      <link>https://github.com/TheHive-Project/TheHive</link>
      <description>&lt;p&gt;TheHive: a Scalable, Open Source and Free Security Incident Response Platform&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;TheHive 3 &amp;amp; TheHive 4 â€“ End of public distribution&lt;/h2&gt; 
&lt;p&gt;Thank you for your interest in TheHive!&lt;/p&gt; 
&lt;h2&gt;End of availability for versions 3.x and 4.x&lt;/h2&gt; 
&lt;p&gt;TheHive 3 and TheHive 4 versions are no longer maintained, distributed, or publicly accessible since 2023. The corresponding GitHub repositories have been archived, and the packages are no longer available for download. This decision reflects our commitment to focus on the latest generation of TheHive, offering enhanced performance, security, and powerful new features tailored for modern SOC operations&lt;/p&gt; 
&lt;h2&gt;Where to get the latest version of TheHive?&lt;/h2&gt; 
&lt;p&gt;TheHive is now distributed as a commercial version&lt;/p&gt; 
&lt;p&gt;To access maintained and secure versions, follow the official documentation: ðŸ”— &lt;a href=&quot;https://docs.strangebee.com&quot;&gt;Link&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ðŸ“¥&lt;/span&gt; Need help or more information?&lt;/h2&gt; 
&lt;p&gt;If you are an existing user or need assistance migrating to a newer version, feel free to contact us:&lt;/p&gt; 
&lt;p&gt;ðŸ“§ &lt;a href=&quot;mailto:contact@strangebee.com&quot;&gt;contact@strangebee.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;ðŸŒ&lt;/span&gt; &lt;a href=&quot;https://www.strangebee.com&quot;&gt;https://www.strangebee.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Thank you for your trust, The StrangeBee Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sbt/sbt</title>
      <link>https://github.com/sbt/sbt</link>
      <description>&lt;p&gt;sbt, the interactive build tool&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/sbt/sbt/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/sbt/sbt/actions/workflows/ci.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://index.scala-lang.org/sbt/sbt&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/tag/sbt/sbt.svg?sanitize=true&quot; alt=&quot;Latest version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.com/channels/632150470000902164/922600050989875282&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/632150470000902164?label=Discord%20%23sbt&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;sbt&lt;/h1&gt; 
&lt;p&gt;sbt is a build tool for Scala, Java, and more.&lt;/p&gt; 
&lt;p&gt;For general documentation, see &lt;a href=&quot;https://www.scala-sbt.org/&quot;&gt;https://www.scala-sbt.org/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;sbt 1.x&lt;/h2&gt; 
&lt;p&gt;This is the 1.x series of sbt. The source code of sbt is split across several GitHub repositories, including this one.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sbt/io&quot;&gt;sbt/io&lt;/a&gt; hosts &lt;code&gt;sbt.io&lt;/code&gt; module.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sbt/zinc&quot;&gt;sbt/zinc&lt;/a&gt; hosts Zinc, an incremental compiler for Scala.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sbt/sbt&quot;&gt;sbt/sbt&lt;/a&gt;, this repository hosts modules that implements the build tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.scala-sbt.org/release/docs/Getting-Started/Setup&quot;&gt;Setup&lt;/a&gt;: Describes getting started with the latest binary release.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.scala-sbt.org/release/docs/Faq.html&quot;&gt;FAQ&lt;/a&gt;: Explains how to get help and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sbt/sbt-zero-seven&quot;&gt;sbt/sbt-zero-seven&lt;/a&gt;: hosts sbt 0.7.7 and earlier versions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Issues and Pull Requests&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href=&quot;https://raw.githubusercontent.com/sbt/sbt/develop/CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt; carefully before opening a GitHub Issue.&lt;/p&gt; 
&lt;p&gt;The short version: try &lt;a href=&quot;https://stackoverflow.com/tags/sbt&quot;&gt;searching&lt;/a&gt; or &lt;a href=&quot;https://stackoverflow.com/questions/ask?tags=sbt&quot;&gt;asking&lt;/a&gt; on StackOverflow.&lt;/p&gt; 
&lt;h2&gt;license&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/sbt/sbt/develop/LICENSE&quot;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>delta-io/delta</title>
      <link>https://github.com/delta-io/delta</link>
      <description>&lt;p&gt;An open-source storage framework that enables building a Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://docs.delta.io/latest/_static/delta-lake-white.png&quot; width=&quot;200&quot; alt=&quot;Delta Lake Logo&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/delta-io/delta/actions/workflows/test.yaml&quot;&gt;&lt;img src=&quot;https://github.com/delta-io/delta/actions/workflows/test.yaml/badge.svg?sanitize=true&quot; alt=&quot;Test&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?sanitize=true&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/delta-spark/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/delta-spark.svg?sanitize=true&quot; alt=&quot;PyPI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypistats.org/packages/delta-spark&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/delta-spark&quot; alt=&quot;PyPI - Downloads&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Delta Lake is an open-source storage framework that enables building a &lt;a href=&quot;http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf&quot;&gt;Lakehouse architecture&lt;/a&gt; with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, Ruby, and Python.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;See the &lt;a href=&quot;https://docs.delta.io&quot;&gt;Delta Lake Documentation&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href=&quot;https://docs.delta.io/latest/quick-start.html&quot;&gt;Quick Start Guide&lt;/a&gt; to get started with Scala, Java and Python.&lt;/li&gt; 
 &lt;li&gt;Note, this repo is one of many Delta Lake repositories in the &lt;a href=&quot;https://github.com/delta-io&quot;&gt;delta.io&lt;/a&gt; organizations including &lt;a href=&quot;https://github.com/delta-io/delta&quot;&gt;delta&lt;/a&gt;, &lt;a href=&quot;https://github.com/delta-io/delta-rs&quot;&gt;delta-rs&lt;/a&gt;, &lt;a href=&quot;https://github.com/delta-io/delta-sharing&quot;&gt;delta-sharing&lt;/a&gt;, &lt;a href=&quot;https://github.com/delta-io/kafka-delta-ingest&quot;&gt;kafka-delta-ingest&lt;/a&gt;, and &lt;a href=&quot;https://github.com/delta-io/website&quot;&gt;website&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following are some of the more popular Delta Lake integrations, refer to &lt;a href=&quot;https://delta.io/integrations/&quot;&gt;delta.io/integrations&lt;/a&gt; for the complete list:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/&quot;&gt;Apache Sparkâ„¢&lt;/a&gt;: This connector allows Apache Sparkâ„¢ to read from and write to Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/delta-io/delta/tree/master/connectors/flink&quot;&gt;Apache Flink (Preview)&lt;/a&gt;: This connector allows Apache Flink to write to Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://prestodb.io/docs/current/connector/deltalake.html&quot;&gt;PrestoDB&lt;/a&gt;: This connector allows PrestoDB to read from Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://trino.io/docs/current/connector/delta-lake.html&quot;&gt;Trino&lt;/a&gt;: This connector allows Trino to read from and write to Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/latest/delta-standalone.html&quot;&gt;Delta Standalone&lt;/a&gt;: This library allows Scala and Java-based projects (including Apache Flink, Apache Hive, Apache Beam, and PrestoDB) to read from and write to Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/latest/hive-integration.html&quot;&gt;Apache Hive&lt;/a&gt;: This connector allows Apache Hive to read from Delta Lake.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.rs/deltalake/latest/deltalake/&quot;&gt;Delta Rust API&lt;/a&gt;: This library allows Rust (with Python and Ruby bindings) low level access to Delta tables and is intended to be used with data processing frameworks like datafusion, ballista, rust-dataframe, vega, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;&lt;em&gt;Table of Contents&lt;/em&gt;&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#latest-binaries&quot;&gt;Latest binaries&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#api-documentation&quot;&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#compatibility&quot;&gt;Compatibility&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#api-compatibility&quot;&gt;API Compatibility&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#data-storage-compatibility&quot;&gt;Data Storage Compatibility&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#roadmap&quot;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#building&quot;&gt;Building&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#transaction-protocol&quot;&gt;Transaction Protocol&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#requirements-for-underlying-storage-systems&quot;&gt;Requirements for Underlying Storage Systems&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#concurrency-control&quot;&gt;Concurrency Control&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#reporting-issues&quot;&gt;Reporting issues&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#community&quot;&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Latest Binaries&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://docs.delta.io/latest/&quot;&gt;online documentation&lt;/a&gt; for the latest release.&lt;/p&gt; 
&lt;h2&gt;API Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/latest/delta-apidoc.html&quot;&gt;Scala API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/latest/api/java/index.html&quot;&gt;Java API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.delta.io/latest/api/python/index.html&quot;&gt;Python API docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.delta.io/latest/delta-standalone.html&quot;&gt;Delta Standalone&lt;/a&gt; library is a single-node Java library that can be used to read from and write to Delta tables. Specifically, this library provides APIs to interact with a tableâ€™s metadata in the transaction log, implementing the Delta Transaction Log Protocol to achieve the transactional guarantees of the Delta Lake format.&lt;/p&gt; 
&lt;h3&gt;API Compatibility&lt;/h3&gt; 
&lt;p&gt;There are two types of APIs provided by the Delta Lake project.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Direct Java/Scala/Python APIs - The classes and methods documented in the &lt;a href=&quot;https://docs.delta.io/latest/delta-apidoc.html&quot;&gt;API docs&lt;/a&gt; are considered as stable public APIs. All other classes, interfaces, methods that may be directly accessible in code are considered internal, and they are subject to change across releases.&lt;/li&gt; 
 &lt;li&gt;Spark-based APIs - You can read Delta tables through the &lt;code&gt;DataFrameReader&lt;/code&gt;/&lt;code&gt;Writer&lt;/code&gt; (i.e. &lt;code&gt;spark.read&lt;/code&gt;, &lt;code&gt;df.write&lt;/code&gt;, &lt;code&gt;spark.readStream&lt;/code&gt; and &lt;code&gt;df.writeStream&lt;/code&gt;). Options to these APIs will remain stable within a major release of Delta Lake (e.g., 1.x.x).&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href=&quot;https://docs.delta.io/latest/releases.html&quot;&gt;online documentation&lt;/a&gt; for the releases and their compatibility with Apache Spark versions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Data Storage Compatibility&lt;/h3&gt; 
&lt;p&gt;Delta Lake guarantees backward compatibility for all Delta Lake tables (i.e., newer versions of Delta Lake will always be able to read tables written by older versions of Delta Lake). However, we reserve the right to break forward compatibility as new features are introduced to the transaction protocol (i.e., an older version of Delta Lake may not be able to read a table produced by a newer version).&lt;/p&gt; 
&lt;p&gt;Breaking changes in the protocol are indicated by incrementing the minimum reader/writer version in the &lt;code&gt;Protocol&lt;/code&gt; &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/spark/src/test/scala/org/apache/spark/sql/delta/ActionSerializerSuite.scala&quot;&gt;action&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For the high-level Delta Lake roadmap, see &lt;a href=&quot;http://delta.io/roadmap&quot;&gt;Delta Lake 2022H1 roadmap&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For the detailed timeline, see the &lt;a href=&quot;https://github.com/delta-io/delta/milestones&quot;&gt;project roadmap&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Transaction Protocol&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/PROTOCOL.md&quot;&gt;Delta Transaction Log Protocol&lt;/a&gt; document provides a specification of the transaction protocol.&lt;/p&gt; 
&lt;h2&gt;Requirements for Underlying Storage Systems&lt;/h2&gt; 
&lt;p&gt;Delta Lake ACID guarantees are predicated on the atomicity and durability guarantees of the storage system. Specifically, we require the storage system to provide the following.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Atomic visibility&lt;/strong&gt;: There must be a way for a file to be visible in its entirety or not visible at all.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mutual exclusion&lt;/strong&gt;: Only one writer must be able to create (or rename) a file at the final destination.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistent listing&lt;/strong&gt;: Once a file has been written in a directory, all future listings for that directory must return that file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://docs.delta.io/latest/delta-storage.html&quot;&gt;online documentation on Storage Configuration&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Concurrency Control&lt;/h2&gt; 
&lt;p&gt;Delta Lake ensures &lt;em&gt;serializability&lt;/em&gt; for concurrent reads and writes. Please see &lt;a href=&quot;https://docs.delta.io/latest/delta-concurrency.html&quot;&gt;Delta Lake Concurrency Control&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Reporting issues&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href=&quot;https://github.com/delta-io/delta/issues&quot;&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href=&quot;https://raw.githubusercontent.com/delta-io/delta/master/#community&quot;&gt;contact&lt;/a&gt; the community for getting answers.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to Delta Lake. See our &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;We also adhere to the &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/CODE_OF_CONDUCT.md&quot;&gt;Delta Lake Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;Delta Lake is compiled using &lt;a href=&quot;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&quot;&gt;SBT&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To compile, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt compile
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To generate artifacts, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt package
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To execute tests, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To execute a single test suite, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt spark/&#39;testOnly org.apache.spark.sql.delta.optimize.OptimizeCompactionSQLSuite&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To execute a single test within and a single test suite, run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;build/sbt spark/&#39;testOnly *.OptimizeCompactionSQLSuite -- -z &quot;optimize command: on partitioned table - all partitions&quot;&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;a href=&quot;https://www.scala-sbt.org/1.x/docs/Command-Line-Reference.html&quot;&gt;SBT docs&lt;/a&gt; for more commands.&lt;/p&gt; 
&lt;h2&gt;Running python tests locally&lt;/h2&gt; 
&lt;h3&gt;Setup Environment&lt;/h3&gt; 
&lt;h4&gt;Install Conda (Skip if you already installed it)&lt;/h4&gt; 
&lt;p&gt;Follow &lt;a href=&quot;https://www.anaconda.com/download/&quot;&gt;Conda Download&lt;/a&gt; to install Anaconda.&lt;/p&gt; 
&lt;h4&gt;Create an environment from environment file&lt;/h4&gt; 
&lt;p&gt;Follow &lt;a href=&quot;https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#create-env-from-file&quot;&gt;Create Environment From Environment file&lt;/a&gt; to create a Conda environment from &lt;code&gt;&amp;lt;repo-root&amp;gt;/python/environment.yml&lt;/code&gt; and activate the newly created &lt;code&gt;delta_python_tests&lt;/code&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Note the `--file` argument should be a fully qualified path. Using `~` in file
# path doesn&#39;t work. Example valid path: `/Users/macuser/delta/python/environment.yml`

conda env create --name delta_python_tests --file=&amp;lt;absolute_path_to_delta_repo&amp;gt;/python/environment.yml`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;JDK Setup&lt;/h4&gt; 
&lt;p&gt;Build needs JDK 1.8. Make sure to setup &lt;code&gt;JAVA_HOME&lt;/code&gt; that points to JDK 1.8.&lt;/p&gt; 
&lt;h4&gt;Running tests&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;conda activate delta_python_tests
python3 &amp;lt;delta-root&amp;gt;/python/run-tests.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;IntelliJ Setup&lt;/h2&gt; 
&lt;p&gt;IntelliJ is the recommended IDE to use when developing Delta Lake. To import Delta Lake as a new project:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone Delta Lake into, for example, &lt;code&gt;~/delta&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;In IntelliJ, select &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;New Project&lt;/code&gt; &amp;gt; &lt;code&gt;Project from Existing Sources...&lt;/code&gt; and select &lt;code&gt;~/delta&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Under &lt;code&gt;Import project from external model&lt;/code&gt; select &lt;code&gt;sbt&lt;/code&gt;. Click &lt;code&gt;Next&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Under &lt;code&gt;Project JDK&lt;/code&gt; specify a valid Java &lt;code&gt;1.8&lt;/code&gt; JDK and opt to use SBT shell for &lt;code&gt;project reload&lt;/code&gt; and &lt;code&gt;builds&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;Finish&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;In your terminal, run &lt;code&gt;build/sbt clean package&lt;/code&gt;. Make sure you use Java &lt;code&gt;1.8&lt;/code&gt;. The build will generate files that are necessary for Intellij to index the repository.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Setup Verification&lt;/h3&gt; 
&lt;p&gt;After waiting for IntelliJ to index, verify your setup by running a test suite in IntelliJ.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Search for and open &lt;code&gt;DeltaLogSuite&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Next to the class declaration, right click on the two green arrows and select &lt;code&gt;Run &#39;DeltaLogSuite&#39;&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you see errors of the form&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Error:(46, 28) object DeltaSqlBaseParser is not a member of package io.delta.sql.parser
import io.delta.sql.parser.DeltaSqlBaseParser._
...
Error:(91, 22) not found: type DeltaSqlBaseParser
    val parser = new DeltaSqlBaseParser(tokenStream)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ensure you are using Java &lt;code&gt;1.8&lt;/code&gt;. You can set this using&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;export JAVA_HOME=`/usr/libexec/java_home -v 1.8`
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Compile using the SBT CLI: &lt;code&gt;build/sbt clean compile&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Go to &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;Project Structure...&lt;/code&gt; &amp;gt; &lt;code&gt;Modules&lt;/code&gt; &amp;gt; &lt;code&gt;delta-spark&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;In the right panel under &lt;code&gt;Source Folders&lt;/code&gt; remove any &lt;code&gt;target&lt;/code&gt; folders, e.g. &lt;code&gt;target/scala-2.12/src_managed/main [generated]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Click &lt;code&gt;Apply&lt;/code&gt; and then re-run your test.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href=&quot;https://github.com/delta-io/delta/raw/master/LICENSE.txt&quot;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;There are two mediums of communication within the Delta Lake community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Public Slack Channel 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://go.delta.io/slack&quot;&gt;Register here&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://delta-users.slack.com/&quot;&gt;Login here&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/company/deltalake&quot;&gt;Linkedin page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/c/deltalake&quot;&gt;Youtube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Public &lt;a href=&quot;https://groups.google.com/forum/#!forum/delta-users&quot;&gt;Mailing list&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>twitter/the-algorithm</title>
      <link>https://github.com/twitter/the-algorithm</link>
      <description>&lt;p&gt;Source code for Twitter&#39;s Recommendation Algorithm&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Twitter&#39;s Recommendation Algorithm&lt;/h1&gt; 
&lt;p&gt;Twitter&#39;s Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of Tweets and other content across all Twitter product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our &lt;a href=&quot;https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm&quot;&gt;engineering blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Product surfaces at Twitter are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/tweetypie/server/README.md&quot;&gt;tweetypie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Core Tweet service that handles the reading and writing of Tweet data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/unified_user_actions/README.md&quot;&gt;unified-user-actions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time stream of user actions on Twitter.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/user-signal-service/README.md&quot;&gt;user-signal-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/simclusters_v2/README.md&quot;&gt;SimClusters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Community detection and sparse embeddings into those communities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/twitter/the-algorithm-ml/raw/main/projects/twhin/README.md&quot;&gt;TwHIN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Dense knowledge graph embeddings for Users and Tweets.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/trust_and_safety_models/README.md&quot;&gt;trust-and-safety-models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Models for detecting NSFW or abusive content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/interaction_graph/README.md&quot;&gt;real-graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Model to predict the likelihood of a Twitter User interacting with another User.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/graph/batch/job/tweepcred/README&quot;&gt;tweepcred&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Page-Rank algorithm for calculating Twitter User reputation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/recos-injector/README.md&quot;&gt;recos-injector&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Streaming event processor for building input streams for &lt;a href=&quot;https://github.com/twitter/GraphJet&quot;&gt;GraphJet&lt;/a&gt; based services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/graph-feature-service/README.md&quot;&gt;graph-feature-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Serves graph features for a directed pair of Users (e.g. how many of User A&#39;s following liked Tweets from User B).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/topic-social-proof/README.md&quot;&gt;topic-social-proof&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Identifies topics related to individual Tweets.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-scorer/README.md&quot;&gt;representation-scorer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Compute scores between pairs of entities (Users, Tweets, etc.) using embedding similarity.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Software framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/navi/README.md&quot;&gt;navi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;High performance, machine learning model serving written in Rust.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md&quot;&gt;product-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Software framework for building feeds of content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/timelines/data_processing/ml_util/aggregation_framework/README.md&quot;&gt;timelines-aggregation-framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Framework for generating aggregate features in batch or real time.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-manager/README.md&quot;&gt;representation-manager&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Service to retrieve embeddings (i.e. SimClusers and TwHIN).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/twml/README.md&quot;&gt;twml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy machine learning framework built on TensorFlow v1.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.&lt;/p&gt; 
&lt;h3&gt;For You Timeline&lt;/h3&gt; 
&lt;p&gt;The diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/docs/system-diagram.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;The core components of the For You Timeline included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Candidate Source&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/java/com/twitter/search/README.md&quot;&gt;search-index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Find and rank In-Network Tweets. ~50% of Tweets come from this candidate source.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/cr-mixer/README.md&quot;&gt;cr-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos/user_tweet_entity_graph/README.md&quot;&gt;user-tweet-entity-graph&lt;/a&gt; (UTEG)&lt;/td&gt; 
   &lt;td&gt;Maintains an in memory User to Tweet interaction graph, and finds candidates based on traversals of this graph. This is built on the &lt;a href=&quot;https://github.com/twitter/GraphJet&quot;&gt;GraphJet&lt;/a&gt; framework. Several other GraphJet based features and candidate sources are located &lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos&quot;&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/follow-recommendations-service/README.md&quot;&gt;follow-recommendation-service&lt;/a&gt; (FRS)&lt;/td&gt; 
   &lt;td&gt;Provides Users with recommendations for accounts to follow, and Tweets from those accounts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md&quot;&gt;light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by search index (Earlybird) to rank Tweets.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/twitter/the-algorithm-ml/raw/main/projects/home/recap/README.md&quot;&gt;heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Neural network for ranking candidate tweets. One of the main signals used to select timeline Tweets post candidate sourcing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tweet mixing &amp;amp; filtering&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/home-mixer/README.md&quot;&gt;home-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main service used to construct and serve the Home Timeline. Built on &lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md&quot;&gt;product-mixer&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/visibilitylib/README.md&quot;&gt;visibility-filters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Responsible for filtering Twitter content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/timelineranker/README.md&quot;&gt;timelineranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy service which provides relevance-scored tweets from the Earlybird Search Index and UTEG service.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Recommended Notifications&lt;/h3&gt; 
&lt;p&gt;The core components of Recommended Notifications included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Service&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/README.md&quot;&gt;pushservice&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main recommendation service at Twitter used to surface recommendations to our users via notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/light_ranking/README.md&quot;&gt;pushservice-light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by pushservice to rank Tweets. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/heavy_ranking/README.md&quot;&gt;pushservice-heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Build and test code&lt;/h2&gt; 
&lt;p&gt;We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official &lt;a href=&quot;https://hackerone.com/twitter&quot;&gt;bug bounty program&lt;/a&gt; through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better Twitter.&lt;/p&gt; 
&lt;p&gt;Read our blog on the open source initiative &lt;a href=&quot;https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>joernio/joern</title>
      <link>https://github.com/joernio/joern</link>
      <description>&lt;p&gt;Open-source code analysis platform for C/C++/Java/Binary/Javascript/Python/Kotlin based on code property graphs. Discord https://discord.gg/vv4MH284Hc&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Joern - The Bug Hunter&#39;s Workbench&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/joernio/joern/actions/workflows/release.yml&quot;&gt;&lt;img src=&quot;https://github.com/joernio/joern/actions/workflows/release.yml/badge.svg?sanitize=true&quot; alt=&quot;release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://index.scala-lang.org/joernio/joern&quot;&gt;&lt;img src=&quot;https://index.scala-lang.org/joernio/joern/latest.svg?sanitize=true&quot; alt=&quot;Joern SBT&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/joernio/joern/releases/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/joernio/joern/total.svg?sanitize=true&quot; alt=&quot;Github All Releases&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.com/invite/vv4MH284Hc&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/-Discord-lime?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=black&quot; alt=&quot;Gitter&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Joern is a platform for analyzing source code, bytecode, and binary executables. It generates code property graphs (CPGs), a graph representation of code for cross-language code analysis. Code property graphs are stored in a custom graph database. This allows code to be mined using search queries formulated in a Scala-based domain-specific query language. Joern is developed with the goal of providing a useful tool for vulnerability discovery and research in static program analysis.&lt;/p&gt; 
&lt;p&gt;Website: &lt;a href=&quot;https://joern.io&quot;&gt;https://joern.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Documentation: &lt;a href=&quot;https://docs.joern.io/&quot;&gt;https://docs.joern.io/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Specification: &lt;a href=&quot;https://cpg.joern.io&quot;&gt;https://cpg.joern.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;News / Changelog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Joern v4.0.0 &lt;a href=&quot;https://raw.githubusercontent.com/joernio/joern/master/changelog/4.0.0-flatgraph.md&quot;&gt;migrates from overflowdb to flatgraph&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Joern v2.0.0 &lt;a href=&quot;https://raw.githubusercontent.com/joernio/joern/master/changelog/2.0.0-scala3.md&quot;&gt;upgrades from Scala2 to Scala3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Joern v1.2.0 removes the &lt;code&gt;overflowdb.traversal.Traversal&lt;/code&gt; class. This change is not completely backwards compatible. See &lt;a href=&quot;https://raw.githubusercontent.com/joernio/joern/master/changelog/traversal_removal.md&quot;&gt;here&lt;/a&gt; for a detailed writeup.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;JDK 21 (other versions &lt;em&gt;might&lt;/em&gt; work, but have not been properly tested)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;optional&lt;/em&gt;: gcc and g++ (for auto-discovery of C/C++ system header files if included/used in your C/C++ code)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;wget https://github.com/joernio/joern/releases/latest/download/joern-install.sh
chmod +x ./joern-install.sh
sudo ./joern-install.sh
joern

     â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘
     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘
â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
 â•šâ•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•
Version: 2.0.1
Type `help` to begin

joern&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the installation script fails for any reason, try&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./joern-install --interactive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://jdk.java.net/&quot;&gt;java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.scala-sbt.org&quot;&gt;sbt&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Run unit and integration tests locally&lt;/h2&gt; 
&lt;p&gt;Unit tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sbt test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Integration tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sbt joerncli/stage querydb/createDistribution
python -m pip install requests pexpect # wexpect on Windows
python -u ./testDistro.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker based execution&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -it -v /tmp:/tmp -v $(pwd):/app:rw -w /app -t ghcr.io/joernio/joern joern
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run joern in server mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -it -v /tmp:/tmp -v $(pwd):/app:rw -w /app -t ghcr.io/joernio/joern joern --server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Almalinux 9 requires the CPU to support SSE4.2. For kvm64 VM use the Almalinux 8 version instead.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -it -v /tmp:/tmp -v $(pwd):/app:rw -w /app -t ghcr.io/joernio/joern-alma8 joern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;A new release is &lt;a href=&quot;https://raw.githubusercontent.com/joernio/joern/master/.github/workflows/release.yml&quot;&gt;created automatically&lt;/a&gt; once per day. Contributers can also manually run the &lt;a href=&quot;https://github.com/joernio/joern/actions/workflows/release.yml&quot;&gt;release workflow&lt;/a&gt; if they need the release sooner.&lt;/p&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Thank you for taking time to contribute to Joern! Here are a few guidelines to ensure your pull request will get merged as soon as possible:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try to make use of the templates as far as possible, however they may not suit all needs. The minimum we would like to see is: 
  &lt;ul&gt; 
   &lt;li&gt;A title that briefly describes the change and purpose of the PR, preferably with the affected module in square brackets, e.g. &lt;code&gt;[javasrc2cpg] Addition Operator Fix&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;A short description of the changes in the body of the PR. This could be in bullet points or paragraphs.&lt;/li&gt; 
   &lt;li&gt;A link or reference to the related issue, if any exists.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Do not: 
  &lt;ul&gt; 
   &lt;li&gt;Immediately CC/@/email spam other contributors, the team will review the PR and assign the most appropriate contributor to review the PR. Joern is maintained by industry partners and researchers alike, for the most part with their own goals and priorities, and additional help is largely volunteer work. If your PR is going stale, then reach out to us in follow-up comments with @&#39;s asking for an explanation of priority or planning of when it may be addressed (if ever, depending on quality).&lt;/li&gt; 
   &lt;li&gt;Leave the description body empty, this makes reviewing the purpose of the PR difficult.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Remember to: 
  &lt;ul&gt; 
   &lt;li&gt;Remember to format your code, i.e. run &lt;code&gt;sbt scalafmt Test/scalafmt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Add a unit test to verify your change.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;IDE setup&lt;/h3&gt; 
&lt;h4&gt;Intellij IDEA&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/idea/download&quot;&gt;Download Intellij Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install and run it&lt;/li&gt; 
 &lt;li&gt;Install the &lt;a href=&quot;https://plugins.jetbrains.com/plugin/1347-scala&quot;&gt;Scala Plugin&lt;/a&gt; - just search and install from within Intellij.&lt;/li&gt; 
 &lt;li&gt;Important: open &lt;code&gt;sbt&lt;/code&gt; in your local joern repository, run &lt;code&gt;compile&lt;/code&gt; and keep it open - this will allow us to use the BSP build in the next step&lt;/li&gt; 
 &lt;li&gt;Back to Intellij: open project: select your local joern clone: select to open as &lt;code&gt;BSP project&lt;/code&gt; (i.e. &lt;em&gt;not&lt;/em&gt; &lt;code&gt;sbt project&lt;/code&gt;!)&lt;/li&gt; 
 &lt;li&gt;Await the import and indexing to complete, then you can start, e.g. &lt;code&gt;Build -&amp;gt; build project&lt;/code&gt; or run a test&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;VSCode&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install VSCode and Docker&lt;/li&gt; 
 &lt;li&gt;Install the plugin &lt;code&gt;ms-vscode-remote.remote-containers&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Open Joern project folder in VSCode 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure-sphere/app-development/container-build-vscode#build-and-debug-the-project&quot;&gt;Option 1&lt;/a&gt;: Visual Studio Code detects the new files and opens a message box saying: &lt;code&gt;Folder contains a Dev Container configuration file. Reopen to folder to develop in a container.&lt;/code&gt;. Select the &lt;code&gt;Reopen in Container&lt;/code&gt; button to reopen the folder in the container created by the &lt;code&gt;.devcontainer/Dockerfile&lt;/code&gt; file.&lt;/li&gt; 
   &lt;li&gt;Option 2: press &lt;code&gt;Ctrl + Shift + P&lt;/code&gt; then select &lt;code&gt;Dev Containers: Reopen in Container&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Press &lt;code&gt;Ctrl + Shift + P&lt;/code&gt; then select &lt;code&gt;Metals: Import build&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;After &lt;code&gt;Metals: Import build&lt;/code&gt; succeeds, you are ready to start writing code for Joern&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;QueryDB (queries plugin)&lt;/h2&gt; 
&lt;p&gt;Quick way to develop and test QueryDB:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sbt stage
./querydb-install.sh
./joern-scan --list-query-names
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The last command prints all available queries - add your own in querydb, run the above commands again to see that your query got deployed. More details in the &lt;a href=&quot;https://raw.githubusercontent.com/joernio/joern/master/querydb/README.md&quot;&gt;separate querydb readme&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zio/zio-blocks</title>
      <link>https://github.com/zio/zio-blocks</link>
      <description>&lt;p&gt;Powerful, joyful building blocks for modern cloud-native applications.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;zio-blocks&lt;/h1&gt; 
&lt;p&gt;Powerful, joyful building blocks for modern cloud-native applications.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ucb-bar/riscv-torture</title>
      <link>https://github.com/ucb-bar/riscv-torture</link>
      <description>&lt;p&gt;RISC-V Torture Test&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;=========================================================================== RISC-V Torture Test Generator&lt;/h1&gt; 
&lt;h1&gt;Author: Yunsup Lee and Henry Cook&lt;/h1&gt; 
&lt;h1&gt;Date: January 29th, 2012&lt;/h1&gt; 
&lt;h1&gt;Version: (under version control)&lt;/h1&gt; 
&lt;p&gt;This is the RISC-V torture test generator and framework. This repository contains three sub-projects that build upon one another. The first, [generator], is used to create a single random torture test. The second, [testrun], is used to run a particular test on particular simulators, diffing the resulting signature with the ISA simulator and optionally creating a derivative test subset that pinpoints the divergence. The third, [overnight], wraps testrun, allowing tests to be run repeatedly for a given duration or until a failure count.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Instructions&lt;/h2&gt; 
&lt;p&gt;Modify &quot;config/default.config&quot; to set the parameters desired for building tests (e.g., setting which instructions to use and in which ratio).&lt;/p&gt; 
&lt;p&gt;Modify &quot;Makefile&quot; as desired to execute the C simulator or RTL simulator of your choice, and to set the other parameters as you require.&lt;/p&gt; 
&lt;p&gt;To build a single test and test it on Spike:&lt;/p&gt; 
&lt;p&gt;$ make igentest&lt;/p&gt; 
&lt;p&gt;To build single test and run it on the C simulator or RTL simulator, use &quot;make cgentest&quot; or &quot;make rgentest&quot;.&lt;/p&gt; 
&lt;p&gt;To run overnight tests, you can use &quot;make cnight&quot; and &quot;make rnight&quot;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Signatures&lt;/h2&gt; 
&lt;p&gt;Torture works by dumping the register state out to memory at the end of the test program execution. This output is then compared against the output from the Spike ISA simulator.&lt;/p&gt; 
&lt;p&gt;The torture program writes the register state to the memory address specified by &quot;xreg_output_data&quot;, which is located in the memory section &quot;.global begin_signature&quot;. The Spike ISA simulator will write out the data found in the &quot;begin_signature&quot; section on exit if provided with the &quot;+signature=&quot; argument:&lt;/p&gt; 
&lt;p&gt;$ spike +signature=my_spike_signature.txt test_binary&lt;/p&gt; 
&lt;p&gt;The Rocket-chip infrastructure uses the &quot;riscv-fesvr&quot; program to control the execution of the C and RTL simulators. The &quot;riscv-fesvr&quot; also accepts the +signature argument too.&lt;/p&gt; 
&lt;p&gt;$ ./csim-rocket-chip +signature=my_rocket_signature.txt test_binary&lt;/p&gt; 
&lt;p&gt;A simple diff between the Spike and chip simulator signatures will tell you if any errors have occurred.&lt;/p&gt; 
&lt;p&gt;$ diff my_spike_signature.txt my_rocket_signature.txt&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PORTING TORTURE TO YOUR OWN RISC-V PROCESSOR:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to use riscv-torture with your own RISC-V processor, you will need to provide a way to dump the &quot;begin_signature&quot; section to a file.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Low-level Usage&lt;/h2&gt; 
&lt;p&gt;Some basic use cases are illustrated here (note the Makefile abstracts this for you).&lt;/p&gt; 
&lt;p&gt;Make a single test: % ./sbt generator/run % cd output % make % spike +signature=test.sig test&lt;/p&gt; 
&lt;p&gt;Take an existing test and diff the signatures of ISA and C simulators: % ./sbt &#39;testrun/run -a output/test.S -c /path/to/reference-chip/emulator/emulator&#39;&lt;/p&gt; 
&lt;p&gt;*** Currently, due to the limiation of scala process library, you cannot torture the RTL simulator ***&lt;/p&gt; 
&lt;h1&gt;Generate a random test and diff the signatures of ISA and RTL simulators:&lt;/h1&gt; 
&lt;h1&gt;% ./sbt &#39;testrun/run -r /path/to/reference-chip/vlsi/build/vcs-sim-rtl/simv&#39;&lt;/h1&gt; 
&lt;p&gt;Run tests for 30 minutes, email hcook when done, and save failures to dir: % ./sbt &#39;overnight/run -m 30 -e &lt;a href=&quot;mailto:hcook@eecs.berkeley.edu&quot;&gt;hcook@eecs.berkeley.edu&lt;/a&gt; -p dir&#39;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installing&lt;/h2&gt; 
&lt;p&gt;% git submodule update --init&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Overnight Overview&lt;/h2&gt; 
&lt;p&gt;This framework utilizes both the test runner and test generator to perform a long terms serach for failing test cases. It takes the following command line arguments:&lt;/p&gt; 
&lt;p&gt;Usage: overnight/run [options] -C 
 &lt;file&gt;
   | --config 
  &lt;file&gt;
    config file -p 
  &lt;/file&gt;
 &lt;/file&gt;&lt;/p&gt;
&lt;dir&gt;
  | --permdir 
 &lt;dir&gt;
   dir to store failing tests -c 
  &lt;file&gt;
    | --csim 
   &lt;file&gt;
     C simulator -r 
    &lt;file&gt;
      | --rtlsim 
     &lt;file&gt;
       RTL simulator -e 
      &lt;address&gt; | --email &lt;address&gt; email to report to -t 
        &lt;count&gt;
          | --threshold 
         &lt;count&gt;
           number of failures to trigger email -m 
          &lt;int&gt;
            | --minutes 
           &lt;int&gt;
             number of minutes to run tests
            &lt;p&gt;&lt;/p&gt; 
            &lt;p&gt;You can only generate tests with one instruction mix at a time (based on the setting in the config file). It doesn&#39;t matter what simulator you use with the -r and -c flags, they just determines the name used to describe whose diff failed.&lt;/p&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;Testrun Overview&lt;/h2&gt; 
            &lt;p&gt;This utility compares the signatures generated by passing the -testsig flag to the specified simulators. If it encounters a difference, it subdivides the test into many subtests and searches for which exact program segment reveals the failure. It takes the following command line arguments:&lt;/p&gt; 
            &lt;p&gt;Usage: testrun/run [options] -C 
             &lt;file&gt;
               | --config 
              &lt;file&gt;
                config file -a 
               &lt;file&gt;
                 | --asm 
                &lt;file&gt;
                  input ASM file -c 
                 &lt;file&gt;
                   | --csim 
                  &lt;file&gt;
                    C simulator -r 
                   &lt;file&gt;
                     | --rtlsim 
                    &lt;file&gt;
                      RTL simulator -s 
                     &lt;boolean&gt;
                       | --seek 
                      &lt;boolean&gt;
                        Seek for failing pseg -d 
                       &lt;boolean&gt;
                         | --dump 
                        &lt;boolean&gt;
                          Dump mismatched signatures
                        &lt;/boolean&gt;
                       &lt;/boolean&gt;
                      &lt;/boolean&gt;
                     &lt;/boolean&gt;
                    &lt;/file&gt;
                   &lt;/file&gt;
                  &lt;/file&gt;
                 &lt;/file&gt;
                &lt;/file&gt;
               &lt;/file&gt;
              &lt;/file&gt;
             &lt;/file&gt;&lt;/p&gt; 
            &lt;p&gt;If you don&#39;t specify a asm file, a random one will be generated for you. You can only generate tests with one instruction mix at a time (based on the setting in the config file). It doesn&#39;t matter what simulator you use with the -r and -c flags, they just determines the name used to describe whose diff failed. By default, a failed diff will result in the subtest sweep occuring, but this search can be diasbled. Note that the pseg ID reported is actually the pseg following the pseg containing the error. You can optionally dump mistmatched signatures to the dir containing the asm file under test.&lt;/p&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;Generator Overview&lt;/h2&gt; 
            &lt;p&gt;To generate a random test, the torture test generator randomly generates many test sequences from a set of test sequences that are written by hand, performs a random register allocation for all test sequences, and finally randomly interleaves instructions from these test sequences. To extend the set of tests or coverage, the programmer needs to write new test sequences. It takes the following command line arguments:&lt;/p&gt; 
            &lt;p&gt;Usage: generator/run [options] -o 
             &lt;filename&gt;
               | --output 
              &lt;filename&gt;
                output filename -C 
               &lt;file&gt;
                 | --config 
                &lt;file&gt;
                  config file
                &lt;/file&gt;
               &lt;/file&gt;
              &lt;/filename&gt;
             &lt;/filename&gt;&lt;/p&gt; 
            &lt;p&gt;The following sections describe adding new functionality to the generator.&lt;/p&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;Test sequence example&lt;/h2&gt; 
            &lt;p&gt;Before we talk about how to write a test sequence, let&#39;s look at a very simple example. The following example is a test sequence, which emits an add instruction.&lt;/p&gt; 
            &lt;p&gt;class SeqADD extends Seq { val src1 = reg_read_any() val src2 = reg_read_any() val dest = reg_write(src1, src2) insts += ADD(dest, src1, src2) }&lt;/p&gt; 
            &lt;p&gt;As I hinted in the overview that the test generator will do register allocation you don&#39;t write a string of instructions with architectural registers. You request a virtual registers (i.e., registers that are yet tied down to architectural registers) when you need them, save them in scala values, and use them when you need to (e.g., in an instruction).&lt;/p&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;Types of virtual registers&lt;/h2&gt; 
            &lt;ul&gt; 
             &lt;li&gt; &lt;p&gt;Hidden (position dependent registers): Registers that will have different values when the code is positioned at a different address. An example is registers that hold addresses. Registers that are hidden should be excluded from the output signature.&lt;/p&gt; &lt;/li&gt; 
             &lt;li&gt; &lt;p&gt;Visible (position independent registers): Registers that are not hidden, therefore will have the same values when the code is positioned at a different address. These registers should be included as part of the output signature.&lt;/p&gt; &lt;/li&gt; 
            &lt;/ul&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;How to write a sequence&lt;/h2&gt; 
            &lt;p&gt;Use the following functions to request a register, and generate a string of instructions (look at Inst.scala to see what instructions are available) that uses these virtual registers, and add them to the insts array.&lt;/p&gt; 
            &lt;ul&gt; 
             &lt;li&gt;reg_read_zero(): returns register x0&lt;/li&gt; 
             &lt;li&gt;reg_read_any(): returns any type of register (hidden or visible)&lt;/li&gt; 
             &lt;li&gt;reg_read_visible(): returns a visible register&lt;/li&gt; 
             &lt;li&gt;reg_write_ra(): returns register ra for write&lt;/li&gt; 
             &lt;li&gt;reg_write_visible(): returns a visible register for write&lt;/li&gt; 
             &lt;li&gt;reg_write_hidden(): returns a hidden register for write&lt;/li&gt; 
             &lt;li&gt;reg_write(regs: Reg*): returns a register that matches the type of regs (if any reg in regs are hidden, the output type is hidden)&lt;/li&gt; 
            &lt;/ul&gt; 
            &lt;p&gt;Note that the torture test framework is written in scala, you can use any scala functionality to generate instructions. Look at SeqALU.scala, SeqMem.scala, and SeqBranch.scala to get inspired.&lt;/p&gt; 
            &lt;hr /&gt; 
            &lt;h2&gt;Future TODO&lt;/h2&gt; 
            &lt;ul&gt; 
             &lt;li&gt; &lt;p&gt;provide support for loops&lt;/p&gt; &lt;/li&gt; 
             &lt;li&gt; &lt;p&gt;generate statistics of a test to get a sense of coverage&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt;statistics should include instruction count of each type&lt;/li&gt; 
               &lt;li&gt;statistics should include register usage&lt;/li&gt; 
              &lt;/ul&gt; &lt;/li&gt; 
             &lt;li&gt; &lt;p&gt;complete floating point tests&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt;add floating point memory move tests&lt;/li&gt; 
               &lt;li&gt;improve floating point init randomization&lt;/li&gt; 
               &lt;li&gt;add rounding modes tests&lt;/li&gt; 
              &lt;/ul&gt; &lt;/li&gt; 
             &lt;li&gt; &lt;p&gt;complete vector tests&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt;better randomization&lt;/li&gt; 
               &lt;li&gt;add SeqVOnly: Tests special vf-only instructions&lt;/li&gt; 
              &lt;/ul&gt; &lt;/li&gt; 
             &lt;li&gt; &lt;p&gt;code refactoring&lt;/p&gt; 
              &lt;ul&gt; 
               &lt;li&gt;consolidate RegPool logic&lt;/li&gt; 
               &lt;li&gt;detect and suppress unallocatable sequences&lt;/li&gt; 
              &lt;/ul&gt; &lt;/li&gt; 
            &lt;/ul&gt; 
           &lt;/int&gt;
          &lt;/int&gt;
         &lt;/count&gt;
        &lt;/count&gt;&lt;/address&gt;&lt;/address&gt;
     &lt;/file&gt;
    &lt;/file&gt;
   &lt;/file&gt;
  &lt;/file&gt;
 &lt;/dir&gt;
&lt;/dir&gt;</description>
    </item>
    
    <item>
      <title>OpenXiangShan/XiangShan</title>
      <link>https://github.com/OpenXiangShan/XiangShan</link>
      <description>&lt;p&gt;Open-source high-performance RISC-V processor&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;XiangShan&lt;/h1&gt; 
&lt;p&gt;XiangShan (é¦™å±±) is an open-source high-performance RISC-V processor project.&lt;/p&gt; 
&lt;p&gt;ä¸­æ–‡è¯´æ˜Ž&lt;a href=&quot;https://raw.githubusercontent.com/OpenXiangShan/XiangShan/master/readme.zh-cn.md&quot;&gt;åœ¨æ­¤&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;XiangShan&#39;s documentation is available at &lt;a href=&quot;https://docs.xiangshan.cc&quot;&gt;docs.xiangshan.cc&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;XiangShan Design Document for Kunminghu V2R2 has been published separately. You can find it at &lt;a href=&quot;https://docs.xiangshan.cc/projects/design/&quot;&gt;docs.xiangshan.cc/projects/design&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;XiangShan User Guide has been published separately. You can find it at &lt;a href=&quot;https://docs.xiangshan.cc/projects/user-guide/&quot;&gt;docs.xiangshan.cc/projects/user-guide&lt;/a&gt; or &lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan-User-Guide/releases&quot;&gt;XiangShan-User-Guide/releases&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We are using &lt;a href=&quot;https://hosted.weblate.org/projects/openxiangshan/&quot;&gt;Weblate&lt;/a&gt; to translate documentation into English and other languages. Your contributions are welcomeâ€”come and help us improve it!&lt;/p&gt; 
&lt;p&gt;All XiangShan documents are licensed under the CC-BY-4.0.&lt;/p&gt; 
&lt;h2&gt;Publications&lt;/h2&gt; 
&lt;h3&gt;MICRO 2022: Towards Developing High Performance RISC-V Processors Using Agile Methodology&lt;/h3&gt; 
&lt;p&gt;Our paper introduces XiangShan and the practice of agile development methodology on high performance RISC-V processors. It covers some representative tools we have developed and used to accelerate the chip development process, including design, functional verification, debugging, performance validation, etc. This paper is awarded all three available badges for artifact evaluation (Available, Functional, and Reproduced).&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/images/artifacts_available_dl.jpg&quot; alt=&quot;Artifacts Available&quot; /&gt; &lt;img src=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/images/artifacts_evaluated_functional_dl.jpg&quot; alt=&quot;Artifacts Evaluated â€” Functional&quot; /&gt; &lt;img src=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/images/results_reproduced_dl.jpg&quot; alt=&quot;Results Reproduced&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/micro2022-xiangshan.pdf&quot;&gt;Paper PDF&lt;/a&gt; | &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9923860&quot;&gt;IEEE Xplore&lt;/a&gt; | &lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/micro2022-xiangshan.bib&quot;&gt;BibTeX&lt;/a&gt; | &lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan-doc/raw/main/publications/micro2022-xiangshan-slides.pdf&quot;&gt;Presentation Slides&lt;/a&gt; | &lt;a href=&quot;https://www.bilibili.com/video/BV1FB4y1j7Jy&quot;&gt;Presentation Video&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Follow us&lt;/h2&gt; 
&lt;p&gt;Wechat/å¾®ä¿¡ï¼šé¦™å±±å¼€æºå¤„ç†å™¨&lt;/p&gt; 
&lt;div align=&quot;left&quot;&gt;
 &lt;img width=&quot;340&quot; height=&quot;117&quot; src=&quot;https://raw.githubusercontent.com/OpenXiangShan/XiangShan/master/images/wechat.png&quot; /&gt;
&lt;/div&gt; 
&lt;p&gt;Zhihu/çŸ¥ä¹Žï¼š&lt;a href=&quot;https://www.zhihu.com/people/openxiangshan&quot;&gt;é¦™å±±å¼€æºå¤„ç†å™¨&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Weibo/å¾®åšï¼š&lt;a href=&quot;https://weibo.com/u/7706264932&quot;&gt;é¦™å±±å¼€æºå¤„ç†å™¨&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can contact us through &lt;a href=&quot;mailto:xiangshan-all@ict.ac.cn&quot;&gt;our mailing list&lt;/a&gt;. All mails from this list will be archived &lt;a href=&quot;https://www.mail-archive.com/xiangshan-all@ict.ac.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;The first stable micro-architecture of XiangShan is called Yanqihu (é›æ –æ¹–) and is &lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan/tree/yanqihu&quot;&gt;on the yanqihu branch&lt;/a&gt;, which has been developed since June 2020.&lt;/p&gt; 
&lt;p&gt;The second stable micro-architecture of XiangShan is called Nanhu (å—æ¹–) and is &lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan/tree/nanhu&quot;&gt;on the nanhu branch&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The current version of XiangShan, also known as Kunminghu (æ˜†æ˜Žæ¹–), is still under development on the master branch.&lt;/p&gt; 
&lt;p&gt;The micro-architecture overview of Kunminghu (æ˜†æ˜Žæ¹–) is shown below.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/OpenXiangShan/XiangShan/master/images/xs-arch-kunminghu.svg?sanitize=true&quot; alt=&quot;xs-arch-kunminghu&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Sub-directories Overview&lt;/h2&gt; 
&lt;p&gt;Some of the key directories are shown below.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.
â”œâ”€â”€ src
â”‚   â””â”€â”€ main/scala         # design files
â”‚       â”œâ”€â”€ device         # virtual device for simulation
â”‚       â”œâ”€â”€ system         # SoC wrapper
â”‚       â”œâ”€â”€ top            # top module
â”‚       â”œâ”€â”€ utils          # utilization code
â”‚       â””â”€â”€ xiangshan      # main design code
â”‚           â””â”€â”€ transforms # some useful firrtl transforms
â”œâ”€â”€ scripts                # scripts for agile development
â”œâ”€â”€ fudian                 # floating unit submodule of XiangShan
â”œâ”€â”€ huancun                # L2/L3 cache submodule of XiangShan
â”œâ”€â”€ difftest               # difftest co-simulation framework
â””â”€â”€ ready-to-run           # pre-built simulation images
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;IDE Support&lt;/h2&gt; 
&lt;h3&gt;bsp&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make bsp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;IDEA&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make idea
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate Verilog&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;make verilog&lt;/code&gt; to generate verilog code. This generates multiple &lt;code&gt;.sv&lt;/code&gt; files in the &lt;code&gt;build/rtl/&lt;/code&gt; folder (e.g., &lt;code&gt;build/rtl/XSTop.sv&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Refer to &lt;code&gt;Makefile&lt;/code&gt; for more information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Run Programs by Simulation&lt;/h2&gt; 
&lt;h3&gt;Prepare environment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set environment variable &lt;code&gt;NEMU_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the &lt;a href=&quot;https://github.com/OpenXiangShan/NEMU&quot;&gt;NEMU project&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set environment variable &lt;code&gt;NOOP_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the XiangShan project.&lt;/li&gt; 
 &lt;li&gt;Set environment variable &lt;code&gt;AM_HOME&lt;/code&gt; to the &lt;strong&gt;absolute path&lt;/strong&gt; of the &lt;a href=&quot;https://github.com/OpenXiangShan/nexus-am&quot;&gt;AM project&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;mill&lt;/code&gt;. Refer to &lt;a href=&quot;https://mill-build.org/mill/cli/installation-ide.html#_bootstrap_scripts&quot;&gt;the Manual section in this guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Clone this project and run &lt;code&gt;make init&lt;/code&gt; to initialize submodules.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run with simulator&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;a href=&quot;https://verilator.org/guide/latest/&quot;&gt;Verilator&lt;/a&gt;, the open-source Verilog simulator.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make emu&lt;/code&gt; to build the C++ simulator &lt;code&gt;./build/emu&lt;/code&gt; with Verilator.&lt;/li&gt; 
 &lt;li&gt;Refer to &lt;code&gt;./build/emu --help&lt;/code&gt; for run-time arguments of the simulator.&lt;/li&gt; 
 &lt;li&gt;Refer to &lt;code&gt;Makefile&lt;/code&gt; and &lt;code&gt;verilator.mk&lt;/code&gt; for more information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make emu CONFIG=MinimalConfig EMU_THREADS=2 -j10
./build/emu -b 0 -e 0 -i ./ready-to-run/coremark-2-iteration.bin --diff ./ready-to-run/riscv64-nemu-interpreter-so
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Troubleshooting Guide&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/OpenXiangShan/XiangShan/wiki/Troubleshooting-Guide&quot;&gt;Troubleshooting Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;The implementation of XiangShan is inspired by several key papers. We list these papers in XiangShan document, see: &lt;a href=&quot;https://docs.xiangshan.cc/zh-cn/latest/acknowledgments/&quot;&gt;Acknowledgements&lt;/a&gt;. We very much encourage and expect that more academic innovations can be realised based on XiangShan in the future.&lt;/p&gt; 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;Copyright Â© 2020-2025 Institute of Computing Technology, Chinese Academy of Sciences.&lt;/p&gt; 
&lt;p&gt;Copyright Â© 2021-2025 Beijing Institute of Open Source Chip&lt;/p&gt; 
&lt;p&gt;Copyright Â© 2020-2022 by Peng Cheng Laboratory.&lt;/p&gt; 
&lt;p&gt;XiangShan is licensed under &lt;a href=&quot;https://raw.githubusercontent.com/OpenXiangShan/XiangShan/master/LICENSE&quot;&gt;Mulan PSL v2&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apache/incubator-gluten</title>
      <link>https://github.com/apache/incubator-gluten</link>
      <description>&lt;p&gt;Gluten is a middle layer responsible for offloading JVM-based SQL engines&#39; execution to native engines.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/image/gluten-logo.svg?sanitize=true&quot; alt=&quot;Gluten&quot; /&gt;&lt;/p&gt; 
&lt;h1&gt;Apache Gluten (Incubating): A Middle Layer for Offloading JVM-based SQL Engines&#39; Execution to Native Engines&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.bestpractices.dev/projects/8452&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8452/badge&quot; alt=&quot;OpenSSF Best Practices&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;1. Introduction&lt;/h1&gt; 
&lt;h2&gt;Problem Statement&lt;/h2&gt; 
&lt;p&gt;Apache Spark is a stable, mature project that has been developed for many years. It is one of the best frameworks to scale out for processing petabyte-scale datasets. However, the Spark community has had to address performance challenges that require various optimizations over time. As a key optimization in Spark 2.0, Whole Stage Code Generation is introduced to replace Volcano Model, which achieves 2x speedup. Henceforth, most optimizations are at query plan level. Single operator&#39;s performance almost stops growing.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://user-images.githubusercontent.com/47296334/199853029-b6d0ea19-f8e4-4f62-9562-2838f7f159a7.png&quot; width=&quot;800&quot; /&gt; &lt;/p&gt; 
&lt;p&gt;On the other side, native SQL engines have been developed for a few years, such as Clickhouse, Arrow and Velox, etc. With features like native execution, columnar data format and vectorized data processing, these native engines can outperform Spark&#39;s JVM based SQL engine. However, they only support single node execution.&lt;/p&gt; 
&lt;h2&gt;Gluten&#39;s Basic Design&lt;/h2&gt; 
&lt;p&gt;â€œGlutenâ€ is Latin for &quot;glue&quot;. The main goal of Gluten project is to glue native engines with SparkSQL. Thus, we can benefit from high scalability of Spark SQL framework and high performance of native engines.&lt;/p&gt; 
&lt;p&gt;The basic design rule is that we would reuse Spark&#39;s whole control flow and as much JVM code as possible but offload the compute-intensive data processing to native side. Here is what Gluten does basically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transform Sparkâ€™s physical plan to Substrait plan, then transform it to native engine&#39;s plan.&lt;/li&gt; 
 &lt;li&gt;Offload performance-critical data processing to native engine.&lt;/li&gt; 
 &lt;li&gt;Define clear JNI interfaces for native SQL engines.&lt;/li&gt; 
 &lt;li&gt;Switch available native backends easily.&lt;/li&gt; 
 &lt;li&gt;Reuse Sparkâ€™s distributed control flow.&lt;/li&gt; 
 &lt;li&gt;Manage data sharing between JVM and native.&lt;/li&gt; 
 &lt;li&gt;Extensible to support more native engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Target User&lt;/h2&gt; 
&lt;p&gt;Gluten&#39;s target user is anyone who aspires to accelerate SparkSQL fundamentally. As a plugin to Spark, Gluten doesn&#39;t require any change for dataframe API or SQL query, but only requires user to make correct configuration. See Gluten configuration properties &lt;a href=&quot;https://github.com/apache/incubator-gluten/raw/main/docs/Configuration.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;p&gt;You can click below links for more related information.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=0Q6gHT_N-1U&quot;&gt;Gluten Intro Video at Data AI Summit 2022&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/intel-analytics-software/accelerate-spark-sql-queries-with-gluten-9000b65d1b4e&quot;&gt;Gluten Intro Article at Medium.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cn.kyligence.io/blog/gluten-spark/&quot;&gt;Gluten Intro Article at Kyligence.io(in Chinese)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.fb.com/2023/03/09/open-source/velox-open-source-execution-engine/&quot;&gt;Velox Intro from Meta&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;2. Architecture&lt;/h1&gt; 
&lt;p&gt;The overview chart is like below. Substrait provides a well-defined cross-language specification for data compute operations (see more details &lt;a href=&quot;https://substrait.io/&quot;&gt;here&lt;/a&gt;). Spark physical plan is transformed to Substrait plan. Then Substrait plan is passed to native through JNI call. On native side, the native operator chain will be built out and offloaded to native engine. Gluten will return Columnar Batch to Spark and Spark Columnar API (since Spark-3.0) will be used at execution time. Gluten uses Apache Arrow data format as its basic data format, so the returned data to Spark JVM is ArrowColumnarBatch.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://user-images.githubusercontent.com/47296334/199617207-1140698a-4d53-462d-9bc7-303d14be060b.png&quot; width=&quot;800&quot; /&gt; &lt;/p&gt; Currently, Gluten only supports Clickhouse backend &amp;amp; Velox backend. Velox is a C++ database acceleration library which provides reusable, extensible and high-performance data processing components. More details can be found from https://github.com/facebookincubator/velox/. Gluten can also be extended to support more backends. 
&lt;p&gt;There are several key components in Gluten:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Plan Conversion&lt;/strong&gt;: converts Spark&#39;s physical plan to Substrait plan.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Memory Management&lt;/strong&gt;: controls native memory allocation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Columnar Shuffle&lt;/strong&gt;: shuffles Gluten columnar data. The shuffle service still reuses the one in Spark core. A kind of columnar exchange operator is implemented to support Gluten columnar data format.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fallback Mechanism&lt;/strong&gt;: supports falling back to Vanilla spark for unsupported operators. Gluten ColumnarToRow (C2R) and RowToColumnar (R2C) will convert Gluten columnar data and Spark&#39;s internal row data if needed. Both C2R and R2C are implemented in native code as well&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metrics&lt;/strong&gt;: collected from Gluten native engine to help identify bugs, performance bottlenecks, etc. The metrics are displayed in Spark UI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shim Layer&lt;/strong&gt;: supports multiple Spark versions. We plan to only support Spark&#39;s latest 2 or 3 releases. Currently, Spark-3.2, Spark-3.3 &amp;amp; Spark-3.4 (experimental) are supported.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;3. User Guide&lt;/h1&gt; 
&lt;p&gt;Here is a basic configuration to enable Gluten in Spark.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export GLUTEN_JAR=/PATH/TO/GLUTEN_JAR
spark-shell \
  --master yarn --deploy-mode client \
  --conf spark.plugins=org.apache.gluten.GlutenPlugin \
  --conf spark.memory.offHeap.enabled=true \
  --conf spark.memory.offHeap.size=20g \
  --conf spark.driver.extraClassPath=${GLUTEN_JAR} \
  --conf spark.executor.extraClassPath=${GLUTEN_JAR} \
  --conf spark.shuffle.manager=org.apache.spark.shuffle.sort.ColumnarShuffleManager
  ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are two ways to acquire Gluten jar for the above configuration.&lt;/p&gt; 
&lt;h3&gt;Use Released Jar&lt;/h3&gt; 
&lt;p&gt;Please download a tar package &lt;a href=&quot;https://downloads.apache.org/incubator/gluten/&quot;&gt;here&lt;/a&gt;, then extract out Gluten jar from it. Additionally, Gluten offers nightly builds based on the main branch, which are available for early testing. You can find these release jars at this link: &lt;a href=&quot;https://nightlies.apache.org/gluten/&quot;&gt;Apache Gluten Nightlies&lt;/a&gt;. It was verified on Centos-7, Centos-8, Centos-9, Ubuntu-20.04 and Ubuntu-22.04.&lt;/p&gt; 
&lt;h3&gt;Build From Source&lt;/h3&gt; 
&lt;p&gt;For &lt;strong&gt;Velox&lt;/strong&gt; backend, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/Velox.md&quot;&gt;Velox.md&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/build-guide.md&quot;&gt;build-guide.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For &lt;strong&gt;ClickHouse&lt;/strong&gt; backend, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/get-started/ClickHouse.md&quot;&gt;ClickHouse.md&lt;/a&gt;. ClickHouse backend is developed by &lt;a href=&quot;https://kyligence.io/&quot;&gt;Kyligence&lt;/a&gt;, please visit &lt;a href=&quot;https://github.com/Kyligence/ClickHouse&quot;&gt;https://github.com/Kyligence/ClickHouse&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;Gluten jar will be generated under &lt;code&gt;/PATH/TO/GLUTEN/package/target/&lt;/code&gt; after the build.&lt;/p&gt; 
&lt;h1&gt;4. Gluten Website&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://gluten.apache.org/&quot;&gt;https://gluten.apache.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;5. Contribution&lt;/h1&gt; 
&lt;p&gt;Welcome to contribute to Gluten project! See &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; about how to make contributions.&lt;/p&gt; 
&lt;h1&gt;6. Community&lt;/h1&gt; 
&lt;p&gt;Gluten successfully became Apache incubator project in March 2024. Here are several ways to contact us:&lt;/p&gt; 
&lt;h2&gt;GitHub&lt;/h2&gt; 
&lt;p&gt;Welcome to report any issue or create any discussion related to Gluten in GitHub. Please do a search from GitHub issue list before creating a new one to avoid repetition.&lt;/p&gt; 
&lt;h2&gt;Mail Lists&lt;/h2&gt; 
&lt;p&gt;For any technical discussion, please send email to &lt;a href=&quot;mailto:dev@gluten.apache.org&quot;&gt;dev@gluten.apache.org&lt;/a&gt;. You can go to &lt;a href=&quot;https://lists.apache.org/list.html?dev@gluten.apache.org&quot;&gt;archives&lt;/a&gt; for getting historical discussions. Please click &lt;a href=&quot;mailto:dev-subscribe@gluten.apache.org&quot;&gt;here&lt;/a&gt; to subscribe the mail list.&lt;/p&gt; 
&lt;h2&gt;Slack Channel (English communication)&lt;/h2&gt; 
&lt;p&gt;Please click &lt;a href=&quot;https://github.com/apache/incubator-gluten/discussions/8429&quot;&gt;here&lt;/a&gt; to get invitation for ASF Slack workspace where you can find &quot;incubator-gluten&quot; channel.&lt;/p&gt; 
&lt;p&gt;The ASF Slack login entry: &lt;a href=&quot;https://the-asf.slack.com/&quot;&gt;https://the-asf.slack.com/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;WeChat Group (Chinese communication)&lt;/h2&gt; 
&lt;p&gt;For PRC developers/users, please contact weitingchen at apache.org or zhangzc at apache.org for getting invited to the WeChat group.&lt;/p&gt; 
&lt;h1&gt;7. Performance&lt;/h1&gt; 
&lt;p&gt;We use Decision Support Benchmark1 (TPC-H like) to evaluate Gluten&#39;s performance. Decision Support Benchmark1 is a query set modified from &lt;a href=&quot;http://tpc.org/tpch/default5.asp&quot;&gt;TPC-H benchmark&lt;/a&gt;. We use Parquet file format for Velox testing &amp;amp; MergeTree file format for Clickhouse testing, compared to Parquet file format as baseline. See &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/tools/workload/tpch&quot;&gt;Decision Support Benchmark1&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The below test environment: single node with 2TB data; Spark-3.3.2 for both baseline and Gluten. The Decision Support Benchmark1 result (tested in Jun. 2023) shows an overall speedup of 2.71x and up to 14.53x speedup in a single query with Gluten Velox backend used.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/image/velox_decision_support_bench1_22queries_performance.png&quot; alt=&quot;Performance&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;The below testing environment: a 8-nodes AWS cluster with 1TB data; Spark-3.1.1 for both baseline and Gluten. The Decision Support Benchmark1 result shows an average speedup of 2.12x and up to 3.48x speedup with Gluten Clickhouse backend.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/docs/image/clickhouse_decision_support_bench1_22queries_performance.png&quot; alt=&quot;Performance&quot; /&gt;&lt;/p&gt; 
&lt;h1&gt;8. Qualification Tool&lt;/h1&gt; 
&lt;p&gt;The Qualification Tool is a utility to analyze Spark event log files and assess the compatibility and performance of SQL workloads with Gluten. This tool helps users understand how their workloads can benefit from Gluten.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Analyzes Spark SQL execution plans for compatibility with Gluten.&lt;/li&gt; 
 &lt;li&gt;Supports various types of event log files, including single files, folders, compressed files, and rolling event logs.&lt;/li&gt; 
 &lt;li&gt;Generates detailed reports highlighting supported and unsupported operations.&lt;/li&gt; 
 &lt;li&gt;Provides metrics on SQL execution times and operator impact.&lt;/li&gt; 
 &lt;li&gt;Offers configurable options such as threading, output directory, and date-based filtering.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To use the Qualification Tool, follow the instructions in its &lt;a href=&quot;https://raw.githubusercontent.com/apache/incubator-gluten/main/tools/qualification-tool/README.MD&quot;&gt;README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Example Command&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;java -jar target/qualification-tool-1.3.0-SNAPSHOT-jar-with-dependencies.jar -f /path/to/eventlog
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed usage instructions and advanced options, see the Qualification Tool README.&lt;/p&gt; 
&lt;h1&gt;9. License&lt;/h1&gt; 
&lt;p&gt;Gluten is licensed under &lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;10. Acknowledgements&lt;/h1&gt; 
&lt;p&gt;Gluten was initiated by Intel and Kyligence in 2022. Several companies are also actively participating in the development, such as BIGO, Meituan, Alibaba Cloud, NetEase, Baidu, Microsoft, IBM, Google, etc.&lt;/p&gt; 
&lt;a href=&quot;https://github.com/apache/incubator-gluten/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=apache/incubator-gluten&amp;amp;columns=25&quot; /&gt; &lt;/a&gt; 
&lt;h5&gt;* LEGAL NOTICE: Your use of this software and any required dependent software (the &quot;Software Package&quot;) is subject to the terms and conditions of the software license agreements for the Software Package, which may also include notices, disclaimers, or license terms for third party or open source software included in or with the Software Package, and your use indicates your acceptance of all such terms. Please refer to the &quot;TPP.txt&quot; or other similarly-named text file included with the Software Package for additional details.&lt;/h5&gt;</description>
    </item>
    
    <item>
      <title>ucb-bar/chipyard</title>
      <link>https://github.com/ucb-bar/chipyard</link>
      <description>&lt;p&gt;An Agile RISC-V SoC Design Framework with in-order cores, out-of-order cores, accelerators, and more&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/ucb-bar/chipyard/raw/main/docs/_static/images/chipyard-logo-full.png&quot; alt=&quot;CHIPYARD&quot; /&gt;&lt;/p&gt; 
&lt;h1&gt;Chipyard Framework &lt;a href=&quot;https://github.com/ucb-bar/chipyard/actions&quot;&gt;&lt;img src=&quot;https://github.com/ucb-bar/chipyard/actions/workflows/chipyard-run-tests.yml/badge.svg?sanitize=true&quot; alt=&quot;Test&quot; /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Latest Documentation&lt;/strong&gt;: &lt;a href=&quot;https://chipyard.readthedocs.io/&quot;&gt;https://chipyard.readthedocs.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User Question Forum&lt;/strong&gt;: &lt;a href=&quot;https://groups.google.com/forum/#!forum/chipyard&quot;&gt;https://groups.google.com/forum/#!forum/chipyard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs and Feature Requests&lt;/strong&gt;: &lt;a href=&quot;https://github.com/ucb-bar/chipyard/issues&quot;&gt;https://github.com/ucb-bar/chipyard/issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Using Chipyard&lt;/h2&gt; 
&lt;p&gt;To get started using Chipyard, see the documentation on the Chipyard documentation site: &lt;a href=&quot;https://chipyard.readthedocs.io/&quot;&gt;https://chipyard.readthedocs.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Chipyard&lt;/h2&gt; 
&lt;p&gt;Chipyard is an open source framework for agile development of Chisel-based systems-on-chip. It will allow you to leverage the Chisel HDL, Rocket Chip SoC generator, and other &lt;a href=&quot;https://berkeley.edu&quot;&gt;Berkeley&lt;/a&gt; projects to produce a &lt;a href=&quot;https://riscv.org/&quot;&gt;RISC-V&lt;/a&gt; SoC with everything from MMIO-mapped peripherals to custom accelerators. Chipyard contains processor cores (&lt;a href=&quot;https://github.com/freechipsproject/rocket-chip&quot;&gt;Rocket&lt;/a&gt;, &lt;a href=&quot;https://github.com/riscv-boom/riscv-boom&quot;&gt;BOOM&lt;/a&gt;, &lt;a href=&quot;https://github.com/openhwgroup/cva6/&quot;&gt;CVA6 (Ariane)&lt;/a&gt;), vector units (&lt;a href=&quot;https://raw.githubusercontent.com/ucb-bar/chipyard/main/saturn&quot;&gt;Saturn&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/ucb-bar/chipyard/main/ara&quot;&gt;Ara&lt;/a&gt;), accelerators (&lt;a href=&quot;https://github.com/ucb-bar/gemmini&quot;&gt;Gemmini&lt;/a&gt;, &lt;a href=&quot;http://nvdla.org/&quot;&gt;NVDLA&lt;/a&gt;), memory systems, and additional peripherals and tooling to help create a full featured SoC. Chipyard supports multiple concurrent flows of agile hardware development, including software RTL simulation, FPGA-accelerated simulation (&lt;a href=&quot;https://fires.im&quot;&gt;FireSim&lt;/a&gt;), automated VLSI flows (&lt;a href=&quot;https://github.com/ucb-bar/hammer&quot;&gt;Hammer&lt;/a&gt;), and software workload generation for bare-metal and Linux-based systems (&lt;a href=&quot;https://github.com/firesim/FireMarshal/&quot;&gt;FireMarshal&lt;/a&gt;). Chipyard is actively developed in the &lt;a href=&quot;http://bar.eecs.berkeley.edu&quot;&gt;Berkeley Architecture Research Group&lt;/a&gt; in the &lt;a href=&quot;https://eecs.berkeley.edu&quot;&gt;Electrical Engineering and Computer Sciences Department&lt;/a&gt; at the &lt;a href=&quot;https://berkeley.edu&quot;&gt;University of California, Berkeley&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chipyard Documentation: &lt;a href=&quot;https://chipyard.readthedocs.io/&quot;&gt;https://chipyard.readthedocs.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chipyard (x FireSim) Tutorial: &lt;a href=&quot;https://fires.im/tutorial-recent/&quot;&gt;https://fires.im/tutorial-recent/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chipyard Basics slides: &lt;a href=&quot;https://fires.im/asplos23-slides-pdf/02_chipyard_basics.pdf&quot;&gt;https://fires.im/asplos23-slides-pdf/02_chipyard_basics.pdf&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Need help?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the Chipyard Mailing List: &lt;a href=&quot;https://groups.google.com/forum/#!forum/chipyard&quot;&gt;https://groups.google.com/forum/#!forum/chipyard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;If you find a bug or would like propose a feature, post an issue on this repo: &lt;a href=&quot;https://github.com/ucb-bar/chipyard/issues&quot;&gt;https://github.com/ucb-bar/chipyard/issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/ucb-bar/chipyard/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Attribution and Chipyard-related Publications&lt;/h2&gt; 
&lt;p&gt;If used for research, please cite Chipyard by the following publication:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{chipyard,
  author={Amid, Alon and Biancolin, David and Gonzalez, Abraham and Grubb, Daniel and Karandikar, Sagar and Liew, Harrison and Magyar,   Albert and Mao, Howard and Ou, Albert and Pemberton, Nathan and Rigge, Paul and Schmidt, Colin and Wright, John and Zhao, Jerry and Shao, Yakun Sophia and Asanovi\&#39;{c}, Krste and Nikoli\&#39;{c}, Borivoje},
  journal={IEEE Micro},
  title={Chipyard: Integrated Design, Simulation, and Implementation Framework for Custom SoCs},
  year={2020},
  volume={40},
  number={4},
  pages={10-21},
  doi={10.1109/MM.2020.2996616},
  ISSN={1937-4143},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chipyard&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A. Amid, et al. &lt;em&gt;IEEE Micro&#39;20&lt;/em&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/document/9099108&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;A. Amid, et al. &lt;em&gt;DAC&#39;20&lt;/em&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/document/9218756&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;A. Amid, et al. &lt;em&gt;ISCAS&#39;21&lt;/em&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9401515&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These additional publications cover many of the internal components used in Chipyard. However, for the most up-to-date details, users should refer to the Chipyard docs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Generators&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Rocket Chip&lt;/strong&gt;: K. Asanovic, et al., &lt;em&gt;UCB EECS TR&lt;/em&gt;. &lt;a href=&quot;http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;BOOM&lt;/strong&gt;: C. Celio, et al., &lt;em&gt;Hot Chips 30&lt;/em&gt;. &lt;a href=&quot;https://old.hotchips.org/hc30/1conf/1.03_Berkeley_BROOM_HC30.Berkeley.Celio.v02.pdf&quot;&gt;PDF&lt;/a&gt;. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;SonicBOOM (BOOMv3)&lt;/strong&gt;: J. Zhao, et al., &lt;em&gt;CARRV&#39;20&lt;/em&gt;. &lt;a href=&quot;https://carrv.github.io/2020/papers/CARRV2020_paper_15_Zhao.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;COBRA (BOOM Branch Prediction)&lt;/strong&gt;: J. Zhao, et al., &lt;em&gt;ISPASS&#39;21&lt;/em&gt;. &lt;a href=&quot;https://ieeexplore.ieee.org/document/9408173&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Gemmini&lt;/strong&gt;: H. Genc, et al., &lt;em&gt;DAC&#39;21&lt;/em&gt;. &lt;a href=&quot;https://arxiv.org/pdf/1911.09925&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sims&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;FireSim&lt;/strong&gt;: S. Karandikar, et al., &lt;em&gt;ISCA&#39;18&lt;/em&gt;. &lt;a href=&quot;https://sagark.org/assets/pubs/firesim-isca2018.pdf&quot;&gt;PDF&lt;/a&gt;. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;FireSim Micro Top Picks&lt;/strong&gt;: S. Karandikar, et al., &lt;em&gt;IEEE Micro, Top Picks 2018&lt;/em&gt;. &lt;a href=&quot;https://sagark.org/assets/pubs/firesim-micro-top-picks2018.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;FASED&lt;/strong&gt;: D. Biancolin, et al., &lt;em&gt;FPGA&#39;19&lt;/em&gt;. &lt;a href=&quot;https://people.eecs.berkeley.edu/~biancolin/papers/fased-fpga19.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Golden Gate&lt;/strong&gt;: A. Magyar, et al., &lt;em&gt;ICCAD&#39;19&lt;/em&gt;. &lt;a href=&quot;https://davidbiancolin.github.io/papers/goldengate-iccad19.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;FirePerf&lt;/strong&gt;: S. Karandikar, et al., &lt;em&gt;ASPLOS&#39;20&lt;/em&gt;. &lt;a href=&quot;https://sagark.org/assets/pubs/fireperf-asplos2020.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;FireSim ISCA@50 Retrospective&lt;/strong&gt;: S. Karandikar, et al., &lt;em&gt;ISCA@50 Retrospective: 1996-2020&lt;/em&gt;. &lt;a href=&quot;https://sites.coecis.cornell.edu/isca50retrospective/files/2023/06/Karandikar_2018_FireSim.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Chisel&lt;/strong&gt;: J. Bachrach, et al., &lt;em&gt;DAC&#39;12&lt;/em&gt;. &lt;a href=&quot;https://people.eecs.berkeley.edu/~krste/papers/chisel-dac2012.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;FIRRTL&lt;/strong&gt;: A. Izraelevitz, et al., &lt;em&gt;ICCAD&#39;17&lt;/em&gt;. &lt;a href=&quot;https://ieeexplore.ieee.org/document/8203780&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Chisel DSP&lt;/strong&gt;: A. Wang, et al., &lt;em&gt;DAC&#39;18&lt;/em&gt;. &lt;a href=&quot;https://ieeexplore.ieee.org/document/8465790&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;FireMarshal&lt;/strong&gt;: N. Pemberton, et al., &lt;em&gt;ISPASS&#39;21&lt;/em&gt;. &lt;a href=&quot;https://ieeexplore.ieee.org/document/9408192&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VLSI&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Hammer&lt;/strong&gt;: E. Wang, et al., &lt;em&gt;ISQED&#39;20&lt;/em&gt;. &lt;a href=&quot;https://www.isqed.org/English/Archives/2020/Technical_Sessions/113.html&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Hammer&lt;/strong&gt;: H. Liew, et al., &lt;em&gt;DAC&#39;22&lt;/em&gt;. &lt;a href=&quot;https://dl.acm.org/doi/abs/10.1145/3489517.3530672&quot;&gt;PDF&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This work is supported by the NSF CCRI ENS Chipyard Award #2016662.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zio/zio</title>
      <link>https://github.com/zio/zio</link>
      <description>&lt;p&gt;ZIO â€” A type-safe, composable library for async and concurrent programming in Scala&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/ZIO.png&quot; alt=&quot;ZIO Logo&quot; /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project Stage&lt;/th&gt; 
   &lt;th&gt;CI&lt;/th&gt; 
   &lt;th&gt;Release&lt;/th&gt; 
   &lt;th&gt;Snapshot&lt;/th&gt; 
   &lt;th&gt;Issues&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/zio/zio/wiki/Project-Stages&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Project%20Stage-Production%20Ready-brightgreen.svg?sanitize=true&quot; alt=&quot;Project stage&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://github.com/zio/zio/workflows/CI/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://oss.sonatype.org/content/repositories/releases/dev/zio/zio_3/&quot; title=&quot;Sonatype Releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio_3.svg?sanitize=true&quot; alt=&quot;Release Artifacts&quot; title=&quot;Sonatype Releases&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio_3/&quot; title=&quot;Sonatype Snapshots&quot;&gt;&lt;img src=&quot;https://img.shields.io/nexus/s/https/oss.sonatype.org/dev.zio/zio_3.svg?sanitize=true&quot; alt=&quot;Snapshot Artifacts&quot; title=&quot;Sonatype Snapshots&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://isitmaintained.com/project/zio/zio&quot; title=&quot;Average time to resolve an issue&quot;&gt;&lt;img src=&quot;http://isitmaintained.com/badge/resolution/zio/zio.svg?sanitize=true&quot; alt=&quot;Average time to resolve an issue&quot; title=&quot;Average time to resolve an issue&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scaladoc&lt;/th&gt; 
   &lt;th&gt;Scaladex&lt;/th&gt; 
   &lt;th&gt;Discord&lt;/th&gt; 
   &lt;th&gt;Twitter&lt;/th&gt; 
   &lt;th&gt;Gitpod&lt;/th&gt; 
   &lt;th&gt;Gurubase&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://javadoc.io/doc/dev.zio/zio_3/latest/zio/index.html&quot;&gt;Scaladoc&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://index.scala-lang.org/zio/zio/zio&quot; title=&quot;Scaladex&quot;&gt;&lt;img src=&quot;https://index.scala-lang.org/zio/zio/zio/latest.svg?sanitize=true&quot; alt=&quot;Badge-Scaladex-page&quot; title=&quot;Scaladex&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://discord.gg/2ccFBr4&quot; title=&quot;Discord&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/629491597070827530?logo=discord&quot; alt=&quot;Badge-Discord&quot; title=&quot;chat on discord&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://twitter.com/zioscala&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/zioscala.svg?style=plastic&amp;amp;label=follow&amp;amp;logo=twitter&quot; alt=&quot;Badge-Twitter&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://gitpod.io/#https://github.com/zio/zio&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&quot; alt=&quot;Gitpod ready-to-code&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://gurubase.io/g/zio&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20ZIO%20Guru-006BFF&quot; alt=&quot;Gurubase&quot; /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Welcome to ZIO&lt;/h1&gt; 
&lt;p&gt;ZIO is a zero-dependency Scala library for asynchronous and concurrent programming.&lt;/p&gt; 
&lt;p&gt;Powered by highly-scalable, non-blocking fibers that never waste or leak resources, ZIO lets you build scalable, resilient, and reactive applications that meet the needs of your business.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-performance&lt;/strong&gt;. Build scalable applications with minimal runtime overhead.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type-safe&lt;/strong&gt;. Use the full power of the Scala compiler to catch bugs at compile time.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Concurrent&lt;/strong&gt;. Easily build concurrent apps without deadlocks, race conditions, or complexity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;. Write sequential code that looks the same whether it&#39;s asynchronous or synchronous.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resource-safe&lt;/strong&gt;. Build apps that never leak resources (including threads!), even when they fail.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;. Inject test services into your app for fast, deterministic, and type-safe testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resilient&lt;/strong&gt;. Build apps that never lose errors, and which respond to failure locally and flexibly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Functional&lt;/strong&gt;. Rapidly compose solutions to complex problems from simple building blocks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more about ZIO, see the following references:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://zio.dev/&quot;&gt;Homepage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/docs/contributor-guidelines.md&quot;&gt;Contributor&#39;s Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/LICENSE&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/zio/zio/issues&quot;&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/zio/zio/pulls&quot;&gt;Pull Requests&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Adopters&lt;/h1&gt; 
&lt;p&gt;Following is a partial list of companies happily using ZIO in production to craft concurrent applications.&lt;/p&gt; 
&lt;p&gt;Want to see your company here? &lt;a href=&quot;https://github.com/zio/zio/edit/series/2.x/README.md&quot;&gt;Submit a PR&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://adgear.com/en/&quot;&gt;AdGear / Samsung Ads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.adidas.com/&quot;&gt;Adidas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.adpulse.io/&quot;&gt;adpulse.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.adsquare.com/&quot;&gt;adsquare&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.anduintransact.com/&quot;&gt;Anduin Transactions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://anymindgroup.com&quot;&gt;AnyMind Group&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.ayolab.com/&quot;&gt;Ayolab&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://asana.com/&quot;&gt;Asana&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.aurinko.io/&quot;&gt;Aurinko&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://auto.ru&quot;&gt;auto.ru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.autoscout24.de&quot;&gt;AutoScout24&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.avast.com&quot;&gt;Avast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.bofa.com&quot;&gt;Bank of America&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.believe.com&quot;&gt;Believe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.blueinsight.digital/&quot;&gt;Blue Insight Digital&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.bluelabs.eu/&quot;&gt;BlueLabs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.bpp.it/&quot;&gt;Bpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://broad.app&quot;&gt;Broad&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.caesars.com/sportsbook-and-casino&quot;&gt;Caesars Digital&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.calcbank.com.br&quot;&gt;CalcBank&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.callhandling.co.uk/&quot;&gt;Call Handling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.carvana.com&quot;&gt;Carvana&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.cellular.de&quot;&gt;Cellular&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://channelpilot.com/de&quot;&gt;ChannelPilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://chartboost.com&quot;&gt;Chartboost&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cloudfarms.com&quot;&gt;Cloudfarms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://codecomprehension.com&quot;&gt;CodeComprehension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.codept.de/&quot;&gt;Codept&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.colisweb.com/en&quot;&gt;Colisweb&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.collibra.com/&quot;&gt;Collibra&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.compellon.com/&quot;&gt;Compellon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.complicatedrobot.com/&quot;&gt;Complicated Robot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.conduktor.io&quot;&gt;Conduktor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.contramap.dev&quot;&gt;Contramap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://coralogix.com&quot;&gt;Coralogix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://creditkarma.com&quot;&gt;Credit Karma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.currencycloud.com/&quot;&gt;CurrencyCloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://de-solution.com/&quot;&gt;D.E.Solution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dasch.swiss/&quot;&gt;DaSCH&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://datachef.co&quot;&gt;DataChef&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.demandbase.com&quot;&gt;Demandbase&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://demyst.com&quot;&gt;Demyst&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://devsisters.com/&quot;&gt;Devsisters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.werkenbijdhl.nl/it&quot;&gt;DHL Parcel The Netherlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.disneyplus.com/&quot;&gt;Disney+ Streaming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://doomoolmori.com/&quot;&gt;Doomoolmori&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.dowjones.com&quot;&gt;Dow Jones&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.dpgrecruitment.nl&quot;&gt;DPG recruitment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dream11.com&quot;&gt;Dream11&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://iot.telekom.com/en&quot;&gt;Deutsche Telekom IoT GmbH&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.ebay.com&quot;&gt;eBay&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.eaglescience.nl&quot;&gt;Eaglescience&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.edf.fr/&quot;&gt;ElectricitÃ© de France (EDF)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.enelx.com&quot;&gt;EnelX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://evolution.engineering&quot;&gt;Evolution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://evo.company&quot;&gt;Evo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flipp.com/&quot;&gt;Flipp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.fugo.ai&quot;&gt;Fugo.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.garnercorp.com/&quot;&gt;Garner Distributed Workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.gleancompany.com&quot;&gt;Glean&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://grandparade.co.uk&quot;&gt;GrandParade&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://greyflower.media&quot;&gt;greyflower.media GmbH&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hunters.ai&quot;&gt;Hunters.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://hypefactors.com/&quot;&gt;Hypefactors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.iheart.com/&quot;&gt;iHeartRadio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ihsmarkit.com/&quot;&gt;IHS Markit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://investsuite.com/&quot;&gt;Investsuite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.invia.cz/&quot;&gt;Invia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kaizen-solutions.net/&quot;&gt;Kaizen Solutions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kamon.io/&quot;&gt;Kamon APM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.kodmagi.se&quot;&gt;Kodmagi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kensu.io&quot;&gt;Kensu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.lambdaworks.io/&quot;&gt;LambdaWorks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://leadiq.com&quot;&gt;LeadIQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lernkunst.com/&quot;&gt;Lernkunst&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://liveintent.com&quot;&gt;LiveIntent Inc.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://lottoland.com&quot;&gt;Lottoland&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://matechs.com&quot;&gt;MATECHS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://megogo.net&quot;&gt;Megogo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.moia.io&quot;&gt;MOIA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mylivn.com/&quot;&gt;Mylivn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://newmotion.com&quot;&gt;NewMotion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nexxchange.com&quot;&gt;Nexxchange&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://nike.com&quot;&gt;Nike&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nslookup.io&quot;&gt;NsLookup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ocadotechnology.com&quot;&gt;Ocado Technology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://olyro.de&quot;&gt;Olyro GmbH&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://optrak.com&quot;&gt;Optrak&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.performance-immo.com/&quot;&gt;Performance Immo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.pirum.com/&quot;&gt;Pirum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.pitsdatarecovery.net/&quot;&gt;PITS Global Data Recovery Services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.playtika.com&quot;&gt;Playtika&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ppcsamurai.com/&quot;&gt;PPC Samurai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://prezi.com/&quot;&gt;Prezi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.radix.bio/&quot;&gt;Radix Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.railroad19.com&quot;&gt;Railroad19&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.werkenbijrandstad.nl&quot;&gt;Randstad Groep Nederland&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.rapidor.co&quot;&gt;Rapidor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pimsolutions.ru/&quot;&gt;PIM Solutions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.rememberthemilk.com/&quot;&gt;Remember The Milk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://rewe-digital.com/&quot;&gt;REWE Digital&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://lkwfee.de/&quot;&gt;LKWfee&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://riskident.com/&quot;&gt;Risk Ident&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://rocker.com/&quot;&gt;Rocker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.rudder.io/&quot;&gt;Rudder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://samsungfood.com/&quot;&gt;Samsung Food&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sanjagh.pro/&quot;&gt;Sanjagh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://scalac.io/&quot;&gt;Scalac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.securityscorecard.io/&quot;&gt;SecurityScorecard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.sentinelone.com/&quot;&gt;SentinelOne&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.signicat.com/&quot;&gt;Signicat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://info.sgmarkets.com/en/&quot;&gt;SociÃ©tÃ© GÃ©nÃ©rale Corporate and Investment Banking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://softwaremill.com/&quot;&gt;SoftwareMill&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.streamweaver.com/&quot;&gt;StreamWeaver&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://stuart.com/&quot;&gt;Stuart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://teads.com&quot;&gt;Teads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.pokemon.com/us/about-pokemon/&quot;&gt;The Pokemon Company International&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tomtom.com&quot;&gt;TomTom&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.tinka.com/&quot;&gt;Tinka&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tinkoff.ru&quot;&gt;Tinkoff&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://trackabus.com&quot;&gt;Trackabus&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.trainor.no&quot;&gt;Trainor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tranzzo.com&quot;&gt;Tranzzo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://treutech.io&quot;&gt;TreuTech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tweddle.com&quot;&gt;Tweddle Group&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.undo.app&quot;&gt;Undo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://unit.co&quot;&gt;Unit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://univalence.io&quot;&gt;Univalence&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.unzer.com&quot;&gt;Unzer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.vakantiediscounter.nl&quot;&gt;Vakantiediscounter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.verbund.com&quot;&gt;Verbund AG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.waylay.io/&quot;&gt;Waylay&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.wehkamp.nl&quot;&gt;Wehkamp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://wefunder.com&quot;&gt;Wefunder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.wolt.com/&quot;&gt;Wolt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://o.yandex.ru&quot;&gt;Yandex.Classifieds&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://audela.ca&quot;&gt;Audela&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://valamis.com&quot;&gt;Valamis Group&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://valsea.com&quot;&gt;Valsea&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://virtuslab.com/&quot;&gt;VirtusLab&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://getvish.com&quot;&gt;Vish&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://vivid.money&quot;&gt;Vivid Money&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://zalando.com/&quot;&gt;Zalando&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://zooz.com/&quot;&gt;Zooz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Sponsors&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://ziverge.com&quot; title=&quot;Ziverge&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/website/static/img/ziverge.png&quot; alt=&quot;Ziverge&quot; title=&quot;Ziverge&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://ziverge.com&quot; title=&quot;Ziverge&quot;&gt;Ziverge&lt;/a&gt; is a leading contributor to ZIO.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://7mind.io&quot; title=&quot;Septimal Mind&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/website/static/img/septimal_mind.svg?sanitize=true&quot; alt=&quot;Septimal Mind&quot; title=&quot;Septimal Mind&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://7mind.io&quot; title=&quot;Septimal Mind&quot;&gt;Septimal Mind&lt;/a&gt; sponsors work on ZIO Tracing and continuous maintenance.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.yourkit.com&quot; title=&quot;YourKit&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/website/static/img/yourkit.png&quot; alt=&quot;YourKit&quot; title=&quot;YourKit&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.yourkit.com&quot; title=&quot;YourKit&quot;&gt;YourKit&lt;/a&gt; generously provides use of their monitoring and profiling tools to maximize the performance of ZIO applications.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;a href=&quot;https://zio.dev/&quot;&gt;Learn More on the ZIO Homepage&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/zio/zio/series/2.x/docs/code-of-conduct.md&quot;&gt;Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Come chat with us on &lt;a href=&quot;https://discord.gg/2ccFBr4&quot; title=&quot;Discord&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/629491597070827530?logo=discord&quot; alt=&quot;Badge-Discord&quot; title=&quot;chat on discord&quot; /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;Copyright 2017 - 2024 John A. De Goes and the ZIO Contributors. All rights reserved.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/spark-rapids</title>
      <link>https://github.com/NVIDIA/spark-rapids</link>
      <description>&lt;p&gt;Spark RAPIDS plugin - accelerate Apache Spark with GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAPIDS Accelerator For Apache Spark&lt;/h1&gt; 
&lt;p&gt;NOTE: For the latest stable &lt;a href=&quot;https://github.com/nvidia/spark-rapids/raw/main/README.md&quot;&gt;README.md&lt;/a&gt; ensure you are on the main branch.&lt;/p&gt; 
&lt;p&gt;The RAPIDS Accelerator for Apache Spark provides a set of plugins for &lt;a href=&quot;https://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt; that leverage GPUs to accelerate processing via the &lt;a href=&quot;https://rapids.ai&quot;&gt;RAPIDS&lt;/a&gt; libraries.&lt;/p&gt; 
&lt;p&gt;Documentation on the current release can be found &lt;a href=&quot;https://nvidia.github.io/spark-rapids/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started and try the plugin out use the &lt;a href=&quot;https://docs.nvidia.com/spark-rapids/user-guide/latest/getting-started/overview.html&quot;&gt;getting started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://deepwiki.com/NVIDIA/spark-rapids&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg?sanitize=true&quot; alt=&quot;Ask DeepWiki&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;The SQL plugin tries to produce results that are bit for bit identical with Apache Spark. Operator compatibility is documented &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-25.10/docs/compatibility.md&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Tuning&lt;/h2&gt; 
&lt;p&gt;To get started tuning your job and get the most performance out of it please start with the &lt;a href=&quot;https://docs.nvidia.com/spark-rapids/user-guide/latest/tuning-guide.html&quot;&gt;tuning guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The plugin has a set of Spark configs that control its behavior and are documented &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-25.10/docs/configs.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Issues &amp;amp; Questions&lt;/h2&gt; 
&lt;p&gt;We use github to track bugs, feature requests, and answer questions. File an &lt;a href=&quot;https://github.com/NVIDIA/spark-rapids/issues/new/choose&quot;&gt;issue&lt;/a&gt; for a bug or feature request. Ask or answer a question on the &lt;a href=&quot;https://github.com/NVIDIA/spark-rapids/discussions&quot;&gt;discussion board&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;The jar files for the most recent release can be retrieved from the &lt;a href=&quot;https://nvidia.github.io/spark-rapids/docs/download.html&quot;&gt;download&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Building From Source&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-25.10/CONTRIBUTING.md#building-from-source&quot;&gt;build instructions in the contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;Tests are described &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/spark-rapids/branch-25.10/tests/README.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Integration&lt;/h2&gt; 
&lt;p&gt;The RAPIDS Accelerator For Apache Spark does provide some APIs for doing zero copy data transfer into other GPU enabled applications. It is described &lt;a href=&quot;https://docs.nvidia.com/spark-rapids/user-guide/latest/additional-functionality/ml-integration.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Currently, we are working with XGBoost to try to provide this integration out of the box.&lt;/p&gt; 
&lt;p&gt;You may need to disable RMM caching when exporting data to an ML library as that library will likely want to use all of the GPU&#39;s memory and if it is not aware of RMM it will not have access to any of the memory that RMM is holding.&lt;/p&gt; 
&lt;h2&gt;Qualification and Profiling tools&lt;/h2&gt; 
&lt;p&gt;The Qualification and Profiling tools have been moved to &lt;a href=&quot;https://github.com/NVIDIA/spark-rapids-tools&quot;&gt;nvidia/spark-rapids-tools&lt;/a&gt; repo.&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href=&quot;https://docs.nvidia.com/spark-rapids/user-guide/latest/qualification/overview.html&quot;&gt;Qualification tool documentation&lt;/a&gt; and &lt;a href=&quot;https://docs.nvidia.com/spark-rapids/user-guide/latest/profiling/overview.html&quot;&gt;Profiling tool documentation&lt;/a&gt; for more details on how to use the tools.&lt;/p&gt; 
&lt;h2&gt;Dependency for External Projects&lt;/h2&gt; 
&lt;p&gt;If you need to develop some functionality on top of RAPIDS Accelerator For Apache Spark (we currently limit support to GPU-accelerated UDFs) we recommend you declare our distribution artifact as a &lt;code&gt;provided&lt;/code&gt; dependency.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.nvidia&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;rapids-4-spark_2.12&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;25.10.0-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>scala/scala</title>
      <link>https://github.com/scala/scala</link>
      <description>&lt;p&gt;Scala 2 compiler and standard library. Scala 2 bugs at https://github.com/scala/bug; Scala 3 at https://github.com/scala/scala3&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;This is Scala 2! Welcome!&lt;/h1&gt; 
&lt;p&gt;This is the home of the &lt;a href=&quot;https://www.scala-lang.org&quot;&gt;Scala 2&lt;/a&gt; standard library, compiler, and language spec.&lt;/p&gt; 
&lt;p&gt;For Scala 3, visit &lt;a href=&quot;https://github.com/scala/scala3&quot;&gt;scala/scala3&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;How to contribute&lt;/h1&gt; 
&lt;p&gt;Issues and bug reports for Scala 2 are located in &lt;a href=&quot;https://github.com/scala/bug&quot;&gt;scala/bug&lt;/a&gt;. That tracker is also where new contributors may find issues to work on: &lt;a href=&quot;https://github.com/scala/bug/labels/good%20first%20issue&quot;&gt;good first issues&lt;/a&gt;, &lt;a href=&quot;https://github.com/scala/bug/labels/help%20wanted&quot;&gt;help wanted&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For coordinating broader efforts, we also use the &lt;a href=&quot;https://github.com/scala/scala-dev/issues&quot;&gt;scala/scala-dev tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute here, please open a &lt;a href=&quot;https://help.github.com/articles/using-pull-requests/#fork--pull&quot;&gt;pull request&lt;/a&gt; from your fork of this repository.&lt;/p&gt; 
&lt;p&gt;Be aware that we can&#39;t accept additions to the standard library, only modifications to existing code. Binary compatibility forbids adding new public classes or public methods. Additions are made to &lt;a href=&quot;https://github.com/scala/scala-library-next&quot;&gt;scala-library-next&lt;/a&gt; instead.&lt;/p&gt; 
&lt;p&gt;We require that you sign the &lt;a href=&quot;https://contribute.akka.io/contribute/cla/scala&quot;&gt;Scala CLA&lt;/a&gt; before we can merge any of your work, to protect Scala&#39;s future as open source software.&lt;/p&gt; 
&lt;p&gt;The general workflow is as follows.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Find/file an issue in scala/bug (or submit a well-documented PR right away!).&lt;/li&gt; 
 &lt;li&gt;Fork the scala/scala repo.&lt;/li&gt; 
 &lt;li&gt;Push your changes to a branch in your forked repo. For coding guidelines, go &lt;a href=&quot;https://github.com/scala/scala#coding-guidelines&quot;&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Submit a pull request to scala/scala from your forked repo.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For more information on building and developing the core of Scala, read the rest of this README, especially for &lt;a href=&quot;https://github.com/scala/scala#get-ready-to-contribute&quot;&gt;setting up your machine&lt;/a&gt;!&lt;/p&gt; 
&lt;h1&gt;Get in touch!&lt;/h1&gt; 
&lt;p&gt;In order to get in touch with other Scala contributors, join the #scala-contributors channel on the &lt;a href=&quot;https://discord.com/invite/scala&quot;&gt;Scala Discord&lt;/a&gt; chat, or post on &lt;a href=&quot;https://contributors.scala-lang.org&quot;&gt;contributors.scala-lang.org&lt;/a&gt; (Discourse).&lt;/p&gt; 
&lt;p&gt;If you need some help with your PR at any time, please feel free to @-mention anyone from the list below, and we will do our best to help you out:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;username&lt;/th&gt; 
   &lt;th&gt;talk to me about...&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/lrytz&quot; height=&quot;50px&quot; title=&quot;Lukas Rytz&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/lrytz&quot;&gt;&lt;code&gt;@lrytz&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;back end, optimizer, named &amp;amp; default arguments, reporters&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/retronym&quot; height=&quot;50px&quot; title=&quot;Jason Zaugg&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/retronym&quot;&gt;&lt;code&gt;@retronym&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;compiler performance, weird compiler bugs, lambdas&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/SethTisue&quot; height=&quot;50px&quot; title=&quot;Seth Tisue&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/SethTisue&quot;&gt;&lt;code&gt;@SethTisue&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;getting started, build, CI, community build, Jenkins, docs, library, REPL&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/dwijnand&quot; height=&quot;50px&quot; title=&quot;Dale Wijnand&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/dwijnand&quot;&gt;&lt;code&gt;@dwijnand&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;pattern matcher, MiMa, partest&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/som-snytt&quot; height=&quot;50px&quot; title=&quot;Som Snytt&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/som-snytt&quot;&gt;&lt;code&gt;@som-snytt&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;warnings/lints/errors, REPL, compiler options, compiler internals, partest&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Ichoran&quot; height=&quot;50px&quot; title=&quot;Rex Kerr&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/Ichoran&quot;&gt;&lt;code&gt;@Ichoran&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;collections library, performance&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/viktorklang&quot; height=&quot;50px&quot; title=&quot;Viktor Klang&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/viktorklang&quot;&gt;&lt;code&gt;@viktorklang&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;concurrency, futures&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/sjrd&quot; height=&quot;50px&quot; title=&quot;SÃ©bastien Doeraene&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/sjrd&quot;&gt;&lt;code&gt;@sjrd&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;interactions with Scala.js&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/NthPortal&quot; height=&quot;50px&quot; title=&quot;Princess | April&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/NthPortal&quot;&gt;&lt;code&gt;@NthPortal&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;library, concurrency, &lt;code&gt;scala.math&lt;/code&gt;, &lt;code&gt;LazyList&lt;/code&gt;, &lt;code&gt;Using&lt;/code&gt;, warnings&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/bishabosha&quot; height=&quot;50px&quot; title=&quot;Jamie Thompson&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/bishabosha&quot;&gt;&lt;code&gt;@bishabosha&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TASTy reader&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/joroKr21&quot; height=&quot;50px&quot; title=&quot;Georgi Krastev&quot; /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/joroKr21&quot;&gt;&lt;code&gt;@joroKr21&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;higher-kinded types, implicits, variance&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;P.S.: If you have some spare time to help out around here, we would be delighted to add your name to this list!&lt;/p&gt; 
&lt;h1&gt;Branches&lt;/h1&gt; 
&lt;p&gt;Target the oldest branch you would like your changes to end up in. We periodically merge forward from 2.12.x to 2.13.x. Most changes should target 2.13.x, as 2.12.x is now under minimal maintenance.&lt;/p&gt; 
&lt;p&gt;If your change is difficult to merge forward, you may be asked to also submit a separate PR targeting the newer branch.&lt;/p&gt; 
&lt;p&gt;If your change is version-specific and shouldn&#39;t be merged forward, put &lt;code&gt;[nomerge]&lt;/code&gt; in the PR name.&lt;/p&gt; 
&lt;p&gt;If your change is a backport from a newer branch and thus doesn&#39;t need to be merged forward, put &lt;code&gt;[backport]&lt;/code&gt; in the PR name.&lt;/p&gt; 
&lt;h2&gt;Choosing a branch&lt;/h2&gt; 
&lt;p&gt;Most changes should target 2.13.x. We are increasingly reluctant to target 2.12.x unless there is a special reason (e.g. if an especially bad bug is found, or if there is commercial sponsorship). See &lt;a href=&quot;https://www.scala-lang.org/development/#scala-2-maintenance&quot;&gt;Scala 2 maintenance&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Repository structure&lt;/h1&gt; 
&lt;p&gt;Most importantly:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;scala/
+--build.sbt                 The main sbt build definition
+--project/                  The rest of the sbt build
+--src/                      All sources
   +---/library              Scala Standard Library
   +---/reflect              Scala Reflection
   +---/compiler             Scala Compiler
+--test/                     The Scala test suite
   +---/files                Partest tests
   +---/junit                JUnit tests
   +---/scalacheck           ScalaCheck tests
+--spec/                     The Scala language specification
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;but also:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;scala/
   +---/library-aux          Scala Auxiliary Library, for bootstrapping and documentation purposes
   +---/interactive          Scala Interactive Compiler, for clients such as an IDE (aka Presentation Compiler)
   +---/intellij             IntelliJ project templates
   +---/manual               Scala&#39;s runner scripts &quot;man&quot; (manual) pages
   +---/partest              Scala&#39;s internal parallel testing framework
   +---/partest-javaagent    Partest&#39;s helper java agent
   +---/repl                 Scala REPL core
   +---/repl-frontend        Scala REPL frontend
   +---/scaladoc             Scala&#39;s documentation tool
   +---/scalap               Scala&#39;s class file decompiler
   +---/testkit              Scala&#39;s unit-testing kit
+--admin/                    Scripts for the CI jobs and releasing
+--doc/                      Additional licenses and copyrights
+--scripts/                  Scripts for the CI jobs and releasing
+--tools/                    Scripts useful for local development
+--build/                    Build products
+--dist/                     Build products
+--target/                   Build products
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Get ready to contribute&lt;/h1&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;You need the following tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java SDK. The baseline version is 8 for both 2.12.x and 2.13.x. It is almost always fine to use a later SDK (such as 17 or 21) for local development. CI will verify against the baseline version.&lt;/li&gt; 
 &lt;li&gt;sbt&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MacOS and Linux work. Windows may work if you use Cygwin. Community help with keeping the build working on Windows and documenting any needed setup is appreciated.&lt;/p&gt; 
&lt;h2&gt;Tools we use&lt;/h2&gt; 
&lt;p&gt;We are grateful for the following OSS licenses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.ej-technologies.com/products/jprofiler/overview.html&quot;&gt;JProfiler Java profiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.yourkit.com/java/profiler/&quot;&gt;YourKit Java Profiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/idea/download/&quot;&gt;IntelliJ IDEA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://develocity.scala-lang.org&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&amp;amp;labelColor=02303A&quot; alt=&quot;Revved up by Develocity&quot; /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build setup&lt;/h2&gt; 
&lt;h3&gt;Basics&lt;/h3&gt; 
&lt;p&gt;During ordinary development, a new Scala build is built by the previously released version, known as the &quot;reference compiler&quot; or, slangily, as &quot;STARR&quot; (stable reference release). Building with STARR is sufficient for most kinds of changes.&lt;/p&gt; 
&lt;p&gt;However, a full build of Scala is &lt;em&gt;bootstrapped&lt;/em&gt;. Bootstrapping has two steps: first, build with STARR; then, build again using the freshly built compiler, leaving STARR behind. This guarantees that every Scala version can build itself.&lt;/p&gt; 
&lt;p&gt;If you change the code generation part of the Scala compiler, your changes will only show up in the bytecode of the library and compiler after a bootstrap. Our CI does a bootstrapped build.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Bootstrapping locally&lt;/strong&gt;: To perform a bootstrap, run &lt;code&gt;restarrFull&lt;/code&gt; within an sbt session. This will build and publish the Scala distribution to your local artifact repository and then switch sbt to use that version as its new &lt;code&gt;scalaVersion&lt;/code&gt;. You may then revert back with &lt;code&gt;reload&lt;/code&gt;. Note &lt;code&gt;restarrFull&lt;/code&gt; will also write the STARR version to &lt;code&gt;buildcharacter.properties&lt;/code&gt; so you can switch back to it with &lt;code&gt;restarr&lt;/code&gt; without republishing. This will switch the sbt session to use the &lt;code&gt;build-restarr&lt;/code&gt; and &lt;code&gt;target-restarr&lt;/code&gt; directories instead of &lt;code&gt;build&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;, which avoids wiping out classfiles and incremental metadata. IntelliJ will continue to be configured to compile and run tests using the starr version in &lt;code&gt;versions.properties&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For history on how the current scheme was arrived at, see &lt;a href=&quot;https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion&quot;&gt;https://groups.google.com/d/topic/scala-internals/gp5JsM1E0Fo/discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Building with fatal warnings&lt;/strong&gt;: To make warnings in the project fatal (i.e. turn them into errors), run &lt;code&gt;set Global / fatalWarnings := true&lt;/code&gt; in sbt (replace &lt;code&gt;Global&lt;/code&gt; with the name of a moduleâ€”such as &lt;code&gt;reflect&lt;/code&gt;â€”to only make warnings fatal for that module). To disable fatal warnings again, either &lt;code&gt;reload&lt;/code&gt; sbt, or run &lt;code&gt;set Global / fatalWarnings := false&lt;/code&gt; (again, replace &lt;code&gt;Global&lt;/code&gt; with the name of a module if you only enabled fatal warnings for that module). CI always has fatal warnings enabled.&lt;/p&gt; 
&lt;h3&gt;Using the sbt build&lt;/h3&gt; 
&lt;p&gt;Once you&#39;ve started an &lt;code&gt;sbt&lt;/code&gt; session you can run one of the core commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;compile&lt;/code&gt; compiles all sub-projects (library, reflect, compiler, scaladoc, etc)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;scala&lt;/code&gt; / &lt;code&gt;scalac&lt;/code&gt; run the REPL / compiler directly from sbt (accept options / arguments)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;enableOptimizer&lt;/code&gt; reloads the build with the Scala optimizer enabled. Our releases are built this way. Enable this when working on compiler performance improvements. When the optimizer is enabled the build will be slower and incremental builds can be incorrect.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;setupPublishCore&lt;/code&gt; runs &lt;code&gt;enableOptimizer&lt;/code&gt; and configures a version number based on the current Git SHA. Often used as part of bootstrapping: &lt;code&gt;sbt setupPublishCore publishLocal &amp;amp;&amp;amp; sbt -Dstarr.version=&amp;lt;VERSION&amp;gt; testAll&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dist/mkBin&lt;/code&gt; generates runner scripts (&lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt;, etc) in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dist/mkPack&lt;/code&gt; creates a build in the Scala distribution format in &lt;code&gt;build/pack&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;junit/test&lt;/code&gt; runs the JUnit tests; &lt;code&gt;junit/testOnly *Foo&lt;/code&gt; runs a subset&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;scalacheck/test&lt;/code&gt; runs scalacheck tests, use &lt;code&gt;testOnly&lt;/code&gt; to run a subset&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;partest&lt;/code&gt; runs partest tests (accepts options, try &lt;code&gt;partest --help&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;publishLocal&lt;/code&gt; publishes a distribution locally (can be used as &lt;code&gt;scalaVersion&lt;/code&gt; in other sbt projects) 
  &lt;ul&gt; 
   &lt;li&gt;Optionally &lt;code&gt;set baseVersionSuffix := &quot;bin-abcd123-SNAPSHOT&quot;&lt;/code&gt; where &lt;code&gt;abcd123&lt;/code&gt; is the git hash of the revision being published. You can also use something custom like &lt;code&gt;&quot;bin-mypatch&quot;&lt;/code&gt;. This changes the version number from &lt;code&gt;2.13.2-SNAPSHOT&lt;/code&gt; to something more stable (&lt;code&gt;2.13.2-bin-abcd123-SNAPSHOT&lt;/code&gt;).&lt;/li&gt; 
   &lt;li&gt;Note that the &lt;code&gt;-bin&lt;/code&gt; string marks the version binary compatible. Using it in sbt will cause the &lt;code&gt;scalaBinaryVersion&lt;/code&gt; to be &lt;code&gt;2.13&lt;/code&gt;. If the version is not binary compatible, we recommend using &lt;code&gt;-pre&lt;/code&gt;, e.g., &lt;code&gt;2.14.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Optionally &lt;code&gt;set ThisBuild / Compile / packageDoc / publishArtifact := false&lt;/code&gt; to skip generating / publishing API docs (speeds up the process).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If a command results in an error message like &lt;code&gt;a module is not authorized to depend on itself&lt;/code&gt;, it may be that a global sbt plugin is causing a cyclical dependency. Try disabling global sbt plugins (perhaps by temporarily commenting them out in &lt;code&gt;~/.sbt/1.0/plugins/plugins.sbt&lt;/code&gt;).&lt;/p&gt; 
&lt;h4&gt;Sandbox&lt;/h4&gt; 
&lt;p&gt;We recommend keeping local test files in the &lt;code&gt;sandbox&lt;/code&gt; directory which is listed in the &lt;code&gt;.gitignore&lt;/code&gt; of the Scala repo.&lt;/p&gt; 
&lt;h4&gt;Incremental compilation&lt;/h4&gt; 
&lt;p&gt;Note that sbt&#39;s incremental compilation is often too coarse for the Scala compiler codebase and re-compiles too many files, resulting in long build times (check &lt;a href=&quot;https://github.com/sbt/sbt/issues/1104&quot;&gt;sbt#1104&lt;/a&gt; for progress on that front). In the meantime you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use IntelliJ IDEA for incremental compiles (see &lt;a href=&quot;https://raw.githubusercontent.com/scala/scala/2.13.x/#ide-setup&quot;&gt;IDE Setup&lt;/a&gt; below) - its incremental compiler is a bit less conservative, but usually correct.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;IDE setup&lt;/h3&gt; 
&lt;p&gt;We suggest using IntelliJ IDEA (see &lt;a href=&quot;https://raw.githubusercontent.com/scala/scala/2.13.x/src/intellij/README.md&quot;&gt;src/intellij/README.md&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://scalameta.org/metals/&quot;&gt;Metals&lt;/a&gt; may also work, but we don&#39;t yet have instructions or sample configuration for that. A pull request in this area would be exceedingly welcome. In the meantime, we are collecting guidance at &lt;a href=&quot;https://github.com/scala/scala-dev/issues/668&quot;&gt;scala/scala-dev#668&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to use IntelliJ&#39;s incremental compiler:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;run &lt;code&gt;dist/mkBin&lt;/code&gt; in sbt to get a build and the runner scripts in &lt;code&gt;build/quick/bin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;run &quot;Build&quot; - &quot;Make Project&quot; in IntelliJ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now you can edit and build in IntelliJ and use the scripts (compiler, REPL) to directly test your changes. You can also run the &lt;code&gt;scala&lt;/code&gt;, &lt;code&gt;scalac&lt;/code&gt; and &lt;code&gt;partest&lt;/code&gt; commands in sbt. Enable &quot;Ant mode&quot; (explained above) to prevent sbt&#39;s incremental compiler from re-compiling (too many) files before each &lt;code&gt;partest&lt;/code&gt; invocation.&lt;/p&gt; 
&lt;h1&gt;Coding guidelines&lt;/h1&gt; 
&lt;p&gt;Our guidelines for contributing are explained in &lt;a href=&quot;https://raw.githubusercontent.com/scala/scala/2.13.x/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;. It contains useful information on our coding standards, testing, documentation, how we use git and GitHub and how to get your code reviewed.&lt;/p&gt; 
&lt;p&gt;You may also want to check out the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href=&quot;https://scala-lang.org/contribute/hacker-guide.html&quot;&gt;&quot;Scala Hacker Guide&quot;&lt;/a&gt; covers some of the same ground as this README, but in greater detail and in a more tutorial style, using a running example.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.scala-lang.org&quot;&gt;Scala documentation site&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Scala CI&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://travis-ci.com/scala/scala&quot;&gt;&lt;img src=&quot;https://travis-ci.com/scala/scala.svg?branch=2.13.x&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Once you submit a PR your commits will be automatically tested by the Scala CI.&lt;/p&gt; 
&lt;p&gt;Our CI setup is always evolving. See &lt;a href=&quot;https://github.com/scala/scala-dev/issues/751&quot;&gt;scala/scala-dev#751&lt;/a&gt; for more details on how things currently work and how we expect they might change.&lt;/p&gt; 
&lt;p&gt;If you see a spurious failure on Jenkins, you can post &lt;code&gt;/rebuild&lt;/code&gt; as a PR comment. The &lt;a href=&quot;https://github.com/scala/scabot&quot;&gt;scabot README&lt;/a&gt; lists all available commands.&lt;/p&gt; 
&lt;p&gt;If you&#39;d like to test your patch before having everything polished for review, you can have Travis CI build your branch (make sure you have a fork and have Travis CI enabled for branch builds on it first, and then push your branch). Also feel free to submit a draft PR. In case your draft branch contains a large number of commits (that you didn&#39;t clean up / squash yet for review), consider adding &lt;code&gt;[ci: last-only]&lt;/code&gt; to the PR title. That way only the last commit will be tested, saving some energy and CI-resources. Note that inactive draft PRs will be closed eventually, which does not mean the change is being rejected.&lt;/p&gt; 
&lt;p&gt;CI performs a compiler bootstrap. The first task, &lt;code&gt;validatePublishCore&lt;/code&gt;, publishes a build of your commit to the temporary repository &lt;a href=&quot;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots&quot;&gt;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots&lt;/a&gt;. Note that this build is not yet bootstrapped, its bytecode is built using the current STARR. The version number is &lt;code&gt;2.13.2-bin-abcd123-SNAPSHOT&lt;/code&gt; where &lt;code&gt;abcd123&lt;/code&gt; is the commit hash. For binary incompatible builds, the version number is &lt;code&gt;2.14.0-pre-abcd123-SNAPSHOT&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can use Scala builds in the validation repository locally by adding a resolver and specifying the corresponding &lt;code&gt;scalaVersion&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sbt
&amp;gt; set resolvers += &quot;pr&quot; at &quot;https://scala-ci.typesafe.com/artifactory/scala-pr-validation-snapshots/&quot;
&amp;gt; set scalaVersion := &quot;2.13.17-bin-abcd123-SNAPSHOT&quot;
&amp;gt; console
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&quot;Nightly&quot; builds&lt;/h2&gt; 
&lt;p&gt;The Scala CI publishes these to &lt;a href=&quot;https://scala-ci.typesafe.com/artifactory/scala-integration/&quot;&gt;https://scala-ci.typesafe.com/artifactory/scala-integration/&lt;/a&gt; .&lt;/p&gt; 
&lt;p&gt;Using a nightly build in sbt and other tools is explained on this &lt;a href=&quot;https://docs.scala-lang.org/overviews/core/nightlies.html&quot;&gt;doc page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Although we casually refer to these as &quot;nightly&quot; builds, they aren&#39;t actually built nightly, but &quot;mergely&quot;. That is to say, a build is published for every merged PR.&lt;/p&gt; 
&lt;h2&gt;Scala CI internals&lt;/h2&gt; 
&lt;p&gt;The Scala CI runs as a Jenkins instance on &lt;a href=&quot;https://scala-ci.typesafe.com/&quot;&gt;scala-ci.typesafe.com&lt;/a&gt;, configured by a chef cookbook at &lt;a href=&quot;https://github.com/scala/scala-jenkins-infra&quot;&gt;scala/scala-jenkins-infra&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The build bot that watches PRs, triggers testing builds and applies the &quot;reviewed&quot; label after an LGTM comment is in the &lt;a href=&quot;https://github.com/scala/scabot&quot;&gt;scala/scabot&lt;/a&gt; repo.&lt;/p&gt; 
&lt;h2&gt;Community build&lt;/h2&gt; 
&lt;p&gt;The Scala community build is an important method for testing Scala releases. A community build can be launched for any Scala commit, even before the commit&#39;s PR has been merged. That commit is then used to build a large number of open-source projects from source and run their test suites.&lt;/p&gt; 
&lt;p&gt;To request a community build run on your PR, just ask in a comment on the PR and a Scala team member (probably @SethTisue) will take care of it. (&lt;a href=&quot;https://github.com/scala/community-builds/wiki#can-i-run-it-against-a-pull-request-in-scalascala&quot;&gt;details&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;Community builds run on the Scala Jenkins instance. The jobs are named &lt;code&gt;..-integrate-community-build&lt;/code&gt;. See the &lt;a href=&quot;https://github.com/scala/community-builds&quot;&gt;scala/community-builds&lt;/a&gt; repo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>databricks/Spark-The-Definitive-Guide</title>
      <link>https://github.com/databricks/Spark-The-Definitive-Guide</link>
      <description>&lt;p&gt;Spark: The Definitive Guide&#39;s Code Repository&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
  </channel>
</rss>
