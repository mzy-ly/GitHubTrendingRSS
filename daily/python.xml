<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:36:21 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>cheahjs/free-llm-api-resources</title>
      <link>https://github.com/cheahjs/free-llm-api-resources</link>
      <description>&lt;p&gt;A list of free LLM inference resources accessible via API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Free LLM API resources&lt;/h1&gt; 
&lt;p&gt;This lists various services that provide free access or credits towards API-based LLM usage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; Please don&#39;t abuse these services, else we might lose them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; This list explicitly excludes any services that are not legitimate (eg reverse engineers an existing chatbot)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#free-providers&quot;&gt;Free Providers&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#openrouter&quot;&gt;OpenRouter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#google-ai-studio&quot;&gt;Google AI Studio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#nvidia-nim&quot;&gt;NVIDIA NIM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#mistral-la-plateforme&quot;&gt;Mistral (La Plateforme)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#mistral-codestral&quot;&gt;Mistral (Codestral)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#huggingface-inference-providers&quot;&gt;HuggingFace Inference Providers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#vercel-ai-gateway&quot;&gt;Vercel AI Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#cerebras&quot;&gt;Cerebras&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#groq&quot;&gt;Groq&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#together-free&quot;&gt;Together (Free)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#cohere&quot;&gt;Cohere&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#github-models&quot;&gt;GitHub Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#cloudflare-workers-ai&quot;&gt;Cloudflare Workers AI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#google-cloud-vertex-ai&quot;&gt;Google Cloud Vertex AI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#providers-with-trial-credits&quot;&gt;Providers with trial credits&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#together&quot;&gt;Together&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#fireworks&quot;&gt;Fireworks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#baseten&quot;&gt;Baseten&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#nebius&quot;&gt;Nebius&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#novita&quot;&gt;Novita&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#ai21&quot;&gt;AI21&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#upstage&quot;&gt;Upstage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#nlp-cloud&quot;&gt;NLP Cloud&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#alibaba-cloud-international-model-studio&quot;&gt;Alibaba Cloud (International) Model Studio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#modal&quot;&gt;Modal&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#inferencenet&quot;&gt;Inference.net&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#ncompass&quot;&gt;nCompass&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#hyperbolic&quot;&gt;Hyperbolic&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#sambanova-cloud&quot;&gt;SambaNova Cloud&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/cheahjs/free-llm-api-resources/main/#scaleway-generative-apis&quot;&gt;Scaleway Generative APIs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Free Providers&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://openrouter.ai&quot;&gt;OpenRouter&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://openrouter.ai/docs/api-reference/limits&quot;&gt;20 requests/minute&lt;br /&gt;50 requests/day&lt;br /&gt;1000 requests/day with $10 lifetime topup&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Models share a common quota.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/agentica-org/deepcoder-14b-preview:free&quot;&gt;DeepCoder 14B Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/nousresearch/deephermes-3-llama-3-8b-preview:free&quot;&gt;DeepHermes 3 Llama 3 8B Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-r1:free&quot;&gt;DeepSeek R1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-r1-distill-llama-70b:free&quot;&gt;DeepSeek R1 Distill Llama 70B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-r1-distill-qwen-14b:free&quot;&gt;DeepSeek R1 Distill Qwen 14B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free&quot;&gt;DeepSeek V3 0324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/cognitivecomputations/dolphin3.0-mistral-24b:free&quot;&gt;Dolphin 3.0 Mistral 24B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b:free&quot;&gt;Dolphin 3.0 R1 Mistral 24B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/featherless/qwerky-72b:free&quot;&gt;Featherless Qwerky 72B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-2-9b-it:free&quot;&gt;Gemma 2 9B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-3-12b-it:free&quot;&gt;Gemma 3 12B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-3-27b-it:free&quot;&gt;Gemma 3 27B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-3-4b-it:free&quot;&gt;Gemma 3 4B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/moonshotai/kimi-vl-a3b-thinking:free&quot;&gt;Kimi VL A3B Thinking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/meta-llama/llama-3.1-405b-instruct:free&quot;&gt;Llama 3.1 405B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/nvidia/llama-3.1-nemotron-ultra-253b-v1:free&quot;&gt;Llama 3.1 Nemotron Ultra 253B v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/meta-llama/llama-3.2-11b-vision-instruct:free&quot;&gt;Llama 3.2 11B Vision Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/meta-llama/llama-3.2-3b-instruct:free&quot;&gt;Llama 3.2 3B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/meta-llama/llama-3.3-70b-instruct:free&quot;&gt;Llama 3.3 70B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/mistral-7b-instruct:free&quot;&gt;Mistral 7B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/mistral-nemo:free&quot;&gt;Mistral Nemo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free&quot;&gt;Mistral Small 24B Instruct 2501&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct:free&quot;&gt;Mistral Small 3.1 24B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/arliai/qwq-32b-arliai-rpr-v1:free&quot;&gt;QwQ 32B ArliAI RpR v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen-2.5-72b-instruct:free&quot;&gt;Qwen 2.5 72B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen2.5-vl-32b-instruct:free&quot;&gt;Qwen 2.5 VL 32B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwq-32b:free&quot;&gt;Qwen QwQ 32B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen-2.5-coder-32b-instruct:free&quot;&gt;Qwen2.5 Coder 32B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen2.5-vl-72b-instruct:free&quot;&gt;Qwen2.5 VL 72B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/rekaai/reka-flash-3:free&quot;&gt;Reka Flash 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/shisa-ai/shisa-v2-llama3.3-70b:free&quot;&gt;Shisa V2 Llama 3.3 70B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/cognitivecomputations/dolphin-mistral-24b-venice-edition:free&quot;&gt;cognitivecomputations/dolphin-mistral-24b-venice-edition:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-r1-0528-qwen3-8b:free&quot;&gt;deepseek/deepseek-r1-0528-qwen3-8b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/deepseek/deepseek-r1-0528:free&quot;&gt;deepseek/deepseek-r1-0528:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-3n-e2b-it:free&quot;&gt;google/gemma-3n-e2b-it:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/google/gemma-3n-e4b-it:free&quot;&gt;google/gemma-3n-e4b-it:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/microsoft/mai-ds-r1:free&quot;&gt;microsoft/mai-ds-r1:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/devstral-small-2505:free&quot;&gt;mistralai/devstral-small-2505:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/mistralai/mistral-small-3.2-24b-instruct:free&quot;&gt;mistralai/mistral-small-3.2-24b-instruct:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/moonshotai/kimi-dev-72b:free&quot;&gt;moonshotai/kimi-dev-72b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/moonshotai/kimi-k2:free&quot;&gt;moonshotai/kimi-k2:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/openai/gpt-oss-20b:free&quot;&gt;openai/gpt-oss-20b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-14b:free&quot;&gt;qwen/qwen3-14b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-235b-a22b:free&quot;&gt;qwen/qwen3-235b-a22b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-30b-a3b:free&quot;&gt;qwen/qwen3-30b-a3b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-4b:free&quot;&gt;qwen/qwen3-4b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-8b:free&quot;&gt;qwen/qwen3-8b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/qwen/qwen3-coder:free&quot;&gt;qwen/qwen3-coder:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/sarvamai/sarvam-m:free&quot;&gt;sarvamai/sarvam-m:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/tencent/hunyuan-a13b-instruct:free&quot;&gt;tencent/hunyuan-a13b-instruct:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/thudm/glm-z1-32b:free&quot;&gt;thudm/glm-z1-32b:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/tngtech/deepseek-r1t-chimera:free&quot;&gt;tngtech/deepseek-r1t-chimera:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/tngtech/deepseek-r1t2-chimera:free&quot;&gt;tngtech/deepseek-r1t2-chimera:free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://openrouter.ai/z-ai/glm-4.5-air:free&quot;&gt;z-ai/glm-4.5-air:free&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://aistudio.google.com&quot;&gt;Google AI Studio&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Data is used for training when used outside of the UK/CH/EEA/EU.&lt;/p&gt; 
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th&gt;Model Name&lt;/th&gt;
   &lt;th&gt;Model Limits&lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 2.5 Pro&lt;/td&gt;
   &lt;td&gt;6,000,000 tokens/day&lt;br /&gt;250,000 tokens/minute&lt;br /&gt;100 requests/day&lt;br /&gt;5 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;
   &lt;td&gt;250,000 tokens/minute&lt;br /&gt;250 requests/day&lt;br /&gt;10 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 2.0 Flash&lt;/td&gt;
   &lt;td&gt;1,000,000 tokens/minute&lt;br /&gt;200 requests/day&lt;br /&gt;15 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 2.0 Flash-Lite&lt;/td&gt;
   &lt;td&gt;1,000,000 tokens/minute&lt;br /&gt;200 requests/day&lt;br /&gt;30 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 2.0 Flash (Experimental)&lt;/td&gt;
   &lt;td&gt;250,000 tokens/minute&lt;br /&gt;50 requests/day&lt;br /&gt;10 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 1.5 Flash&lt;/td&gt;
   &lt;td&gt;250,000 tokens/minute&lt;br /&gt;50 requests/day&lt;br /&gt;15 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemini 1.5 Flash-8B&lt;/td&gt;
   &lt;td&gt;250,000 tokens/minute&lt;br /&gt;50 requests/day&lt;br /&gt;15 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;LearnLM 2.0 Flash (Experimental)&lt;/td&gt;
   &lt;td&gt;1,500 requests/day&lt;br /&gt;15 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemma 3 27B Instruct&lt;/td&gt;
   &lt;td&gt;15,000 tokens/minute&lt;br /&gt;14,400 requests/day&lt;br /&gt;30 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemma 3 12B Instruct&lt;/td&gt;
   &lt;td&gt;15,000 tokens/minute&lt;br /&gt;14,400 requests/day&lt;br /&gt;30 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemma 3 4B Instruct&lt;/td&gt;
   &lt;td&gt;15,000 tokens/minute&lt;br /&gt;14,400 requests/day&lt;br /&gt;30 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemma 3 1B Instruct&lt;/td&gt;
   &lt;td&gt;15,000 tokens/minute&lt;br /&gt;14,400 requests/day&lt;br /&gt;30 requests/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;text-embedding-004&lt;/td&gt;
   &lt;td rowspan=&quot;2&quot;&gt;10,000 batch requests/minute&lt;br /&gt;10,000 requests/minute&lt;br /&gt;100 content/batch&lt;br /&gt;Shared Quota&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;embedding-001&lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;&lt;a href=&quot;https://build.nvidia.com/explore/discover&quot;&gt;NVIDIA NIM&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Phone number verification required. Models tend to be context window limited.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; 40 requests/minute&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://build.nvidia.com/models&quot;&gt;Various open models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://console.mistral.ai/&quot;&gt;Mistral (La Plateforme)&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Free tier (Experiment plan) requires opting into data training&lt;/li&gt; 
 &lt;li&gt;Requires phone number verification.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Limits (per-model):&lt;/strong&gt; 1 request/second, 500,000 tokens/minute, 1,000,000,000 tokens/month&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.mistral.ai/getting-started/models/models_overview/&quot;&gt;Open and Proprietary Mistral models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://codestral.mistral.ai/&quot;&gt;Mistral (Codestral)&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Currently free to use&lt;/li&gt; 
 &lt;li&gt;Monthly subscription based&lt;/li&gt; 
 &lt;li&gt;Requires phone number verification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; 30 requests/minute, 2,000 requests/day&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codestral&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://huggingface.co/docs/inference-providers/en/index&quot;&gt;HuggingFace Inference Providers&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;HuggingFace Serverless Inference limited to models smaller than 10GB. Some popular models are supported even if they exceed 10GB.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; &lt;a href=&quot;https://huggingface.co/docs/inference-providers/en/pricing&quot;&gt;$0.10/month in credits&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Various open models across supported providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://vercel.com/docs/ai-gateway&quot;&gt;Vercel AI Gateway&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Routes to various supported providers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; &lt;a href=&quot;https://vercel.com/docs/ai-gateway/pricing&quot;&gt;$5/month&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://cloud.cerebras.ai/&quot;&gt;Cerebras&lt;/a&gt;&lt;/h3&gt; 
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th&gt;Model Name&lt;/th&gt;
   &lt;th&gt;Model Limits&lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt; 
  &lt;tr&gt;
   &lt;td&gt;Qwen 3 235B A22B Instruct&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;60,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Qwen 3 235B A22B Thinking&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;60,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Qwen 3 Coder 480B&lt;/td&gt;
   &lt;td&gt;10 requests/minute&lt;br /&gt;150,000 tokens/minute&lt;br /&gt;100 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;100 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3.3 70B&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;64,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Qwen 3 32B&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;64,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3.1 8B&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;60,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 4 Scout&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;60,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 4 Maverick&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;60,000 tokens/minute&lt;br /&gt;900 requests/hour&lt;br /&gt;1,000,000 tokens/hour&lt;br /&gt;14,400 requests/day&lt;br /&gt;1,000,000 tokens/day&lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;&lt;a href=&quot;https://console.groq.com&quot;&gt;Groq&lt;/a&gt;&lt;/h3&gt; 
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th&gt;Model Name&lt;/th&gt;
   &lt;th&gt;Model Limits&lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt; 
  &lt;tr&gt;
   &lt;td&gt;Allam 2 7B&lt;/td&gt;
   &lt;td&gt;7,000 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;DeepSeek R1 Distill Llama 70B&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Distil Whisper Large v3&lt;/td&gt;
   &lt;td&gt;7,200 audio-seconds/minute&lt;br /&gt;2,000 requests/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Gemma 2 9B Instruct&lt;/td&gt;
   &lt;td&gt;14,400 requests/day&lt;br /&gt;15,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Groq compound-beta&lt;/td&gt;
   &lt;td&gt;200 requests/day&lt;br /&gt;70,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Groq compound-beta-mini&lt;/td&gt;
   &lt;td&gt;200 requests/day&lt;br /&gt;70,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3 70B&lt;/td&gt;
   &lt;td&gt;14,400 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3 8B&lt;/td&gt;
   &lt;td&gt;14,400 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3.1 8B&lt;/td&gt;
   &lt;td&gt;14,400 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 3.3 70B&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;12,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 4 Maverick 17B 128E Instruct&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Llama 4 Scout Instruct&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;30,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Whisper Large v3&lt;/td&gt;
   &lt;td&gt;7,200 audio-seconds/minute&lt;br /&gt;2,000 requests/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Whisper Large v3 Turbo&lt;/td&gt;
   &lt;td&gt;7,200 audio-seconds/minute&lt;br /&gt;2,000 requests/day&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;meta-llama/llama-guard-4-12b&lt;/td&gt;
   &lt;td&gt;14,400 requests/day&lt;br /&gt;15,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;meta-llama/llama-prompt-guard-2-22m&lt;/td&gt;
   &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;meta-llama/llama-prompt-guard-2-86m&lt;/td&gt;
   &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;moonshotai/kimi-k2-instruct&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;10,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;openai/gpt-oss-120b&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;8,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;8,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;qwen/qwen3-32b&lt;/td&gt;
   &lt;td&gt;1,000 requests/day&lt;br /&gt;6,000 tokens/minute&lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;&lt;a href=&quot;https://together.ai&quot;&gt;Together (Free)&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; Up to 60 requests/minute&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://together.ai/models/llama-3-2-11b-free&quot;&gt;Llama 3.2 11B Vision Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://together.ai/models/llama-3-3-70b-free&quot;&gt;Llama 3.3 70B Instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://together.ai/models/deepseek-r1-distilled-llama-70b-free&quot;&gt;DeepSeek R1 Distil Llama 70B&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://cohere.com&quot;&gt;Cohere&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.cohere.com/docs/rate-limits&quot;&gt;20 requests/minute&lt;br /&gt;1,000 requests/month&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Models share a common quota.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Command-A&lt;/li&gt; 
 &lt;li&gt;Command-R7B&lt;/li&gt; 
 &lt;li&gt;Command-R+&lt;/li&gt; 
 &lt;li&gt;Command-R&lt;/li&gt; 
 &lt;li&gt;Aya Expanse 8B&lt;/li&gt; 
 &lt;li&gt;Aya Expanse 32B&lt;/li&gt; 
 &lt;li&gt;Aya Vision 8B&lt;/li&gt; 
 &lt;li&gt;Aya Vision 32B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://github.com/marketplace/models&quot;&gt;GitHub Models&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Extremely restrictive input/output token limits.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; &lt;a href=&quot;https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits&quot;&gt;Dependent on Copilot subscription tier (Free/Pro/Pro+/Business/Enterprise)&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI21 Jamba 1.5 Large&lt;/li&gt; 
 &lt;li&gt;AI21 Jamba 1.5 Mini&lt;/li&gt; 
 &lt;li&gt;Codestral 25.01&lt;/li&gt; 
 &lt;li&gt;Cohere Command A&lt;/li&gt; 
 &lt;li&gt;Cohere Command R 08-2024&lt;/li&gt; 
 &lt;li&gt;Cohere Command R+ 08-2024&lt;/li&gt; 
 &lt;li&gt;Cohere Embed v3 English&lt;/li&gt; 
 &lt;li&gt;Cohere Embed v3 Multilingual&lt;/li&gt; 
 &lt;li&gt;DeepSeek-R1&lt;/li&gt; 
 &lt;li&gt;DeepSeek-R1-0528&lt;/li&gt; 
 &lt;li&gt;DeepSeek-V3-0324&lt;/li&gt; 
 &lt;li&gt;Grok 3&lt;/li&gt; 
 &lt;li&gt;Grok 3 Mini&lt;/li&gt; 
 &lt;li&gt;JAIS 30b Chat&lt;/li&gt; 
 &lt;li&gt;Llama 4 Maverick 17B 128E Instruct FP8&lt;/li&gt; 
 &lt;li&gt;Llama 4 Scout 17B 16E Instruct&lt;/li&gt; 
 &lt;li&gt;Llama-3.2-11B-Vision-Instruct&lt;/li&gt; 
 &lt;li&gt;Llama-3.2-90B-Vision-Instruct&lt;/li&gt; 
 &lt;li&gt;Llama-3.3-70B-Instruct&lt;/li&gt; 
 &lt;li&gt;MAI-DS-R1&lt;/li&gt; 
 &lt;li&gt;Meta-Llama-3.1-405B-Instruct&lt;/li&gt; 
 &lt;li&gt;Meta-Llama-3.1-8B-Instruct&lt;/li&gt; 
 &lt;li&gt;Ministral 3B&lt;/li&gt; 
 &lt;li&gt;Mistral Large 24.11&lt;/li&gt; 
 &lt;li&gt;Mistral Medium 3 (25.05)&lt;/li&gt; 
 &lt;li&gt;Mistral Nemo&lt;/li&gt; 
 &lt;li&gt;Mistral Small 3.1&lt;/li&gt; 
 &lt;li&gt;OpenAI GPT-4.1&lt;/li&gt; 
 &lt;li&gt;OpenAI GPT-4.1-mini&lt;/li&gt; 
 &lt;li&gt;OpenAI GPT-4.1-nano&lt;/li&gt; 
 &lt;li&gt;OpenAI GPT-4o&lt;/li&gt; 
 &lt;li&gt;OpenAI GPT-4o mini&lt;/li&gt; 
 &lt;li&gt;OpenAI Text Embedding 3 (large)&lt;/li&gt; 
 &lt;li&gt;OpenAI Text Embedding 3 (small)&lt;/li&gt; 
 &lt;li&gt;OpenAI gpt-5&lt;/li&gt; 
 &lt;li&gt;OpenAI gpt-5-chat (preview)&lt;/li&gt; 
 &lt;li&gt;OpenAI gpt-5-mini&lt;/li&gt; 
 &lt;li&gt;OpenAI gpt-5-nano&lt;/li&gt; 
 &lt;li&gt;OpenAI o1&lt;/li&gt; 
 &lt;li&gt;OpenAI o1-mini&lt;/li&gt; 
 &lt;li&gt;OpenAI o1-preview&lt;/li&gt; 
 &lt;li&gt;OpenAI o3&lt;/li&gt; 
 &lt;li&gt;OpenAI o3-mini&lt;/li&gt; 
 &lt;li&gt;OpenAI o4-mini&lt;/li&gt; 
 &lt;li&gt;Phi-3-medium instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-3-medium instruct (4k)&lt;/li&gt; 
 &lt;li&gt;Phi-3-mini instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-3-mini instruct (4k)&lt;/li&gt; 
 &lt;li&gt;Phi-3-small instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-3-small instruct (8k)&lt;/li&gt; 
 &lt;li&gt;Phi-3.5-MoE instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-3.5-mini instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-3.5-vision instruct (128k)&lt;/li&gt; 
 &lt;li&gt;Phi-4&lt;/li&gt; 
 &lt;li&gt;Phi-4-Reasoning&lt;/li&gt; 
 &lt;li&gt;Phi-4-mini-instruct&lt;/li&gt; 
 &lt;li&gt;Phi-4-mini-reasoning&lt;/li&gt; 
 &lt;li&gt;Phi-4-multimodal-instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://developers.cloudflare.com/workers-ai&quot;&gt;Cloudflare Workers AI&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Limits:&lt;/strong&gt; &lt;a href=&quot;https://developers.cloudflare.com/workers-ai/platform/pricing/#free-allocation&quot;&gt;10,000 neurons/day&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;@cf/openai/gpt-oss-120b&lt;/li&gt; 
 &lt;li&gt;@cf/openai/gpt-oss-20b&lt;/li&gt; 
 &lt;li&gt;DeepSeek R1 Distill Qwen 32B&lt;/li&gt; 
 &lt;li&gt;Deepseek Coder 6.7B Base (AWQ)&lt;/li&gt; 
 &lt;li&gt;Deepseek Coder 6.7B Instruct (AWQ)&lt;/li&gt; 
 &lt;li&gt;Deepseek Math 7B Instruct&lt;/li&gt; 
 &lt;li&gt;Discolm German 7B v1 (AWQ)&lt;/li&gt; 
 &lt;li&gt;Falcom 7B Instruct&lt;/li&gt; 
 &lt;li&gt;Gemma 2B Instruct (LoRA)&lt;/li&gt; 
 &lt;li&gt;Gemma 3 12B Instruct&lt;/li&gt; 
 &lt;li&gt;Gemma 7B Instruct&lt;/li&gt; 
 &lt;li&gt;Gemma 7B Instruct (LoRA)&lt;/li&gt; 
 &lt;li&gt;Hermes 2 Pro Mistral 7B&lt;/li&gt; 
 &lt;li&gt;Llama 2 13B Chat (AWQ)&lt;/li&gt; 
 &lt;li&gt;Llama 2 7B Chat (FP16)&lt;/li&gt; 
 &lt;li&gt;Llama 2 7B Chat (INT8)&lt;/li&gt; 
 &lt;li&gt;Llama 2 7B Chat (LoRA)&lt;/li&gt; 
 &lt;li&gt;Llama 3 8B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3 8B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3 8B Instruct (AWQ)&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 8B Instruct (AWQ)&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 8B Instruct (FP8)&lt;/li&gt; 
 &lt;li&gt;Llama 3.2 11B Vision Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.2 1B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.2 3B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.3 70B Instruct (FP8)&lt;/li&gt; 
 &lt;li&gt;Llama 4 Scout Instruct&lt;/li&gt; 
 &lt;li&gt;Llama Guard 3 8B&lt;/li&gt; 
 &lt;li&gt;LlamaGuard 7B (AWQ)&lt;/li&gt; 
 &lt;li&gt;Mistral 7B Instruct v0.1&lt;/li&gt; 
 &lt;li&gt;Mistral 7B Instruct v0.1 (AWQ)&lt;/li&gt; 
 &lt;li&gt;Mistral 7B Instruct v0.2&lt;/li&gt; 
 &lt;li&gt;Mistral 7B Instruct v0.2 (LoRA)&lt;/li&gt; 
 &lt;li&gt;Mistral Small 3.1 24B Instruct&lt;/li&gt; 
 &lt;li&gt;Neural Chat 7B v3.1 (AWQ)&lt;/li&gt; 
 &lt;li&gt;OpenChat 3.5 0106&lt;/li&gt; 
 &lt;li&gt;OpenHermes 2.5 Mistral 7B (AWQ)&lt;/li&gt; 
 &lt;li&gt;Phi-2&lt;/li&gt; 
 &lt;li&gt;Qwen 1.5 0.5B Chat&lt;/li&gt; 
 &lt;li&gt;Qwen 1.5 1.8B Chat&lt;/li&gt; 
 &lt;li&gt;Qwen 1.5 14B Chat (AWQ)&lt;/li&gt; 
 &lt;li&gt;Qwen 1.5 7B Chat (AWQ)&lt;/li&gt; 
 &lt;li&gt;Qwen 2.5 Coder 32B Instruct&lt;/li&gt; 
 &lt;li&gt;Qwen QwQ 32B&lt;/li&gt; 
 &lt;li&gt;SQLCoder 7B 2&lt;/li&gt; 
 &lt;li&gt;Starling LM 7B Beta&lt;/li&gt; 
 &lt;li&gt;TinyLlama 1.1B Chat v1.0&lt;/li&gt; 
 &lt;li&gt;Una Cybertron 7B v2 (BF16)&lt;/li&gt; 
 &lt;li&gt;Zephyr 7B Beta (AWQ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/model-garden&quot;&gt;Google Cloud Vertex AI&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Very stringent payment verification for Google Cloud.&lt;/p&gt; 
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th&gt;Model Name&lt;/th&gt;
   &lt;th&gt;Model Limits&lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt; 
  &lt;tr&gt;
   &lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-2-90b-vision-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.2 90B Vision Instruct&lt;/a&gt;&lt;/td&gt;
   &lt;td&gt;30 requests/minute&lt;br /&gt;Free during preview&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 70B Instruct&lt;/a&gt;&lt;/td&gt;
   &lt;td&gt;60 requests/minute&lt;br /&gt;Free during preview&lt;/td&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;&lt;a href=&quot;https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas&quot; target=&quot;_blank&quot;&gt;Llama 3.1 8B Instruct&lt;/a&gt;&lt;/td&gt;
   &lt;td&gt;60 requests/minute&lt;br /&gt;Free during preview&lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Providers with trial credits&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://together.ai&quot;&gt;Together&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1 when you add a payment method&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://together.ai/models&quot;&gt;Various open models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://fireworks.ai/&quot;&gt;Fireworks&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://fireworks.ai/models&quot;&gt;Various open models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://app.baseten.co/&quot;&gt;Baseten&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $30&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://www.baseten.co/library/&quot;&gt;Any supported model - pay by compute time&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://studio.nebius.com/&quot;&gt;Nebius&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://studio.nebius.ai/models&quot;&gt;Various open models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://novita.ai/?ref=ytblmjc&amp;amp;utm_source=affiliate&quot;&gt;Novita&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $0.5 for 1 year&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://novita.ai/models&quot;&gt;Various open models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://studio.ai21.com/&quot;&gt;AI21&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $10 for 3 months&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Jamba family of models&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://console.upstage.ai/&quot;&gt;Upstage&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $10 for 3 months&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Solar Pro/Mini&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://nlpcloud.com/home&quot;&gt;NLP Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $15&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Phone number verification&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Various open models&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://bailian.console.alibabacloud.com/&quot;&gt;Alibaba Cloud (International) Model Studio&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; 1 million tokens/model&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; &lt;a href=&quot;https://www.alibabacloud.com/en/product/modelstudio&quot;&gt;Various open and proprietary Qwen models&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://modal.com&quot;&gt;Modal&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $5/month upon sign up, $30/month with payment method added&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Any supported model - pay by compute time&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://inference.net&quot;&gt;Inference.net&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1, $25 on responding to email survey&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Various open models&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://ncompass.tech&quot;&gt;nCompass&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; Various open models&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://app.hyperbolic.xyz/&quot;&gt;Hyperbolic&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $1&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek V3&lt;/li&gt; 
 &lt;li&gt;DeepSeek V3 0324&lt;/li&gt; 
 &lt;li&gt;Hermes 3 Llama 3.1 70B&lt;/li&gt; 
 &lt;li&gt;Llama 3 70B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 405B Base&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 405B Base (FP8)&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 405B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 70B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 8B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.2 3B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.3 70B Instruct&lt;/li&gt; 
 &lt;li&gt;Pixtral 12B (2409)&lt;/li&gt; 
 &lt;li&gt;Qwen QwQ 32B&lt;/li&gt; 
 &lt;li&gt;Qwen QwQ 32B Preview&lt;/li&gt; 
 &lt;li&gt;Qwen2.5 72B Instruct&lt;/li&gt; 
 &lt;li&gt;Qwen2.5 Coder 32B Instruct&lt;/li&gt; 
 &lt;li&gt;Qwen2.5 VL 72B Instruct&lt;/li&gt; 
 &lt;li&gt;Qwen2.5 VL 7B Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://cloud.sambanova.ai/&quot;&gt;SambaNova Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; $5 for 3 months&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;E5-Mistral-7B-Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 8B&lt;/li&gt; 
 &lt;li&gt;Llama 3.3 70B&lt;/li&gt; 
 &lt;li&gt;Llama 3.3 70B&lt;/li&gt; 
 &lt;li&gt;Llama-4-Maverick-17B-128E-Instruct&lt;/li&gt; 
 &lt;li&gt;Qwen/Qwen3-32B&lt;/li&gt; 
 &lt;li&gt;Whisper-Large-v3&lt;/li&gt; 
 &lt;li&gt;deepseek-ai/DeepSeek-R1-0528&lt;/li&gt; 
 &lt;li&gt;deepseek-ai/DeepSeek-R1-Distill-Llama-70B&lt;/li&gt; 
 &lt;li&gt;deepseek-ai/DeepSeek-V3-0324&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href=&quot;https://console.scaleway.com/generative-api/models&quot;&gt;Scaleway Generative APIs&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt; 1,000,000 free tokens&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;BGE-Multilingual-Gemma2&lt;/li&gt; 
 &lt;li&gt;DeepSeek R1 Distill Llama 70B&lt;/li&gt; 
 &lt;li&gt;Gemma 3 27B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.1 8B Instruct&lt;/li&gt; 
 &lt;li&gt;Llama 3.3 70B Instruct&lt;/li&gt; 
 &lt;li&gt;Mistral Nemo 2407&lt;/li&gt; 
 &lt;li&gt;Mistral Small 3.1 24B Instruct 2503&lt;/li&gt; 
 &lt;li&gt;Pixtral 12B (2409)&lt;/li&gt; 
 &lt;li&gt;Qwen2.5 Coder 32B Instruct&lt;/li&gt; 
 &lt;li&gt;devstral-small-2505&lt;/li&gt; 
 &lt;li&gt;qwen3-235b-a22b-instruct-2507&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tadata-org/fastapi_mcp</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <description>&lt;p&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/tadata-org/fastapi_mcp&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/7e44e98b-a0ba-4aff-a68a-4ffee3a6189c&quot; alt=&quot;fastapi-to-mcp&quot; height=&quot;100/&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;span style=&quot;font-size: 0.85em; font-weight: normal;&quot;&gt;Built by &lt;a href=&quot;https://tadata.com&quot;&gt;Tadata&lt;/a&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;h1 align=&quot;center&quot;&gt; FastAPI-MCP &lt;/h1&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://trendshift.io/repositories/14064&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14064&quot; alt=&quot;tadata-org%2Ffastapi_mcp | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p align=&quot;center&quot;&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://pypi.org/project/fastapi-mcp/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/fastapi-mcp?color=%2334D058&amp;amp;label=pypi%20package&quot; alt=&quot;PyPI version&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/fastapi-mcp/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/fastapi-mcp.svg?sanitize=true&quot; alt=&quot;Python Versions&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/#&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/FastAPI-009485.svg?logo=fastapi&amp;amp;logoColor=white&quot; alt=&quot;FastAPI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/tadata-org/fastapi_mcp&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/tadata-org/fastapi_mcp/branch/main/graph/badge.svg?sanitize=true&quot; alt=&quot;Coverage&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/tadata-org/fastapi_mcp&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/b205adc6-28c0-4e3c-a68b-9c1a80eb7d0c&quot; alt=&quot;fastapi-mcp-usage&quot; height=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Authentication&lt;/strong&gt; built in, using your existing FastAPI dependencies!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI-native:&lt;/strong&gt; Not just another OpenAPI -&amp;gt; MCP converter&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zero/Minimal configuration&lt;/strong&gt; required - just point it at your FastAPI app and it works&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserving schemas&lt;/strong&gt; of your request models and response models&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserve documentation&lt;/strong&gt; of all your endpoints, just as it is in Swagger&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible deployment&lt;/strong&gt; - Mount your MCP server to the same app, or deploy separately&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt; - Uses FastAPI&#39;s ASGI interface directly for efficient communication&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hosted Solution&lt;/h2&gt; 
&lt;p&gt;If you prefer a managed hosted solution check out &lt;a href=&quot;https://tadata.com&quot;&gt;tadata.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;a href=&quot;https://docs.astral.sh/uv/&quot;&gt;uv&lt;/a&gt;, a fast Python package installer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Basic Usage&lt;/h2&gt; 
&lt;p&gt;The simplest way to use FastAPI-MCP is to add an MCP server directly to your FastAPI application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from fastapi import FastAPI
from fastapi_mcp import FastApiMCP

app = FastAPI()

mcp = FastApiMCP(app)

# Mount the MCP server directly to your FastAPI app
mcp.mount()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That&#39;s it! Your auto-generated MCP server is now available at &lt;code&gt;https://app.base.url/mcp&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation, Examples and Advanced Usage&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP provides &lt;a href=&quot;https://fastapi-mcp.tadata.com/&quot;&gt;comprehensive documentation&lt;/a&gt;. Additionaly, check out the &lt;a href=&quot;https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/examples&quot;&gt;examples directory&lt;/a&gt; for code samples demonstrating these features in action.&lt;/p&gt; 
&lt;h2&gt;FastAPI-first Approach&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP is designed as a native extension of FastAPI, not just a converter that generates MCP tools from your API. This approach offers several key advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native dependencies&lt;/strong&gt;: Secure your MCP endpoints using familiar FastAPI &lt;code&gt;Depends()&lt;/code&gt; for authentication and authorization&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt;: Communicates directly with your FastAPI app using its ASGI interface, eliminating the need for HTTP calls from the MCP to your API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified infrastructure&lt;/strong&gt;: Your FastAPI app doesn&#39;t need to run separately from the MCP server (though &lt;a href=&quot;https://fastapi-mcp.tadata.com/advanced/deploy#deploying-separately-from-original-fastapi-app&quot;&gt;separate deployment&lt;/a&gt; is also supported)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This design philosophy ensures minimum friction when adding MCP capabilities to your existing FastAPI services.&lt;/p&gt; 
&lt;h2&gt;Development and Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to FastAPI-MCP! We encourage the community to post Issues and create Pull Requests.&lt;/p&gt; 
&lt;p&gt;Before you get started, please see our &lt;a href=&quot;https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/CONTRIBUTING.md&quot;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href=&quot;https://join.slack.com/t/themcparty/shared_invite/zt-30yxr1zdi-2FG~XjBA0xIgYSYuKe7~Xg&quot;&gt;MCParty Slack community&lt;/a&gt; to connect with other MCP enthusiasts, ask questions, and share your experiences with FastAPI-MCP.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+ (Recommended 3.12)&lt;/li&gt; 
 &lt;li&gt;uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License. Copyright (c) 2025 Tadata Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>denizsafak/abogen</title>
      <link>https://github.com/denizsafak/abogen</link>
      <description>&lt;p&gt;Generate audiobooks from EPUBs, PDFs and text with synchronized captions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;abogen &lt;img width=&quot;40px&quot; title=&quot;abogen icon&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/abogen/assets/icon.ico&quot; align=&quot;right&quot; style=&quot;padding-left: 10px; padding-top:5px;&quot; /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/denizsafak/abogen/actions&quot;&gt;&lt;img src=&quot;https://github.com/denizsafak/abogen/actions/workflows/test_pip.yml/badge.svg?sanitize=true&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/denizsafak/abogen/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/denizsafak/abogen&quot; alt=&quot;GitHub Release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/abogen/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/abogen&quot; alt=&quot;Abogen PyPi Python Versions&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/denizsafak/abogen/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/os-windows%20%7C%20linux%20%7C%20macos%20-blue&quot; alt=&quot;Operating Systems&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/psf/black&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&quot; alt=&quot;Code style: black&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-maroon.svg?sanitize=true&quot; alt=&quot;License: MIT&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Abogen is a powerful text-to-speech conversion tool that makes it easy to turn ePub, PDF, or text files into high-quality audio with matching subtitles in seconds. Use it for audiobooks, voiceovers for Instagram, YouTube, TikTok, or any project that needs natural-sounding text-to-speech, using &lt;a href=&quot;https://huggingface.co/hexgrad/Kokoro-82M&quot;&gt;Kokoro-82M&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img title=&quot;Abogen Main&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.png&quot; width=&quot;380&quot; /&gt; &lt;img title=&quot;Abogen Processing&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen2.png&quot; width=&quot;380&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/cb66512d-0a52-48c3-bda4-f1e6a03fb8d6&quot;&gt;https://github.com/user-attachments/assets/cb66512d-0a52-48c3-bda4-f1e6a03fb8d6&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This demo was generated in just 5&amp;nbsp;seconds, producing ∼1&amp;nbsp;minute of audio with perfectly synced subtitles. To create a similar video, see &lt;a href=&quot;https://github.com/denizsafak/abogen/tree/main/demo&quot;&gt;the demo guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to install?&lt;/code&gt; &lt;a href=&quot;https://pypi.org/project/abogen/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/abogen&quot; alt=&quot;Abogen Compatible PyPi Python Versions&quot; align=&quot;right&quot; style=&quot;margin-top:6px;&quot; /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;Go to &lt;a href=&quot;https://github.com/espeak-ng/espeak-ng/releases/latest&quot;&gt;espeak-ng latest release&lt;/a&gt; download and run the *.msi file.&lt;/p&gt; 
&lt;h4&gt;OPTION 1: Install using script&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/denizsafak/abogen/archive/refs/heads/main.zip&quot;&gt;Download&lt;/a&gt; the repository&lt;/li&gt; 
 &lt;li&gt;Extract the ZIP file&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;WINDOWS_INSTALL.bat&lt;/code&gt; by double-clicking it&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This method handles everything automatically - installing all dependencies including CUDA in a self-contained environment without requiring a separate Python installation. (You still need to install &lt;a href=&quot;https://github.com/espeak-ng/espeak-ng/releases/latest&quot;&gt;espeak-ng&lt;/a&gt;.)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You don&#39;t need to install Python separately. The script will install Python automatically.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;OPTION 2: Install using pip&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Create a virtual environment (optional)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python -m venv venv
venv\Scripts\activate

# For NVIDIA GPUs:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# For AMD GPUs:
# Not supported yet, because ROCm is not available on Windows. Use Linux if you have AMD GPU.

# Install abogen
pip install abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Mac&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install espeak-ng
brew install espeak-ng

# Create a virtual environment (recommended)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install espeak-ng
sudo apt install espeak-ng # Ubuntu/Debian
sudo pacman -S espeak-ng # Arch Linux
sudo dnf install espeak-ng # Fedora

# Create a virtual environment (recommended)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen

# For NVIDIA GPUs:
# Already supported, no need to install CUDA separately.

# For AMD GPUs:
# After installing abogen, we need to uninstall the existing torch package
pip3 uninstall torch 
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you get &lt;code&gt;WARNING: The script abogen-cli is installed in &#39;/home/username/.local/bin&#39; which is not on PATH.&lt;/code&gt; error, run the following command to add it to your PATH:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;echo &quot;export PATH=\&quot;/home/$USER/.local/bin:\$PATH\&quot;&quot; &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you get &quot;No matching distribution found&quot; error, try installing it on supported Python (3.10 to 3.12). You can use &lt;a href=&quot;https://github.com/pyenv/pyenv&quot;&gt;pyenv&lt;/a&gt; to manage multiple Python versions easily in Linux. Watch this &lt;a href=&quot;https://www.youtube.com/watch?v=MVyb-nI4KyI&quot;&gt;video&lt;/a&gt; by NetworkChuck for a quick guide.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Special thanks to &lt;a href=&quot;https://github.com/hg000125&quot;&gt;@hg000125&lt;/a&gt; for his contribution in &lt;a href=&quot;https://github.com/denizsafak/abogen/issues/23&quot;&gt;#23&lt;/a&gt;. AMD GPU support is possible thanks to his work.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to run?&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you installed using pip, you can simply run the following command to start Abogen:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you installed using the Windows installer &lt;code&gt;(WINDOWS_INSTALL.bat)&lt;/code&gt;, It should have created a shortcut in the same folder, or your desktop. You can run it from there. If you lost the shortcut, Abogen is located in &lt;code&gt;python_embedded/Scripts/abogen.exe&lt;/code&gt;. You can run it from there directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to use?&lt;/code&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Drag and drop any ePub, PDF, or text file (or use the built-in text editor)&lt;/li&gt; 
 &lt;li&gt;Configure the settings: 
  &lt;ul&gt; 
   &lt;li&gt;Set speech speed&lt;/li&gt; 
   &lt;li&gt;Select a voice (or create a custom voice using voice mixer)&lt;/li&gt; 
   &lt;li&gt;Select subtitle generation style (by sentence, word, etc.)&lt;/li&gt; 
   &lt;li&gt;Select output format&lt;/li&gt; 
   &lt;li&gt;Select where to save the output&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Hit Start&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;code&gt;In action&lt;/code&gt;&lt;/h2&gt; 
&lt;img title=&quot;Abogen in action&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.gif&quot; /&gt; 
&lt;p&gt;Here’s Abogen in action: in this demo, it processes ∼3,000 characters of text in just 11 seconds and turns it into 3 minutes and 28 seconds of audio, and I have a low-end &lt;strong&gt;RTX&amp;nbsp;2060&amp;nbsp;Mobile laptop GPU&lt;/strong&gt;. Your results may vary depending on your hardware.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Configuration&lt;/code&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Input Box&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Drag and drop &lt;code&gt;ePub&lt;/code&gt;, &lt;code&gt;PDF&lt;/code&gt;, or &lt;code&gt;.TXT&lt;/code&gt; files (or use built-in text editor)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Queue options&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Add multiple files to a queue and process them in batch, with individual settings for each file. See &lt;a href=&quot;https://raw.githubusercontent.com/denizsafak/abogen/main/#queue-mode&quot;&gt;Queue mode&lt;/a&gt; for more details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Adjust speech rate from &lt;code&gt;0.1x&lt;/code&gt; to &lt;code&gt;2.0x&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Select Voice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;First letter of the language code (e.g., &lt;code&gt;a&lt;/code&gt; for American English, &lt;code&gt;b&lt;/code&gt; for British English, etc.), second letter is for &lt;code&gt;m&lt;/code&gt; for male and &lt;code&gt;f&lt;/code&gt; for female.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Voice mixer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Create custom voices by mixing different voice models with a profile system. See &lt;a href=&quot;https://raw.githubusercontent.com/denizsafak/abogen/main/#voice-mixer&quot;&gt;Voice Mixer&lt;/a&gt; for more details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Voice preview&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Listen to the selected voice before processing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Generate subtitles&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Disabled&lt;/code&gt;, &lt;code&gt;Sentence&lt;/code&gt;, &lt;code&gt;Sentence + Comma&lt;/code&gt;, &lt;code&gt;1 word&lt;/code&gt;, &lt;code&gt;2 words&lt;/code&gt;, &lt;code&gt;3 words&lt;/code&gt;, etc. (Represents the number of words in each subtitle entry)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output voice format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.WAV&lt;/code&gt;, &lt;code&gt;.FLAC&lt;/code&gt;, &lt;code&gt;.MP3&lt;/code&gt;, &lt;code&gt;.OPUS (best compression)&lt;/code&gt; and &lt;code&gt;M4B (with chapters)&lt;/code&gt; (Special thanks to &lt;a href=&quot;https://github.com/jborza&quot;&gt;@jborza&lt;/a&gt; for chapter support in PR &lt;a href=&quot;https://github.com/denizsafak/abogen/pull/10&quot;&gt;#10&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output subtitle format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the subtitle format as &lt;code&gt;SRT (standard)&lt;/code&gt;, &lt;code&gt;ASS (wide)&lt;/code&gt;, &lt;code&gt;ASS (narrow)&lt;/code&gt;, &lt;code&gt;ASS (centered wide)&lt;/code&gt;, or &lt;code&gt;ASS (centered narrow)&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Replace single newlines with spaces&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Replaces single newlines with spaces in the text. This is useful for texts that have imaginary line breaks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save location&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Save next to input file&lt;/code&gt;, &lt;code&gt;Save to desktop&lt;/code&gt;, or &lt;code&gt;Choose output folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Book handler options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Chapter Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Select specific &lt;code&gt;chapters&lt;/code&gt; from ePUBs or &lt;code&gt;chapters + pages&lt;/code&gt; from PDFs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save each chapter separately&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Save each chapter in e-books as a separate audio file.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Create a merged version&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Create a single audio file that combines all chapters. (If &lt;code&gt;Save each chapter separately&lt;/code&gt; is disabled, this option will be the default behavior.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save in a project folder with metadata&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Save the converted items in a project folder with available metadata files.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Menu options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Theme&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Change the application&#39;s theme using &lt;code&gt;System&lt;/code&gt;, &lt;code&gt;Light&lt;/code&gt;, or &lt;code&gt;Dark&lt;/code&gt; options.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Configure max words per subtitle&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the maximum number of words per subtitle entry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Configure max lines in log window&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the maximum number of lines to display in the log window.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Separate chapters audio format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the audio format for separate chapters as &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;flac&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, or &lt;code&gt;opus&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Create desktop shortcut&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Creates a shortcut on your desktop for easy access.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open config directory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Opens the directory where the configuration file is stored.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open cache directory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Opens the cache directory where converted text files are stored.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Clear cache files&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Deletes cache files created during the conversion or preview.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Check for updates at startup&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automatically checks for updates when the program starts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Disable Kokoro&#39;s internet access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Prevents Kokoro from downloading models or voices from HuggingFace Hub, useful for offline use.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Reset to default settings&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Resets all settings to their default values.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;code&gt;Voice Mixer&lt;/code&gt;&lt;/h2&gt; 
&lt;img title=&quot;Abogen Voice Mixer&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/voice_mixer.png&quot; /&gt; 
&lt;p&gt;With voice mixer, you can create custom voices by mixing different voice models. You can adjust the weight of each voice and save your custom voice as a profile for future use. The voice mixer allows you to create unique and personalized voices. (Huge thanks to &lt;a href=&quot;https://github.com/jborza&quot;&gt;@jborza&lt;/a&gt; for making this possible through his contributions in &lt;a href=&quot;https://github.com/denizsafak/abogen/pull/5&quot;&gt;#5&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Queue Mode&lt;/code&gt;&lt;/h2&gt; 
&lt;img title=&quot;Abogen queue mode&quot; src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/queue.png&quot; /&gt; 
&lt;p&gt;Abogen supports &lt;strong&gt;queue mode&lt;/strong&gt;, allowing you to add multiple files to a processing queue. This is useful if you want to convert several files in one batch.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can add text files (&lt;code&gt;.txt&lt;/code&gt;) directly using the &lt;strong&gt;Add files&lt;/strong&gt; button in the Queue Manager. To add PDF or EPUB files, use the input box in the main window and click the &lt;strong&gt;Add to Queue&lt;/strong&gt; button.&lt;/li&gt; 
 &lt;li&gt;Each file in the queue keeps the configuration settings that were active when it was added. Changing the main window configuration afterward does &lt;strong&gt;not&lt;/strong&gt; affect files already in the queue.&lt;/li&gt; 
 &lt;li&gt;You can view each file&#39;s configuration by hovering over them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Abogen will process each item in the queue automatically, saving outputs as configured.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Special thanks to &lt;a href=&quot;https://github.com/jborza&quot;&gt;@jborza&lt;/a&gt; for adding queue mode in PR &lt;a href=&quot;https://github.com/denizsafak/abogen/pull/35&quot;&gt;#35&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;About Chapter Markers&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;When you process ePUB or PDF files, Abogen converts them into text files stored in your cache directory. When you click &quot;Edit,&quot; you&#39;re actually modifying these converted text files. In these text files, you&#39;ll notice tags that look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;CHAPTER_MARKER:Chapter Title&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These are chapter markers. They are automatically added when you process ePUB or PDF files, based on the chapters you select. They serve an important purpose:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Allow you to split the text into separate audio files for each chapter&lt;/li&gt; 
 &lt;li&gt;Save time by letting you reprocess only specific chapters if errors occur, rather than the entire file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can manually add these markers to plain text files for the same benefits. Simply include them in your text like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;CHAPTER_MARKER:Introduction&amp;gt;&amp;gt;
This is the beginning of my text...  

&amp;lt;&amp;lt;CHAPTER_MARKER:Main Content&amp;gt;&amp;gt; 
Here&#39;s another part...  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you process the text file, Abogen will detect these markers automatically and ask if you want to save each chapter separately and create a merged version.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/chapter_marker.png&quot; alt=&quot;Abogen Chapter Marker&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;About Metadata Tags&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Similar to chapter markers, it is possible to add metadata tags for &lt;code&gt;M4B&lt;/code&gt; files. This is useful for audiobook players that support metadata, allowing you to add information like title, author, year, etc. Abogen automatically adds these tags when you process ePUB or PDF files, but you can also add them manually to your text files. Add metadata tags &lt;strong&gt;at the beginning of your text file&lt;/strong&gt; like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;METADATA_TITLE:Title&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ARTIST:Author&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ALBUM:Album Title&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_YEAR:Year&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ALBUM_ARTIST:Album Artist&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_COMPOSER:Narrator&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_GENRE:Audiobook&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;code&gt;Supported Languages&lt;/code&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# 🇺🇸 &#39;a&#39; =&amp;gt; American English, 🇬🇧 &#39;b&#39; =&amp;gt; British English
# 🇪🇸 &#39;e&#39; =&amp;gt; Spanish es
# 🇫🇷 &#39;f&#39; =&amp;gt; French fr-fr
# 🇮🇳 &#39;h&#39; =&amp;gt; Hindi hi
# 🇮🇹 &#39;i&#39; =&amp;gt; Italian it
# 🇯🇵 &#39;j&#39; =&amp;gt; Japanese: pip install misaki[ja]
# 🇧🇷 &#39;p&#39; =&amp;gt; Brazilian Portuguese pt-br
# 🇨🇳 &#39;z&#39; =&amp;gt; Mandarin Chinese: pip install misaki[zh]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a complete list of supported languages and voices, refer to Kokoro&#39;s &lt;a href=&quot;https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md&quot;&gt;VOICES.md&lt;/a&gt;. To listen to sample audio outputs, see &lt;a href=&quot;https://huggingface.co/hexgrad/Kokoro-82M/blob/main/SAMPLES.md&quot;&gt;SAMPLES.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;MPV Config&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;I highly recommend using &lt;a href=&quot;https://mpv.io/installation/&quot;&gt;MPV&lt;/a&gt; to play your audio files, as it supports displaying subtitles even without a video track. Here&#39;s my &lt;code&gt;mpv.conf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# --- MPV Settings ---
save-position-on-quit
keep-open=yes
# --- Subtitle ---
sub-ass-override=no
sub-margin-y=50
sub-margin-x=50
# --- Audio Quality ---
audio-spdif=ac3,dts,eac3,truehd,dts-hd
audio-channels=auto
audio-samplerate=48000
volume-max=200
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;code&gt;Docker Guide&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you want to run Abogen in a Docker container:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/denizsafak/abogen/archive/refs/heads/main.zip&quot;&gt;Download the repository&lt;/a&gt; and extract, or clone it using git.&lt;/li&gt; 
 &lt;li&gt;Go to &lt;code&gt;abogen&lt;/code&gt; folder. You should see &lt;code&gt;Dockerfile&lt;/code&gt; there.&lt;/li&gt; 
 &lt;li&gt;Open your termminal in that directory and run the following commands:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Build the Docker image:
docker build --progress plain -t abogen .

# Note that building the image may take a while.
# After building is complete, run the Docker container:

# Windows
docker run --name abogen -v %cd%:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# Linux
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# MacOS
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 abogen

# We expose port 5800 for use by a web browser, 5900 if you want to connect with a VNC client.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Abogen launches automatically inside the container.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can access it via a web browser at &lt;a href=&quot;http://localhost:5800&quot;&gt;http://localhost:5800&lt;/a&gt; or connect to it using a VNC client at &lt;code&gt;localhost:5900&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;/shared&lt;/code&gt; directory to share files between your host and the container.&lt;/li&gt; 
 &lt;li&gt;For later use, start it with &lt;code&gt;docker start abogen&lt;/code&gt; and stop it with &lt;code&gt;docker stop abogen&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Audio preview is not working inside container (ALSA error).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Open cache directory&lt;/code&gt; and &lt;code&gt;Open configuration directory&lt;/code&gt; options in settings not working. (Tried pcmanfm, did not work with Abogen).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(Special thanks to &lt;a href=&quot;https://www.reddit.com/user/geo38/&quot;&gt;@geo38&lt;/a&gt; from Reddit, who provided the Dockerfile and instructions in &lt;a href=&quot;https://www.reddit.com/r/selfhosted/comments/1k8x1yo/comment/mpe0bz8/&quot;&gt;this comment&lt;/a&gt;.)&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Similar Projects&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Abogen is a standalone project, but it is inspired by and shares some similarities with other projects. Here are a few:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/santinic/audiblez&quot;&gt;audiblez&lt;/a&gt;: Generate audiobooks from e-books. &lt;strong&gt;(Has CLI and GUI support)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/plusuncold/autiobooks&quot;&gt;autiobooks&lt;/a&gt;: Automatically convert epubs to audiobooks&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mateogon/pdf-narrator&quot;&gt;pdf-narrator&lt;/a&gt;: Convert your PDFs and EPUBs into audiobooks effortlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/p0n1/epub_to_audiobook&quot;&gt;epub_to_audiobook&lt;/a&gt;: EPUB to audiobook converter, optimized for Audiobookshelf&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/DrewThomasson/ebook2audiobook&quot;&gt;ebook2audiobook&lt;/a&gt;: Convert ebooks to audiobooks with chapters and metadata using dynamic AI models and voice cloning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;Roadmap&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; Add OCR scan feature for PDF files using docling/teserract.&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Add chapter metadata for .m4a files. (Issue &lt;a href=&quot;https://github.com/denizsafak/abogen/issues/9&quot;&gt;#9&lt;/a&gt;, PR &lt;a href=&quot;https://github.com/denizsafak/abogen/pull/10&quot;&gt;#10&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; Add support for different languages in GUI.&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Add voice formula feature that enables mixing different voice models. (Issue &lt;a href=&quot;https://github.com/denizsafak/abogen/issues/1&quot;&gt;#1&lt;/a&gt;, PR &lt;a href=&quot;https://github.com/denizsafak/abogen/pull/5&quot;&gt;#5&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; Add support for kokoro-onnx (If it&#39;s necessary).&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Add dark mode.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;Troubleshooting&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you encounter any issues while running Abogen, try launching it from the command line with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;abogen-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start Abogen in command-line mode and display detailed error messages. Please open a new issue on the &lt;a href=&quot;https://github.com/denizsafak/abogen/issues&quot;&gt;Issues&lt;/a&gt; page with the error message and a description of your problem.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Contributing&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;I welcome contributions! If you have ideas for new features, improvements, or bug fixes, please fork the repository and submit a pull request.&lt;/p&gt; 
&lt;h3&gt;For developers and contributors&lt;/h3&gt; 
&lt;p&gt;If you&#39;d like to modify the code and contribute to development, you can &lt;a href=&quot;https://github.com/denizsafak/abogen/archive/refs/heads/main.zip&quot;&gt;download the repository&lt;/a&gt;, extract it and run the following commands to build &lt;strong&gt;or&lt;/strong&gt; install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Go to the directory where you extracted the repository and run:
pip install -e .      # Installs the package in editable mode
pip install build     # Install the build package
python -m build       # Builds the package in dist folder (optional)
abogen                # Opens the GUI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Feel free to explore the code and make any changes you like.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Credits&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Abogen uses &lt;a href=&quot;https://github.com/hexgrad/kokoro&quot;&gt;Kokoro&lt;/a&gt; for its high-quality, natural-sounding text-to-speech synthesis. Huge thanks to the Kokoro team for making this possible.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href=&quot;https://github.com/wojiushixiaobai&quot;&gt;@wojiushixiaobai&lt;/a&gt; for &lt;a href=&quot;https://github.com/wojiushixiaobai/Python-Embed-Win64&quot;&gt;Embedded Python&lt;/a&gt; packages. These modified packages include pip pre-installed, enabling Abogen to function as a standalone application without requiring users to separately install Python in Windows.&lt;/li&gt; 
 &lt;li&gt;Thanks to creators of &lt;a href=&quot;https://github.com/aerkalov/ebooklib&quot;&gt;EbookLib&lt;/a&gt;, a Python library for reading and writing ePub files, which is used for extracting text from ePub files.&lt;/li&gt; 
 &lt;li&gt;Special thanks to the &lt;a href=&quot;https://www.riverbankcomputing.com/software/pyqt/&quot;&gt;PyQt&lt;/a&gt; team for providing the cross-platform GUI toolkit that powers Abogen&#39;s interface.&lt;/li&gt; 
 &lt;li&gt;Icons: &lt;a href=&quot;https://icons8.com/icon/aRiu1GGi6Aoe/usa&quot;&gt;US&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/t3NE3BsOAQwq/great-britain&quot;&gt;Great Britain&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/ly7tzANRt33n/spain&quot;&gt;Spain&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/3muzEmi4dpD5/france&quot;&gt;France&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/esGVrxg9VCJ1/india&quot;&gt;India&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/PW8KZnP7qXzO/italy&quot;&gt;Italy&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/McQbrq9qaQye/japan&quot;&gt;Japan&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/zHmH8HpOmM90/brazil&quot;&gt;Brazil&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/Ej50Oe3crXwF/china&quot;&gt;China&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/uI49hxbpxTkp/female&quot;&gt;Female&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/12351/male&quot;&gt;Male&lt;/a&gt;, &lt;a href=&quot;https://icons8.com/icon/21698/adjust&quot;&gt;Adjust&lt;/a&gt; and &lt;a href=&quot;https://icons8.com/icon/GskSeVoroQ7u/voice-id&quot;&gt;Voice Id&lt;/a&gt; icons by &lt;a href=&quot;https://icons8.com/&quot;&gt;Icons8&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;License&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;This project is available under the MIT License - see the &lt;a href=&quot;https://github.com/denizsafak/abogen/raw/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for details. &lt;a href=&quot;https://github.com/hexgrad/kokoro&quot;&gt;Kokoro&lt;/a&gt; is licensed under &lt;a href=&quot;https://github.com/hexgrad/kokoro/raw/main/LICENSE&quot;&gt;Apache-2.0&lt;/a&gt; which allows commercial use, modification, distribution, and private use.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Subtitle generation currently works only for English. This is because Kokoro provides timestamp tokens only for English text. If you want subtitles in other languages, please request this feature in the &lt;a href=&quot;https://github.com/hexgrad/kokoro&quot;&gt;Kokoro project&lt;/a&gt;. For more technical details, see &lt;a href=&quot;https://github.com/hexgrad/kokoro/raw/6d87f4ae7abc2d14dbc4b3ef2e5f19852e861ac2/kokoro/pipeline.py#L383&quot;&gt;this line&lt;/a&gt; in the Kokoro&#39;s code.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tags: audiobook, kokoro, text-to-speech, TTS, audiobook generator, audiobooks, text to speech, audiobook maker, audiobook creator, audiobook generator, voice-synthesis, text to audio, text to audio converter, text to speech converter, text to speech generator, text to speech software, text to speech app, epub to audio, pdf to audio, content-creation, media-generation&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>TCM-Course-Resources/Practical-Ethical-Hacking-Resources</title>
      <link>https://github.com/TCM-Course-Resources/Practical-Ethical-Hacking-Resources</link>
      <description>&lt;p&gt;Compilation of Resources from TCM&#39;s Practical Ethical Hacking Udemy Course&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Practical-Ethical-Hacking-Resources&lt;/h1&gt; 
&lt;p&gt;Compilation of Resources from TCM&#39;s Udemy Course&lt;/p&gt; 
&lt;h3&gt;General Links&lt;/h3&gt; 
&lt;p&gt;Link to Website: &lt;a href=&quot;https://www.thecybermentor.com/&quot;&gt;https://www.thecybermentor.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Link to the course:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://academy.tcm-sec.com/p/practical-ethical-hacking-the-complete-course&quot;&gt;https://academy.tcm-sec.com/p/practical-ethical-hacking-the-complete-course&lt;/a&gt; (tcm academy)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Link to discord server: &lt;a href=&quot;https://discord.gg/EM6tqPZ&quot;&gt;https://discord.gg/EM6tqPZ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FAQ: &lt;a href=&quot;https://github.com/hmaverickadams/Practical-Ethical-Hacking-FAQ&quot;&gt;https://github.com/hmaverickadams/Practical-Ethical-Hacking-FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Note Keeping&lt;/h3&gt; 
&lt;p&gt;Trilium: &lt;a href=&quot;https://github.com/zadam/trilium&quot;&gt;https://github.com/zadam/trilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;KeepNote: &lt;a href=&quot;http://keepnote.org/&quot;&gt;http://keepnote.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CherryTree: &lt;a href=&quot;https://www.giuspen.com/cherrytree/&quot;&gt;https://www.giuspen.com/cherrytree/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;GreenShot: &lt;a href=&quot;https://getgreenshot.org/downloads/&quot;&gt;https://getgreenshot.org/downloads/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FlameShot: &lt;a href=&quot;https://github.com/lupoDharkael/flameshot&quot;&gt;https://github.com/lupoDharkael/flameshot&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OneNote: &lt;a href=&quot;https://products.office.com/en-us/onenote/digital-note-taking-app?rtc=1&quot;&gt;https://products.office.com/en-us/onenote/digital-note-taking-app?rtc=1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Joplin: &lt;a href=&quot;https://github.com/laurent22/joplin&quot;&gt;https://github.com/laurent22/joplin&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Networking Refresher&lt;/h3&gt; 
&lt;p&gt;Seven Second Subnetting: &lt;a href=&quot;https://www.youtube.com/watch?v=ZxAwQB8TZsM&quot;&gt;https://www.youtube.com/watch?v=ZxAwQB8TZsM&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Subnet Guide: &lt;a href=&quot;https://drive.google.com/file/d/1ETKH31-E7G-7ntEOlWGZcDZWuukmeHFe/view&quot;&gt;https://drive.google.com/file/d/1ETKH31-E7G-7ntEOlWGZcDZWuukmeHFe/view&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Setting up our Lab&lt;/h3&gt; 
&lt;p&gt;VMware: &lt;a href=&quot;https://www.vmware.com/products/workstation-player/workstation-player-evaluation.html&quot;&gt;https://www.vmware.com/products/workstation-player/workstation-player-evaluation.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VirtualBox: &lt;a href=&quot;https://www.virtualbox.org/wiki/Downloads&quot;&gt;https://www.virtualbox.org/wiki/Downloads&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Kali Download: &lt;a href=&quot;https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/&quot;&gt;https://www.offensive-security.com/kali-linux-vm-vmware-virtualbox-image-download/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Official Offensive Security kali 2019.3 release: &lt;a href=&quot;http://old.kali.org/kali-images/kali-2019.3/&quot;&gt;http://old.kali.org/kali-images/kali-2019.3/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Other Offical kali 2019 Releases: &lt;a href=&quot;https://cdimage.kali.org/&quot;&gt;https://cdimage.kali.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Mid-Course Capstone&lt;/h3&gt; 
&lt;p&gt;New Capstone boxes: &lt;a href=&quot;https://drive.google.com/drive/folders/1VXEuyySgzsSo-MYmyCareTnJ5rAeVKeH&quot;&gt;https://drive.google.com/drive/folders/1VXEuyySgzsSo-MYmyCareTnJ5rAeVKeH&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Old Capstone boxes: &lt;a href=&quot;https://youtu.be/JZN3JhoAdWo&quot;&gt;https://youtu.be/JZN3JhoAdWo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Linux Priv Esc course: &lt;a href=&quot;https://academy.tcm-sec.com/p/windows-privilege-escalation-for-beginners&quot;&gt;https://academy.tcm-sec.com/p/windows-privilege-escalation-for-beginners&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Windows Priv Esc Course: &lt;a href=&quot;https://academy.tcm-sec.com/p/linux-privilege-escalation&quot;&gt;https://academy.tcm-sec.com/p/linux-privilege-escalation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Introduction to Exploit Development (Buffer Overflows)&lt;/h3&gt; 
&lt;p&gt;Immunity Debugger: &lt;a href=&quot;https://www.immunityinc.com/products/debugger/&quot;&gt;https://www.immunityinc.com/products/debugger/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vulnserver: &lt;a href=&quot;http://www.thegreycorner.com/p/vulnserver.html&quot;&gt;http://www.thegreycorner.com/p/vulnserver.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Bad Chars: &lt;a href=&quot;https://www.ins1gn1a.com/identifying-bad-characters/&quot;&gt;https://www.ins1gn1a.com/identifying-bad-characters/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Attacking Active Directory: Initial Attack Vectors&lt;/h3&gt; 
&lt;p&gt;Top Five Ways I Got DA on Your Internal Network Before Lunch: &lt;a href=&quot;https://adam-toscher.medium.com/top-five-ways-i-got-domain-admin-on-your-internal-network-before-lunch-2018-edition-82259ab73aaa&quot;&gt;https://adam-toscher.medium.com/top-five-ways-i-got-domain-admin-on-your-internal-network-before-lunch-2018-edition-82259ab73aaa&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;mitm6: &lt;a href=&quot;https://blog.fox-it.com/2018/01/11/mitm6-compromising-ipv4-networks-via-ipv6/&quot;&gt;https://blog.fox-it.com/2018/01/11/mitm6-compromising-ipv4-networks-via-ipv6/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Combining NTLM Relays and Kerberos Delegation: &lt;a href=&quot;https://dirkjanm.io/worst-of-both-worlds-ntlm-relaying-and-kerberos-delegation/&quot;&gt;https://dirkjanm.io/worst-of-both-worlds-ntlm-relaying-and-kerberos-delegation/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Attacking Active Directory: Post-Compromise Enumeration&lt;/h3&gt; 
&lt;p&gt;PowerView Cheat Sheet: &lt;a href=&quot;https://gist.github.com/HarmJ0y/184f9822b195c52dd50c379ed3117993&quot;&gt;https://gist.github.com/HarmJ0y/184f9822b195c52dd50c379ed3117993&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Attacking Active Directory: Post-Compromise Attacks&lt;/h3&gt; 
&lt;p&gt;Group Policy Pwnage: &lt;a href=&quot;https://blog.rapid7.com/2016/07/27/pentesting-in-the-real-world-group-policy-pwnage/&quot;&gt;https://blog.rapid7.com/2016/07/27/pentesting-in-the-real-world-group-policy-pwnage/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Mimikatz: &lt;a href=&quot;https://github.com/gentilkiwi/mimikatz&quot;&gt;https://github.com/gentilkiwi/mimikatz&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Active Directory Security Blog: &lt;a href=&quot;https://adsecurity.org/&quot;&gt;https://adsecurity.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Harmj0y Blog: &lt;a href=&quot;http://blog.harmj0y.net/&quot;&gt;http://blog.harmj0y.net/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Pentester Academy Active Directory: &lt;a href=&quot;https://www.pentesteracademy.com/activedirectorylab&quot;&gt;https://www.pentesteracademy.com/activedirectorylab&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Pentester Academy Red Team Labs: &lt;a href=&quot;https://www.pentesteracademy.com/redteamlab&quot;&gt;https://www.pentesteracademy.com/redteamlab&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;eLS PTX: &lt;a href=&quot;https://www.elearnsecurity.com/course/penetration_testing_extreme/&quot;&gt;https://www.elearnsecurity.com/course/penetration_testing_extreme/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Web Application Enumeration, Revisited&lt;/h3&gt; 
&lt;p&gt;sumrecon: &lt;a href=&quot;https://github.com/thatonetester/sumrecon&quot;&gt;https://github.com/thatonetester/sumrecon&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Testing the Top 10 Web Application Vulnerabilities&lt;/h3&gt; 
&lt;p&gt;OWASP Top 10: &lt;a href=&quot;https://owasp.org/www-pdf-archive/OWASP_Top_10-2017_%28en%29.pdf.pdf&quot;&gt;https://owasp.org/www-pdf-archive/OWASP_Top_10-2017_%28en%29.pdf.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP Testing Checklist: &lt;a href=&quot;https://github.com/tanprathan/OWASP-Testing-Checklist&quot;&gt;https://github.com/tanprathan/OWASP-Testing-Checklist&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP Testing Guide: &lt;a href=&quot;https://owasp.org/www-pdf-archive/OTGv4.pdf&quot;&gt;https://owasp.org/www-pdf-archive/OTGv4.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Installing Docker on Kali: &lt;a href=&quot;https://medium.com/@airman604/installing-docker-in-kali-linux-2017-1-fbaa4d1447fe&quot;&gt;https://medium.com/@airman604/installing-docker-in-kali-linux-2017-1-fbaa4d1447fe&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP Juice Shop: &lt;a href=&quot;https://github.com/bkimminich/juice-shop&quot;&gt;https://github.com/bkimminich/juice-shop&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A1-Injection: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A1-Injection&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A1-Injection&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A2-Broken Authentication: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A2-Broken_Authentication&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A2-Broken_Authentication&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A3-Sensetive Data Exposure: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A3-Sensitive_Data_Exposure&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A3-Sensitive_Data_Exposure&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A4-XML External Entities: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A4-XML_External_Entities_(XXE)&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A4-XML_External_Entities_(XXE)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A5-Broken Access Control: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A5-Broken_Access_Control&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A5-Broken_Access_Control&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A6-Security Misconfigurations: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A6-Security_Misconfiguration&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A6-Security_Misconfiguration&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A7-Cross Site Scripting: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A7-Cross-Site_Scripting_(XSS)&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A7-Cross-Site_Scripting_(XSS)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DOM Based XSS: &lt;a href=&quot;https://www.scip.ch/en/?labs.20171214&quot;&gt;https://www.scip.ch/en/?labs.20171214&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;XSS Game: &lt;a href=&quot;https://xss-game.appspot.com/&quot;&gt;https://xss-game.appspot.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A8-Insecure Deserialization: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A8-Insecure_Deserialization&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A8-Insecure_Deserialization&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A9-Using Components with Known Vulnerabilities: &lt;a href=&quot;https://www.owasp.org/index.php/Top_10-2017_A9-Using_Components_with_Known_Vulnerabilities&quot;&gt;https://www.owasp.org/index.php/Top_10-2017_A9-Using_Components_with_Known_Vulnerabilities&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OWASP A10-Insufficient Logging &amp;amp; Monitoring: &lt;a href=&quot;https://owasp.org/www-project-top-ten/OWASP_Top_Ten_2017/Top_10-2017_A10-Insufficient_Logging%252526Monitoring.html&quot;&gt;https://owasp.org/www-project-top-ten/OWASP_Top_Ten_2017/Top_10-2017_A10-Insufficient_Logging%252526Monitoring.html&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Legal Documents and Report Writing&lt;/h3&gt; 
&lt;p&gt;Sample Pentest Report: &lt;a href=&quot;https://github.com/hmaverickadams/TCM-Security-Sample-Pentest-Report&quot;&gt;https://github.com/hmaverickadams/TCM-Security-Sample-Pentest-Report&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;h4&gt;Pimpmykali&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/Dewalt-arch/pimpmykali&quot;&gt;https://github.com/Dewalt-arch/pimpmykali&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Hunter.io&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Site: &lt;a href=&quot;https://hunter.io/&quot;&gt;https://hunter.io/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;theHarvester&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/laramies/theHarvester&quot;&gt;https://github.com/laramies/theHarvester&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;breach-parse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/hmaverickadams/breach-parse&quot;&gt;https://github.com/hmaverickadams/breach-parse&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Hashcat:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/hashcat/hashcat&quot;&gt;https://github.com/hashcat/hashcat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Installing on Windows: &lt;a href=&quot;https://www.erobber.in/2017/04/hashcat-for-windows.html&quot;&gt;https://www.erobber.in/2017/04/hashcat-for-windows.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;mitm6:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/fox-it/mitm6&quot;&gt;https://github.com/fox-it/mitm6&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;mimikatz:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/gentilkiwi/mimikatz&quot;&gt;https://github.com/gentilkiwi/mimikatz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sumrecon&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://github.com/thatonetester/sumrecon&quot;&gt;https://github.com/thatonetester/sumrecon&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setting up Your AD Lab Using Azure&lt;/h3&gt; 
&lt;p&gt;Building Free AD lab: &lt;a href=&quot;https://medium.com/@kamran.bilgrami/ethical-hacking-lessons-building-free-active-directory-lab-in-azure-6c67a7eddd7f&quot;&gt;https://medium.com/@kamran.bilgrami/ethical-hacking-lessons-building-free-active-directory-lab-in-azure-6c67a7eddd7f&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lipku/LiveTalking</title>
      <link>https://github.com/lipku/LiveTalking</link>
      <description>&lt;p&gt;Real time interactive streaming digital human&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lipku/LiveTalking/main/README-EN.md&quot;&gt;English&lt;/a&gt; | 中文版&lt;br /&gt; 实时交互流式数字人，实现音视频同步对话。基本可以达到商用效果 &lt;a href=&quot;https://www.bilibili.com/video/BV1scwBeyELA/&quot;&gt;wav2lip效果&lt;/a&gt; | &lt;a href=&quot;https://www.bilibili.com/video/BV1G1421z73r/&quot;&gt;ernerf效果&lt;/a&gt; | &lt;a href=&quot;https://www.bilibili.com/video/BV1gm421N7vQ/&quot;&gt;musetalk效果&lt;/a&gt;&lt;br /&gt; 国内镜像地址:&lt;a href=&quot;https://gitee.com/lipku/LiveTalking&quot;&gt;https://gitee.com/lipku/LiveTalking&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;为避免与3d数字人混淆，原项目metahuman-stream改名为livetalking，原有链接地址继续可用&lt;/h2&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2024.12.8 完善多并发，显存不随并发数增加&lt;/li&gt; 
 &lt;li&gt;2024.12.21 添加wav2lip、musetalk模型预热，解决第一次推理卡顿问题。感谢&lt;a href=&quot;https://github.com/heimaojinzhangyz&quot;&gt;@heimaojinzhangyz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2024.12.28 添加数字人模型Ultralight-Digital-Human。 感谢&lt;a href=&quot;https://github.com/lijihua2017&quot;&gt;@lijihua2017&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.2.7 添加fish-speech tts&lt;/li&gt; 
 &lt;li&gt;2025.2.21 添加wav2lip256开源模型 感谢@不蠢不蠢&lt;/li&gt; 
 &lt;li&gt;2025.3.2 添加腾讯语音合成服务&lt;/li&gt; 
 &lt;li&gt;2025.3.16 支持mac gpu推理，感谢&lt;a href=&quot;https://github.com/GcsSloop&quot;&gt;@GcsSloop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.5.1 精简运行参数，ernerf模型移至git分支ernerf-rtmp&lt;/li&gt; 
 &lt;li&gt;2025.6.7 添加虚拟摄像头输出&lt;/li&gt; 
 &lt;li&gt;2025.7.5 添加豆包语音合成, 感谢&lt;a href=&quot;https://github.com/ELK-milu&quot;&gt;@ELK-milu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.7.26 支持musetalk v1.5版本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;支持多种数字人模型: ernerf、musetalk、wav2lip、Ultralight-Digital-Human&lt;/li&gt; 
 &lt;li&gt;支持声音克隆&lt;/li&gt; 
 &lt;li&gt;支持数字人说话被打断&lt;/li&gt; 
 &lt;li&gt;支持全身视频拼接&lt;/li&gt; 
 &lt;li&gt;支持webrtc、虚拟摄像头输出&lt;/li&gt; 
 &lt;li&gt;支持动作编排：不说话时播放自定义视频&lt;/li&gt; 
 &lt;li&gt;支持多并发&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;Tested on Ubuntu 24.04, Python3.10, Pytorch 2.5.0 and CUDA 12.4&lt;/p&gt; 
&lt;h3&gt;1.1 Install dependency&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;conda create -n nerfstream python=3.10
conda activate nerfstream
#如果cuda版本不为12.4(运行nvidia-smi确认版本)，根据&amp;lt;https://pytorch.org/get-started/previous-versions/&amp;gt;安装对应版本的pytorch 
conda install pytorch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 pytorch-cuda=12.4 -c pytorch -c nvidia
pip install -r requirements.txt
#如果需要训练ernerf模型，安装下面的库
# pip install &quot;git+https://github.com/facebookresearch/pytorch3d.git&quot;
# pip install tensorflow-gpu==2.8.0
# pip install --upgrade &quot;protobuf&amp;lt;=3.20.1&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;安装常见问题&lt;a href=&quot;https://livetalking-doc.readthedocs.io/zh-cn/latest/faq.html&quot;&gt;FAQ&lt;/a&gt;&lt;br /&gt; linux cuda环境搭建可以参考这篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/674972886&quot;&gt;https://zhuanlan.zhihu.com/p/674972886&lt;/a&gt;&lt;br /&gt; 视频连不上解决方法 &lt;a href=&quot;https://mp.weixin.qq.com/s/MVUkxxhV2cgMMHalphr2cg&quot;&gt;https://mp.weixin.qq.com/s/MVUkxxhV2cgMMHalphr2cg&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. Quick Start&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下载模型&lt;br /&gt; 夸克云盘&lt;a href=&quot;https://pan.quark.cn/s/83a750323ef0&quot;&gt;https://pan.quark.cn/s/83a750323ef0&lt;/a&gt;&lt;br /&gt; GoogleDriver &lt;a href=&quot;https://drive.google.com/drive/folders/1FOC_MD6wdogyyX_7V1d4NDIO7P9NlSAJ?usp=sharing&quot;&gt;https://drive.google.com/drive/folders/1FOC_MD6wdogyyX_7V1d4NDIO7P9NlSAJ?usp=sharing&lt;/a&gt;&lt;br /&gt; 将wav2lip256.pth拷到本项目的models下, 重命名为wav2lip.pth;&lt;br /&gt; 将wav2lip256_avatar1.tar.gz解压后整个文件夹拷到本项目的data/avatars下&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;运行&lt;br /&gt; python app.py --transport webrtc --model wav2lip --avatar_id wav2lip256_avatar1&lt;br /&gt; &lt;font color=&quot;red&quot;&gt;服务端需要开放端口 tcp:8010; udp:1-65536 &lt;/font&gt;&lt;br /&gt; 客户端可以选用以下两种方式:&lt;br /&gt; (1)用浏览器打开&lt;a href=&quot;http://serverip:8010/webrtcapi.html&quot;&gt;http://serverip:8010/webrtcapi.html&lt;/a&gt; , 先点‘start&#39;,播放数字人视频；然后在文本框输入任意文字，提交。数字人播报该段文字&lt;br /&gt; (2)用客户端方式, 下载地址&lt;a href=&quot;https://pan.quark.cn/s/d7192d8ac19b&quot;&gt;https://pan.quark.cn/s/d7192d8ac19b&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;快速体验&lt;br /&gt; &lt;a href=&quot;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&quot;&gt;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&lt;/a&gt; 用该镜像创建实例即可运行成功&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果访问不了huggingface，在运行前&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. More Usage&lt;/h2&gt; 
&lt;p&gt;使用说明: &lt;a href=&quot;https://livetalking-doc.readthedocs.io/&quot;&gt;https://livetalking-doc.readthedocs.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;4. Docker Run&lt;/h2&gt; 
&lt;p&gt;不需要前面的安装，直接运行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --gpus all -it --network=host --rm registry.cn-zhangjiakou.aliyuncs.com/codewithgpu3/lipku-livetalking:toza2irpHZ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代码在/root/livetalking，先git pull拉一下最新代码，然后执行命令同第2、3步&lt;/p&gt; 
&lt;p&gt;提供如下镜像&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;autodl镜像: &lt;a href=&quot;https://www.codewithgpu.com/i/lipku/livetalking/base&quot;&gt;https://www.codewithgpu.com/i/lipku/livetalking/base&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://livetalking-doc.readthedocs.io/en/latest/autodl/README.html&quot;&gt;autodl教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ucloud镜像: &lt;a href=&quot;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&quot;&gt;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&lt;/a&gt;&lt;br /&gt; 可以开放任意端口，不需要另外部署srs服务.&lt;br /&gt; &lt;a href=&quot;https://livetalking-doc.readthedocs.io/en/latest/ucloud/ucloud.html&quot;&gt;ucloud教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;5. 性能&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能主要跟cpu和gpu相关，每路视频压缩需要消耗cpu，cpu性能与视频分辨率正相关；每路口型推理跟gpu性能相关。&lt;/li&gt; 
 &lt;li&gt;不说话时的并发数跟cpu相关，同时说话的并发数跟gpu相关。&lt;/li&gt; 
 &lt;li&gt;后端日志inferfps表示显卡推理帧率，finalfps表示最终推流帧率。两者都要在25以上才能实时。如果inferfps在25以上，finalfps达不到25表示cpu性能不足。&lt;/li&gt; 
 &lt;li&gt;实时推理性能&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;left&quot;&gt;模型&lt;/th&gt; 
   &lt;th align=&quot;left&quot;&gt;显卡型号&lt;/th&gt; 
   &lt;th align=&quot;left&quot;&gt;fps&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;wav2lip256&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;3060&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;60&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;wav2lip256&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;3080Ti&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;120&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;musetalk&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;3080Ti&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;musetalk&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;3090&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;45&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;musetalk&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;4090&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;72&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;wav2lip256显卡3060以上即可，musetalk需要3080Ti以上。&lt;/p&gt; 
&lt;h2&gt;6. 商业版&lt;/h2&gt; 
&lt;p&gt;提供如下扩展功能，适用于对开源项目已经比较熟悉，需要扩展产品功能的用户&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;高清wav2lip模型&lt;/li&gt; 
 &lt;li&gt;完全语音交互，数字人回答过程中支持通过唤醒词或者按钮打断提问&lt;/li&gt; 
 &lt;li&gt;实时同步字幕，给前端提供数字人每句话播报开始、结束事件&lt;/li&gt; 
 &lt;li&gt;每个连接可以指定对应avatar和音色，avatar图片加载加速&lt;/li&gt; 
 &lt;li&gt;动作编排：不说话时动作、唤醒时动作、思考时动作&lt;/li&gt; 
 &lt;li&gt;支持不限时长的数字人形象avatar&lt;/li&gt; 
 &lt;li&gt;提供实时音频流输入接口&lt;/li&gt; 
 &lt;li&gt;数字人透明背景，叠加动态背景&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;更多详情&lt;a href=&quot;https://livetalking-doc.readthedocs.io/zh-cn/latest/service.html#wav2lip&quot;&gt;https://livetalking-doc.readthedocs.io/zh-cn/latest/service.html#wav2lip&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. 声明&lt;/h2&gt; 
&lt;p&gt;基于本项目开发并发布在B站、视频号、抖音等网站上的视频需带上LiveTalking水印和标识，如需去除请联系作者备案授权。&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;如果本项目对你有帮助，帮忙点个star。也欢迎感兴趣的朋友一起来完善该项目.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;知识星球: &lt;a href=&quot;https://t.zsxq.com/7NMyO&quot;&gt;https://t.zsxq.com/7NMyO&lt;/a&gt; 沉淀高质量常见问题、最佳实践经验、问题解答&lt;/li&gt; 
 &lt;li&gt;微信公众号：数字人技术&lt;br /&gt; &lt;img src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/l3ZibgueFiaeyfaiaLZGuMGQXnhLWxibpJUS2gfs8Dje6JuMY8zu2tVyU9n8Zx1yaNncvKHBMibX0ocehoITy5qQEZg/640?wxfrom=12&amp;amp;tp=wxpic&amp;amp;usePicPrefetch=1&amp;amp;wx_fmt=jpeg&amp;amp;from=appmsg&quot; alt=&quot;&quot; /&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>trailofbits/buttercup</title>
      <link>https://github.com/trailofbits/buttercup</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Buttercup Cyber Reasoning System (CRS)&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/trailofbits/buttercup/actions/workflows/tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?sanitize=true&quot; alt=&quot;Tests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/trailofbits/buttercup/actions/workflows/tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?event=schedule&quot; alt=&quot;Tests (Nightly)&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/trailofbits/buttercup/actions/workflows/integration.yml&quot;&gt;&lt;img src=&quot;https://github.com/trailofbits/buttercup/actions/workflows/integration.yml/badge.svg?sanitize=true&quot; alt=&quot;Integration&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Buttercup&lt;/strong&gt; is a Cyber Reasoning System (CRS) developed by &lt;strong&gt;Trail of Bits&lt;/strong&gt; for the &lt;strong&gt;DARPA AIxCC (AI Cyber Challenge)&lt;/strong&gt;. Buttercup finds and patches software vulnerabilities in open-source code repositories like &lt;a href=&quot;https://github.com/tob-challenges/example-libpng&quot;&gt;example-libpng&lt;/a&gt;. It starts by running an AI/ML-assisted fuzzing campaign (built on oss-fuzz) for the program. When vulnerabilities are found, Buttercup analyzes them and uses a multi-agent AI-driven patcher to repair the vulnerability. &lt;strong&gt;Buttercup&lt;/strong&gt; system consists of several components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt;: Coordinates the overall task process and manages the workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seed Generator&lt;/strong&gt;: Creates inputs for vulnerability discovery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fuzzer&lt;/strong&gt;: Discovers vulnerabilities through intelligent fuzzing techniques&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Program Model&lt;/strong&gt;: Analyzes code structure and semantics for better understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patcher&lt;/strong&gt;: Generates and applies security patches to fix vulnerabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU:&lt;/strong&gt; 8 cores&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory:&lt;/strong&gt; 16 GB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; 100 GB available disk space&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network:&lt;/strong&gt; Stable internet connection for downloading dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup uses third-party AI providers (LLMs from companies like OpenAI, Anthropic and Google), which cost money. Please ensure that you manage per-deployment costs by using the built-in LLM budget setting.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup works best with access to models from OpenAI &lt;strong&gt;and&lt;/strong&gt; Anthropic, but can be run with at least one API key from one third-party provider (support for Gemini coming soon).&lt;/p&gt; 
&lt;h3&gt;Supported Systems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux x86_64&lt;/strong&gt; (fully supported)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ARM64&lt;/strong&gt; (partial support for upstream Google OSS-Fuzz projects)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Required System Packages&lt;/h3&gt; 
&lt;p&gt;Before setup, ensure you have these packages installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y make curl git

# RHEL/CentOS/Fedora
sudo yum install -y make curl git
# or
sudo dnf install -y make curl git

# MacOS
brew install make curl git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Supported Targets&lt;/h3&gt; 
&lt;p&gt;Buttercup works with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;C source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Java source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;Projects that build successfully and have existing fuzzing harnesses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository with submodules:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone --recurse-submodules https://github.com/trailofbits/buttercup.git
cd buttercup
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Run automated setup (Recommended)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make setup-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script will install all dependencies, configure the environment, and guide you through the setup process.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you prefer manual setup, see the &lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md&quot;&gt;Manual Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Start Buttercup locally&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make deploy-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Verify local deployment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When a deployment is successful, you should see all pods in &quot;Running&quot; or &quot;Completed&quot; status.&lt;/p&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt;Send Buttercup a simple task&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When tasked, Buttercup will start consuming third-party AI resources.&lt;/p&gt; 
&lt;p&gt;This command will make Buttercup pull down an example repo &lt;a href=&quot;https://github.com/tob-challenges/example-libpng&quot;&gt;example-libpng&lt;/a&gt; with a known vulnerability. Buttercup will start fuzzing it to find and patch vulnerabilities.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make send-libpng-task
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;6&quot;&gt; 
 &lt;li&gt;Access Buttercup&#39;s web-based GUI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make web-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:31323&lt;/code&gt; in your web browser.&lt;/p&gt; 
&lt;p&gt;In the GUI you can monitor active tasks and see when Buttercup finds bugs and generates patches for them.&lt;/p&gt; 
&lt;ol start=&quot;7&quot;&gt; 
 &lt;li&gt;Stop Buttercup&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This is an important step to ensure Buttercup shuts down and stops consuming third-party AI resources.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make undeploy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Accessing Logs&lt;/h2&gt; 
&lt;p&gt;Buttercup includes local SigNoz deployment by default for comprehensive system observability. You can access logs, traces, and metrics through the SigNoz UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make signoz-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:33301&lt;/code&gt; in your web browser to view:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed traces&lt;/li&gt; 
 &lt;li&gt;Application metrics&lt;/li&gt; 
 &lt;li&gt;Error monitoring&lt;/li&gt; 
 &lt;li&gt;Performance insights&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you configured LangFuse during setup, you can also monitor LLM usage and costs there.&lt;/p&gt; 
&lt;p&gt;For additional log access methods, see the &lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md&quot;&gt;Quick Reference Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md&quot;&gt;Quick Reference Guide&lt;/a&gt; - Common commands and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md&quot;&gt;Manual Setup Guide&lt;/a&gt; - Detailed manual installation steps&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/AKS_DEPLOYMENT.md&quot;&gt;AKS Deployment Guide&lt;/a&gt; - Production deployment on Azure&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt; - Development workflow and standards&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/deployment/README.md&quot;&gt;Deployment Documentation&lt;/a&gt; - Advanced deployment configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/trailofbits/buttercup/main/CUSTOM_CHALLENGES.md&quot;&gt;Writing Custom Challenges&lt;/a&gt; - Custom project configuration and setup&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt; 🚅 LiteLLM &lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://render.com/deploy?repo=https://github.com/BerriAI/litellm&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://render.com/images/deploy-to-render-button.svg?sanitize=true&quot; alt=&quot;Deploy to Render&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://railway.app/template/HLP0Ub?referralCode=jch2ME&quot;&gt; &lt;img src=&quot;https://railway.app/button.svg?sanitize=true&quot; alt=&quot;Deploy on Railway&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br /&gt; &lt;/p&gt; 
&lt;h4 align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot; target=&quot;_blank&quot;&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/hosted&quot; target=&quot;_blank&quot;&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/enterprise&quot; target=&quot;_blank&quot;&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align=&quot;center&quot;&gt; &lt;a href=&quot;https://pypi.org/project/litellm/&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/pypi/v/litellm.svg?sanitize=true&quot; alt=&quot;PyPI Version&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://www.ycombinator.com/companies/berriai&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&quot; alt=&quot;Y Combinator W23&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://wa.link/huol9n&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square&quot; alt=&quot;Whatsapp&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square&quot; alt=&quot;Discord&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square&quot; alt=&quot;Slack&quot; /&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider&#39;s &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/output&quot;&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;[&#39;choices&#39;][0][&#39;message&#39;][&#39;content&#39;]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href=&quot;https://docs.litellm.ai/docs/routing&quot;&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot;&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs&quot;&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href=&quot;https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs&quot;&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🚨 &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/release_cycle&quot;&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href=&quot;https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+&quot;&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href=&quot;https://docs.litellm.ai/docs/&quot;&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href=&quot;https://docs.litellm.ai/docs/migration&quot;&gt;here&lt;/a&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot; /&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion
import os

## set ENV variables
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;
os.environ[&quot;ANTHROPIC_API_KEY&quot;] = &quot;your-anthropic-key&quot;

messages = [{ &quot;content&quot;: &quot;Hello, how are you?&quot;,&quot;role&quot;: &quot;user&quot;}]

# openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages)

# anthropic call
response = completion(model=&quot;anthropic/claude-sonnet-4-20250514&quot;, messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &quot;id&quot;: &quot;chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de&quot;,
    &quot;created&quot;: 1751494488,
    &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
    &quot;object&quot;: &quot;chat.completion&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: &quot;stop&quot;,
            &quot;index&quot;: 0,
            &quot;message&quot;: {
                &quot;content&quot;: &quot;Hello! I&#39;m doing well, thank you for asking. I&#39;m here and ready to help with whatever you&#39;d like to discuss or work on. How are you doing today?&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;tool_calls&quot;: null,
                &quot;function_call&quot;: null
            }
        }
    ],
    &quot;usage&quot;: {
        &quot;completion_tokens&quot;: 39,
        &quot;prompt_tokens&quot;: 13,
        &quot;total_tokens&quot;: 52,
        &quot;completion_tokens_details&quot;: null,
        &quot;prompt_tokens_details&quot;: {
            &quot;audio_tokens&quot;: null,
            &quot;cached_tokens&quot;: 0
        },
        &quot;cache_creation_input_tokens&quot;: 0,
        &quot;cache_read_input_tokens&quot;: 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href=&quot;https://docs.litellm.ai/docs/providers&quot;&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-completion&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = &quot;Hello, how are you?&quot;
    messages = [{&quot;content&quot;: user_message, &quot;role&quot;: &quot;user&quot;}]
    response = await acompletion(model=&quot;openai/gpt-4o&quot;, messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response. Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion
response = completion(model=&quot;openai/gpt-4o&quot;, messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or &quot;&quot;)

# claude sonnet 4
response = completion(&#39;anthropic/claude-sonnet-4-20250514&#39;, messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &quot;id&quot;: &quot;chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca&quot;,
    &quot;created&quot;: 1751494808,
    &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
    &quot;object&quot;: &quot;chat.completion.chunk&quot;,
    &quot;system_fingerprint&quot;: null,
    &quot;choices&quot;: [
        {
            &quot;finish_reason&quot;: null,
            &quot;index&quot;: 0,
            &quot;delta&quot;: {
                &quot;provider_specific_fields&quot;: null,
                &quot;content&quot;: &quot;Hello&quot;,
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;function_call&quot;: null,
                &quot;tool_calls&quot;: null,
                &quot;audio&quot;: null
            },
            &quot;logprobs&quot;: null
        }
    ],
    &quot;provider_specific_fields&quot;: null,
    &quot;stream_options&quot;: null,
    &quot;citations&quot;: null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href=&quot;https://docs.litellm.ai/docs/observability/callbacks&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ[&quot;LUNARY_PUBLIC_KEY&quot;] = &quot;your-lunary-public-key&quot;
os.environ[&quot;HELICONE_API_KEY&quot;] = &quot;your-helicone-auth-key&quot;
os.environ[&quot;LANGFUSE_PUBLIC_KEY&quot;] = &quot;&quot;
os.environ[&quot;LANGFUSE_SECRET_KEY&quot;] = &quot;&quot;
os.environ[&quot;ATHINA_API_KEY&quot;] = &quot;your-athina-api-key&quot;

os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;

# set callbacks
litellm.success_callback = [&quot;lunary&quot;, &quot;mlflow&quot;, &quot;langfuse&quot;, &quot;athina&quot;, &quot;helicone&quot;] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model=&quot;openai/gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi 👋 - i&#39;m openai&quot;}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot;&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/hosted&quot;&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth&quot;&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class&quot;&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend&quot;&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/users#set-rate-limits&quot;&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📖 Proxy Endpoints - &lt;a href=&quot;https://litellm-api.up.railway.app/&quot;&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install &#39;litellm[proxy]&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] 💡 &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/user_keys&quot;&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key=&quot;anything&quot;,base_url=&quot;http://0.0.0.0:4000&quot;) # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model=&quot;gpt-3.5-turbo&quot;, messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;this is a test request, write a short poem&quot;
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href=&quot;https://docs.litellm.ai/docs/proxy/virtual_keys&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo &#39;LITELLM_MASTER_KEY=&quot;sk-1234&quot;&#39; &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/
# password generator to get a random hash for litellm salt key
echo &#39;LITELLM_SALT_KEY=&quot;sk-1234&quot;&#39; &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src=&quot;https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033&quot; alt=&quot;ui_3&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;curl &#39;http://0.0.0.0:4000/key/generate&#39; \
--header &#39;Authorization: Bearer sk-1234&#39; \
--header &#39;Content-Type: application/json&#39; \
--data-raw &#39;{&quot;models&quot;: [&quot;gpt-3.5-turbo&quot;, &quot;gpt-4&quot;, &quot;claude-2&quot;], &quot;duration&quot;: &quot;20m&quot;,&quot;metadata&quot;: {&quot;user&quot;: &quot;ishaan@berri.ai&quot;, &quot;team&quot;: &quot;core-infra&quot;}}&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;{
    &quot;key&quot;: &quot;sk-kdEXbIqZRwEeEiHwdg7sFA&quot;, # Bearer token
    &quot;expires&quot;: &quot;2023-11-19T01:38:25.838000+00:00&quot; # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href=&quot;https://docs.litellm.ai/docs/providers&quot;&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/#basic-usage&quot;&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#streaming-responses&quot;&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-completion&quot;&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/completion/stream#async-streaming&quot;&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/embedding/supported_embedding&quot;&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/image_generation&quot;&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/openai&quot;&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/meta_llama&quot;&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/azure&quot;&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aiml&quot;&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aws_sagemaker&quot;&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/bedrock&quot;&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/vertex&quot;&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/palm&quot;&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/gemini&quot;&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/mistral&quot;&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/cloudflare_workers&quot;&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/cohere&quot;&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/anthropic&quot;&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/empower&quot;&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/huggingface&quot;&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/replicate&quot;&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/togetherai&quot;&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/openrouter&quot;&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/ai21&quot;&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/baseten&quot;&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/vllm&quot;&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/nlp_cloud&quot;&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/aleph_alpha&quot;&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/petals&quot;&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/ollama&quot;&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/deepinfra&quot;&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/perplexity&quot;&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/groq&quot;&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/deepseek&quot;&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/anyscale&quot;&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/watsonx&quot;&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/voyage&quot;&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/xinference&quot;&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/friendliai&quot;&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/galadriel&quot;&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/gradient_ai&quot;&gt;GradientAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link&quot;&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/featherless_ai&quot;&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/providers/nebius&quot;&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/&quot;&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; → &lt;code&gt;make install-dev&lt;/code&gt; → &lt;code&gt;make format&lt;/code&gt; → &lt;code&gt;make lint&lt;/code&gt; → &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href=&quot;https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md&quot;&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat&quot;&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Features under the &lt;a href=&quot;https://docs.litellm.ai/docs/proxy/enterprise&quot;&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you&#39;re fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href=&quot;https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href=&quot;https://google.github.io/styleguide/pyguide.html&quot;&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run all checks locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make lint           # Run all linting (matches CI)
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version&quot;&gt;Schedule Demo 👋&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt;Community Discord 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3&quot;&gt;Community Slack 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers 📞 +1 (770) 8783-106 / ‭+1 (412) 618-6238‬&lt;/li&gt; 
 &lt;li&gt;Our emails ✉️ &lt;a href=&quot;mailto:ishaan@berri.ai&quot;&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href=&quot;mailto:krrish@berri.ai&quot;&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href=&quot;https://github.com/BerriAI/litellm/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=BerriAI/litellm&quot; /&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e &quot;.[all]&quot;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;uvicorn litellm.proxy.proxy_server:app --host localhost --port 4000 --reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md&quot;&gt;English&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md&quot;&gt;日本語&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md&quot;&gt;简体中文&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md&quot;&gt;繁體中文&lt;/a&gt; | &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/170&quot;&gt;العَرَبِيَّة‎&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/220&quot;&gt;বাংলা&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/40&quot;&gt;Português do Brasil&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/186&quot;&gt;Deutsch&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/130&quot;&gt;ελληνικά&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/272&quot;&gt;עברית&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/104&quot;&gt;Italiano&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/102&quot;&gt;한국어&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/110&quot;&gt;فارسی&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/68&quot;&gt;Polski&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/87&quot;&gt;русский язык&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/136&quot;&gt;Español&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/187&quot;&gt;ภาษาไทย&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/39&quot;&gt;Türkçe&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/127&quot;&gt;tiếng Việt&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/250&quot;&gt;Français&lt;/a&gt; | &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/28&quot;&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md&quot;&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png&quot; /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide&quot;&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question&quot;&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions&quot;&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png&quot; /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href=&quot;https://apps.ankiweb.net/&quot;&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg&quot;&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg&quot;&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg&quot;&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges&quot;&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png&quot; /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges&quot;&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg&quot;&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/28&quot;&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development&quot;&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png&quot; /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here&quot;&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture&quot;&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article&quot;&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps&quot;&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability&quot;&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput&quot;&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency&quot;&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance&quot;&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance&quot;&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns&quot;&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency&quot;&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency&quot;&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns&quot;&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over&quot;&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication&quot;&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers&quot;&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system&quot;&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network&quot;&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns&quot;&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns&quot;&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer&quot;&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive&quot;&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active&quot;&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing&quot;&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing&quot;&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling&quot;&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy&quot;&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer&quot;&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices&quot;&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery&quot;&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms&quot;&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication&quot;&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication&quot;&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding&quot;&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization&quot;&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning&quot;&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql&quot;&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store&quot;&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store&quot;&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store&quot;&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database&quot;&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql&quot;&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache&quot;&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching&quot;&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching&quot;&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching&quot;&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching&quot;&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching&quot;&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level&quot;&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level&quot;&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache&quot;&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside&quot;&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through&quot;&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back&quot;&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead&quot;&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism&quot;&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues&quot;&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues&quot;&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure&quot;&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp&quot;&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp&quot;&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc&quot;&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest&quot;&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix&quot;&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table&quot;&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know&quot;&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures&quot;&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures&quot;&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs&quot;&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development&quot;&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits&quot;&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info&quot;&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don&#39;t need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics&quot;&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs&quot;&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures&quot;&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question&quot;&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions&quot;&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;MD5&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics&quot;&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix&quot;&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html&quot;&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table&quot;&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know&quot;&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/&quot;&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.hiredintech.com/system-design&quot;&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZgdS0EUmn70&quot;&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://leetcode.com/discuss/career/229177/My-System-Design-Template&quot;&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon&#39;s sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon&#39;s sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you&#39;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=-W9F__D3oY4&quot;&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono&quot;&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones&quot;&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database&quot;&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache&quot;&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism&quot;&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we&#39;ll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we&#39;ll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=&quot;http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&quot;&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput&quot;&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://robertgreiner.com/2014/08/cap-theorem-revisited&quot;&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren&#39;t reliable, so you&#39;ll need to support partition tolerance. You&#39;ll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://robertgreiner.com/2014/08/cap-theorem-revisited/&quot;&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://ksat.me/a-plain-english-introduction-to-cap-theorem&quot;&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/henryr/cap-faq&quot;&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=k-Yaq8AHlFA&quot;&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://snarfed.org/transactions_across_datacenters_io.html&quot;&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active&#39;s IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in &#39;hot&#39; standby or whether it needs to start up from &#39;cold&#39; standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication&quot;&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication&quot;&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service&#39;s overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/srikrupa5/dns-security-presentation-issa&quot;&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_live&quot;&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href=&quot;https://www.cloudflare.com/dns/&quot;&gt;CloudFlare&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/route53/&quot;&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jscape.com/blog/load-balancing-algorithms&quot;&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html&quot;&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html&quot;&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href=&quot;http://superuser.com/questions/472695/who-controls-the-dns-servers/472729&quot;&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href=&quot;http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/&quot;&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter&#39;s IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx&quot;&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Domain_Name_System&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://support.dnsimple.com/categories/dns/&quot;&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/&quot;&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon&#39;s CloudFront support dynamic content. The site&#39;s DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn&#39;t often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_live&quot;&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://figshare.com/articles/Globally_distributed_content_delivery/6605972&quot;&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/&quot;&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Content_delivery_network&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href=&quot;https://en.wikipedia.org/wiki/X.509&quot;&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client&#39;s requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it&#39;s common to set up multiple load balancers, either in &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive&quot;&gt;active-passive&lt;/a&gt; or &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active&quot;&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb&quot;&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing&quot;&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing&quot;&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-4-load-balancing/&quot;&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache&quot;&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&quot;&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.haproxy.org/download/1.2/doc/architecture.txt&quot;&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Load_balancing_(computing)&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-4-load-balancing/&quot;&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-7-load-balancing/&quot;&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html&quot;&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg&quot;&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server&#39;s response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy&#39;s IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href=&quot;https://en.wikipedia.org/wiki/X.509&quot;&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href=&quot;https://en.wikipedia.org/wiki/Failover&quot;&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/&quot;&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&quot;&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.haproxy.org/download/1.2/doc/architecture.txt&quot;&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reverse_proxy&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer&quot;&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism&quot;&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href=&quot;https://smartbear.com/learn/api-design/what-are-microservices&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href=&quot;https://www.consul.io/docs/index.html&quot;&gt;Consul&lt;/a&gt;, &lt;a href=&quot;https://coreos.com/etcd/docs/latest&quot;&gt;Etcd&lt;/a&gt;, and &lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href=&quot;https://www.consul.io/intro/getting-started/checks.html&quot;&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http&quot;&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store&quot;&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale&quot;&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/&quot;&gt;Here&#39;s what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href=&quot;https://en.wikipedia.org/wiki/Database_transaction&quot;&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication&quot;&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You&#39;ll need a load balancer or you&#39;ll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication&quot;&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can&#39;t do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Multi-master_replication&quot;&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You&#39;ll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href=&quot;http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers&quot;&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you&#39;ll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user&#39;s last name initial or the user&#39;s geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You&#39;ll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href=&quot;http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html&quot;&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html&quot;&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Shard_(database_architecture)&quot;&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html&quot;&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href=&quot;https://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href=&quot;https://en.wikipedia.org/wiki/Materialized_view&quot;&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;federation&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding&quot;&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Denormalization&quot;&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href=&quot;https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning&quot;&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It&#39;s important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href=&quot;http://httpd.apache.org/docs/2.2/programs/ab.html&quot;&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html&quot;&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href=&quot;http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search&quot;&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href=&quot;https://en.wikipedia.org/wiki/B-tree&quot;&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization&quot;&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/query-cache.html&quot;&gt;query cache&lt;/a&gt; could lead to &lt;a href=&quot;https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/&quot;&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/&quot;&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l&quot;&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search&quot;&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html&quot;&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn&#39;t receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql&quot;&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We&#39;ll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href=&quot;https://en.wikipedia.org/wiki/Lexicographical_order&quot;&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Key-value_database&quot;&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or&quot;&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://qnimate.com/overview-of-redis-architecture/&quot;&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://adayinthelifeof.nl/2011/02/06/memcache-internals/&quot;&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value&#39;s metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href=&quot;https://www.mongodb.com/mongodb-architecture&quot;&gt;MongoDB&lt;/a&gt; and &lt;a href=&quot;https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/&quot;&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf&quot;&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Document-oriented_database&quot;&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/mongodb-architecture&quot;&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/&quot;&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up&quot;&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html&quot;&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store&#39;s basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href=&quot;https://www.edureka.co/blog/hbase-architecture/&quot;&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href=&quot;http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html&quot;&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html&quot;&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.edureka.co/blog/hbase-architecture/&quot;&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html&quot;&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png&quot;&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest&quot;&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_database&quot;&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://neo4j.com/&quot;&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/2010/introducing-flockdb&quot;&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/3342497/explanation-of-base-terminology&quot;&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq&quot;&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qI_g07C_Q5I&quot;&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://horicky.blogspot.com/2009/11/nosql-patterns.html&quot;&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://www.infoq.com/articles/Transition-RDBMS-NoSQL/&quot;&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed (&#39;hot&#39;) tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.sitepoint.com/sql-vs-nosql-differences/&quot;&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network&quot;&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href=&quot;https://www.varnish-cache.org/&quot;&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_algorithms&quot;&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)&quot;&gt;least recently used (LRU)&lt;/a&gt; can help invalidate &#39;cold&#39; entries and keep &#39;hot&#39; data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you&#39;ll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def get_user(self, user_id):
    user = cache.get(&quot;user.{0}&quot;, user_id)
    if user is None:
        user = db.query(&quot;SELECT * FROM users WHERE user_id = {0}&quot;, user_id)
        if user is not None:
            key = &quot;user.{0}&quot;.format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://memcached.org/&quot;&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn&#39;t requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;set_user(12345, {&quot;foo&quot;:&quot;bar&quot;})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def set_user(user_id, values):
    user = db.query(&quot;UPDATE Users WHERE id = {0}&quot;, user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_algorithms&quot;&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/&quot;&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html&quot;&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_(computing)&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer&quot;&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://redis.io/&quot;&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.rabbitmq.com/&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the &#39;AMQP&#39; protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aws.amazon.com/sqs/&quot;&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.celeryproject.org/en/stable/&quot;&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href=&quot;http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html&quot;&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_backoff&quot;&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=1KRYH75wgy4&quot;&gt;It&#39;s all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html&quot;&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Little%27s_law&quot;&gt;Little&#39;s law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function&quot;&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.escotal.com/osilayer.html&quot;&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/http/&quot;&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol&quot;&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1&quot;&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/&quot;&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Protocol&quot;&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Handshaking&quot;&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation&quot;&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)&quot;&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href=&quot;https://en.wikipedia.org/wiki/Flow_control_(data)&quot;&gt;flow control&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Network_congestion#Congestion_control&quot;&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href=&quot;https://memcached.org/&quot;&gt;memcached&lt;/a&gt; server. &lt;a href=&quot;https://en.wikipedia.org/wiki/Connection_pool&quot;&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/&quot;&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href=&quot;https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol&quot;&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/&quot;&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/&quot;&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp&quot;&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/User_Datagram_Protocol&quot;&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf&quot;&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href=&quot;https://developers.google.com/protocol-buffers/&quot;&gt;Protobuf&lt;/a&gt;, &lt;a href=&quot;https://thrift.apache.org/&quot;&gt;Thrift&lt;/a&gt;, and &lt;a href=&quot;https://avro.apache.org/docs/current/&quot;&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  &quot;data&quot;:&quot;anId&quot;;
  &quot;anotherdata&quot;: &quot;another value&quot;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your &quot;logic&quot; is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href=&quot;https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/&quot;&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href=&quot;http://www.squid-cache.org/&quot;&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don&#39;t reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://restcookbook.com/Basics/hateoas/&quot;&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{&quot;anotherdata&quot;: &quot;another value&quot;}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href=&quot;https://github.com/for-GET/know-your-http-well/raw/master/headers.md&quot;&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn&#39;t fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br /&gt;{&lt;br /&gt;&quot;personid&quot;: &quot;1234&quot;&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person’s items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a person’s items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br /&gt;{&lt;br /&gt;&quot;personid&quot;: &quot;1234&quot;;&lt;br /&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br /&gt;{&lt;br /&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br /&gt;{&lt;br /&gt;&quot;itemid&quot;: &quot;456&quot;;&lt;br /&gt;&quot;key&quot;: &quot;value&quot;&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br /&gt;{&lt;br /&gt;&quot;key&quot;: &quot;value&quot;&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br /&gt;{&lt;br /&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;i&gt;&lt;a href=&quot;https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/&quot;&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/&quot;&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://programmers.stackexchange.com/a/181186&quot;&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/15056878/rest-vs-json-rpc&quot;&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/&quot;&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs&quot;&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://code.facebook.com/posts/1468950976659943/&quot;&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://arstechnica.com/civis/viewtopic.php?t=1190508&quot;&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won&#39;t need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-site_scripting&quot;&gt;XSS&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/SQL_injection&quot;&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href=&quot;https://en.wikipedia.org/wiki/Principle_of_least_privilege&quot;&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/shieldfy/API-Security-Checklist&quot;&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/FallibleInc/security-guide-for-developers&quot;&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet&quot;&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You&#39;ll sometimes be asked to do &#39;back-of-the-envelope&#39; estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Power_of_two&quot;&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67&quot; alt=&quot;&quot; /&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/jboner/2841832&quot;&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/hellerbarde/2843375&quot;&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf&quot;&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf&quot;&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PE4gwstWhmc&quot;&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://queue.acm.org/detail.cfm?id=988407&quot;&gt;queue.acm.org&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search&quot;&gt;stackexchange.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://www.ardendertat.com/2012/01/11/implementing-search-engines/&quot;&gt;ardendertat.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://infolab.stanford.edu/~backrub/google.html&quot;&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch&quot;&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://code.google.com/p/google-mobwrite/&quot;&gt;code.google.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://neil.fraser.name/writing/sync/&quot;&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/dvirsky/introduction-to-redis&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/oemebamo/introduction-to-memcached&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html&quot;&gt;hulu.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://ijcai13.org/files/tutorial_slides/td3.pdf&quot;&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://n00tc0d3r.blogspot.com/&quot;&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/flickr-architecture&quot;&gt;highscalability.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed&quot;&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed&quot;&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.facebook.com/note.php?note_id=10150468255628920&quot;&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf&quot;&gt;erlang-factory.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0&quot;&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920&quot;&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920&quot;&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920&quot;&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://figshare.com/articles/Globally_distributed_content_delivery/6605972&quot;&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/&quot;&gt;michael-noll.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/&quot;&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://blog.twitter.com/2010/announcing-snowflake&quot;&gt;blog.twitter.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/twitter/snowflake/&quot;&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf&quot;&gt;cs.ucsb.edu&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf&quot;&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html&quot;&gt;indieflashblog.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://buildnewgames.com/real-time-multiplayer/&quot;&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/&quot;&gt;stuffwithstuff.com&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf&quot;&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://stripe.com/blog/rate-limiters&quot;&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/b1e4t2k2KJY&quot;&gt;Jane Street&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/&quot;&gt;Golang Implementation&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://bhomnick.net/building-a-simple-limit-order-in-go/&quot;&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png&quot; /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Twitter-Timeline-Scalability&quot;&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don&#39;t focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn&#39;t&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/AGrishchenko/apache-spark-architecture&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/previa/storm-16094009&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/alexbaranau/intro-to-hbase&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf&quot;&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/mdirolf/introduction-to-mongodb&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://research.google.com/archive/spanner-osdi2012.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/oemebamo/introduction-to-memcached&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/dvirsky/introduction-to-redis&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&quot;&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/mumrah/kafka-talk-tri-hug&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/amazon-architecture&quot;&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html&quot;&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html&quot;&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PE4gwstWhmc&quot;&gt;How we&#39;ve scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html&quot;&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/google-architecture&quot;&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html&quot;&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances&quot;&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html&quot;&gt;Justin.Tv&#39;s live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf&quot;&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf&quot;&gt;TAO: Facebook’s distributed data store for the social graph&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf&quot;&gt;Facebook’s photo storage&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html&quot;&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/flickr-architecture&quot;&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html&quot;&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html&quot;&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html&quot;&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html&quot;&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html&quot;&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html&quot;&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/plentyoffish-architecture&quot;&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html&quot;&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html&quot;&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html&quot;&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html&quot;&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster&quot;&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html&quot;&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html&quot;&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Twitter-Timeline-Scalability&quot;&gt;Timelines at scale&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5cKTP36HVgI&quot;&gt;Big and small data at Twitter&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=z8LU0Cj6BOU&quot;&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html&quot;&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html&quot;&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html&quot;&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html&quot;&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w5WVu624fY8&quot;&gt;YouTube scalability&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://highscalability.com/youtube-architecture&quot;&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://nerds.airbnb.com/&quot;&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.atlassian.com/blog/&quot;&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/aws/&quot;&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://word.bitly.com/&quot;&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.box.com/blog/category/engineering&quot;&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tech.dropbox.com/&quot;&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/q/quoraengineering&quot;&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.ebaytechblog.com/&quot;&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.evernote.com/tech/&quot;&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://codeascraft.com/&quot;&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/Engineering&quot;&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://code.flickr.net/&quot;&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineering.foursquare.com/&quot;&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.blog/category/engineering&quot;&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://googleresearch.blogspot.com/&quot;&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.groupon.com/&quot;&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.heroku.com/&quot;&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://product.hubspot.com/blog/topic/engineering&quot;&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/&quot;&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://instagram-engineering.tumblr.com/&quot;&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/blogs/&quot;&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blogs.janestreet.com/category/ocaml/&quot;&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineering.linkedin.com/blog&quot;&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.microsoft.com/&quot;&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/pythonengineering/&quot;&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://techblog.netflix.com/&quot;&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/paypal-engineering&quot;&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@Pinterest_Engineering&quot;&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.redditblog.com/&quot;&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.salesforce.com/blogs/engineering/&quot;&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://slack.engineering/&quot;&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://labs.spotify.com/&quot;&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://stripe.com/blog/engineering&quot;&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.twilio.com/engineering&quot;&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/engineering/&quot;&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://eng.uber.com/&quot;&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://yahooeng.tumblr.com/&quot;&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineeringblog.yelp.com/&quot;&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.zynga.com/blogs/engineering&quot;&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kilimchoi/engineering-blogs&quot;&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.hiredintech.com/system-design/the-system-design-process/&quot;&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0984782850/&quot;&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/&quot;&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/checkcheckzz/system-design-interview&quot;&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/shashank88/system_design&quot;&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mmcgrana/services-engineering&quot;&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/vasanthk/485d1c25737e8e72759f&quot;&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dancres.github.io/Pages/&quot;&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href=&quot;https://github.com/donnemartin&quot;&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.getzep.com/&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73&quot; width=&quot;150&quot; alt=&quot;Zep Logo&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align=&quot;center&quot;&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align=&quot;center&quot;&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/lint.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat&quot; alt=&quot;Lint&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true&quot; alt=&quot;Unit Tests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml&quot;&gt;&lt;img src=&quot;https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true&quot; alt=&quot;MyPy Check&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://img.shields.io/github/stars/getzep/graphiti&quot; alt=&quot;GitHub Repo stars&quot; /&gt; &lt;a href=&quot;https://discord.com/invite/W8Kw6bsgXQ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat&quot; alt=&quot;arXiv&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/getzep/graphiti/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen&quot; alt=&quot;Release&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://trendshift.io/repositories/12986&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12986&quot; alt=&quot;getzep%2Fgraphiti | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md&quot;&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif&quot; alt=&quot;Graphiti temporal walkthrough&quot; width=&quot;700px&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;&quot;Kendra loves Adidas shoes.&quot;&lt;/em&gt; Each fact is a &quot;triplet&quot; represented by two entities, or nodes (&quot;Kendra&quot;, &quot;Adidas shoes&quot;), and their relationship, or edge (&quot;loves&quot;). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep&#39;s Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href=&quot;https://www.getzep.com&quot;&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we&#39;ve demonstrated Zep is the &lt;a href=&quot;https://blog.getzep.com/state-of-the-art-agent-memory/&quot;&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We&#39;re excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://arxiv.org/abs/2501.13956&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png&quot; alt=&quot;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&quot; width=&quot;700px&quot; /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif&quot; alt=&quot;Graphiti structured + unstructured demo&quot; width=&quot;700px&quot; /&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href=&quot;https://neo4j.com/download/&quot;&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti&#39;s ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md&quot;&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j or FalkorDB database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti&#39;s knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md&quot;&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md&quot;&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri=&quot;bolt://localhost:7687&quot;,
    user=&quot;neo4j&quot;,
    password=&quot;password&quot;,
    database=&quot;my_custom_database&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host=&quot;localhost&quot;,
    port=6379,
    username=&quot;falkor_user&quot;,  # Optional
    password=&quot;falkor_password&quot;,  # Optional
    database=&quot;my_custom_graph&quot;  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;USE_PARALLEL_RUNTIME&lt;/code&gt; is an optional boolean variable that can be set to true if you wish to enable Neo4j&#39;s parallel runtime feature for several of our search queries. Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances, as such this feature is off by default.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = &quot;&amp;lt;your-api-key&amp;gt;&quot;
api_version = &quot;&amp;lt;your-api-version&amp;gt;&quot;
llm_endpoint = &quot;&amp;lt;your-llm-endpoint&amp;gt;&quot;  # e.g., &quot;https://your-llm-resource.openai.azure.com/&quot;
embedding_endpoint = &quot;&amp;lt;your-embedding-endpoint&amp;gt;&quot;  # e.g., &quot;https://your-embedding-resource.openai.azure.com/&quot;

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model=&quot;gpt-4.1-nano&quot;,
    model=&quot;gpt-4.1-mini&quot;,
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=OpenAIClient(
        config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model=&quot;text-embedding-3-small-deployment&quot;  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google&#39;s Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you&#39;ll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add &quot;graphiti-core[google-genai]&quot;

# or

pip install &quot;graphiti-core[google-genai]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = &quot;&amp;lt;your-google-api-key&amp;gt;&quot;

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.0-flash&quot;
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model=&quot;embedding-001&quot;
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model=&quot;gemini-2.5-flash-lite-preview-06-17&quot;
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini&#39;s log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama&#39;s OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models: ollama pull deepseek-r1:7b # LLM ollama pull nomic-embed-text # embeddings&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key=&quot;abc&quot;,  # Ollama doesn&#39;t require a real API key
    model=&quot;deepseek-r1:7b&quot;,
    small_model=&quot;deepseek-r1:7b&quot;,
    base_url=&quot;http://localhost:11434/v1&quot;, # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    &quot;bolt://localhost:7687&quot;,
    &quot;neo4j&quot;,
    &quot;password&quot;,
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key=&quot;abc&quot;,
            embedding_model=&quot;nomic-embed-text&quot;,
            embedding_dim=768,
            base_url=&quot;http://localhost:11434/v1&quot;,
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti&quot;&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti/graphiti/quick-start&quot;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.getzep.com/graphiti/graphiti/lang-graph-agent&quot;&gt;Building an agent with LangChain&#39;s LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here&#39;s exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you&#39;re using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don&#39;t Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py&quot;&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo &#39;export GRAPHITI_TELEMETRY_ENABLED=false&#39; &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo &#39;export GRAPHITI_TELEMETRY_ENABLED=false&#39; &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import os
os.environ[&#39;GRAPHITI_TELEMETRY_ENABLED&#39;] = &#39;false&#39;

# Then initialize Graphiti as usual
from graphiti_core import Graphiti
graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled /&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it&#39;s code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href=&quot;https://discord.com/invite/W8Kw6bsgXQ&quot;&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>paperless-ngx/paperless-ngx</title>
      <link>https://github.com/paperless-ngx/paperless-ngx</link>
      <description>&lt;p&gt;A community-supported supercharged document management system: scan, index and archive all your documents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/actions&quot;&gt;&lt;img src=&quot;https://github.com/paperless-ngx/paperless-ngx/workflows/ci/badge.svg?sanitize=true&quot; alt=&quot;ci&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://crowdin.com/project/paperless-ngx&quot;&gt;&lt;img src=&quot;https://badges.crowdin.net/paperless-ngx/localized.svg?sanitize=true&quot; alt=&quot;Crowdin&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.paperless-ngx.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/deployments/paperless-ngx/paperless-ngx/github-pages?label=docs&quot; alt=&quot;Documentation Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/paperless-ngx/paperless-ngx&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/paperless-ngx/paperless-ngx/branch/main/graph/badge.svg?token=VK6OUPJ3TY&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://matrix.to/#/%23paperlessngx%3Amatrix.org&quot;&gt;&lt;img src=&quot;https://matrix.to/img/matrix-badge.svg?sanitize=true&quot; alt=&quot;Chat on Matrix&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://demo.paperless-ngx.com&quot;&gt;&lt;img src=&quot;https://cronitor.io/badges/ve7ItY/production/W5E_B9jkelG9ZbDiNHUPQEVH3MY.svg?sanitize=true&quot; alt=&quot;demo&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/blob/main/resources/logo/web/png/White%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot; /&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot; /&gt; 
  &lt;img src=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png&quot; width=&quot;50%&quot; /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h1&gt;Paperless-ngx&lt;/h1&gt; 
&lt;p&gt;Paperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, &lt;em&gt;less paper&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Paperless-ngx is the official successor to the original &lt;a href=&quot;https://github.com/the-paperless-project/paperless&quot;&gt;Paperless&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://github.com/jonaswinkler/paperless-ng&quot;&gt;Paperless-ng&lt;/a&gt; projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people. &lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support&quot;&gt;Consider joining us!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Thanks to the generous folks at &lt;a href=&quot;https://m.do.co/c/8d70b916d462&quot;&gt;DigitalOcean&lt;/a&gt;, a demo is available at &lt;a href=&quot;https://demo.paperless-ngx.com&quot;&gt;demo.paperless-ngx.com&lt;/a&gt; using login &lt;code&gt;demo&lt;/code&gt; / &lt;code&gt;demo&lt;/code&gt;. &lt;em&gt;Note: demo content is reset frequently and confidential information should not be uploaded.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#features&quot;&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#getting-started&quot;&gt;Getting started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#contributing&quot;&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support&quot;&gt;Community Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#translation&quot;&gt;Translation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#feature-requests&quot;&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#bugs&quot;&gt;Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#related-projects&quot;&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#important-note&quot;&gt;Important Note&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align=&quot;right&quot;&gt;This project is supported by:&lt;br /&gt; &lt;a href=&quot;https://m.do.co/c/8d70b916d462&quot; style=&quot;padding-top: 4px; display: block;&quot;&gt; 
  &lt;picture&gt; 
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_white.svg&quot; width=&quot;140px&quot; /&gt; 
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg&quot; width=&quot;140px&quot; /&gt; 
   &lt;img src=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_black_.svg?sanitize=true&quot; width=&quot;140px&quot; /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;picture&gt; 
 &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards-dark.png&quot; /&gt; 
 &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot; /&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png&quot; /&gt; 
&lt;/picture&gt; 
&lt;p&gt;A full list of &lt;a href=&quot;https://docs.paperless-ngx.com/#features&quot;&gt;features&lt;/a&gt; and &lt;a href=&quot;https://docs.paperless-ngx.com/#screenshots&quot;&gt;screenshots&lt;/a&gt; are available in the &lt;a href=&quot;https://docs.paperless-ngx.com/&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting started&lt;/h1&gt; 
&lt;p&gt;The easiest way to deploy paperless is &lt;code&gt;docker compose&lt;/code&gt;. The files in the &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/tree/main/docker/compose&quot;&gt;&lt;code&gt;/docker/compose&lt;/code&gt; directory&lt;/a&gt; are configured to pull the image from the GitHub container registry.&lt;/p&gt; 
&lt;p&gt;If you&#39;d like to jump right in, you can configure a &lt;code&gt;docker compose&lt;/code&gt; environment with our install script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;bash -c &quot;$(curl -L https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/install-paperless-ngx.sh)&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details and step-by-step guides for alternative installation methods can be found in &lt;a href=&quot;https://docs.paperless-ngx.com/setup/#installation&quot;&gt;the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Migrating from Paperless-ng is easy, just drop in the new docker image! See the &lt;a href=&quot;https://docs.paperless-ngx.com/setup/#migrating-to-paperless-ngx&quot;&gt;documentation on migrating&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;The documentation for Paperless-ngx is available at &lt;a href=&quot;https://docs.paperless-ngx.com/&quot;&gt;https://docs.paperless-ngx.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;If you feel like contributing to the project, please do! Bug fixes, enhancements, visual fixes etc. are always welcome. If you want to implement something big: Please start a discussion about that! The &lt;a href=&quot;https://docs.paperless-ngx.com/development/&quot;&gt;documentation&lt;/a&gt; has some basic information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Community Support&lt;/h2&gt; 
&lt;p&gt;People interested in continuing the work on paperless-ngx are encouraged to reach out here on github and in the &lt;a href=&quot;https://matrix.to/#/#paperless:matrix.org&quot;&gt;Matrix Room&lt;/a&gt;. If you would like to contribute to the project on an ongoing basis there are multiple &lt;a href=&quot;https://github.com/orgs/paperless-ngx/people&quot;&gt;teams&lt;/a&gt; (frontend, ci/cd, etc) that could use your help so please reach out!&lt;/p&gt; 
&lt;h2&gt;Translation&lt;/h2&gt; 
&lt;p&gt;Paperless-ngx is available in many languages that are coordinated on Crowdin. If you want to help out by translating paperless-ngx into your language, please head over to &lt;a href=&quot;https://crowdin.com/project/paperless-ngx&quot;&gt;https://crowdin.com/project/paperless-ngx&lt;/a&gt;, and thank you! More details can be found in &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/raw/main/CONTRIBUTING.md#translating-paperless-ngx&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;Feature requests can be submitted via &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/discussions/categories/feature-requests&quot;&gt;GitHub Discussions&lt;/a&gt;, you can search for existing ideas, add your own and vote for the ones you care about.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;For bugs please &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/issues&quot;&gt;open an issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/discussions&quot;&gt;start a discussion&lt;/a&gt; if you have questions.&lt;/p&gt; 
&lt;h1&gt;Related Projects&lt;/h1&gt; 
&lt;p&gt;Please see &lt;a href=&quot;https://github.com/paperless-ngx/paperless-ngx/wiki/Related-Projects&quot;&gt;the wiki&lt;/a&gt; for a user-maintained list of related projects and software that is compatible with Paperless-ngx.&lt;/p&gt; 
&lt;h1&gt;Important Note&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Document scanners are typically used to scan sensitive documents like your social insurance number, tax records, invoices, etc. &lt;strong&gt;Paperless-ngx should never be run on an untrusted host&lt;/strong&gt; because information is stored in clear text without encryption. No guarantees are made regarding security (but we do try!) and you use the app at your own risk. &lt;strong&gt;The safest way to run Paperless-ngx is on a local server in your own home with backups in place&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>1Panel-dev/MaxKB</title>
      <link>https://github.com/1Panel-dev/MaxKB</link>
      <description>&lt;p&gt;🔥 MaxKB is an open-source platform for building enterprise-grade agents. MaxKB 是强大易用的开源企业级智能体平台。&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/1Panel-dev/maxkb/assets/52996290/c0694996-0eed-40d8-b369-322bf2a380bf&quot; alt=&quot;MaxKB&quot; width=&quot;300&quot; /&gt;&lt;/p&gt; 
&lt;h3 align=&quot;center&quot;&gt;Open-source platform for building enterprise-grade agents&lt;/h3&gt; 
&lt;h3 align=&quot;center&quot;&gt;强大易用的企业级智能体平台&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://trendshift.io/repositories/9113&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9113&quot; alt=&quot;1Panel-dev%2FMaxKB | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html#license-text&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/1Panel-dev/maxkb?color=%231890FF&quot; alt=&quot;License: GPL v3&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/1Panel-dev/maxkb/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/1Panel-dev/maxkb&quot; alt=&quot;Latest release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/1Panel-dev/maxkb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/1Panel-dev/maxkb?color=%231890FF&amp;amp;style=flat-square&quot; alt=&quot;Stars&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/1panel/maxkb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/1panel/maxkb?label=downloads&quot; alt=&quot;Download&quot; /&gt;&lt;/a&gt;&lt;br /&gt; [&lt;a href=&quot;https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README_CN.md&quot;&gt;中文(简体)&lt;/a&gt;] | [&lt;a href=&quot;https://raw.githubusercontent.com/1Panel-dev/MaxKB/v2/README.md&quot;&gt;English&lt;/a&gt;] &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;MaxKB = Max Knowledge Brain, it is an open-source platform for building enterprise-grade agents. MaxKB integrates Retrieval-Augmented Generation (RAG) pipelines, supports robust workflows, and provides advanced MCP tool-use capabilities. MaxKB is widely applied in scenarios such as intelligent customer service, corporate internal knowledge bases, academic research, and education.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Pipeline&lt;/strong&gt;: Supports direct uploading of documents / automatic crawling of online documents, with features for automatic text splitting, vectorization. This effectively reduces hallucinations in large models, providing a superior smart Q&amp;amp;A interaction experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic Workflow&lt;/strong&gt;: Equipped with a powerful workflow engine, function library and MCP tool-use, enabling the orchestration of AI processes to meet the needs of complex business scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Facilitates zero-coding rapid integration into third-party business systems, quickly equipping existing systems with intelligent Q&amp;amp;A capabilities to enhance user satisfaction.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model-Agnostic&lt;/strong&gt;: Supports various large models, including private models (such as DeepSeek, Llama, Qwen, etc.) and public models (like OpenAI, Claude, Gemini, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for input and output text, image, audio and video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Execute the script below to start a MaxKB container using Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run -d --name=maxkb --restart=always -p 8080:8080 -v ~/.maxkb:/opt/maxkb 1panel/maxkb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access MaxKB web interface at &lt;code&gt;http://your_server_ip:8080&lt;/code&gt; with default admin credentials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;username: admin&lt;/li&gt; 
 &lt;li&gt;password: MaxKB@123..&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;中国用户如遇到 Docker 镜像 Pull 失败问题，请参照该 &lt;a href=&quot;https://maxkb.cn/docs/v2/installation/offline_installtion/&quot;&gt;离线安装文档&lt;/a&gt; 进行安装。&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table style=&quot;border-collapse: collapse; border: 1px solid black;&quot;&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td style=&quot;padding: 5px;background-color:#fff;&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/eb285512-a66a-4752-8941-c65ed1592238&quot; alt=&quot;MaxKB Demo1&quot; /&gt;&lt;/td&gt; 
   &lt;td style=&quot;padding: 5px;background-color:#fff;&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/f732f1f5-472c-4fd2-93c1-a277eda83d04&quot; alt=&quot;MaxKB Demo2&quot; /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;padding: 5px;background-color:#fff;&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/c927474a-9a23-4830-822f-5db26025c9b2&quot; alt=&quot;MaxKB Demo3&quot; /&gt;&lt;/td&gt; 
   &lt;td style=&quot;padding: 5px;background-color:#fff;&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/e6268996-a46d-4e58-9f30-31139df78ad2&quot; alt=&quot;MaxKB Demo4&quot; /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Technical stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Frontend：&lt;a href=&quot;https://vuejs.org/&quot;&gt;Vue.js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Backend：&lt;a href=&quot;https://www.djangoproject.com/&quot;&gt;Python / Django&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LLM Framework：&lt;a href=&quot;https://www.langchain.com/&quot;&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Database：&lt;a href=&quot;https://www.postgresql.org/&quot;&gt;PostgreSQL + pgvector&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#1Panel-dev/MaxKB&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=1Panel-dev/MaxKB&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under The GNU General Public License version 3 (GPLv3) (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;https://www.gnu.org/licenses/gpl-3.0.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
