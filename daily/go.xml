<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Wed, 13 Aug 2025 01:33:16 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>kgateway-dev/kgateway</title>
      <link>https://github.com/kgateway-dev/kgateway</link>
      <description>&lt;p&gt;The Cloud-Native API Gateway and AI Gateway&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot; /&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot; /&gt; 
  &lt;img alt=&quot;kgateway&quot; src=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg?sanitize=true&quot; /&gt; 
 &lt;/picture&gt; &lt;br /&gt; An Envoy-Powered, Kubernetes-Native API Gateway &lt;/h1&gt; 
&lt;h2&gt;About kgateway&lt;/h2&gt; 
&lt;p&gt;Kgateway is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;An ingress/edge router for Kubernetes&lt;/strong&gt;: Powered by &lt;a href=&quot;https://www.envoyproxy.io&quot;&gt;Envoy&lt;/a&gt; and programmed with the &lt;a href=&quot;https://gateway-api.sigs.k8s.io/&quot;&gt;Gateway API&lt;/a&gt;, kgateway is a world-leading Cloud Native ingress.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An advanced API gateway&lt;/strong&gt;: Aggregate web APIs and apply key functions like authentication, authorization and rate limiting in one place&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A better waypoint proxy for &lt;a href=&quot;https://ambientmesh.io/&quot;&gt;ambient mesh&lt;/a&gt;&lt;/strong&gt;: Use the same stack for east-west management as you do for north-south.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An AI gateway for securing LLM usage&lt;/strong&gt;: Protect applications, models, and data from inappropriate access or use, whether you&#39;re producing or consuming. Manage traffic to LLM providers, and enrich prompts at a system level.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;An LLM Gateway utilizing the &lt;a href=&quot;https://gateway-api-inference-extension.sigs.k8s.io/&quot;&gt;Inference Extension&lt;/a&gt; project&lt;/strong&gt;: Intelligently route to AI inference workloads and LLMs in your Kubernetes environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A model context protocol (MCP) gateway&lt;/strong&gt;: Federate MCP tool servers into a single, scalable and secure endpoint.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A migration engine for hybrid apps&lt;/strong&gt;: Route to backends implemented as microservices, serverless functions or legacy apps. This can help you gradually migrate from legacy code to microservices and serverless, add new functionalities using cloud-native technologies while maintaining a legacy codebase or allow different teams in an organization to choose different architectures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Kgateway is feature-rich, fast, and flexible. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.&lt;/p&gt; 
&lt;p&gt;The project was previously known as Gloo, and has been &lt;a href=&quot;https://www.solo.io/blog/announcing-gloo-1-0-a-production-ready-envoy-based-api-gateway&quot;&gt;production-ready since 2019&lt;/a&gt;. Please see &lt;a href=&quot;https://github.com/kgateway-dev/kgateway/issues/10363&quot;&gt;the migration plan&lt;/a&gt; for more information and the current status of the change from Gloo to kgateway.&lt;/p&gt; 
&lt;h2&gt;Get involved&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kgateway.dev/slack/&quot;&gt;Join us on our Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kgateway.dev/docs&quot;&gt;Check out the docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kgateway.dev/blog/&quot;&gt;Read the kgateway blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kgateway-dev/community&quot;&gt;Learn more about the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/@kgateway-dev&quot;&gt;Watch a video on our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href=&quot;https://x.com/kgatewaydev&quot;&gt;X&lt;/a&gt;, &lt;a href=&quot;https://bsky.app/profile/kgateway.dev&quot;&gt;Bluesky&lt;/a&gt;, &lt;a href=&quot;https://mastodon.social/@kgateway&quot;&gt;Mastodon&lt;/a&gt; or &lt;a href=&quot;https://www.linkedin.com/company/kgateway/&quot;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing to kgateway&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href=&quot;https://github.com/kgateway-dev/community/raw/main/CONTRIBUTING.md&quot;&gt;contributing guide&lt;/a&gt; in the community repo.&lt;/p&gt; 
&lt;p&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway/main/devel&quot;&gt;devel&lt;/a&gt; folder should be the starting point for understanding the code, and contributing to the product.&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Kgateway would not be possible without the valuable open source work of projects in the community. We would like to extend a special thank-you to &lt;a href=&quot;https://www.envoyproxy.io&quot;&gt;Envoy&lt;/a&gt;, upon whose shoulders we stand.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Reporting security issues&lt;/em&gt; : We take kgateway&#39;s security very seriously. If you&#39;ve found a security issue or a potential security issue in kgateway, please DO NOT file a public GitHub issue. Instead follow &lt;a href=&quot;https://github.com/kgateway-dev/community/raw/main/CVE.md&quot;&gt;the directions laid out in the kgateway/community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-sandbox/horizontal/color/cncf-sandbox-horizontal-color.svg?sanitize=true&quot; width=&quot;300&quot; alt=&quot;Cloud Native Computing Foundation logo&quot; /&gt; 
 &lt;p&gt;kgateway is a &lt;a href=&quot;https://cncf.io&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; sandbox project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>go-dev-frame/sponge</title>
      <link>https://github.com/go-dev-frame/sponge</link>
      <description>&lt;p&gt;A powerful and easy-to-use Go development framework that enables you to effortlessly build stable, reliable, and high-performance backend services with a &quot;low-code&quot; approach.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;English | &lt;a href=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/readme-cn.md&quot;&gt;简体中文&lt;/a&gt;&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;500px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/logo.png&quot; /&gt; &lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://goreportcard.com/report/github.com/go-dev-frame/sponge&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/go-dev-frame/sponge&quot; alt=&quot;Go Report&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/go-dev-frame/sponge&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/go-dev-frame/sponge/branch/main/graph/badge.svg?sanitize=true&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/go-dev-frame/sponge&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/go-dev-frame/sponge.svg?sanitize=true&quot; alt=&quot;Go Reference&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/go-dev-frame/sponge/actions&quot;&gt;&lt;img src=&quot;https://github.com/go-dev-frame/sponge/workflows/Go/badge.svg?sanitize=true&quot; alt=&quot;Go&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/avelino/awesome-go&quot;&gt;&lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true&quot; alt=&quot;Awesome Go&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://img.shields.io/github/license/go-dev-frame/sponge&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/go-dev-frame/sponge&quot; alt=&quot;License: MIT&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Sponge&lt;/strong&gt; is a powerful and easy-to-use Go development framework. Its core philosophy is &lt;strong&gt;&quot;Definition is Code&quot;&lt;/strong&gt;. It generates modular Go code by parsing &lt;code&gt;SQL&lt;/code&gt;, &lt;code&gt;Protobuf&lt;/code&gt;, and &lt;code&gt;JSON&lt;/code&gt; files. These code modules can be flexibly combined to build various types of complete backend services.&lt;/p&gt; 
&lt;p&gt;Sponge provides a one-stop project development solution, covering code generation, development, testing, API documentation, and deployment. It helps developers easily build stable and reliable high-performance backend services (including RESTful API, gRPC, HTTP+gRPC, gRPC Gateway, etc.) in a &quot;low-code&quot; manner, significantly improving the efficiency and quality of project development.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Why Choose Sponge?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Extremely High Development Efficiency&lt;/strong&gt;: Automatically generates CRUD APIs, project scaffolding, and glue code (non-business code), completely solving the problem of extensive repetitive work in traditional development processes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Out-of-the-Box&lt;/strong&gt;: Covers the entire development lifecycle (generate → develop → test → deploy → monitor), avoiding a fragmented toolchain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standardized Best Practices&lt;/strong&gt;: Based on mature solutions from the Go community (Gin/gRPC/Protobuf, etc.), eliminating the hassle of technology selection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal Learning Curve&lt;/strong&gt;: Get started quickly and focus on business logic through code generation and clear examples.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ideal for Team Collaboration&lt;/strong&gt;: Unified project structure improves code maintainability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Collaboration&lt;/strong&gt;: Based on Sponge&#39;s standardized directory and file structure, it intelligently generates business logic code, significantly reducing manual coding and improving development efficiency and code consistency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;One-Click Generation of Complete Backend Service Code.&lt;/b&gt; &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;For &lt;code&gt;Web&lt;/code&gt;, &lt;code&gt;gRPC&lt;/code&gt;, or &lt;code&gt;HTTP+gRPC&lt;/code&gt; services that only require &lt;code&gt;CRUD APIs&lt;/code&gt;, there is no need to write any &lt;code&gt;Go&lt;/code&gt; code. Simply connect to a database (such as &lt;code&gt;MySQL&lt;/code&gt;, &lt;code&gt;MongoDB&lt;/code&gt;, &lt;code&gt;PostgreSQL&lt;/code&gt;, &lt;code&gt;SQLite&lt;/code&gt;), and you can generate the complete backend service code with one click and easily deploy it to a Linux server, Docker, or Kubernetes.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Efficiently Develop General-Purpose Services, from Definition to Implementation in One Step.&lt;/b&gt; &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;To build general-purpose &lt;code&gt;Web&lt;/code&gt;, &lt;code&gt;gRPC&lt;/code&gt;, &lt;code&gt;HTTP+gRPC&lt;/code&gt;, or &lt;code&gt;gRPC Gateway&lt;/code&gt; services, you only need to focus on these three steps:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Define database tables (SQL DDL);&lt;/li&gt; 
   &lt;li&gt;Describe the API in a Protobuf file (Protobuf IDL);&lt;/li&gt; 
   &lt;li&gt;Implement the business logic (supports a built-in AI assistant to automatically generate and merge business logic code).&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;All basic code, including &lt;strong&gt;CRUD APIs, service framework, and glue code&lt;/strong&gt;, is &lt;strong&gt;automatically generated by Sponge&lt;/strong&gt;, allowing developers to focus on core business and comprehensively improve development efficiency.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Supports Custom Templates for Flexible Expansion.&lt;/b&gt; &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Sponge supports generating various types of code required for a project through custom templates, not limited to the &lt;code&gt;Go&lt;/code&gt; language. Examples include &lt;code&gt;backend code&lt;/code&gt;, &lt;code&gt;frontend code&lt;/code&gt;, &lt;code&gt;test code&lt;/code&gt;, &lt;code&gt;build and deployment scripts&lt;/code&gt;, etc.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Generate Code on a Web Page, Simple and Easy to Use.&lt;/b&gt; &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Sponge provides code generation on a web page, avoiding complex command-line operations. Simply fill in the parameters on the page to generate code with one click.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Sponge and AI Assistant Collaborative Development for Infrastructure Automation and Business Logic Intelligence.&lt;/b&gt; &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Sponge, combined with its built-in AI assistants (DeepSeek, ChatGPT, Gemini), creates a complete, efficient, and intelligent development solution:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Sponge&lt;/strong&gt;: Responsible for the automatic generation of infrastructure code, including &lt;code&gt;service framework&lt;/code&gt;, &lt;code&gt;CRUD APIs&lt;/code&gt;, &lt;code&gt;custom APIs (without business logic)&lt;/code&gt;, etc., ensuring a unified and standardized architecture.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;AI Assistant&lt;/strong&gt;: Focuses on business logic implementation, assisting with tasks such as &lt;code&gt;database table design&lt;/code&gt;, &lt;code&gt;Protobuf API definition&lt;/code&gt;, and &lt;code&gt;business logic writing&lt;/code&gt;, reducing repetitive work and improving R&amp;amp;D efficiency.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;Applicable Scenarios&lt;/h3&gt; 
&lt;p&gt;Sponge is suitable for rapidly building various types of high-performance backend services, including the following scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developing RESTful API services&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Building microservice projects&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud-native project development&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rapidly refactoring legacy projects&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;As a starting point for Go beginners or as a best practice for teams&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, developers can generate various types of code to meet business needs through custom templates.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Online Experience&lt;/h3&gt; 
&lt;p&gt;Sponge provides an online experience for code generation: &lt;a href=&quot;https://go-sponge.com/en/ui&quot;&gt;&lt;strong&gt;Code Generation&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: If you need to run the downloaded service code locally, you must first complete the local installation of Sponge.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Sponge&lt;/strong&gt;: Supports Windows/macOS/Linux/Docker, see the &lt;a href=&quot;https://github.com/go-dev-frame/sponge/raw/main/assets/install-en.md&quot;&gt;&lt;strong&gt;Sponge Installation Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open the Code Generation UI Page&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sponge run
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Access &lt;code&gt;http://localhost:24631&lt;/code&gt; in your local browser to generate code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Example: One-Click Generation of Complete Web Service Backend Code&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Connect to the database, select table names.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Download Code: Get the complete code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Generate Swagger Docs: &lt;code&gt;make docs&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run: &lt;code&gt;make run&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Test: Access the Swagger documentation at &lt;code&gt;http://localhost:8080/swagger/index.html&lt;/code&gt; in your browser to test the API.&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;1500px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/en_sponge-ui.png&quot; /&gt; &lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h3&gt;Components&lt;/h3&gt; 
&lt;p&gt;Sponge has built-in support for over 30 common components in the Go ecosystem (used on demand), including mainstream technology stacks such as &lt;strong&gt;Gin&lt;/strong&gt;, &lt;strong&gt;gRPC&lt;/strong&gt;, &lt;strong&gt;GORM&lt;/strong&gt;, &lt;strong&gt;MongoDB&lt;/strong&gt;, &lt;strong&gt;Redis&lt;/strong&gt;, &lt;strong&gt;Kafka&lt;/strong&gt;, &lt;strong&gt;DTM&lt;/strong&gt;, &lt;strong&gt;WebSocket&lt;/strong&gt;, &lt;strong&gt;Prometheus&lt;/strong&gt;, etc. &lt;a href=&quot;https://go-sponge.com/component/&quot;&gt;&lt;strong&gt;View all components&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Code Generation Engine&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Sponge&lt;/strong&gt; provides powerful code generation capabilities, supporting both &lt;code&gt;built-in templates&lt;/code&gt; and &lt;code&gt;custom templates&lt;/code&gt; to quickly generate the code required for your project. It also integrates an &lt;code&gt;AI assistant&lt;/code&gt; to help generate business logic code.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sponge generates a code framework based on built-in templates, as shown in the diagram below:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;1500px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/sponge-framework.png&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Sponge generates a code framework based on custom templates, as shown in the diagram below:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;1200px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/template-framework.png&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Sponge generates a business logic code framework based on functions and comments, as shown in the diagram below:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;1200px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/ai-assistant-framework.png&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Microservice framework&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Sponge&lt;/strong&gt; is a modern Go microservice framework that adopts a typical layered microservice architecture. It comes with a rich set of built-in service governance features, enabling developers to quickly build and maintain complex microservice systems. The structure of the framework is shown in the diagram below:&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;1000px&quot; src=&quot;https://raw.githubusercontent.com/go-dev-frame/sponge/main/assets/en_microservices-framework.png&quot; /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Performance testing of http and grpc service code created by the microservices framework: 50 concurrent, 1 million total requests.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zhufuyi/microservices_framework_benchmark/main/test/assets/http-server.png&quot; alt=&quot;http-server&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zhufuyi/microservices_framework_benchmark/main/test/assets/grpc-server.png&quot; alt=&quot;grpc-server&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Click to view the &lt;a href=&quot;https://github.com/zhufuyi/microservices_framework_benchmark&quot;&gt;&lt;strong&gt;test code&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Project Code Directory Structure&lt;/h3&gt; 
&lt;p&gt;The project code directory structure created by sponge follows the &lt;a href=&quot;https://github.com/golang-standards/project-layout&quot;&gt;project-layout&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Sponge supports creating project code structures for &lt;code&gt;monolithic application in a single repository (monolith)&lt;/code&gt;, &lt;code&gt;microservices in multiple repositories (multi-repo)&lt;/code&gt;, and &lt;code&gt;microservices in a single repository (mono-repo)&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;1. Directory structure for monolithic applications (monolith) or multi-repo microservices.&lt;/b&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;.
├── api            # Protobuf files and generated * pb.go directory
├── assets         # Store various static resources, such as images, markdown files, etc.
├── cmd            # Program entry directory
├── configs        # Directory for configuration files
├── deployments    # Bare metal, docker, k8s deployment script directory.
├── docs           # Directory for API interface Swagger documentation.
├── internal       # Directory for project internal code.
│    ├── cache        # Cache directory wrapped around business logic.
│    ├── config       # Directory for Go structure configuration files.
│    ├── dao          # Data access directory.
│    ├── database     # Directory for database initialization and migration.
│    ├── ecode        # Directory for system error codes and custom business error codes.
│    ├── handler      # Directory for implementing HTTP business functionality (specific to web services).
│    ├── model        # Database model directory.
│    ├── routers      # HTTP routing directory.
│    ├── rpcclient    # Directory for client-side code that connects to grpc services.
│    ├── server       # Directory for creating servers, including HTTP and grpc.
│    ├── service      # Directory for implementing grpc business functionality (specific to grpc services).
│    └── types        # Directory for defining request and response parameter structures for HTTP.
├── pkg            # Directory for shared libraries.
├── scripts        # Directory for scripts.
├── test           # Directory for scripts required for testing services  and test SQL.
├── third_party    # Directory for third-party protobuf files or external helper programs.
├── Makefile       # Develop, test, deploy related command sets .
├── go.mod         # Go module dependencies and version control file.
└── go.sum         # Go module dependencies key and checksum file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;2. Directory structure for mono-repo microservices (large repository).&lt;/b&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;.
├── api
│    ├── server1       # Protobuf files and generated *pb.go directory for service 1.
│    ├── server2       # Protobuf files and generated *pb.go directory for service 2.
│    ├── server3       # Protobuf files and generated *pb.go directory for service 3.
│    └── ...
├── server1        # Code directory for Service 1, it has a similar structure to the microservice multi repo directory.
├── server2        # Code directory for Service 2, it has a similar structure to the microservice multi repo directory.
├── server3        # Code directory for Service 3, it has a similar structure to the microservice multi repo directory.
├── ...
├── third_party    # Third-party protobuf files.
├── go.mod         # Go module dependencies and version control file.
└── go.sum         # Go module dependencies&#39; checksums and hash keys.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Click to view the &lt;a href=&quot;https://go-sponge.com/en/&quot;&gt;Sponge Official Documentation&lt;/a&gt;, which completely covers core content such as development guides, components, service configuration, and deployment solutions.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;h4&gt;Sponge Create Server Code Examples&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/1_web-gin-CRUD&quot;&gt;Create &lt;strong&gt;web&lt;/strong&gt; service based on &lt;strong&gt;sql&lt;/strong&gt; (including CRUD)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/2_micro-grpc-CRUD&quot;&gt;Create &lt;strong&gt;grpc&lt;/strong&gt; service based on &lt;strong&gt;sql&lt;/strong&gt; (including CRUD)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/3_web-gin-protobuf&quot;&gt;Create &lt;strong&gt;web&lt;/strong&gt; service based on &lt;strong&gt;protobuf&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/4_micro-grpc-protobuf&quot;&gt;Create &lt;strong&gt;grpc&lt;/strong&gt; service based on &lt;strong&gt;protobuf&lt;/strong&gt; &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/5_micro-gin-rpc-gateway&quot;&gt;Create &lt;strong&gt;grpc gateway&lt;/strong&gt; service based on &lt;strong&gt;protobuf&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/_10_micro-grpc-http-protobuf&quot;&gt;Create &lt;strong&gt;grpc+http&lt;/strong&gt; service based on &lt;strong&gt;protobuf&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sponge+DTM Distributed Transaction Examples&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/9_order-grpc-distributed-transaction&quot;&gt;Simple distributed order system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/_12_sponge-dtm-flashSale&quot;&gt;Flash sale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/_14_eshop&quot;&gt;E-Commerce system&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sponge+AI Assistant Collaborative Development Examples&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/_15_appliance_store&quot;&gt;Home appliance retail management&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sponge Development Project Examples&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/7_community-single&quot;&gt;Community backend services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-dev-frame/sponge_examples/tree/main/8_community-cluster&quot;&gt;Monolithic service split into microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Issues/PRs are welcome! &lt;a href=&quot;https://go-sponge.com/en/community/contribution.html&quot;&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If Sponge is helpful to you, please give it a ⭐ Star! This will motivate us to keep iterating.&lt;/p&gt; 
&lt;br /&gt;</description>
    </item>
    
    <item>
      <title>FiloSottile/mkcert</title>
      <link>https://github.com/FiloSottile/mkcert</link>
      <description>&lt;p&gt;A simple zero-config tool to make locally trusted development certificates with any names you&#39;d like.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mkcert&lt;/h1&gt; 
&lt;p&gt;mkcert is a simple tool for making locally-trusted development certificates. It requires no configuration.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkcert -install
Created a new local CA 💥
The local CA is now installed in the system trust store! ⚡️
The local CA is now installed in the Firefox trust store (requires browser restart)! 🦊

$ mkcert example.com &quot;*.example.com&quot; example.test localhost 127.0.0.1 ::1

Created a new certificate valid for the following names 📜
 - &quot;example.com&quot;
 - &quot;*.example.com&quot;
 - &quot;example.test&quot;
 - &quot;localhost&quot;
 - &quot;127.0.0.1&quot;
 - &quot;::1&quot;

The certificate is at &quot;./example.com+5.pem&quot; and the key at &quot;./example.com+5-key.pem&quot; ✅
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;498&quot; alt=&quot;Chrome and Firefox screenshot&quot; src=&quot;https://user-images.githubusercontent.com/1225294/51066373-96d4aa80-15be-11e9-91e2-f4e44a3a4458.png&quot; /&gt;&lt;/p&gt; 
&lt;p&gt;Using certificates from real certificate authorities (CAs) for development can be dangerous or impossible (for hosts like &lt;code&gt;example.test&lt;/code&gt;, &lt;code&gt;localhost&lt;/code&gt; or &lt;code&gt;127.0.0.1&lt;/code&gt;), but self-signed certificates cause trust errors. Managing your own CA is the best solution, but usually involves arcane commands, specialized knowledge and manual steps.&lt;/p&gt; 
&lt;p&gt;mkcert automatically creates and installs a local CA in the system root store, and generates locally-trusted certificates. mkcert does not automatically configure servers to use the certificates, though, that&#39;s up to you.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: the &lt;code&gt;rootCA-key.pem&lt;/code&gt; file that mkcert automatically generates gives complete power to intercept secure requests from your machine. Do not share it.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;On macOS, use &lt;a href=&quot;https://brew.sh/&quot;&gt;Homebrew&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install mkcert
brew install nss # if you use Firefox
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or &lt;a href=&quot;https://www.macports.org/&quot;&gt;MacPorts&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo port selfupdate
sudo port install mkcert
sudo port install nss # if you use Firefox
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;p&gt;On Linux, first install &lt;code&gt;certutil&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install libnss3-tools
    -or-
sudo yum install nss-tools
    -or-
sudo pacman -S nss
    -or-
sudo zypper install mozilla-nss-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can install using &lt;a href=&quot;https://docs.brew.sh/Homebrew-on-Linux&quot;&gt;Homebrew on Linux&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or build from source (requires Go 1.13+)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/FiloSottile/mkcert &amp;amp;&amp;amp; cd mkcert
go build -ldflags &quot;-X main.Version=$(git describe --tags)&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or use &lt;a href=&quot;https://github.com/FiloSottile/mkcert/releases&quot;&gt;the pre-built binaries&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -JLO &quot;https://dl.filippo.io/mkcert/latest?for=linux/amd64&quot;
chmod +x mkcert-v*-linux-amd64
sudo cp mkcert-v*-linux-amd64 /usr/local/bin/mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Arch Linux users, &lt;a href=&quot;https://archlinux.org/packages/extra/x86_64/mkcert/&quot;&gt;&lt;code&gt;mkcert&lt;/code&gt;&lt;/a&gt; is available on the official Arch Linux repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo pacman -Syu mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;On Windows, use &lt;a href=&quot;https://chocolatey.org&quot;&gt;Chocolatey&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;choco install mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or use Scoop&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;scoop bucket add extras
scoop install mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or build from source (requires Go 1.10+), or use &lt;a href=&quot;https://github.com/FiloSottile/mkcert/releases&quot;&gt;the pre-built binaries&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you&#39;re running into permission problems try running &lt;code&gt;mkcert&lt;/code&gt; as an Administrator.&lt;/p&gt; 
&lt;h2&gt;Supported root stores&lt;/h2&gt; 
&lt;p&gt;mkcert supports the following root stores:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS system store&lt;/li&gt; 
 &lt;li&gt;Windows system store&lt;/li&gt; 
 &lt;li&gt;Linux variants that provide either 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;update-ca-trust&lt;/code&gt; (Fedora, RHEL, CentOS) or&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;update-ca-certificates&lt;/code&gt; (Ubuntu, Debian, OpenSUSE, SLES) or&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;trust&lt;/code&gt; (Arch)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Firefox (macOS and Linux only)&lt;/li&gt; 
 &lt;li&gt;Chrome and Chromium&lt;/li&gt; 
 &lt;li&gt;Java (when &lt;code&gt;JAVA_HOME&lt;/code&gt; is set)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To only install the local root CA into a subset of them, you can set the &lt;code&gt;TRUST_STORES&lt;/code&gt; environment variable to a comma-separated list. Options are: &quot;system&quot;, &quot;java&quot; and &quot;nss&quot; (includes Firefox).&lt;/p&gt; 
&lt;h2&gt;Advanced topics&lt;/h2&gt; 
&lt;h3&gt;Advanced options&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;	-cert-file FILE, -key-file FILE, -p12-file FILE
	    Customize the output paths.

	-client
	    Generate a certificate for client authentication.

	-ecdsa
	    Generate a certificate with an ECDSA key.

	-pkcs12
	    Generate a &quot;.p12&quot; PKCS #12 file, also know as a &quot;.pfx&quot; file,
	    containing certificate and key for legacy applications.

	-csr CSR
	    Generate a certificate based on the supplied CSR. Conflicts with
	    all other flags and arguments except -install and -cert-file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You &lt;em&gt;must&lt;/em&gt; place these options before the domain names list.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Example&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;mkcert -key-file key.pem -cert-file cert.pem example.com *.example.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;S/MIME&lt;/h3&gt; 
&lt;p&gt;mkcert automatically generates an S/MIME certificate if one of the supplied names is an email address.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mkcert filippo@example.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Mobile devices&lt;/h3&gt; 
&lt;p&gt;For the certificates to be trusted on mobile devices, you will have to install the root CA. It&#39;s the &lt;code&gt;rootCA.pem&lt;/code&gt; file in the folder printed by &lt;code&gt;mkcert -CAROOT&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;On iOS, you can either use AirDrop, email the CA to yourself, or serve it from an HTTP server. After opening it, you need to &lt;a href=&quot;https://github.com/FiloSottile/mkcert/issues/233#issuecomment-690110809&quot;&gt;install the profile in Settings &amp;gt; Profile Downloaded&lt;/a&gt; and then &lt;a href=&quot;https://support.apple.com/en-nz/HT204477&quot;&gt;enable full trust in it&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For Android, you will have to install the CA and then enable user roots in the development build of your app. See &lt;a href=&quot;https://stackoverflow.com/a/22040887/749014&quot;&gt;this StackOverflow answer&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Using the root with Node.js&lt;/h3&gt; 
&lt;p&gt;Node does not use the system root store, so it won&#39;t accept mkcert certificates automatically. Instead, you will have to set the &lt;a href=&quot;https://nodejs.org/api/cli.html#cli_node_extra_ca_certs_file&quot;&gt;&lt;code&gt;NODE_EXTRA_CA_CERTS&lt;/code&gt;&lt;/a&gt; environment variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export NODE_EXTRA_CA_CERTS=&quot;$(mkcert -CAROOT)/rootCA.pem&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Changing the location of the CA files&lt;/h3&gt; 
&lt;p&gt;The CA certificate and its key are stored in an application data folder in the user home. You usually don&#39;t have to worry about it, as installation is automated, but the location is printed by &lt;code&gt;mkcert -CAROOT&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to manage separate CAs, you can use the environment variable &lt;code&gt;$CAROOT&lt;/code&gt; to set the folder where mkcert will place and look for the local CA files.&lt;/p&gt; 
&lt;h3&gt;Installing the CA on other systems&lt;/h3&gt; 
&lt;p&gt;Installing in the trust store does not require the CA key, so you can export the CA certificate and use mkcert to install it in other machines.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for the &lt;code&gt;rootCA.pem&lt;/code&gt; file in &lt;code&gt;mkcert -CAROOT&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;copy it to a different machine&lt;/li&gt; 
 &lt;li&gt;set &lt;code&gt;$CAROOT&lt;/code&gt; to its directory&lt;/li&gt; 
 &lt;li&gt;run &lt;code&gt;mkcert -install&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Remember that mkcert is meant for development purposes, not production, so it should not be used on end users&#39; machines, and that you should &lt;em&gt;not&lt;/em&gt; export or share &lt;code&gt;rootCA-key.pem&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helm/helm</title>
      <link>https://github.com/helm/helm</link>
      <description>&lt;p&gt;The Kubernetes Package Manager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Helm&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/helm/helm/actions?workflow=release&quot;&gt;&lt;img src=&quot;https://github.com/helm/helm/workflows/release/badge.svg?sanitize=true&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/helm.sh/helm/v4&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/helm.sh/helm/v4&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/helm.sh/helm/v4&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=godoc&amp;amp;message=reference&amp;amp;color=blue&quot; alt=&quot;GoDoc&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/3131&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/3131/badge&quot; alt=&quot;CII Best Practices&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://scorecard.dev/viewer/?uri=github.com/helm/helm&quot;&gt;&lt;img src=&quot;https://api.scorecard.dev/projects/github.com/helm/helm/badge&quot; alt=&quot;OpenSSF Scorecard&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://insights.linuxfoundation.org/project/helm&quot;&gt;&lt;img src=&quot;https://insights.production.lfx.dev/api/badge/health-score?project=helm&quot; alt=&quot;LFX Health Score&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.&lt;/p&gt; 
&lt;p&gt;Use Helm to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Find and use &lt;a href=&quot;https://artifacthub.io/packages/search?kind=0&quot;&gt;popular software packaged as Helm Charts&lt;/a&gt; to run in Kubernetes&lt;/li&gt; 
 &lt;li&gt;Share your own applications as Helm Charts&lt;/li&gt; 
 &lt;li&gt;Create reproducible builds of your Kubernetes applications&lt;/li&gt; 
 &lt;li&gt;Intelligently manage your Kubernetes manifest files&lt;/li&gt; 
 &lt;li&gt;Manage releases of Helm packages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm in a Handbasket&lt;/h2&gt; 
&lt;p&gt;Helm is a tool that streamlines installing and managing Kubernetes applications. Think of it like apt/yum/homebrew for Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm renders your templates and communicates with the Kubernetes API&lt;/li&gt; 
 &lt;li&gt;Helm runs on your laptop, CI/CD, or wherever you want it to run.&lt;/li&gt; 
 &lt;li&gt;Charts are Helm packages that contain at least two things: 
  &lt;ul&gt; 
   &lt;li&gt;A description of the package (&lt;code&gt;Chart.yaml&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;One or more templates, which contain Kubernetes manifest files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Charts can be stored on disk, or fetched from remote chart repositories (like Debian or RedHat packages)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm Development and Stable Versions&lt;/h2&gt; 
&lt;p&gt;Helm v4 is currently under development on the &lt;code&gt;main&lt;/code&gt; branch. This is unstable and the APIs within the Go SDK and at the command line are changing. Helm v3 (current stable) is maintained on the &lt;code&gt;dev-v3&lt;/code&gt; branch. APIs there follow semantic versioning.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Binary downloads of the Helm client can be found on &lt;a href=&quot;https://github.com/helm/helm/releases/latest&quot;&gt;the Releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unpack the &lt;code&gt;helm&lt;/code&gt; binary and add it to your PATH and you are good to go!&lt;/p&gt; 
&lt;p&gt;If you want to use a package manager:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://brew.sh/&quot;&gt;Homebrew&lt;/a&gt; users can use &lt;code&gt;brew install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://chocolatey.org/&quot;&gt;Chocolatey&lt;/a&gt; users can use &lt;code&gt;choco install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://learn.microsoft.com/en-us/windows/package-manager/&quot;&gt;Winget&lt;/a&gt; users can use &lt;code&gt;winget install Helm.Helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://scoop.sh/&quot;&gt;Scoop&lt;/a&gt; users can use &lt;code&gt;scoop install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://snapcraft.io/&quot;&gt;Snapcraft&lt;/a&gt; users can use &lt;code&gt;snap install helm --classic&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://flox.dev&quot;&gt;Flox&lt;/a&gt; users can use &lt;code&gt;flox install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To rapidly get Helm up and running, start with the &lt;a href=&quot;https://helm.sh/docs/intro/quickstart/&quot;&gt;Quick Start Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://helm.sh/docs/intro/install/&quot;&gt;installation guide&lt;/a&gt; for more options, including installing pre-releases.&lt;/p&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;p&gt;Get started with the &lt;a href=&quot;https://helm.sh/docs/intro/quickstart/&quot;&gt;Quick Start guide&lt;/a&gt; or plunge into the &lt;a href=&quot;https://helm.sh/docs&quot;&gt;complete documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The &lt;a href=&quot;https://github.com/helm/helm/milestones&quot;&gt;Helm roadmap uses GitHub milestones&lt;/a&gt; to track the progress of the project.&lt;/p&gt; 
&lt;p&gt;The development of Helm v4 is currently happening on the &lt;code&gt;main&lt;/code&gt; branch while the development of Helm v3, the stable branch, is happening on the &lt;code&gt;dev-v3&lt;/code&gt; branch. Changes should be made to the &lt;code&gt;main&lt;/code&gt; branch prior to being added to the &lt;code&gt;dev-v3&lt;/code&gt; branch so that all changes are carried along to Helm v4.&lt;/p&gt; 
&lt;h2&gt;Community, discussion, contribution, and support&lt;/h2&gt; 
&lt;p&gt;You can reach the Helm community and developers via the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kubernetes.slack.com&quot;&gt;Kubernetes Slack&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://kubernetes.slack.com/messages/helm-users&quot;&gt;#helm-users&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://kubernetes.slack.com/messages/helm-dev&quot;&gt;#helm-dev&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://kubernetes.slack.com/messages/charts&quot;&gt;#charts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Mailing List: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://lists.cncf.io/g/cncf-helm&quot;&gt;Helm Mailing List&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Developer Call: Thursdays at 9:30-10:00 Pacific (&lt;a href=&quot;https://github.com/helm/community/raw/master/communication.md#meetings&quot;&gt;meeting details&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;If you&#39;re interested in contributing, please refer to the &lt;a href=&quot;https://raw.githubusercontent.com/helm/helm/main/CONTRIBUTING.md&quot;&gt;Contributing Guide&lt;/a&gt; &lt;strong&gt;before submitting a pull request&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Code of conduct&lt;/h3&gt; 
&lt;p&gt;Participation in the Helm community is governed by the &lt;a href=&quot;https://raw.githubusercontent.com/helm/helm/main/code-of-conduct.md&quot;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>j3ssie/osmedeus</title>
      <link>https://github.com/j3ssie/osmedeus</link>
      <description>&lt;p&gt;A Workflow Engine for Offensive Security&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Osmedeus Core Engine&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.osmedeus.org&quot;&gt;&lt;img alt=&quot;Osmedeus&quot; src=&quot;https://raw.githubusercontent.com/osmedeus/assets/main/logo-transparent.png&quot; height=&quot;140&quot; /&gt;&lt;/a&gt; &lt;br /&gt; &lt;strong&gt;Osmedeus - A Workflow Engine for Offensive Security&lt;/strong&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://docs.osmedeus.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Documentation-0078D4?style=for-the-badge&amp;amp;logo=GitBook&amp;amp;logoColor=39ff14&amp;amp;labelColor=black&amp;amp;color=black&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.osmedeus.org/donation/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Sponsors-0078D4?style=for-the-badge&amp;amp;logo=GitHub-Sponsors&amp;amp;logoColor=39ff14&amp;amp;labelColor=black&amp;amp;color=black&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/OsmedeusEngine&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/%40OsmedeusEngine-0078D4?style=for-the-badge&amp;amp;logo=Twitter&amp;amp;logoColor=39ff14&amp;amp;labelColor=black&amp;amp;color=black&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/gy4SWhpaPU&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord%20Server-0078D4?style=for-the-badge&amp;amp;logo=Discord&amp;amp;logoColor=39ff14&amp;amp;labelColor=black&amp;amp;color=black&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/j3ssie/osmedeus/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/j3ssie/osmedeus?style=for-the-badge&amp;amp;labelColor=black&amp;amp;color=2fc414&amp;amp;logo=Github&quot; /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔥 What is Osmedeus?&lt;/h2&gt; 
&lt;p&gt;Osmedeus is a Workflow Engine for Offensive Security. It was designed to build a foundation with the capability and flexibility that allows you to build your own reconnaissance system and run it on a large number of targets.&lt;/p&gt; 
&lt;h2&gt;📖 Documentation &amp;amp; FAQ&lt;/h2&gt; 
&lt;p&gt;You can check out the documentation at &lt;a href=&quot;https://docs.osmedeus.org&quot;&gt;&lt;strong&gt;docs.osmedeus.org&lt;/strong&gt;&lt;/a&gt; and the Frequently Asked Questions at &lt;a href=&quot;https://docs.osmedeus.org/faq&quot;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;📦 Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;NOTE that you need some essential tools like &lt;code&gt;curl, wget, git, zip&lt;/code&gt; and login as &lt;strong&gt;root&lt;/strong&gt; to start&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;bash &amp;lt;(curl -fsSL https://raw.githubusercontent.com/osmedeus/osmedeus-base/master/install.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build the engine from the source&lt;/h3&gt; 
&lt;p&gt;Make sure you installed &lt;code&gt;golang &amp;gt;= v1.17&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;go install -v github.com/j3ssie/osmedeus@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://docs.osmedeus.org/installation/&quot;&gt;&lt;strong&gt;this page&lt;/strong&gt;&lt;/a&gt; for more the install on other platforms and &lt;a href=&quot;https://docs.osmedeus.org/installation/using-docker/&quot;&gt;&lt;strong&gt;docker image&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🚀 Key Features of Osmedeus&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Significantly speed up your recon process&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Organize your scan results&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Efficiently to customize and optimize your recon process&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Seamlessly integrate with new public and private tools&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Easy to scale across large number of targets&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled /&gt; Easy to synchronize the results across many places&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💡 Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Example Scan Commands:
  ## Start a simple scan with default &#39;general&#39; flow
  osmedeus scan -t sample.com

  ## Start a general scan but exclude some of the module
  osmedeus scan -t sample.com -x screenshot -x spider

  ## Start a scan directly with a module with inputs as a list of http domains like this https://sub.example.com
  osmedeus scan -m content-discovery -t http-file.txt

  ## Initiate the scan using a speed option other than the default setting
  osmedeus scan -f vuln --tactic gently -t sample.com
  osmedeus scan --threads-hold=10 -t sample.com
  osmedeus scan -B 5 -t sample.com

  ## Start a simple scan with other flow
  osmedeus scan -f vuln -t sample.com
  osmedeus scan -f extensive -t sample.com -t another.com
  osmedeus scan -f urls -t list-of-urls.txt

  ## Scan list of targets
  osmedeus scan -T list_of_targets.txt
  osmedeus scan -f vuln -T list-of-targets.txt

  ## Performing static vulnerability scan and secret scan on a git repo
  osmedeus scan -m repo-scan -t https://github.com/j3ssie/sample-repo
  osmedeus scan -m repo-scan -t /tmp/source-code-folder
  osmedeus scan -m repo-scan -T list-of-repo.txt

  ## Scan for CIDR with file contains CIDR with the format &#39;1.2.3.4/24&#39;
  osmedeus scan -f cidr -t list-of-ciders.txt
  osmedeus scan -f cidr -t &#39;1.2.3.4/24&#39; # this will auto convert the single input to the file and run

  ## Directly run on vuln scan and directory scan on list of domains
  osmedeus scan -f domains -t list-of-domains.txt
  osmedeus scan -f vuln-and-dirb -t list-of-domains.txt

  ## Use a custom wordlist
  osmedeus scan -t sample.com -p &#39;wordlists={{Data}}/wordlists/content/big.txt&#39;

  ## Use a custom wordlist
  cat list_of_targets.txt | osmedeus scan -c 2

  ## Start a normal scan and backup entire workflow folder to the backup folder
  osmedeus scan --backup -f domains -t list-of-subdomains.txt

  ## Start the scan with chunk inputs to review the output way more much faster
  osmedeus scan --chunk --chunk-parts 20 -f cidr -t list-of-100-cidr.txt

  ## Continuously run the scan on a target right after it finished
  osmedeus utils cron --for --cmd &#39;osmedeus scan -t example.com&#39;

  ## Backing up all workspaces
  ls ~/workspaces-osmedeus | osmedeus report compress


# Scan Usage:
  osmedeus scan -f [flowName] -t [target]
  osmedeus scan -m [modulePath] -T [targetsFile]
  osmedeus scan -f /path/to/flow.yaml -t [target]
  osmedeus scan -m /path/to/module.yaml -t [target] --params &#39;port=9200&#39;
  osmedeus scan -m /path/to/module.yaml -t [target] -l /tmp/log.log
  osmedeus scan --tactic aggressive -m module -t [target]
  cat targets | osmedeus scan -f sample

# Practical Scan Usage:
  osmedeus scan -T list_of_targets.txt -W custom_workspaces
  osmedeus scan -t target.com -w workspace_name --debug
  osmedeus scan -f general -t sample.com
  osmedeus scan --tactic aggressive -f general -t sample.com
  osmedeus scan -f extensive -t sample.com -t another.com
  cat list_of_urls.txt | osmedeus scan -f urls
  osmedeus scan --threads-hold=15 -f cidr -t 1.2.3.4/24
  osmedeus scan -m ~/.osmedeus/core/workflow/test/dirbscan.yaml -t list_of_urls.txt
  osmedeus scan --wfFolder ~/custom-workflow/ -f your-custom-workflow -t list_of_urls.txt
  osmedeus scan --chunk --chunk-part 40 -c 2 -f cidr -t list-of-cidr.txt

💡 For full help message, please run: osmedeus --hh or osmedeus scan --hh
📖 Documentation can be found here: https://docs.osmedeus.org
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://docs.osmedeus.org/installation/usage/&quot;&gt;&lt;strong&gt;this page&lt;/strong&gt;&lt;/a&gt; for full usage and the &lt;a href=&quot;https://docs.osmedeus.org/installation/practical-usage/&quot;&gt;&lt;strong&gt;Practical Usage&lt;/strong&gt;&lt;/a&gt; to see how to use Osmedeus in a practical way.&lt;/p&gt; 
&lt;h2&gt;💬 Community &amp;amp; Discussion&lt;/h2&gt; 
&lt;p&gt;Join Our Discord server &lt;a href=&quot;https://discord.gg/mtQG2FQsYA&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Osmedeus&lt;/code&gt; is made with ♥ by &lt;a href=&quot;https://twitter.com/j3ssiejjj&quot;&gt;@j3ssiejjj&lt;/a&gt; and it is released under the MIT license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DataDog/datadog-agent</title>
      <link>https://github.com/DataDog/datadog-agent</link>
      <description>&lt;p&gt;Main repository for Datadog Agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Datadog Agent&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/DataDog/datadog-agent/actions/workflows/windows-unittests.yml&quot;&gt;&lt;img src=&quot;https://github.com/DataDog/datadog-agent/actions/workflows/windows-unittests.yml/badge.svg?sanitize=true&quot; alt=&quot;Windows unit tests&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/github/DataDog/datadog-agent?branch=main&quot;&gt;&lt;img src=&quot;https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main&quot; alt=&quot;Coverage status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://godoc.org/github.com/DataDog/datadog-agent&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/DataDog/datadog-agent?status.svg?sanitize=true&quot; alt=&quot;GoDoc&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/DataDog/datadog-agent&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/DataDog/datadog-agent&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The present repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the &lt;a href=&quot;https://docs.datadoghq.com/agent/&quot;&gt;Agent user documentation&lt;/a&gt; for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process &lt;a href=&quot;https://app.datadoghq.com/account/settings/agent/latest?platform=overview&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; the source code of Datadog Agent v5 is located in the &lt;a href=&quot;https://github.com/DataDog/dd-agent&quot;&gt;dd-agent&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The general documentation of the project, including instructions for installation and development, is located under &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs&quot;&gt;the docs directory&lt;/a&gt; of the present repo.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;To build the Agent you need:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://golang.org/doc/install&quot;&gt;Go&lt;/a&gt; 1.24. You&#39;ll also need to set your &lt;code&gt;$GOPATH&lt;/code&gt; and have &lt;code&gt;$GOPATH/bin&lt;/code&gt; in your path.&lt;/li&gt; 
 &lt;li&gt;Python 3.12 along with development libraries for tooling.&lt;/li&gt; 
 &lt;li&gt;Python dependencies. You may install these with &lt;code&gt;pip install dda&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;CMake version 3.15 or later and a C++ compiler&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; you may want to use a python virtual environment to avoid polluting your system-wide python environment with the agent build/dev dependencies. You can create a virtual environment using &lt;code&gt;virtualenv&lt;/code&gt; and then use the &lt;code&gt;dda inv agent.build&lt;/code&gt; parameters &lt;code&gt;--python-home-3=&amp;lt;venv_path&amp;gt;&lt;/code&gt; to use the virtual environment&#39;s interpreter and libraries. By default, this environment is only used for dev dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You may have previously installed &lt;code&gt;invoke&lt;/code&gt; via brew on MacOS, or &lt;code&gt;pip&lt;/code&gt; in any other platform. We recommend you use the version pinned in the requirements file for a smooth development/build experience.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can enable auto completion for invoke tasks. Use the command below to add the appropriate line to your &lt;code&gt;.zshrc&lt;/code&gt; file. &lt;code&gt;echo &quot;source &amp;lt;(dda inv --print-completion-script zsh)&quot; &amp;gt;&amp;gt; ~/.zshrc&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Builds and tests are orchestrated with &lt;code&gt;invoke&lt;/code&gt;, type &lt;code&gt;dda inv --list&lt;/code&gt; on a shell to see the available tasks.&lt;/p&gt; 
&lt;p&gt;To start working on the Agent, you can build the &lt;code&gt;main&lt;/code&gt; branch:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Checkout the repo: &lt;code&gt;git clone https://github.com/DataDog/datadog-agent.git $GOPATH/src/github.com/DataDog/datadog-agent&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;cd into the project folder: &lt;code&gt;cd $GOPATH/src/github.com/DataDog/datadog-agent&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install go tools: &lt;code&gt;dda inv install-tools&lt;/code&gt; (if you have a timeout error, you might need to prepend the &lt;code&gt;GOPROXY=https://proxy.golang.org,https://goproxy.io,direct&lt;/code&gt; env var to the command).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a development &lt;code&gt;datadog.yaml&lt;/code&gt; configuration file in &lt;code&gt;dev/dist/datadog.yaml&lt;/code&gt;, containing a valid API key: &lt;code&gt;api_key: &amp;lt;API_KEY&amp;gt;&lt;/code&gt;. You can either start with an empty one or use the full one generated by the Agent build from Step 5 (located in &lt;code&gt;cmd/agent/dist/datadog.yaml&lt;/code&gt; after the build finishes).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the agent with &lt;code&gt;dda inv agent.build --build-exclude=systemd&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;You can specify a custom Python location for the agent (useful when using virtualenvs):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dda inv agent.build \
  --python-home-3=$GOPATH/src/github.com/DataDog/datadog-agent/venv3
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Running &lt;code&gt;dda inv agent.build&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discards any changes done in &lt;code&gt;bin/agent/dist&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Builds the Agent and writes the binary to &lt;code&gt;bin/agent/agent&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Copies files from &lt;code&gt;dev/dist&lt;/code&gt; to &lt;code&gt;bin/agent/dist&lt;/code&gt;. See &lt;code&gt;https://github.com/DataDog/datadog-agent/blob/main/dev/dist/README.md&lt;/code&gt; for more information.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;If you built an older version of the agent, you may have the error &lt;code&gt;make: *** No targets specified and no makefile found. Stop.&lt;/code&gt;. To solve the issue, you should remove &lt;code&gt;CMakeCache.txt&lt;/code&gt; from &lt;code&gt;rtloader&lt;/code&gt; folder with &lt;code&gt;rm rtloader/CMakeCache.txt&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Please note that the &lt;a href=&quot;https://docs.datadoghq.com/tracing/trace_collection/&quot;&gt;trace agent&lt;/a&gt; needs to be built and run separately.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please refer to the &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs/dev/README.md&quot;&gt;Agent Developer Guide&lt;/a&gt; for more details. For instructions on setting up a windows dev environment, refer to &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/devenv&quot;&gt;Windows Dev Env&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;Run unit tests using &lt;code&gt;dda inv test&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dda inv test --targets=./pkg/aggregator
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;dda inv linter.go&lt;/code&gt; to run just the go linters.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dda inv linter.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When testing code that depends on &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/rtloader&quot;&gt;rtloader&lt;/a&gt;, build and install it first.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dda inv rtloader.make &amp;amp;&amp;amp; dda inv rtloader.install
dda inv test --targets=./pkg/collector/python
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run&lt;/h2&gt; 
&lt;p&gt;You can run the agent with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./bin/agent/agent run -c bin/agent/dist/datadog.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The file &lt;code&gt;bin/agent/dist/datadog.yaml&lt;/code&gt; is copied from &lt;code&gt;dev/dist/datadog.yaml&lt;/code&gt; by &lt;code&gt;dda inv agent.build&lt;/code&gt; and must contain a valid api key.&lt;/p&gt; 
&lt;h3&gt;Run a JMX check&lt;/h3&gt; 
&lt;p&gt;In order to run a JMX based check locally, you must have:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A copy of a JMXFetch &lt;code&gt;jar&lt;/code&gt; copied to &lt;code&gt;dev/dist/jmx/jmxfetch.jar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;java&lt;/code&gt; available on your &lt;code&gt;$PATH&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed instructions, see &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs/dev/checks/jmxfetch.md&quot;&gt;JMX checks&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing code&lt;/h2&gt; 
&lt;p&gt;You&#39;ll find information and help on how to contribute code to this project under &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/docs/dev&quot;&gt;the &lt;code&gt;docs/dev&lt;/code&gt; directory&lt;/a&gt; of the present repo.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The Datadog agent user space components are licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/LICENSE&quot;&gt;Apache License, Version 2.0&lt;/a&gt;. The BPF code is licensed under the &lt;a href=&quot;https://raw.githubusercontent.com/DataDog/datadog-agent/main/pkg/ebpf/c/COPYING&quot;&gt;General Public License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usememos/memos</title>
      <link>https://github.com/usememos/memos</link>
      <description>&lt;p&gt;A modern, open-source, self-hosted knowledge management and note-taking platform designed for privacy-conscious users and organizations.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Memos&lt;/h1&gt; 
&lt;img align=&quot;right&quot; height=&quot;96px&quot; src=&quot;https://www.usememos.com/logo-rounded.png&quot; alt=&quot;Memos&quot; /&gt; 
&lt;p&gt;A modern, open-source, self-hosted knowledge management and note-taking platform designed for privacy-conscious users and organizations. Memos provides a lightweight yet powerful solution for capturing, organizing, and sharing thoughts with comprehensive Markdown support and cross-platform accessibility.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.usememos.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Home-www.usememos.com-blue&quot; alt=&quot;Home Page&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.usememos.com/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-Available-green&quot; alt=&quot;Documentation&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://demo.usememos.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Demo-Try%20Now-orange&quot; alt=&quot;Live Demo&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.usememos.com/blog&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Blog-Read%20More-lightblue&quot; alt=&quot;Blog&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/neosmemo/memos&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/neosmemo/memos.svg?sanitize=true&quot; alt=&quot;Docker Pulls&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/neosmemo/memos&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/image-size/neosmemo/memos?sort=semver&quot; alt=&quot;Docker Image Size&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/tfPJa4UmAv&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-chat-5865f2?logo=discord&amp;amp;logoColor=f5f5f5&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src=&quot;https://www.usememos.com/demo.png&quot; alt=&quot;Memos Application Screenshot&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#overview&quot;&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#key-features&quot;&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#quick-start&quot;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#installation-methods&quot;&gt;Installation Methods&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#development-setup&quot;&gt;Development Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Memos is a lightweight, self-hosted alternative to cloud-based note-taking services. Built with privacy and performance in mind, it offers a comprehensive platform for personal knowledge management without compromising data ownership or security.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Data Privacy and Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete Data Ownership&lt;/strong&gt;: All application data is stored locally in your chosen database&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-Hosted Architecture&lt;/strong&gt;: Full control over your data infrastructure and access policies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No External Dependencies&lt;/strong&gt;: Runtime operations require no third-party services or cloud connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Content Creation and Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plain Text Efficiency&lt;/strong&gt;: Streamlined text input with immediate save functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Markdown Support&lt;/strong&gt;: Comprehensive Markdown rendering with syntax highlighting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich Media Integration&lt;/strong&gt;: Support for images, links, and embedded content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Technical Excellence&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-Performance Backend&lt;/strong&gt;: Built with Go for optimal resource utilization and scalability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Frontend&lt;/strong&gt;: React.js-based user interface with responsive design&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight Deployment&lt;/strong&gt;: Minimal system requirements with efficient resource consumption&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform Compatibility&lt;/strong&gt;: Supports Linux, macOS, Windows, and containerized environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Customization and Extensibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Interface&lt;/strong&gt;: Customizable server branding, themes, and user interface elements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API-First Design&lt;/strong&gt;: RESTful API with comprehensive documentation for third-party integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Database Support&lt;/strong&gt;: Compatible with SQLite, PostgreSQL, and MySQL databases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cost-Effective Solution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source License&lt;/strong&gt;: MIT licensed with full source code availability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero Licensing Costs&lt;/strong&gt;: No subscription fees, usage limits, or premium tiers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community-Driven Development&lt;/strong&gt;: Active community contribution and transparent development process&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; or Docker Compose installed on your system&lt;/li&gt; 
 &lt;li&gt;Minimum 512MB RAM and 1GB available disk space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker Deployment&lt;/h3&gt; 
&lt;p&gt;Deploy Memos in production mode using Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Create data directory
mkdir -p ~/.memos

# Run Memos container
docker run -d \
  --name memos \
  --restart unless-stopped \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;code&gt;http://localhost:5230&lt;/code&gt; and complete the initial setup process.&lt;/p&gt; 
&lt;h3&gt;Docker Compose Deployment&lt;/h3&gt; 
&lt;p&gt;For advanced configurations, use Docker Compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# docker-compose.yml
version: &quot;3.8&quot;
services:
  memos:
    image: neosmemo/memos:stable
    container_name: memos
    restart: unless-stopped
    ports:
      - &quot;5230:5230&quot;
    volumes:
      - ./data:/var/opt/memos
    environment:
      - MEMOS_MODE=prod
      - MEMOS_PORT=5230
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Deploy with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The data directory (&lt;code&gt;~/.memos/&lt;/code&gt; or &lt;code&gt;./data/&lt;/code&gt;) stores all application data including the database, uploaded files, and configuration. Ensure this directory is included in your backup strategy.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Platform Compatibility&lt;/strong&gt;: The above commands are optimized for Unix-like systems (Linux, macOS). For Windows deployments, please refer to the &lt;a href=&quot;https://www.usememos.com/docs/install/container-install#docker-on-windows&quot;&gt;Windows-specific documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation Methods&lt;/h2&gt; 
&lt;p&gt;Memos supports multiple installation approaches to accommodate different deployment scenarios:&lt;/p&gt; 
&lt;h3&gt;Container Deployment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Hub&lt;/strong&gt;: Official images available at &lt;code&gt;neosmemo/memos&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Container Registry&lt;/strong&gt;: Alternative registry with the same image versions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;: Helm charts and YAML manifests for cluster deployments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Binary Installation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-compiled Binaries&lt;/strong&gt;: Available for Linux, macOS, and Windows on the &lt;a href=&quot;https://github.com/usememos/memos/releases&quot;&gt;releases page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source Installation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go Build&lt;/strong&gt;: Compile from source using Go 1.24 or later&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development Mode&lt;/strong&gt;: Local development setup with hot reloading&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed installation instructions, refer to the &lt;a href=&quot;https://www.usememos.com/docs/install&quot;&gt;comprehensive installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development Setup&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://go.dev/&quot;&gt;Go 1.24&lt;/a&gt; or later&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://nodejs.org/en&quot;&gt;Node.js 22+&lt;/a&gt; and &lt;a href=&quot;https://pnpm.io/&quot;&gt;pnpm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://git-scm.com/&quot;&gt;Git&lt;/a&gt; for version control&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Backend Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Clone the repository
git clone https://github.com/usememos/memos.git
cd memos

# Install Go dependencies
go mod download

# Run the backend server
go run ./bin/memos/main.go --mode dev --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Frontend Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Navigate to web directory
cd web

# Install dependencies
pnpm install

# Start development server
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The development servers will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8081&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Frontend: &lt;code&gt;http://localhost:3001&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Memos is an open-source project that welcomes contributions from developers, designers, and users worldwide. We maintain a collaborative and inclusive development environment that values quality, innovation, and community feedback.&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code Contributions&lt;/strong&gt;: Bug fixes, feature implementations, and performance improvements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: API documentation, user guides, and technical specifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt;: Quality assurance, test case development, and bug reporting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Localization&lt;/strong&gt;: Translation support for multiple languages and regions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: Helping users on Discord, GitHub discussions, and forums&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Memos is released under the MIT License, providing maximum flexibility for both personal and commercial use. This license allows for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Commercial Use&lt;/strong&gt;: Deploy Memos in commercial environments without licensing fees&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modification&lt;/strong&gt;: Adapt and customize the codebase for specific requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distribution&lt;/strong&gt;: Share modified versions while maintaining license attribution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private Use&lt;/strong&gt;: Use Memos internally without disclosure requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/usememos/memos/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file for complete licensing terms.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Development Status&lt;/strong&gt;: Memos is actively maintained and under continuous development. While the core functionality is stable and production-ready, users should expect regular updates, feature additions, and potential breaking changes as the project evolves.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Version Compatibility&lt;/strong&gt;: We maintain backward compatibility for data storage and API interfaces where possible. Migration guides are provided for major version transitions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support and Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href=&quot;https://www.usememos.com/docs&quot;&gt;Official Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Chat&lt;/strong&gt;: &lt;a href=&quot;https://discord.gg/tfPJa4UmAv&quot;&gt;Discord Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issue Tracking&lt;/strong&gt;: &lt;a href=&quot;https://github.com/usememos/memos/issues&quot;&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discussions&lt;/strong&gt;: &lt;a href=&quot;https://github.com/usememos/memos/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#usememos/memos&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=usememos/memos&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href=&quot;https://github.com/hashicorp/vault/actions/workflows/build.yml&quot;&gt;&lt;img src=&quot;https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true&quot; alt=&quot;build&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/hashicorp/vault/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true&quot; alt=&quot;ci&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000&quot; alt=&quot;vault enterprise&quot; /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault&#39;s security and our users&#39; trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href=&quot;mailto:security@hashicorp.com&quot;&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href=&quot;https://developer.hashicorp.com/vault&quot;&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href=&quot;https://groups.google.com/group/hashicorp-announce&quot;&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href=&quot;https://discuss.hashicorp.com/c/vault&quot;&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href=&quot;https://developer.hashicorp.com/vault/docs&quot;&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href=&quot;https://developer.hashicorp.com/vault/tutorials&quot;&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href=&quot;https://developer.hashicorp.com/certifications/security-automation&quot;&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width=&quot;300&quot; alt=&quot;Vault Logo&quot; src=&quot;https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png&quot; /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn&#39;t enough to access your secrets. Vault can write to disk, &lt;a href=&quot;https://www.consul.io&quot;&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href=&quot;https://developer.hashicorp.com/vault/docs&quot;&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you&#39;re new to Vault and want to get started with security automation, please check out our &lt;a href=&quot;https://learn.hashicorp.com/collections/vault/getting-started&quot;&gt;Getting Started guides&lt;/a&gt; on HashiCorp&#39;s learning platform. There are also &lt;a href=&quot;https://learn.hashicorp.com/vault&quot;&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href=&quot;https://github.com/hashicorp/vault-examples&quot;&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href=&quot;https://github.com/hashicorp/hello-vault-go&quot;&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href=&quot;https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate&quot;&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href=&quot;https://learn.hashicorp.com/collections/vault/certification&quot;&gt;study materials&lt;/a&gt; on HashiCorp&#39;s learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you&#39;ll first need &lt;a href=&quot;https://www.golang.org&quot;&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href=&quot;https://golang.org/doc/code.html#GOPATH&quot;&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href=&quot;https://pkg.go.dev/cmd/go#hdr-Environment_variables&quot;&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href=&quot;https://github.com/golang/go/wiki/Modules&quot;&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you&#39;re developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for &#39;https://github.com&#39;&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ git config --global --add url.&quot;git@github.com:&quot;.insteadOf &quot;https://github.com/&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href=&quot;https://raw.githubusercontent.com/hashicorp/vault/main/go.mod&quot;&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren&#39;t likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section &quot;Docker-based tests&quot; below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href=&quot;https://en.wikipedia.org/wiki/Acceptance_testing&quot;&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you&#39;re working on a feature of a secret or auth method and want to verify it is functioning (and also hasn&#39;t broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you&#39;re testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href=&quot;https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise&quot;&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault&quot;, // or &quot;hashicorp/vault-enterprise&quot;
    ImageTag:    &quot;latest&quot;,
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read(&quot;sys/storage/raft/configuration&quot;)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
  &quot;testing&quot;
  &quot;github.com/hashicorp/vault/sdk/helper/testcluster/docker&quot;
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: &quot;hashicorp/vault-enterprise&quot;,
    ImageTag:  &quot;latest&quot;,
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn&#39;t become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here&#39;s an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run &#39;TestRaft_Configuration_Docker&#39; ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>prometheus/prometheus</title>
      <link>https://github.com/prometheus/prometheus</link>
      <description>&lt;p&gt;The Prometheus monitoring system and time series database.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt; &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Prometheus&quot; src=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/documentation/images/prometheus-logo.svg?sanitize=true&quot; /&gt;&lt;/a&gt;&lt;br /&gt;Prometheus &lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt;Visit &lt;a href=&quot;https://prometheus.io&quot; target=&quot;_blank&quot;&gt;prometheus.io&lt;/a&gt; for the full documentation, examples and guides.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/prometheus/prometheus/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/prometheus/prometheus/actions/workflows/ci.yml/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://quay.io/repository/prometheus/prometheus&quot;&gt;&lt;img src=&quot;https://quay.io/repository/prometheus/prometheus/status&quot; alt=&quot;Docker Repository on Quay&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/prom/prometheus/&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/prom/prometheus.svg?maxAge=604800&quot; alt=&quot;Docker Pulls&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/prometheus/prometheus&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/prometheus/prometheus&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/486&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/486/badge&quot; alt=&quot;CII Best Practices&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://securityscorecards.dev/viewer/?uri=github.com/prometheus/prometheus&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/prometheus/prometheus/badge&quot; alt=&quot;OpenSSF Scorecard&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://clomonitor.io/projects/cncf/prometheus&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/prometheus/badge&quot; alt=&quot;CLOMonitor&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://gitpod.io/#https://github.com/prometheus/prometheus&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&quot; alt=&quot;Gitpod ready-to-code&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:prometheus&quot;&gt;&lt;img src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/prometheus.svg?sanitize=true&quot; alt=&quot;Fuzzing Status&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Prometheus, a &lt;a href=&quot;https://cncf.io/&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; project, is a systems and service monitoring system. It collects metrics from configured targets at given intervals, evaluates rule expressions, displays the results, and can trigger alerts when specified conditions are observed.&lt;/p&gt; 
&lt;p&gt;The features that distinguish Prometheus from other metrics and monitoring systems are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;strong&gt;multi-dimensional&lt;/strong&gt; data model (time series defined by metric name and set of key/value dimensions)&lt;/li&gt; 
 &lt;li&gt;PromQL, a &lt;strong&gt;powerful and flexible query language&lt;/strong&gt; to leverage this dimensionality&lt;/li&gt; 
 &lt;li&gt;No dependency on distributed storage; &lt;strong&gt;single server nodes are autonomous&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;An HTTP &lt;strong&gt;pull model&lt;/strong&gt; for time series collection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pushing time series&lt;/strong&gt; is supported via an intermediary gateway for batch jobs&lt;/li&gt; 
 &lt;li&gt;Targets are discovered via &lt;strong&gt;service discovery&lt;/strong&gt; or &lt;strong&gt;static configuration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Multiple modes of &lt;strong&gt;graphing and dashboarding support&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Support for hierarchical and horizontal &lt;strong&gt;federation&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture overview&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/documentation/images/architecture.svg?sanitize=true&quot; alt=&quot;Architecture overview&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Prometheus.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href=&quot;https://prometheus.io/download/&quot;&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href=&quot;https://prometheus.io&quot;&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Prometheus. See the &lt;a href=&quot;https://prometheus.io/docs/introduction/install/&quot;&gt;Installing&lt;/a&gt; chapter in the documentation for all the details.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href=&quot;https://quay.io/repository/prometheus/prometheus&quot;&gt;Quay.io&lt;/a&gt; or &lt;a href=&quot;https://hub.docker.com/r/prom/prometheus/&quot;&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch a Prometheus container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Prometheus will now be reachable at &lt;a href=&quot;http://localhost:9090/&quot;&gt;http://localhost:9090/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Building from source&lt;/h3&gt; 
&lt;p&gt;To build Prometheus from source code, You need:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go: Version specified in &lt;a href=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/go.mod&quot;&gt;go.mod&lt;/a&gt; or greater.&lt;/li&gt; 
 &lt;li&gt;NodeJS: Version specified in &lt;a href=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/web/ui/.nvmrc&quot;&gt;.nvmrc&lt;/a&gt; or greater.&lt;/li&gt; 
 &lt;li&gt;npm: Version 8 or greater (check with &lt;code&gt;npm --version&lt;/code&gt; and &lt;a href=&quot;https://www.npmjs.com/&quot;&gt;here&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Start by cloning the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/prometheus/prometheus.git
cd prometheus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can use the &lt;code&gt;go&lt;/code&gt; tool to build and install the &lt;code&gt;prometheus&lt;/code&gt; and &lt;code&gt;promtool&lt;/code&gt; binaries into your &lt;code&gt;GOPATH&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;GO111MODULE=on go install github.com/prometheus/prometheus/cmd/...
prometheus --config.file=your_config.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;However&lt;/em&gt;, when using &lt;code&gt;go install&lt;/code&gt; to build Prometheus, Prometheus will expect to be able to read its web assets from local filesystem directories under &lt;code&gt;web/ui/static&lt;/code&gt; and &lt;code&gt;web/ui/templates&lt;/code&gt;. In order for these assets to be found, you will have to run Prometheus from the root of the cloned repository. Note also that these directories do not include the React UI unless it has been built explicitly using &lt;code&gt;make assets&lt;/code&gt; or &lt;code&gt;make build&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;An example of the above configuration file can be found &lt;a href=&quot;https://github.com/prometheus/prometheus/raw/main/documentation/examples/prometheus.yml&quot;&gt;here.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also build using &lt;code&gt;make build&lt;/code&gt;, which will compile in the web assets so that Prometheus can be run from anywhere:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make build
./prometheus --config.file=your_config.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Makefile provides several targets:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;build&lt;/em&gt;: build the &lt;code&gt;prometheus&lt;/code&gt; and &lt;code&gt;promtool&lt;/code&gt; binaries (includes building and compiling in web assets)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;test&lt;/em&gt;: run the tests&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;test-short&lt;/em&gt;: run the short tests&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;format&lt;/em&gt;: format the source code&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;vet&lt;/em&gt;: check the source code for common errors&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;assets&lt;/em&gt;: build the React UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Service discovery plugins&lt;/h3&gt; 
&lt;p&gt;Prometheus is bundled with many service discovery plugins. When building Prometheus from source, you can edit the &lt;a href=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/plugins.yml&quot;&gt;plugins.yml&lt;/a&gt; file to disable some service discoveries. The file is a yaml-formatted list of go import path that will be built into the Prometheus binary.&lt;/p&gt; 
&lt;p&gt;After you have changed the file, you need to run &lt;code&gt;make build&lt;/code&gt; again.&lt;/p&gt; 
&lt;p&gt;If you are using another method to compile Prometheus, &lt;code&gt;make plugins&lt;/code&gt; will generate the plugins file accordingly.&lt;/p&gt; 
&lt;p&gt;If you add out-of-tree plugins, which we do not endorse at the moment, additional steps might be needed to adjust the &lt;code&gt;go.mod&lt;/code&gt; and &lt;code&gt;go.sum&lt;/code&gt; files. As always, be extra careful when loading third party code.&lt;/p&gt; 
&lt;h3&gt;Building the Docker image&lt;/h3&gt; 
&lt;p&gt;You can build a docker image locally with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make promu
promu crossbuild -p linux/amd64
make npm_licenses
make common-docker-amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make docker&lt;/code&gt; target is intended only for use in our CI system and will not produce a fully working image when run locally.&lt;/p&gt; 
&lt;h2&gt;Using Prometheus as a Go Library&lt;/h2&gt; 
&lt;h3&gt;Remote Write&lt;/h3&gt; 
&lt;p&gt;We are publishing our Remote Write protobuf independently at &lt;a href=&quot;https://buf.build/prometheus/prometheus/assets&quot;&gt;buf.build&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use that as a library:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get buf.build/gen/go/prometheus/prometheus/protocolbuffers/go@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is experimental.&lt;/p&gt; 
&lt;h3&gt;Prometheus code base&lt;/h3&gt; 
&lt;p&gt;In order to comply with &lt;a href=&quot;https://go.dev/ref/mod#versions&quot;&gt;go mod&lt;/a&gt; rules, Prometheus release number do not exactly match Go module releases.&lt;/p&gt; 
&lt;p&gt;For the Prometheus v3.y.z releases, we are publishing equivalent v0.3y.z tags. The y in v0.3y.z is always padded to two digits, with a leading zero if needed.&lt;/p&gt; 
&lt;p&gt;Therefore, a user that would want to use Prometheus v3.0.0 as a library could do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get github.com/prometheus/prometheus@v0.300.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the Prometheus v2.y.z releases, we published the equivalent v0.y.z tags.&lt;/p&gt; 
&lt;p&gt;Therefore, a user that would want to use Prometheus v2.35.0 as a library could do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get github.com/prometheus/prometheus@v0.35.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This solution makes it clear that we might break our internal Go APIs between minor user-facing releases, as &lt;a href=&quot;https://semver.org/#spec-item-4&quot;&gt;breaking changes are allowed in major version zero&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;React UI Development&lt;/h2&gt; 
&lt;p&gt;For more information on building, running, and developing on the React-based UI, see the React app&#39;s &lt;a href=&quot;https://raw.githubusercontent.com/prometheus/prometheus/main/web/ui/README.md&quot;&gt;README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;More information&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Godoc documentation is available via &lt;a href=&quot;https://pkg.go.dev/github.com/prometheus/prometheus&quot;&gt;pkg.go.dev&lt;/a&gt;. Due to peculiarities of Go Modules, v3.y.z will be displayed as v0.3y.z (the y in v0.3y.z is always padded to two digits, with a leading zero if needed), while v2.y.z will be displayed as v0.y.z.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href=&quot;https://prometheus.io/community&quot;&gt;Community page&lt;/a&gt; for how to reach the Prometheus developers and users on various communication channels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to &lt;a href=&quot;https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href=&quot;https://github.com/prometheus/prometheus/raw/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>golang-migrate/migrate</title>
      <link>https://github.com/golang-migrate/migrate</link>
      <description>&lt;p&gt;Database migrations. CLI and Golang library.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/golang-migrate/migrate/actions/workflows/ci.yaml?query=branch%3Amaster&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/golang-migrate/migrate/ci.yaml?branch=master&quot; alt=&quot;GitHub Workflow Status (branch)&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/golang-migrate/migrate/v4&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/golang-migrate/migrate&quot; alt=&quot;GoDoc&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://coveralls.io/github/golang-migrate/migrate?branch=master&quot;&gt;&lt;img src=&quot;https://img.shields.io/coveralls/github/golang-migrate/migrate/master.svg?sanitize=true&quot; alt=&quot;Coverage Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://packagecloud.io/golang-migrate/migrate?filter=debs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/deb-packagecloud.io-844fec.svg?sanitize=true&quot; alt=&quot;packagecloud.io&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/migrate/migrate/&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/migrate/migrate.svg?sanitize=true&quot; alt=&quot;Docker Pulls&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/badge/Go-1.23%2C%201.24-lightgrey.svg?sanitize=true&quot; alt=&quot;Supported Go Versions&quot; /&gt; &lt;a href=&quot;https://github.com/golang-migrate/migrate/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/golang-migrate/migrate.svg?sanitize=true&quot; alt=&quot;GitHub Release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/golang-migrate/migrate/v4&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/golang-migrate/migrate/v4&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;migrate&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Database migrations written in Go. Use as &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/#cli-usage&quot;&gt;CLI&lt;/a&gt; or import as &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/#use-in-your-go-project&quot;&gt;library&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Migrate reads migrations from &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/#migration-sources&quot;&gt;sources&lt;/a&gt; and applies them in correct order to a &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/#databases&quot;&gt;database&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Drivers are &quot;dumb&quot;, migrate glues everything together and makes sure the logic is bulletproof. (Keeps the drivers lightweight, too.)&lt;/li&gt; 
 &lt;li&gt;Database drivers don&#39;t assume things or try to correct user input. When in doubt, fail.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Forked from &lt;a href=&quot;https://github.com/mattes/migrate&quot;&gt;mattes/migrate&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Databases&lt;/h2&gt; 
&lt;p&gt;Database drivers run migrations. &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/driver.go&quot;&gt;Add a new database?&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/postgres&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/pgx&quot;&gt;PGX v4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/pgx/v5&quot;&gt;PGX v5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/redshift&quot;&gt;Redshift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/ql&quot;&gt;Ql&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/cassandra&quot;&gt;Cassandra / ScyllaDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/sqlite&quot;&gt;SQLite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/sqlite3&quot;&gt;SQLite3&lt;/a&gt; (&lt;a href=&quot;https://github.com/mattes/migrate/issues/165&quot;&gt;todo #165&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/sqlcipher&quot;&gt;SQLCipher&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/mysql&quot;&gt;MySQL / MariaDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/neo4j&quot;&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/mongodb&quot;&gt;MongoDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/crate&quot;&gt;CrateDB&lt;/a&gt; (&lt;a href=&quot;https://github.com/mattes/migrate/issues/170&quot;&gt;todo #170&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/shell&quot;&gt;Shell&lt;/a&gt; (&lt;a href=&quot;https://github.com/mattes/migrate/issues/171&quot;&gt;todo #171&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/spanner&quot;&gt;Google Cloud Spanner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/cockroachdb&quot;&gt;CockroachDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/yugabytedb&quot;&gt;YugabyteDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/clickhouse&quot;&gt;ClickHouse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/firebird&quot;&gt;Firebird&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/sqlserver&quot;&gt;MS SQL Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/rqlite&quot;&gt;rqlite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database URLs&lt;/h3&gt; 
&lt;p&gt;Database connection strings are specified via URLs. The URL format is driver dependent but generally has the form: &lt;code&gt;dbdriver://username:password@host:port/dbname?param1=true&amp;amp;param2=false&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any &lt;a href=&quot;https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters&quot;&gt;reserved URL characters&lt;/a&gt; need to be escaped. Note, the &lt;code&gt;%&lt;/code&gt; character also &lt;a href=&quot;https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_the_percent_character&quot;&gt;needs to be escaped&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Explicitly, the following characters need to be escaped: &lt;code&gt;!&lt;/code&gt;, &lt;code&gt;#&lt;/code&gt;, &lt;code&gt;$&lt;/code&gt;, &lt;code&gt;%&lt;/code&gt;, &lt;code&gt;&amp;amp;&lt;/code&gt;, &lt;code&gt;&#39;&lt;/code&gt;, &lt;code&gt;(&lt;/code&gt;, &lt;code&gt;)&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;,&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;:&lt;/code&gt;, &lt;code&gt;;&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt;, &lt;code&gt;?&lt;/code&gt;, &lt;code&gt;@&lt;/code&gt;, &lt;code&gt;[&lt;/code&gt;, &lt;code&gt;]&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;It&#39;s easiest to always run the URL parts of your DB connection URL (e.g. username, password, etc) through an URL encoder. See the example Python snippets below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ python3 -c &#39;import urllib.parse; print(urllib.parse.quote(input(&quot;String to encode: &quot;), &quot;&quot;))&#39;
String to encode: FAKEpassword!#$%&amp;amp;&#39;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$ python2 -c &#39;import urllib; print urllib.quote(raw_input(&quot;String to encode: &quot;), &quot;&quot;)&#39;
String to encode: FAKEpassword!#$%&amp;amp;&#39;()*+,/:;=?@[]
FAKEpassword%21%23%24%25%26%27%28%29%2A%2B%2C%2F%3A%3B%3D%3F%40%5B%5D
$
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Migration Sources&lt;/h2&gt; 
&lt;p&gt;Source drivers read migrations from local or remote sources. &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/driver.go&quot;&gt;Add a new source?&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/file&quot;&gt;Filesystem&lt;/a&gt; - read from filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/iofs&quot;&gt;io/fs&lt;/a&gt; - read from a Go &lt;a href=&quot;https://pkg.go.dev/io/fs#FS&quot;&gt;io/fs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/go_bindata&quot;&gt;Go-Bindata&lt;/a&gt; - read from embedded binary data (&lt;a href=&quot;https://github.com/jteeuwen/go-bindata&quot;&gt;jteeuwen/go-bindata&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/pkger&quot;&gt;pkger&lt;/a&gt; - read from embedded binary data (&lt;a href=&quot;https://github.com/markbates/pkger&quot;&gt;markbates/pkger&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/github&quot;&gt;GitHub&lt;/a&gt; - read from remote GitHub repositories&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/github_ee&quot;&gt;GitHub Enterprise&lt;/a&gt; - read from remote GitHub Enterprise repositories&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/bitbucket&quot;&gt;Bitbucket&lt;/a&gt; - read from remote Bitbucket repositories&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/gitlab&quot;&gt;Gitlab&lt;/a&gt; - read from remote Gitlab repositories&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/aws_s3&quot;&gt;AWS S3&lt;/a&gt; - read from Amazon Web Services S3&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/source/google_cloud_storage&quot;&gt;Google Cloud Storage&lt;/a&gt; - read from Google Cloud Platform Storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;CLI usage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple wrapper around this library.&lt;/li&gt; 
 &lt;li&gt;Handles ctrl+c (SIGINT) gracefully.&lt;/li&gt; 
 &lt;li&gt;No config search paths, no config files, no magic ENV var injections.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/cmd/migrate&quot;&gt;CLI Documentation&lt;/a&gt; (includes CLI install instructions)&lt;/p&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ migrate -source file://path/to/migrations -database postgres://localhost:5432/database up 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker run -v {{ migration dir }}:/migrations --network host migrate/migrate
    -path=/migrations/ -database postgres://localhost:5432/database up 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Use in your Go project&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;API is stable and frozen for this release (v3 &amp;amp; v4).&lt;/li&gt; 
 &lt;li&gt;Uses &lt;a href=&quot;https://golang.org/cmd/go/#hdr-Modules__module_versions__and_more&quot;&gt;Go modules&lt;/a&gt; to manage dependencies.&lt;/li&gt; 
 &lt;li&gt;To help prevent database corruptions, it supports graceful stops via &lt;code&gt;GracefulStop chan bool&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Bring your own logger.&lt;/li&gt; 
 &lt;li&gt;Uses &lt;code&gt;io.Reader&lt;/code&gt; streams internally for low memory overhead.&lt;/li&gt; 
 &lt;li&gt;Thread-safe and no goroutine leaks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/golang-migrate/migrate/v4&quot;&gt;Go Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;github.com/golang-migrate/migrate/v4&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/github&quot;
)

func main() {
    m, err := migrate.New(
        &quot;github://mattes:personal-access-token@mattes/migrate_test&quot;,
        &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    m.Steps(2)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Want to use an existing database client?&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;database/sql&quot;
    _ &quot;github.com/lib/pq&quot;
    &quot;github.com/golang-migrate/migrate/v4&quot;
    &quot;github.com/golang-migrate/migrate/v4/database/postgres&quot;
    _ &quot;github.com/golang-migrate/migrate/v4/source/file&quot;
)

func main() {
    db, err := sql.Open(&quot;postgres&quot;, &quot;postgres://localhost:5432/database?sslmode=enable&quot;)
    driver, err := postgres.WithInstance(db, &amp;amp;postgres.Config{})
    m, err := migrate.NewWithDatabaseInstance(
        &quot;file:///migrations&quot;,
        &quot;postgres&quot;, driver)
    m.Up() // or m.Steps(2) if you want to explicitly set the number of migrations to run
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Go to &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/GETTING_STARTED.md&quot;&gt;getting started&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/cockroachdb/TUTORIAL.md&quot;&gt;CockroachDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/database/postgres/TUTORIAL.md&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(more tutorials to come)&lt;/p&gt; 
&lt;h2&gt;Migration files&lt;/h2&gt; 
&lt;p&gt;Each migration has an up and down migration. &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/FAQ.md#why-two-separate-files-up-and-down-for-a-migration&quot;&gt;Why?&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;1481574547_create_users_table.up.sql
1481574547_create_users_table.down.sql
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/MIGRATIONS.md&quot;&gt;Best practices: How to write migrations.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Coming from another db migration tool?&lt;/h2&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://github.com/musinit/migradaptor/&quot;&gt;migradaptor&lt;/a&gt;. &lt;em&gt;Note: migradaptor is not affiliated or supported by this project&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Versions&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Supported?&lt;/th&gt; 
   &lt;th&gt;Import&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;master&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;import &quot;github.com/golang-migrate/migrate/v4&quot;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;New features and bug fixes arrive here first&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;import &quot;github.com/golang-migrate/migrate/v4&quot;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Used for stable releases&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;❌&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;import &quot;github.com/golang-migrate/migrate&quot;&lt;/code&gt; (with package manager) or &lt;code&gt;import &quot;gopkg.in/golang-migrate/migrate.v3&quot;&lt;/code&gt; (not recommended)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DO NOT USE&lt;/strong&gt; - No longer supported&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Development and Contributing&lt;/h2&gt; 
&lt;p&gt;Yes, please! &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/Makefile&quot;&gt;&lt;code&gt;Makefile&lt;/code&gt;&lt;/a&gt; is your friend, read the &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/CONTRIBUTING.md&quot;&gt;development guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Also have a look at the &lt;a href=&quot;https://raw.githubusercontent.com/golang-migrate/migrate/master/FAQ.md&quot;&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Looking for alternatives? &lt;a href=&quot;https://awesome-go.com/#database&quot;&gt;https://awesome-go.com/#database&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/redis/go-redis/actions&quot;&gt;&lt;img src=&quot;https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true&quot; alt=&quot;build workflow&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/redis/go-redis/v9&quot; alt=&quot;PkgGoDev&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://redis.uptrace.dev/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/redis-documentation-informational&quot; alt=&quot;Documentation&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/redis/go-redis/v9&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/redis/go-redis/v9&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/github/redis/go-redis&quot;&gt;&lt;img src=&quot;https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://discord.gg/W4txy5AeKM&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.twitch.tv/redisinc&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitch/status/redisinc?style=social&quot; alt=&quot;Twitch&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/redisinc&quot;&gt;&lt;img src=&quot;https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social&quot; alt=&quot;YouTube&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/redisinc&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/redisinc?style=social&quot; alt=&quot;Twitter&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://stackoverflow.com/questions/tagged/go-redis&quot;&gt;&lt;img src=&quot;https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow&quot; alt=&quot;Stack Exchange questions&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES&quot;&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES&quot;&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES&quot;&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES&quot;&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href=&quot;https://go.dev/doc/devel/release#go1.23.0&quot;&gt;1.23&lt;/a&gt;, &lt;a href=&quot;https://go.dev/doc/devel/release#go1.24.0&quot;&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://university.redis.com/&quot;&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://launchpad.redis.com/&quot;&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://redis.com/try-free/&quot;&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://developer.redis.com/&quot;&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://redis.com/community/&quot;&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://redis.com/company/careers/jobs/&quot;&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev&quot;&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/zh/&quot;&gt;简体中文&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/redis/go-redis/discussions&quot;&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/W4txy5AeKM&quot;&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/redis/go-redis/v9&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-redis/redismock&quot;&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/bsm/redislock&quot;&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-redis/cache&quot;&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/go-redis/redis_rate&quot;&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href=&quot;https://github.com/apache/incubator-kvrocks&quot;&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority&quot;&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/go-redis-pubsub.html&quot;&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/go-redis-pipelines.html&quot;&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/lua-scripting.html&quot;&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/go-redis-sentinel.html&quot;&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/go-redis-cluster.html&quot;&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/ring.html&quot;&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.uptrace.dev/guide/redis-performance-monitoring.html&quot;&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://redis.io/docs/data-types/probabilistic/&quot;&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes&quot;&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href=&quot;https://github.com/golang/go/wiki/Modules&quot;&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;context&quot;
    &quot;fmt&quot;

    &quot;github.com/redis/go-redis/v9&quot;
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     &quot;localhost:6379&quot;,
        Password: &quot;&quot;, // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, &quot;key&quot;).Result()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;key&quot;, val)

    val2, err := rdb.Get(ctx, &quot;key2&quot;).Result()
    if err == redis.Nil {
        fmt.Println(&quot;key2 does not exist&quot;)
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println(&quot;key2&quot;, val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href=&quot;https://github.com/redis/go-redis-entraid&quot;&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure&#39;s managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;github.com/redis/go-redis/v9&quot;
    &quot;github.com/redis/go-redis-entraid&quot;
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: &quot;your-redis-server.redis.cache.windows.net:6380&quot;,
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return &quot;user&quot;, &quot;pass&quot;, nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: &quot;localhost:6379&quot;,
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return &quot;user&quot;, &quot;pass&quot;
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     &quot;localhost:6379&quot;,
    Username: &quot;user&quot;,
    Password: &quot;pass&quot;,
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     &quot;localhost:6379&quot;,
    Password: &quot;&quot;, // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href=&quot;https://github.com/redis/redis-specifications/tree/master/uri/redis.txt&quot;&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;github.com/redis/go-redis/v9&quot;
)

func ExampleClient() *redis.Client {
    url := &quot;redis://user:password@localhost:6379/0?protocol=3&quot;
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
    &quot;github.com/redis/go-redis/v9&quot;
    &quot;github.com/redis/go-redis/extra/redisotel/v9&quot;
    &quot;errors&quot;
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 0.5MiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            &quot;localhost:6379&quot;,
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is &quot;fire and forget&quot;, meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            &quot;localhost:6379&quot;,
    Password:        &quot;&quot;,
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it&#39;s important to note that some response structures aren&#39;t final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it&#39;s necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn&#39;t have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;res1, err := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		&quot;idx:bicycle&quot;,
		&quot;@pickup_zone:[CONTAINS $bike]&quot;,
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				&quot;bike&quot;: &quot;POINT(-0.1278 51.5074)&quot;,
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href=&quot;https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/&quot;&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 256KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            &quot;localhost:6379&quot;,
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href=&quot;https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md&quot;&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, &quot;list&quot;, &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: &quot;ASC&quot;}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, &quot;zset&quot;, &amp;amp;redis.ZRangeBy{
    Min: &quot;-inf&quot;,
    Max: &quot;+inf&quot;,
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, &quot;out&quot;, &amp;amp;redis.ZStore{
    Keys: []string{&quot;zset1&quot;, &quot;zset2&quot;},
    Weights: []int64{2, 3}
}).Result()

// EVAL &quot;return {KEYS[1],ARGV[1]}&quot; 1 &quot;key&quot; &quot;hello&quot;
vals, err := rdb.Eval(ctx, &quot;return {KEYS[1],ARGV[1]}&quot;, []string{&quot;key&quot;}, &quot;hello&quot;).Result()

// custom command
res, err := rdb.Do(ctx, &quot;set&quot;, &quot;key&quot;, &quot;value&quot;).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;go-redis will start a redis-server and run the test cases.&lt;/p&gt; 
&lt;p&gt;The paths of redis-server bin file and redis config file are defined in &lt;code&gt;main_test.go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;var (
	redisServerBin, _  = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;src&quot;, &quot;redis-server&quot;))
	redisServerConf, _ = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;redis.conf&quot;))
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For local testing, you can change the variables to refer to your local files, or create a soft link to the corresponding folder for redis-server and copy the config file to &lt;code&gt;testdata/redis/&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;ln -s /usr/bin/redis-server ./go-redis/testdata/redis/src
cp ./go-redis/testdata/redis.conf ./go-redis/testdata/redis/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Lastly, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another option is to run your specific tests with an already running redis. The example below, tests against a redis running on port 9999.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;REDIS_PORT=9999 go test &amp;lt;your options&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bun.uptrace.dev&quot;&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bun.uptrace.dev/postgres/&quot;&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://bunrouter.uptrace.dev/&quot;&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/uptrace/go-clickhouse&quot;&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;⭐&lt;/span&gt; &lt;a href=&quot;https://github.com/uptrace/uptrace&quot;&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href=&quot;https://github.com/redis/go-redis/tree/master/example/otel&quot;&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href=&quot;https://github.com/redis/go-redis/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contributors-img.web.app/image?repo=redis/go-redis&quot; /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>grpc-ecosystem/grpc-gateway</title>
      <link>https://github.com/grpc-ecosystem/grpc-gateway</link>
      <description>&lt;p&gt;gRPC to JSON proxy generator following the gRPC HTTP spec&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;h1&gt;gRPC-Gateway&lt;/h1&gt; 
 &lt;p&gt; gRPC to JSON proxy generator following the gRPC HTTP spec &lt;/p&gt; 
 &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/grpc-ecosystem/grpc-gateway/ci.yml?color=379c9c&amp;amp;label=build&amp;amp;logo=github&amp;amp;logoColor=ffffff&amp;amp;style=flat-square&quot; /&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://app.slack.com/client/T029RQSE6/CBATURP1D&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-grpc--gateway-379c9c?logo=slack&amp;amp;logoColor=ffffff&amp;amp;style=flat-square&quot; /&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/grpc-ecosystem/grpc-gateway?color=379c9c&amp;amp;style=flat-square&quot; /&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/grpc-ecosystem/grpc-gateway?color=379c9c&amp;amp;logoColor=ffffff&amp;amp;style=flat-square&quot; /&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/grpc-ecosystem/grpc-gateway?color=379c9c&amp;amp;style=flat-square&quot; /&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot;&gt;&lt;img src=&quot;https://slsa.dev/images/gh-badge-level3.svg?sanitize=true&quot; /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;The gRPC-Gateway is a plugin of the Google protocol buffers compiler &lt;a href=&quot;https://github.com/protocolbuffers/protobuf&quot;&gt;protoc&lt;/a&gt;. It reads protobuf service definitions and generates a reverse-proxy server which translates a RESTful HTTP API into gRPC. This server is generated according to the &lt;a href=&quot;https://github.com/googleapis/googleapis/raw/master/google/api/http.proto#L46&quot;&gt;&lt;code&gt;google.api.http&lt;/code&gt;&lt;/a&gt; annotations in your service definitions.&lt;/p&gt; 
&lt;p&gt;This helps you provide your APIs in both gRPC and RESTful style at the same time.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/grpc-ecosystem/grpc-gateway/main/docs/assets/images/architecture_introduction_diagram.svg?sanitize=true&quot; /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;p&gt;You can read our docs at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://grpc-ecosystem.github.io/grpc-gateway/&quot;&gt;https://grpc-ecosystem.github.io/grpc-gateway/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Testimonials&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We use the gRPC-Gateway to serve millions of API requests per day, and have been since 2018 and through all of that, we have never had any issues with it.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;- William Mill, &lt;a href=&quot;http://adhocteam.us/&quot;&gt;Ad Hoc&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Background&lt;/h2&gt; 
&lt;p&gt;gRPC is great -- it generates API clients and server stubs in many programming languages, it is fast, easy-to-use, bandwidth-efficient and its design is combat-proven by Google. However, you might still want to provide a traditional RESTful JSON API as well. Reasons can range from maintaining backward-compatibility, supporting languages or clients that are not well supported by gRPC, to simply maintaining the aesthetics and tooling involved with a RESTful JSON architecture.&lt;/p&gt; 
&lt;p&gt;This project aims to provide that HTTP+JSON interface to your gRPC service. A small amount of configuration in your service to attach HTTP semantics is all that&#39;s needed to generate a reverse-proxy with this library.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Compile from source&lt;/h3&gt; 
&lt;p&gt;The following instructions assume you are using &lt;a href=&quot;https://go.dev/wiki/Modules&quot;&gt;Go Modules&lt;/a&gt; for dependency management. Use a &lt;a href=&quot;https://go.dev/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module&quot;&gt;tool dependency&lt;/a&gt; to track the versions of the following executable packages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// +build tools

package tools

import (
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway&quot;
    _ &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2&quot;
    _ &quot;google.golang.org/grpc/cmd/protoc-gen-go-grpc&quot;
    _ &quot;google.golang.org/protobuf/cmd/protoc-gen-go&quot;
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run &lt;code&gt;go mod tidy&lt;/code&gt; to resolve the versions. Install by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go install \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \
    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \
    google.golang.org/protobuf/cmd/protoc-gen-go \
    google.golang.org/grpc/cmd/protoc-gen-go-grpc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will place four binaries in your &lt;code&gt;$GOBIN&lt;/code&gt;;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-grpc-gateway&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-openapiv2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-go&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-go-grpc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Make sure that your &lt;code&gt;$GOBIN&lt;/code&gt; is in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Using the &lt;code&gt;tool&lt;/code&gt; Directive in Go 1.24&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Starting from Go 1.24, the &lt;code&gt;tool&lt;/code&gt; directive in &lt;code&gt;go.mod&lt;/code&gt; provides a structured way to track and manage executable dependencies. This replaces the previous workaround of using a separate &lt;code&gt;tools.go&lt;/code&gt; file with blank imports.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Tracking Tools in &lt;code&gt;go.mod&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Instead of manually importing tool dependencies in a Go source file, you can now use the &lt;code&gt;tool&lt;/code&gt; directive in &lt;code&gt;go.mod&lt;/code&gt; to declare the tools your project depends on. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;module tools

go 1.24

tool (
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
	github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
	google.golang.org/grpc/cmd/protoc-gen-go-grpc
	google.golang.org/protobuf/cmd/protoc-gen-go
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Managing Tool Dependencies&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;To add tools to your module, use the &lt;code&gt;-tool&lt;/code&gt; flag with &lt;code&gt;go get&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway
go get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2
go get -tool google.golang.org/protobuf/cmd/protoc-gen-go
go get -tool google.golang.org/grpc/cmd/protoc-gen-go-grpc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This automatically updates &lt;code&gt;go.mod&lt;/code&gt;, adding the tools under the &lt;code&gt;tool&lt;/code&gt; directive along with &lt;code&gt;require&lt;/code&gt; statements to ensure version tracking.&lt;/p&gt; 
&lt;h3&gt;Install Tools&lt;/h3&gt; 
&lt;p&gt;Once the tool dependencies are properly recorded in the &lt;code&gt;go.mod&lt;/code&gt; file, simply execute the following command in the root directory of your project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go install tool
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will place four binaries in your &lt;code&gt;$GOBIN&lt;/code&gt;;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-grpc-gateway&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-openapiv2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-go&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protoc-gen-go-grpc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Make sure that your &lt;code&gt;$GOBIN&lt;/code&gt; is in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Download the binaries&lt;/h3&gt; 
&lt;p&gt;You may alternatively download the binaries from the &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases/latest&quot;&gt;GitHub releases page&lt;/a&gt;. We generate &lt;a href=&quot;https://raw.githubusercontent.com/grpc-ecosystem/grpc-gateway/main/slsa.dev&quot;&gt;SLSA3 signatures&lt;/a&gt; using the OpenSSF&#39;s &lt;a href=&quot;https://github.com/slsa-framework/slsa-github-generator&quot;&gt;slsa-framework/slsa-github-generator&lt;/a&gt; during the release process. To verify a release binary:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the verification tool from &lt;a href=&quot;https://github.com/slsa-framework/slsa-verifier#installation&quot;&gt;slsa-framework/slsa-verifier#installation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the provenance file &lt;code&gt;attestation.intoto.jsonl&lt;/code&gt; from the &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/releases/latest&quot;&gt;GitHub releases page&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the verifier:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;slsa-verifier -artifact-path &amp;lt;the-binary&amp;gt; -provenance attestation.intoto.jsonl -source github.com/grpc-ecosystem/grpc-gateway -tag &amp;lt;the-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, see the section on remotely managed plugin versions below.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;1.Define your &lt;a href=&quot;https://grpc.io/docs/&quot;&gt;gRPC&lt;/a&gt; service using protocol buffers&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;your_service.proto&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-protobuf&quot;&gt; syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;

 message StringMessage {
   string value = 1;
 }

 service YourService {
   rpc Echo(StringMessage) returns (StringMessage) {}
 }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Generate gRPC stubs&lt;/h3&gt; 
&lt;p&gt;This step generates the gRPC stubs that you can use to implement the service and consume from clients:&lt;/p&gt; 
&lt;p&gt;Here&#39;s an example &lt;code&gt;buf.gen.yaml&lt;/code&gt; you can use to generate the stubs with &lt;a href=&quot;https://github.com/bufbuild/buf&quot;&gt;buf&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this file in place, you can generate your files using &lt;code&gt;buf generate&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For a complete example of using &lt;code&gt;buf generate&lt;/code&gt; to generate protobuf stubs, see &lt;a href=&quot;https://github.com/johanbrandhorst/grpc-gateway-boilerplate&quot;&gt;the boilerplate repo&lt;/a&gt;. For more information on generating the stubs with buf, see &lt;a href=&quot;https://docs.buf.build/generate-usage&quot;&gt;the official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you are using &lt;code&gt;protoc&lt;/code&gt; to generate stubs, here&#39;s an example of what a command might look like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;protoc -I . \
    --go_out ./gen/go/ --go_opt paths=source_relative \
    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \
    your/service/v1/your_service.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Implement your service in gRPC as usual.&lt;/h3&gt; 
&lt;h3&gt;4. Generate reverse-proxy using &lt;code&gt;protoc-gen-grpc-gateway&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;At this point, you have 3 options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;no further modifications, use the default mapping to HTTP semantics (method, path, etc.) 
  &lt;ul&gt; 
   &lt;li&gt;this will work on any &lt;code&gt;.proto&lt;/code&gt; file, but will not allow setting HTTP paths, request parameters or similar&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;additional &lt;code&gt;.proto&lt;/code&gt; modifications to use a custom mapping 
  &lt;ul&gt; 
   &lt;li&gt;relies on parameters in the &lt;code&gt;.proto&lt;/code&gt; file to set custom HTTP mappings&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;no &lt;code&gt;.proto&lt;/code&gt; modifications, but use an external configuration file 
  &lt;ul&gt; 
   &lt;li&gt;relies on an external configuration file to set custom HTTP mappings&lt;/li&gt; 
   &lt;li&gt;mostly useful when the source proto file isn&#39;t under your control&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Using the default mapping&lt;/h4&gt; 
&lt;p&gt;This requires no additional modification to the &lt;code&gt;.proto&lt;/code&gt; file but does require enabling a specific option when executing the plugin. The &lt;code&gt;generate_unbound_methods&lt;/code&gt; should be enabled.&lt;/p&gt; 
&lt;p&gt;Here&#39;s what a &lt;code&gt;buf.gen.yaml&lt;/code&gt; file might look like with this option enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With &lt;code&gt;protoc&lt;/code&gt; (just the grpc-gateway stubs):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt generate_unbound_methods=true \
    your/service/v1/your_service.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. With custom annotations&lt;/h4&gt; 
&lt;p&gt;Add a &lt;a href=&quot;https://github.com/googleapis/googleapis/raw/master/google/api/http.proto#L46&quot;&gt;&lt;code&gt;google.api.http&lt;/code&gt;&lt;/a&gt; annotation to your .proto file&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;your_service.proto&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-diff&quot;&gt; syntax = &quot;proto3&quot;;
 package your.service.v1;
 option go_package = &quot;github.com/yourorg/yourprotos/gen/go/your/service/v1&quot;;
+
+import &quot;google/api/annotations.proto&quot;;
+
 message StringMessage {
   string value = 1;
 }

 service YourService {
-  rpc Echo(StringMessage) returns (StringMessage) {}
+  rpc Echo(StringMessage) returns (StringMessage) {
+    option (google.api.http) = {
+      post: &quot;/v1/example/echo&quot;
+      body: &quot;*&quot;
+    };
+  }
 }
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You will need to provide the required third party protobuf files to the protobuf compiler. If you are using &lt;a href=&quot;https://github.com/bufbuild/buf&quot;&gt;buf&lt;/a&gt;, this dependency can be added to the &lt;code&gt;deps&lt;/code&gt; array in your &lt;code&gt;buf.yaml&lt;/code&gt; under the name &lt;code&gt;buf.build/googleapis/googleapis&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
name: buf.build/yourorg/myprotos
deps:
  - buf.build/googleapis/googleapis
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Always run &lt;code&gt;buf dep update&lt;/code&gt; after adding a dependency to your &lt;code&gt;buf.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/grpc-ecosystem/grpc-gateway/main/examples/internal/proto/examplepb/a_bit_of_everything.proto&quot;&gt;a_bit_of_everything.proto&lt;/a&gt; for examples of more annotations you can add to customize gateway behavior and generated OpenAPI output.&lt;/p&gt; 
&lt;p&gt;Here&#39;s what a &lt;code&gt;buf.gen.yaml&lt;/code&gt; file might look like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using &lt;code&gt;protoc&lt;/code&gt; to generate stubs, you need to ensure the required dependencies are available to the compiler at compile time. These can be found by manually cloning and copying the relevant files from the &lt;a href=&quot;https://github.com/googleapis/googleapis&quot;&gt;googleapis repository&lt;/a&gt;, and providing them to &lt;code&gt;protoc&lt;/code&gt; when running. The files you will need are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;google/api/annotations.proto
google/api/field_behavior.proto
google/api/http.proto
google/api/httpbody.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here&#39;s what a &lt;code&gt;protoc&lt;/code&gt; execution might look like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    your/service/v1/your_service.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. External configuration&lt;/h4&gt; 
&lt;p&gt;If you do not want to (or cannot) modify the proto file for use with gRPC-Gateway you can alternatively use an external &lt;a href=&quot;https://cloud.google.com/endpoints/docs/grpc/grpc-service-config&quot;&gt;gRPC Service Configuration&lt;/a&gt; file. &lt;a href=&quot;https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/&quot;&gt;Check our documentation&lt;/a&gt; for more information. This is best combined with the &lt;code&gt;standalone=true&lt;/code&gt; option to generate a file that can live in its own package, separate from the files generated by the source protobuf file.&lt;/p&gt; 
&lt;p&gt;Here&#39;s what a &lt;code&gt;buf.gen.yaml&lt;/code&gt; file might look like with this option enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With &lt;code&gt;protoc&lt;/code&gt; (just the grpc-gateway stubs):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;protoc -I . --grpc-gateway_out ./gen/go \
    --grpc-gateway_opt paths=source_relative \
    --grpc-gateway_opt grpc_api_configuration=path/to/config.yaml \
    --grpc-gateway_opt standalone=true \
    your/service/v1/your_service.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5. Write an entrypoint for the HTTP reverse-proxy server&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
  &quot;context&quot;
  &quot;flag&quot;
  &quot;net/http&quot;

  &quot;github.com/grpc-ecosystem/grpc-gateway/v2/runtime&quot;
  &quot;google.golang.org/grpc&quot;
  &quot;google.golang.org/grpc/credentials/insecure&quot;
  &quot;google.golang.org/grpc/grpclog&quot;

  gw &quot;github.com/yourorg/yourrepo/proto/gen/go/your/service/v1/your_service&quot;  // Update
)

var (
  // command-line options:
  // gRPC server endpoint
  grpcServerEndpoint = flag.String(&quot;grpc-server-endpoint&quot;,  &quot;localhost:9090&quot;, &quot;gRPC server endpoint&quot;)
)

func run() error {
  ctx := context.Background()
  ctx, cancel := context.WithCancel(ctx)
  defer cancel()

  // Register gRPC server endpoint
  // Note: Make sure the gRPC server is running properly and accessible
  mux := runtime.NewServeMux()
  opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}
  err := gw.RegisterYourServiceHandlerFromEndpoint(ctx, mux,  *grpcServerEndpoint, opts)
  if err != nil {
    return err
  }

  // Start HTTP server (and proxy calls to gRPC server endpoint)
  return http.ListenAndServe(&quot;:8081&quot;, mux)
}

func main() {
  flag.Parse()

  if err := run(); err != nil {
    grpclog.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;6. (Optional) Generate OpenAPI definitions using &lt;code&gt;protoc-gen-openapiv2&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Here&#39;s what a &lt;code&gt;buf.gen.yaml&lt;/code&gt; file might look like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-go
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-go-grpc
    out: gen/go
    opt:
      - paths=source_relative
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - generate_unbound_methods=true
  - local: protoc-gen-openapiv2
    out: gen/go
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the custom protobuf annotations supported by &lt;code&gt;protoc-gen-openapiv2&lt;/code&gt;, we need another dependency added to our protobuf generation step. If you are using &lt;code&gt;buf&lt;/code&gt;, you can add the &lt;code&gt;buf.build/grpc-ecosystem/grpc-gateway&lt;/code&gt; dependency to your &lt;code&gt;deps&lt;/code&gt; array:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
name: buf.build/yourorg/myprotos
deps:
  - buf.build/googleapis/googleapis
  - buf.build/grpc-ecosystem/grpc-gateway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With &lt;code&gt;protoc&lt;/code&gt; (just the swagger file):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;protoc -I . --openapiv2_out ./gen/openapiv2 \
    your/service/v1/your_service.proto
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using &lt;code&gt;protoc&lt;/code&gt; to generate stubs, you will need to copy the protobuf files from the &lt;code&gt;protoc-gen-openapiv2/options&lt;/code&gt; directory of this repository, and providing them to &lt;code&gt;protoc&lt;/code&gt; when running.&lt;/p&gt; 
&lt;p&gt;Note that this plugin also supports generating OpenAPI definitions for unannotated methods; use the &lt;code&gt;generate_unbound_methods&lt;/code&gt; option to enable this.&lt;/p&gt; 
&lt;p&gt;It is possible with the HTTP mapping for a gRPC service method to create duplicate mappings with the only difference being constraints on the path parameter.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;/v1/{name=projects/*}&lt;/code&gt; and &lt;code&gt;/v1/{name=organizations/*}&lt;/code&gt; both become &lt;code&gt;/v1/{name}&lt;/code&gt;. When this occurs the plugin will rename the path parameter with a &quot;_1&quot; (or &quot;_2&quot; etc) suffix to differentiate the different operations. So in the above example, the 2nd path would become &lt;code&gt;/v1/{name_1=organizations/*}&lt;/code&gt;. This can also cause OpenAPI clients to URL encode the &quot;/&quot; that is part of the path parameter as that is what OpenAPI defines in the specification. To allow gRPC gateway to accept the URL encoded slash and still route the request, use the UnescapingModeAllCharacters or UnescapingModeLegacy (which is the default currently though may change in future versions). See &lt;a href=&quot;https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/customizing_your_gateway/&quot;&gt;Customizing Your Gateway&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Usage with remote plugins&lt;/h2&gt; 
&lt;p&gt;As an alternative to all of the above, you can use &lt;code&gt;buf&lt;/code&gt; with &lt;a href=&quot;https://buf.build/docs/bsr/remote-plugins/usage&quot;&gt;remote plugins&lt;/a&gt; to manage plugin versions and generation. An example &lt;code&gt;buf.gen.yaml&lt;/code&gt; using remote plugin generation looks like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - remote: buf.build/protocolbuffers/go:v1.31.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc/go:v1.3.0
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/gateway:v2.16.2
    out: gen/go
    opt:
      - paths=source_relative
  - remote: buf.build/grpc-ecosystem/openapiv2:v2.16.2
    out: gen/openapiv2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This requires no local installation of any plugins. Be careful to use the same version of the generator as the runtime library, i.e. if using &lt;code&gt;v2.16.2&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ go get github.com/grpc-ecosystem/grpc-gateway/v2@v2.16.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get the same version of the runtime in your &lt;code&gt;go.mod&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that usage of remote plugins is incompatible with usage of external configuration files like &lt;a href=&quot;https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/#using-an-external-configuration-file&quot;&gt;grpc_api_configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Video intro&lt;/h2&gt; 
&lt;p&gt;This GopherCon UK 2019 presentation from our maintainer &lt;a href=&quot;https://github.com/johanbrandhorst&quot;&gt;@JohanBrandhorst&lt;/a&gt; provides a good intro to using the gRPC-Gateway. It uses the following boilerplate repo as a base: &lt;a href=&quot;https://github.com/johanbrandhorst/grpc-gateway-boilerplate&quot;&gt;https://github.com/johanbrandhorst/grpc-gateway-boilerplate&lt;/a&gt;.&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://www.youtube.com/watch?v=Pq1paKC-fXk&quot;&gt; &lt;img src=&quot;https://img.youtube.com/vi/Pq1paKC-fXk/0.jpg&quot; /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Parameters and flags&lt;/h2&gt; 
&lt;p&gt;When using &lt;code&gt;buf&lt;/code&gt; to generate stubs, flags and parameters are passed through the &lt;code&gt;opt&lt;/code&gt; field in your &lt;code&gt;buf.gen.yaml&lt;/code&gt; file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;version: v2
plugins:
  - local: protoc-gen-grpc-gateway
    out: gen/go
    opt:
      - paths=source_relative
      - grpc_api_configuration=path/to/config.yaml
      - standalone=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;During code generation with &lt;code&gt;protoc&lt;/code&gt;, flags to gRPC-Gateway tools must be passed through &lt;code&gt;protoc&lt;/code&gt; using one of 2 patterns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;as part of the &lt;code&gt;--&amp;lt;tool_suffix&amp;gt;_out&lt;/code&gt; &lt;code&gt;protoc&lt;/code&gt; parameter: &lt;code&gt;--&amp;lt;tool_suffix&amp;gt;_out=&amp;lt;flags&amp;gt;:&amp;lt;path&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;--grpc-gateway_out=repeated_path_param_separator=ssv:.
--openapiv2_out=repeated_path_param_separator=ssv:.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;using additional &lt;code&gt;--&amp;lt;tool_suffix&amp;gt;_opt&lt;/code&gt; parameters: &lt;code&gt;--&amp;lt;tool_suffix&amp;gt;_opt=&amp;lt;flag&amp;gt;[,&amp;lt;flag&amp;gt;]*&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;--grpc-gateway_opt repeated_path_param_separator=ssv
--openapiv2_opt repeated_path_param_separator=ssv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;More examples&lt;/h2&gt; 
&lt;p&gt;More examples are available under the &lt;code&gt;examples&lt;/code&gt; directory.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;proto/examplepb/echo_service.proto&lt;/code&gt;, &lt;code&gt;proto/examplepb/a_bit_of_everything.proto&lt;/code&gt;, &lt;code&gt;proto/examplepb/unannotated_echo_service.proto&lt;/code&gt;: service definition 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;proto/examplepb/echo_service.pb.go&lt;/code&gt;, &lt;code&gt;proto/examplepb/a_bit_of_everything.pb.go&lt;/code&gt;, &lt;code&gt;proto/examplepb/unannotated_echo_service.pb.go&lt;/code&gt;: [generated] stub of the service&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;proto/examplepb/echo_service.pb.gw.go&lt;/code&gt;, &lt;code&gt;proto/examplepb/a_bit_of_everything.pb.gw.go&lt;/code&gt;, &lt;code&gt;proto/examplepb/uannotated_echo_service.pb.gw.go&lt;/code&gt;: [generated] reverse proxy for the service&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;proto/examplepb/unannotated_echo_service.yaml&lt;/code&gt;: gRPC API Configuration for &lt;code&gt;unannotated_echo_service.proto&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;server/main.go&lt;/code&gt;: service implementation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;main.go&lt;/code&gt;: entrypoint of the generated reverse proxy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use the same port for custom HTTP handlers (e.g. serving &lt;code&gt;swagger.json&lt;/code&gt;), gRPC-Gateway, and a gRPC server, see &lt;a href=&quot;https://github.com/philips/grpc-gateway-example/raw/master/cmd/serve.go&quot;&gt;this example by CoreOS&lt;/a&gt; (and its accompanying &lt;a href=&quot;https://web.archive.org/web/20201112010739/https://coreos.com/blog/grpc-protobufs-swagger.html&quot;&gt;blog post&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/mynalabsai/grpc_gateway_media_example&quot;&gt;This example by neiro.ai&lt;/a&gt; (and its accompanying &lt;a href=&quot;https://medium.com/neiro-ai/grpc-gateway-for-media-api-by-neiro-9033caab12c8&quot;&gt;blog post&lt;/a&gt;) shows how mediafiles using &lt;code&gt;multipart/form-data&lt;/code&gt; can be integrated into rpc messages using a middleware.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Supported&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating JSON API handlers.&lt;/li&gt; 
 &lt;li&gt;Method parameters in the request body.&lt;/li&gt; 
 &lt;li&gt;Method parameters in the request path.&lt;/li&gt; 
 &lt;li&gt;Method parameters in the query string.&lt;/li&gt; 
 &lt;li&gt;Enum fields in the path parameter (including repeated enum fields).&lt;/li&gt; 
 &lt;li&gt;Mapping streaming APIs to newline-delimited JSON streams.&lt;/li&gt; 
 &lt;li&gt;Mapping HTTP headers with &lt;code&gt;Grpc-Metadata-&lt;/code&gt; prefix to gRPC metadata (prefixed with &lt;code&gt;grpcgateway-&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Optionally emitting API definitions for &lt;a href=&quot;https://swagger.io/docs/specification/2-0/basic-structure/&quot;&gt;OpenAPI (Swagger) v2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Setting &lt;a href=&quot;https://github.com/grpc/grpc/raw/master/doc/PROTOCOL-HTTP2.md#requests&quot;&gt;gRPC timeouts&lt;/a&gt; through inbound HTTP &lt;code&gt;Grpc-Timeout&lt;/code&gt; header.&lt;/li&gt; 
 &lt;li&gt;Partial support for &lt;a href=&quot;https://cloud.google.com/endpoints/docs/grpc/grpc-service-config&quot;&gt;gRPC API Configuration&lt;/a&gt; files as an alternative to annotation.&lt;/li&gt; 
 &lt;li&gt;Automatically translating PATCH requests into Field Mask gRPC requests. See &lt;a href=&quot;https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/patch_feature/&quot;&gt;the docs&lt;/a&gt; for more information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;No plan to support&lt;/h3&gt; 
&lt;p&gt;But patches are welcome.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Method parameters in HTTP headers.&lt;/li&gt; 
 &lt;li&gt;Handling trailer metadata.&lt;/li&gt; 
 &lt;li&gt;Encoding request/response body in XML.&lt;/li&gt; 
 &lt;li&gt;True bi-directional streaming.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Mapping gRPC to HTTP&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/raw/main/runtime/errors.go#L15&quot;&gt;How gRPC error codes map to HTTP status codes in the response&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;HTTP request source IP is added as &lt;code&gt;X-Forwarded-For&lt;/code&gt; gRPC request header.&lt;/li&gt; 
 &lt;li&gt;HTTP request host is added as &lt;code&gt;X-Forwarded-Host&lt;/code&gt; gRPC request header.&lt;/li&gt; 
 &lt;li&gt;HTTP &lt;code&gt;Authorization&lt;/code&gt; header is added as &lt;code&gt;authorization&lt;/code&gt; gRPC request header.&lt;/li&gt; 
 &lt;li&gt;Remaining Permanent HTTP header keys (as specified by the IANA &lt;a href=&quot;http://www.iana.org/assignments/message-headers/message-headers.xhtml&quot;&gt;here&lt;/a&gt;) are prefixed with &lt;code&gt;grpcgateway-&lt;/code&gt; and added with their values to gRPC request header.&lt;/li&gt; 
 &lt;li&gt;HTTP headers that start with &#39;Grpc-Metadata-&#39; are mapped to gRPC metadata (prefixed with &lt;code&gt;grpcgateway-&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;While configurable, the default {un,}marshaling uses &lt;a href=&quot;https://pkg.go.dev/google.golang.org/protobuf/encoding/protojson&quot;&gt;protojson&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The path template used to map gRPC service methods to HTTP endpoints supports the &lt;a href=&quot;https://github.com/googleapis/googleapis/raw/master/google/api/http.proto&quot;&gt;google.api.http&lt;/a&gt; path template syntax. For example, &lt;code&gt;/api/v1/{name=projects/*/topics/*}&lt;/code&gt; or &lt;code&gt;/prefix/{path=organizations/**}&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;http://github.com/grpc-ecosystem/grpc-gateway/blob/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;gRPC-Gateway is licensed under the BSD 3-Clause License. See &lt;a href=&quot;https://github.com/grpc-ecosystem/grpc-gateway/raw/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio-go</title>
      <link>https://github.com/minio/minio-go</link>
      <description>&lt;p&gt;MinIO Go client SDK for S3 compatible object storage&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Go Client SDK for Amazon S3 Compatible Cloud Storage &lt;a href=&quot;https://slack.min.io&quot;&gt;&lt;img src=&quot;https://slack.min.io/slack?type=svg&quot; alt=&quot;Slack&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://sourcegraph.com/github.com/minio/minio-go?badge&quot;&gt;&lt;img src=&quot;https://sourcegraph.com/github.com/minio/minio-go/-/badge.svg?sanitize=true&quot; alt=&quot;Sourcegraph&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/minio/minio-go/raw/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%20V2-blue.svg?sanitize=true&quot; alt=&quot;Apache V2 License&quot; /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;The MinIO Go Client SDK provides straightforward APIs to access any Amazon S3 compatible object storage.&lt;/p&gt; 
&lt;p&gt;This Quickstart Guide covers how to install the MinIO client SDK, connect to MinIO, and create a sample file uploader. For a complete list of APIs and examples, see the &lt;a href=&quot;https://pkg.go.dev/github.com/minio/minio-go/v7&quot;&gt;godoc documentation&lt;/a&gt; or &lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html&quot;&gt;Go Client API Reference&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;These examples presume a working &lt;a href=&quot;https://golang.org/doc/install&quot;&gt;Go development environment&lt;/a&gt; and the &lt;a href=&quot;https://min.io/docs/minio/linux/reference/minio-mc.html&quot;&gt;MinIO &lt;code&gt;mc&lt;/code&gt; command line tool&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Download from Github&lt;/h2&gt; 
&lt;p&gt;From your project directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go get github.com/minio/minio-go/v7
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Initialize a MinIO Client Object&lt;/h2&gt; 
&lt;p&gt;The MinIO client requires the following parameters to connect to an Amazon S3 compatible object storage:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;endpoint&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL to object storage service.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;_minio.Options_&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;All the options such as credentials, custom transport etc.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;log&quot;

	&quot;github.com/minio/minio-go/v7&quot;
	&quot;github.com/minio/minio-go/v7/pkg/credentials&quot;
)

func main() {
	endpoint := &quot;play.min.io&quot;
	accessKeyID := &quot;Q3AM3UQ867SPQQA43P2F&quot;
	secretAccessKey := &quot;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&quot;
	useSSL := true

	// Initialize minio client object.
	minioClient, err := minio.New(endpoint, &amp;amp;minio.Options{
		Creds:  credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;),
		Secure: useSSL,
	})
	if err != nil {
		log.Fatalln(err)
	}

	log.Printf(&quot;%#v\n&quot;, minioClient) // minioClient is now set up
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example - File Uploader&lt;/h2&gt; 
&lt;p&gt;This sample code connects to an object storage server, creates a bucket, and uploads a file to the bucket. It uses the MinIO &lt;code&gt;play&lt;/code&gt; server, a public MinIO cluster located at &lt;a href=&quot;https://play.min.io&quot;&gt;https://play.min.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;play&lt;/code&gt; server runs the latest stable version of MinIO and may be used for testing and development. The access credentials shown in this example are open to the public and all data uploaded to &lt;code&gt;play&lt;/code&gt; should be considered public and non-protected.&lt;/p&gt; 
&lt;h3&gt;FileUploader.go&lt;/h3&gt; 
&lt;p&gt;This example does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Connects to the MinIO &lt;code&gt;play&lt;/code&gt; server using the provided credentials.&lt;/li&gt; 
 &lt;li&gt;Creates a bucket named &lt;code&gt;testbucket&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Uploads a file named &lt;code&gt;testdata&lt;/code&gt; from &lt;code&gt;/tmp&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Verifies the file was created using &lt;code&gt;mc ls&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// FileUploader.go MinIO example
package main

import (
	&quot;context&quot;
	&quot;log&quot;

	&quot;github.com/minio/minio-go/v7&quot;
	&quot;github.com/minio/minio-go/v7/pkg/credentials&quot;
)

func main() {
	ctx := context.Background()
	endpoint := &quot;play.min.io&quot;
	accessKeyID := &quot;Q3AM3UQ867SPQQA43P2F&quot;
	secretAccessKey := &quot;zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG&quot;
	useSSL := true

	// Initialize minio client object.
	minioClient, err := minio.New(endpoint, &amp;amp;minio.Options{
		Creds:  credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;),
		Secure: useSSL,
	})
	if err != nil {
		log.Fatalln(err)
	}

	// Make a new bucket called testbucket.
	bucketName := &quot;testbucket&quot;
	location := &quot;us-east-1&quot;

	err = minioClient.MakeBucket(ctx, bucketName, minio.MakeBucketOptions{Region: location})
	if err != nil {
		// Check to see if we already own this bucket (which happens if you run this twice)
		exists, errBucketExists := minioClient.BucketExists(ctx, bucketName)
		if errBucketExists == nil &amp;amp;&amp;amp; exists {
			log.Printf(&quot;We already own %s\n&quot;, bucketName)
		} else {
			log.Fatalln(err)
		}
	} else {
		log.Printf(&quot;Successfully created %s\n&quot;, bucketName)
	}

	// Upload the test file
	// Change the value of filePath if the file is in another location
	objectName := &quot;testdata&quot;
	filePath := &quot;/tmp/testdata&quot;
	contentType := &quot;application/octet-stream&quot;

	// Upload the test file with FPutObject
	info, err := minioClient.FPutObject(ctx, bucketName, objectName, filePath, minio.PutObjectOptions{ContentType: contentType})
	if err != nil {
		log.Fatalln(err)
	}

	log.Printf(&quot;Successfully uploaded %s of size %d\n&quot;, objectName, info.Size)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;1. Create a test file containing data:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can do this with &lt;code&gt;dd&lt;/code&gt; on Linux or macOS systems:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;dd if=/dev/urandom of=/tmp/testdata bs=2048 count=10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or &lt;code&gt;fsutil&lt;/code&gt; on Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;fsutil file createnew &quot;C:\Users\&amp;lt;username&amp;gt;\Desktop\sample.txt&quot; 20480
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2. Run FileUploader with the following commands:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go mod init example/FileUploader
go get github.com/minio/minio-go/v7
go get github.com/minio/minio-go/v7/pkg/credentials
go run FileUploader.go
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The output resembles the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;2023/11/01 14:27:55 Successfully created testbucket
2023/11/01 14:27:55 Successfully uploaded testdata of size 20480
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;3. Verify the Uploaded File With &lt;code&gt;mc ls&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;mc ls play/testbucket
[2023-11-01 14:27:55 UTC]  20KiB STANDARD TestDataFile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API Reference&lt;/h2&gt; 
&lt;p&gt;The full API Reference is available here.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html&quot;&gt;Complete API Reference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Bucket Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#MakeBucket&quot;&gt;&lt;code&gt;MakeBucket&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#ListBuckets&quot;&gt;&lt;code&gt;ListBuckets&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#BucketExists&quot;&gt;&lt;code&gt;BucketExists&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#RemoveBucket&quot;&gt;&lt;code&gt;RemoveBucket&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#ListObjects&quot;&gt;&lt;code&gt;ListObjects&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#ListIncompleteUploads&quot;&gt;&lt;code&gt;ListIncompleteUploads&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Bucket policy Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#SetBucketPolicy&quot;&gt;&lt;code&gt;SetBucketPolicy&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#GetBucketPolicy&quot;&gt;&lt;code&gt;GetBucketPolicy&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Bucket notification Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#SetBucketNotification&quot;&gt;&lt;code&gt;SetBucketNotification&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#GetBucketNotification&quot;&gt;&lt;code&gt;GetBucketNotification&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#RemoveAllBucketNotification&quot;&gt;&lt;code&gt;RemoveAllBucketNotification&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#ListenBucketNotification&quot;&gt;&lt;code&gt;ListenBucketNotification&lt;/code&gt;&lt;/a&gt; (MinIO Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#ListenNotification&quot;&gt;&lt;code&gt;ListenNotification&lt;/code&gt;&lt;/a&gt; (MinIO Extension)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : File Object Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#FPutObject&quot;&gt;&lt;code&gt;FPutObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#FGetObject&quot;&gt;&lt;code&gt;FGetObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Object Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#GetObject&quot;&gt;&lt;code&gt;GetObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PutObject&quot;&gt;&lt;code&gt;PutObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PutObjectStreaming&quot;&gt;&lt;code&gt;PutObjectStreaming&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#StatObject&quot;&gt;&lt;code&gt;StatObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#CopyObject&quot;&gt;&lt;code&gt;CopyObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#RemoveObject&quot;&gt;&lt;code&gt;RemoveObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#RemoveObjects&quot;&gt;&lt;code&gt;RemoveObjects&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#RemoveIncompleteUpload&quot;&gt;&lt;code&gt;RemoveIncompleteUpload&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#SelectObjectContent&quot;&gt;&lt;code&gt;SelectObjectContent&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Presigned Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PresignedGetObject&quot;&gt;&lt;code&gt;PresignedGetObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PresignedPutObject&quot;&gt;&lt;code&gt;PresignedPutObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PresignedHeadObject&quot;&gt;&lt;code&gt;PresignedHeadObject&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#PresignedPostPolicy&quot;&gt;&lt;code&gt;PresignedPostPolicy&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Reference : Client custom settings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#SetAppInfo&quot;&gt;&lt;code&gt;SetAppInfo&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#TraceOn&quot;&gt;&lt;code&gt;TraceOn&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html#TraceOff&quot;&gt;&lt;code&gt;TraceOff&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Full Examples&lt;/h2&gt; 
&lt;h3&gt;Full Examples : Bucket Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/makebucket.go&quot;&gt;makebucket.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/listbuckets.go&quot;&gt;listbuckets.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/bucketexists.go&quot;&gt;bucketexists.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removebucket.go&quot;&gt;removebucket.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/listobjects.go&quot;&gt;listobjects.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/listobjectsV2.go&quot;&gt;listobjectsV2.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/listincompleteuploads.go&quot;&gt;listincompleteuploads.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Bucket policy Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/setbucketpolicy.go&quot;&gt;setbucketpolicy.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getbucketpolicy.go&quot;&gt;getbucketpolicy.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/listbucketpolicies.go&quot;&gt;listbucketpolicies.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Bucket lifecycle Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/setbucketlifecycle.go&quot;&gt;setbucketlifecycle.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getbucketlifecycle.go&quot;&gt;getbucketlifecycle.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Bucket encryption Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/setbucketencryption.go&quot;&gt;setbucketencryption.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getbucketencryption.go&quot;&gt;getbucketencryption.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removebucketencryption.go&quot;&gt;removebucketencryption.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Bucket replication Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/setbucketreplication.go&quot;&gt;setbucketreplication.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getbucketreplication.go&quot;&gt;getbucketreplication.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removebucketreplication.go&quot;&gt;removebucketreplication.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Bucket notification Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/setbucketnotification.go&quot;&gt;setbucketnotification.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getbucketnotification.go&quot;&gt;getbucketnotification.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removeallbucketnotification.go&quot;&gt;removeallbucketnotification.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/minio/listenbucketnotification.go&quot;&gt;listenbucketnotification.go&lt;/a&gt; (MinIO Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/minio/listen-notification.go&quot;&gt;listennotification.go&lt;/a&gt; (MinIO Extension)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : File Object Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/fputobject.go&quot;&gt;fputobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/fgetobject.go&quot;&gt;fgetobject.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Object Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/putobject.go&quot;&gt;putobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/getobject.go&quot;&gt;getobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/statobject.go&quot;&gt;statobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/copyobject.go&quot;&gt;copyobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removeobject.go&quot;&gt;removeobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removeincompleteupload.go&quot;&gt;removeincompleteupload.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/removeobjects.go&quot;&gt;removeobjects.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Encrypted Object Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/put-encrypted-object.go&quot;&gt;put-encrypted-object.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/get-encrypted-object.go&quot;&gt;get-encrypted-object.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/fputencrypted-object.go&quot;&gt;fput-encrypted-object.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Full Examples : Presigned Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/presignedgetobject.go&quot;&gt;presignedgetobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/presignedputobject.go&quot;&gt;presignedputobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/presignedheadobject.go&quot;&gt;presignedheadobject.go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/examples/s3/presignedpostpolicy.go&quot;&gt;presignedpostpolicy.go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/minio/minio-go/v7&quot;&gt;Godoc Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/kubernetes/upstream/index.html&quot;&gt;Complete Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://min.io/docs/minio/linux/developers/go/API.html&quot;&gt;MinIO Go Client SDK API Reference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/minio/minio-go/raw/master/CONTRIBUTING.md&quot;&gt;Contributors Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This SDK is distributed under the &lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;Apache License, Version 2.0&lt;/a&gt;, see &lt;a href=&quot;https://github.com/minio/minio-go/raw/master/LICENSE&quot;&gt;LICENSE&lt;/a&gt; and &lt;a href=&quot;https://github.com/minio/minio-go/raw/master/NOTICE&quot;&gt;NOTICE&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/go-github</title>
      <link>https://github.com/google/go-github</link>
      <description>&lt;p&gt;Go library for accessing the GitHub v3 API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;go-github&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/google/go-github/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/google/go-github?sort=semver&quot; alt=&quot;go-github release (latest SemVer)&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/google/go-github/v74/github&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=godoc&amp;amp;message=reference&amp;amp;color=blue&quot; alt=&quot;Go Reference&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/google/go-github/actions/workflows/tests.yml&quot;&gt;&lt;img src=&quot;https://github.com/google/go-github/actions/workflows/tests.yml/badge.svg?branch=master&quot; alt=&quot;Test Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/google/go-github&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/google/go-github/branch/master/graph/badge.svg?sanitize=true&quot; alt=&quot;Test Coverage&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://groups.google.com/group/go-github&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discuss-go--github%40googlegroups.com-blue.svg?sanitize=true&quot; alt=&quot;Discuss at go-github@googlegroups.com&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/796&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/796/badge&quot; alt=&quot;CII Best Practices&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;go-github is a Go client library for accessing the &lt;a href=&quot;https://docs.github.com/en/rest&quot;&gt;GitHub API v3&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;go-github tracks &lt;a href=&quot;https://golang.org/doc/devel/release.html#policy&quot;&gt;Go&#39;s version support policy&lt;/a&gt; supporting any minor version of the latest two major releases of Go and the go directive in go.mod reflects that. We do our best not to break older versions of Go if we don&#39;t have to, but we don&#39;t explicitly test older versions and as of Go 1.23 the go directive in go.mod declares a hard required &lt;em&gt;minimum&lt;/em&gt; version of Go to use with this module and this &lt;em&gt;must&lt;/em&gt; be greater than or equal to the go line of all dependencies so go-github will require the N-1 major release of Go by default.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;If you&#39;re interested in using the &lt;a href=&quot;https://developer.github.com/v4/&quot;&gt;GraphQL API v4&lt;/a&gt;, the recommended library is &lt;a href=&quot;https://github.com/shurcooL/githubv4&quot;&gt;shurcooL/githubv4&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-github is compatible with modern Go releases in module mode, with Go installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;go get github.com/google/go-github/v74
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will resolve and add the package to the current development module, along with its dependencies.&lt;/p&gt; 
&lt;p&gt;Alternatively the same can be achieved if you use import in a package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import &quot;github.com/google/go-github/v74/github&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and run &lt;code&gt;go get&lt;/code&gt; without parameters.&lt;/p&gt; 
&lt;p&gt;Finally, to use the top-of-trunk version of this repo, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;go get github.com/google/go-github/v74@master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import &quot;github.com/google/go-github/v74/github&quot;	// with go modules enabled (GO111MODULE=on or outside GOPATH)
import &quot;github.com/google/go-github/github&quot; // with go modules disabled
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Construct a new GitHub client, then use the various services on the client to access different parts of the GitHub API. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := github.NewClient(nil)

// list all organizations for user &quot;willnorris&quot;
orgs, _, err := client.Organizations.List(context.Background(), &quot;willnorris&quot;, nil)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Some API methods have optional parameters that can be passed. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := github.NewClient(nil)

// list public repositories for org &quot;github&quot;
opt := &amp;amp;github.RepositoryListByOrgOptions{Type: &quot;public&quot;}
repos, _, err := client.Repositories.ListByOrg(context.Background(), &quot;github&quot;, opt)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The services of a client divide the API into logical chunks and correspond to the structure of the &lt;a href=&quot;https://docs.github.com/en/rest&quot;&gt;GitHub API documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;NOTE: Using the &lt;a href=&quot;https://pkg.go.dev/context&quot;&gt;context&lt;/a&gt; package, one can easily pass cancellation signals and deadlines to various services of the client for handling a request. In case there is no context available, then &lt;code&gt;context.Background()&lt;/code&gt; can be used as a starting point.&lt;/p&gt; 
&lt;p&gt;For more sample code snippets, head over to the &lt;a href=&quot;https://github.com/google/go-github/tree/master/example&quot;&gt;example&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;WithAuthToken&lt;/code&gt; method to configure your client to authenticate using an OAuth token (for example, a &lt;a href=&quot;https://github.com/blog/1509-personal-api-tokens&quot;&gt;personal access token&lt;/a&gt;). This is what is needed for a majority of use cases aside from GitHub Apps.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := github.NewClient(nil).WithAuthToken(&quot;... your access token ...&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that when using an authenticated Client, all calls made by the client will include the specified OAuth token. Therefore, authenticated clients should almost never be shared between different users.&lt;/p&gt; 
&lt;p&gt;For API methods that require HTTP Basic Authentication, use the &lt;a href=&quot;https://pkg.go.dev/github.com/google/go-github/v74/github#BasicAuthTransport&quot;&gt;&lt;code&gt;BasicAuthTransport&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;As a GitHub App&lt;/h4&gt; 
&lt;p&gt;GitHub Apps authentication can be provided by different pkgs like &lt;a href=&quot;https://github.com/bradleyfalzon/ghinstallation&quot;&gt;bradleyfalzon/ghinstallation&lt;/a&gt; or &lt;a href=&quot;https://github.com/jferrl/go-githubauth&quot;&gt;jferrl/go-githubauth&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Most endpoints (ex. &lt;a href=&quot;https://docs.github.com/en/rest/rate-limit#get-rate-limit-status-for-the-authenticated-user&quot;&gt;&lt;code&gt;GET /rate_limit&lt;/code&gt;&lt;/a&gt;) require access token authentication while a few others (ex. &lt;a href=&quot;https://docs.github.com/en/rest/apps/webhooks#list-deliveries-for-an-app-webhook&quot;&gt;&lt;code&gt;GET /app/hook/deliveries&lt;/code&gt;&lt;/a&gt;) require &lt;a href=&quot;https://docs.github.com/en/developers/apps/building-github-apps/authenticating-with-github-apps#authenticating-as-a-github-app&quot;&gt;JWT&lt;/a&gt; authentication.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;code&gt;ghinstallation&lt;/code&gt; provides &lt;code&gt;Transport&lt;/code&gt;, which implements &lt;code&gt;http.RoundTripper&lt;/code&gt; to provide authentication as an installation for GitHub Apps.&lt;/p&gt; 
&lt;p&gt;Here is an example of how to authenticate as a GitHub App using the &lt;code&gt;ghinstallation&lt;/code&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
	&quot;net/http&quot;

	&quot;github.com/bradleyfalzon/ghinstallation/v2&quot;
	&quot;github.com/google/go-github/v74/github&quot;
)

func main() {
	// Wrap the shared transport for use with the integration ID 1 authenticating with installation ID 99.
	itr, err := ghinstallation.NewKeyFromFile(http.DefaultTransport, 1, 99, &quot;2016-10-19.private-key.pem&quot;)

	// Or for endpoints that require JWT authentication
	// itr, err := ghinstallation.NewAppsTransportKeyFromFile(http.DefaultTransport, 1, &quot;2016-10-19.private-key.pem&quot;)

	if err != nil {
		// Handle error.
	}

	// Use installation transport with client.
	client := github.NewClient(&amp;amp;http.Client{Transport: itr})

	// Use client...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;go-githubauth&lt;/code&gt; implements a set of &lt;code&gt;oauth2.TokenSource&lt;/code&gt; to be used with &lt;code&gt;oauth2.Client&lt;/code&gt;. An &lt;code&gt;oauth2.Client&lt;/code&gt; can be injected into the &lt;code&gt;github.Client&lt;/code&gt; to authenticate requests.&lt;/p&gt; 
&lt;p&gt;Other example using &lt;code&gt;go-githubauth&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;
	&quot;strconv&quot;

	&quot;github.com/google/go-github/v74/github&quot;
	&quot;github.com/jferrl/go-githubauth&quot;
	&quot;golang.org/x/oauth2&quot;
)

func main() {
	privateKey := []byte(os.Getenv(&quot;GITHUB_APP_PRIVATE_KEY&quot;))

	appTokenSource, err := githubauth.NewApplicationTokenSource(1112, privateKey)
	if err != nil {
		fmt.Println(&quot;Error creating application token source:&quot;, err)
		return
	 }

	installationTokenSource := githubauth.NewInstallationTokenSource(1113, appTokenSource)

	// oauth2.NewClient uses oauth2.ReuseTokenSource to reuse the token until it expires.
	// The token will be automatically refreshed when it expires.
	// InstallationTokenSource has the mechanism to refresh the token when it expires.
	httpClient := oauth2.NewClient(context.Background(), installationTokenSource)

	client := github.NewClient(httpClient)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: In order to interact with certain APIs, for example writing a file to a repo, one must generate an installation token using the installation ID of the GitHub app and authenticate with the OAuth method mentioned above. See the examples.&lt;/p&gt; 
&lt;h3&gt;Rate Limiting&lt;/h3&gt; 
&lt;p&gt;GitHub imposes rate limits on all API clients. The &lt;a href=&quot;https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-primary-rate-limits&quot;&gt;primary rate limit&lt;/a&gt; is the limit to the number of REST API requests that a client can make within a specific amount of time. This limit helps prevent abuse and denial-of-service attacks, and ensures that the API remains available for all users. Some endpoints, like the search endpoints, have more restrictive limits. Unauthenticated clients may request public data but have a low rate limit, while authenticated clients have rate limits based on the client identity.&lt;/p&gt; 
&lt;p&gt;In addition to primary rate limits, GitHub enforces &lt;a href=&quot;https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-secondary-rate-limits&quot;&gt;secondary rate limits&lt;/a&gt; in order to prevent abuse and keep the API available for all users. Secondary rate limits generally limit the number of concurrent requests that a client can make.&lt;/p&gt; 
&lt;p&gt;The client returned &lt;code&gt;Response.Rate&lt;/code&gt; value contains the rate limit information from the most recent API call. If a recent enough response isn&#39;t available, you can use the client &lt;code&gt;RateLimits&lt;/code&gt; service to fetch the most up-to-date rate limit data for the client.&lt;/p&gt; 
&lt;p&gt;To detect a primary API rate limit error, you can check if the error is a &lt;code&gt;RateLimitError&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;repos, _, err := client.Repositories.List(ctx, &quot;&quot;, nil)
var rateErr *github.RateLimitError
if errors.As(err, &amp;amp;rateError) {
	log.Printf(&quot;hit primary rate limit, used %d of %d\n&quot;, rateErr.Rate.Used, rateErr.rate.Limit)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To detect an API secondary rate limit error, you can check if the error is an &lt;code&gt;AbuseRateLimitError&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;repos, _, err := client.Repositories.List(ctx, &quot;&quot;, nil)
var rateErr *github.AbuseRateLimitError
if errors.As(err, &amp;amp;rateErr) {
	log.Printf(&quot;hit secondary rate limit, retry after %v\n&quot;, rateErr.RetryAfter)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you hit the primary rate limit, you can use the &lt;code&gt;SleepUntilPrimaryRateLimitResetWhenRateLimited&lt;/code&gt; method to block until the rate limit is reset.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;repos, _, err := client.Repositories.List(context.WithValue(ctx, github.SleepUntilPrimaryRateLimitResetWhenRateLimited, true), &quot;&quot;, nil)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need to make a request even if the rate limit has been hit you can use the &lt;code&gt;BypassRateLimitCheck&lt;/code&gt; method to bypass the rate limit check and make the request anyway.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;repos, _, err := client.Repositories.List(context.WithValue(ctx, github.BypassRateLimitCheck, true), &quot;&quot;, nil)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more advanced use cases, you can use &lt;a href=&quot;https://github.com/gofri/go-github-ratelimit&quot;&gt;gofri/go-github-ratelimit&lt;/a&gt; which provides a middleware (&lt;code&gt;http.RoundTripper&lt;/code&gt;) that handles both the primary rate limit and secondary rate limit for the GitHub API. In this case you can set the client &lt;code&gt;DisableRateLimitCheck&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; so the client doesn&#39;t track the rate limit usage.&lt;/p&gt; 
&lt;p&gt;If the client is an &lt;a href=&quot;https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#primary-rate-limit-for-oauth-apps&quot;&gt;OAuth app&lt;/a&gt; you can use the apps higher rate limit to request public data by using the &lt;code&gt;UnauthenticatedRateLimitedTransport&lt;/code&gt; to make calls as the app instead of as the user.&lt;/p&gt; 
&lt;h3&gt;Accepted Status&lt;/h3&gt; 
&lt;p&gt;Some endpoints may return a 202 Accepted status code, meaning that the information required is not yet ready and was scheduled to be gathered on the GitHub side. Methods known to behave like this are documented specifying this behavior.&lt;/p&gt; 
&lt;p&gt;To detect this condition of error, you can check if its type is &lt;code&gt;*github.AcceptedError&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;stats, _, err := client.Repositories.ListContributorsStats(ctx, org, repo)
if _, ok := err.(*github.AcceptedError); ok {
	log.Println(&quot;scheduled on GitHub side&quot;)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Conditional Requests&lt;/h3&gt; 
&lt;p&gt;The GitHub REST API has good support for &lt;a href=&quot;https://docs.github.com/en/rest/using-the-rest-api/best-practices-for-using-the-rest-api?apiVersion=2022-11-28#use-conditional-requests-if-appropriate&quot;&gt;conditional HTTP requests&lt;/a&gt; via the &lt;code&gt;ETag&lt;/code&gt; header which will help prevent you from burning through your rate limit, as well as help speed up your application. &lt;code&gt;go-github&lt;/code&gt; does not handle conditional requests directly, but is instead designed to work with a caching &lt;code&gt;http.Transport&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Typically, an &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc9111&quot;&gt;RFC 9111&lt;/a&gt; compliant HTTP cache such as &lt;a href=&quot;https://github.com/bartventer/httpcache&quot;&gt;bartventer/httpcache&lt;/a&gt; is recommended, ex:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
	&quot;github.com/bartventer/httpcache&quot;
	_ &quot;github.com/bartventer/httpcache/store/memcache&quot; //  Register the in-memory backend
)

client := github.NewClient(
	httpcache.NewClient(&quot;memcache://&quot;),
).WithAuthToken(os.Getenv(&quot;GITHUB_TOKEN&quot;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, the &lt;a href=&quot;https://github.com/bored-engineer/github-conditional-http-transport&quot;&gt;bored-engineer/github-conditional-http-transport&lt;/a&gt; package relies on (undocumented) GitHub specific cache logic and is recommended when making requests using short-lived credentials such as a &lt;a href=&quot;https://docs.github.com/en/apps/creating-github-apps/authenticating-with-a-github-app/authenticating-as-a-github-app-installation&quot;&gt;GitHub App installation token&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Creating and Updating Resources&lt;/h3&gt; 
&lt;p&gt;All structs for GitHub resources use pointer values for all non-repeated fields. This allows distinguishing between unset fields and those set to a zero-value. Helper functions have been provided to easily create these pointers for string, bool, and int values. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// create a new private repository named &quot;foo&quot;
repo := &amp;amp;github.Repository{
	Name:    github.Ptr(&quot;foo&quot;),
	Private: github.Ptr(true),
}
client.Repositories.Create(ctx, &quot;&quot;, repo)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Users who have worked with protocol buffers should find this pattern familiar.&lt;/p&gt; 
&lt;h3&gt;Pagination&lt;/h3&gt; 
&lt;p&gt;All requests for resource collections (repos, pull requests, issues, etc.) support pagination. Pagination options are described in the &lt;code&gt;github.ListOptions&lt;/code&gt; struct and passed to the list methods directly or as an embedded type of a more specific list options struct (for example &lt;code&gt;github.PullRequestListOptions&lt;/code&gt;). Pages information is available via the &lt;code&gt;github.Response&lt;/code&gt; struct.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := github.NewClient(nil)

opt := &amp;amp;github.RepositoryListByOrgOptions{
	ListOptions: github.ListOptions{PerPage: 10},
}
// get all pages of results
var allRepos []*github.Repository
for {
	repos, resp, err := client.Repositories.ListByOrg(ctx, &quot;github&quot;, opt)
	if err != nil {
		return err
	}
	allRepos = append(allRepos, repos...)
	if resp.NextPage == 0 {
		break
	}
	opt.Page = resp.NextPage
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Iterators (&lt;strong&gt;experimental&lt;/strong&gt;)&lt;/h4&gt; 
&lt;p&gt;Go v1.23 introduces the new &lt;code&gt;iter&lt;/code&gt; package.&lt;/p&gt; 
&lt;p&gt;With the &lt;code&gt;enrichman/gh-iter&lt;/code&gt; package, it is possible to create iterators for &lt;code&gt;go-github&lt;/code&gt;. The iterator will handle pagination for you, looping through all the available results.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := github.NewClient(nil)
var allRepos []*github.Repository

// create an iterator and start looping through all the results
repos := ghiter.NewFromFn1(client.Repositories.ListByOrg, &quot;github&quot;)
for repo := range repos.All() {
	allRepos = append(allRepos, repo)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For complete usage of &lt;code&gt;enrichman/gh-iter&lt;/code&gt;, see the full &lt;a href=&quot;https://github.com/enrichman/gh-iter&quot;&gt;package docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Middleware&lt;/h4&gt; 
&lt;p&gt;You can use &lt;a href=&quot;https://github.com/gofri/go-github-pagination&quot;&gt;gofri/go-github-pagination&lt;/a&gt; to handle pagination for you. It supports both sync and async modes, as well as customizations.&lt;br /&gt; By default, the middleware automatically paginates through all pages, aggregates results, and returns them as an array.&lt;br /&gt; See &lt;code&gt;example/ratelimit/main.go&lt;/code&gt; for usage.&lt;/p&gt; 
&lt;h3&gt;Webhooks&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;go-github&lt;/code&gt; provides structs for almost all &lt;a href=&quot;https://docs.github.com/en/developers/webhooks-and-events/webhooks/webhook-events-and-payloads&quot;&gt;GitHub webhook events&lt;/a&gt; as well as functions to validate them and unmarshal JSON payloads from &lt;code&gt;http.Request&lt;/code&gt; structs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func (s *GitHubEventMonitor) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	payload, err := github.ValidatePayload(r, s.webhookSecretKey)
	if err != nil { ... }
	event, err := github.ParseWebHook(github.WebHookType(r), payload)
	if err != nil { ... }
	switch event := event.(type) {
	case *github.CommitCommentEvent:
		processCommitCommentEvent(event)
	case *github.CreateEvent:
		processCreateEvent(event)
	...
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Furthermore, there are libraries like &lt;a href=&quot;https://github.com/cbrgm/githubevents&quot;&gt;cbrgm/githubevents&lt;/a&gt; that build upon the example above and provide functions to subscribe callbacks to specific events.&lt;/p&gt; 
&lt;p&gt;For complete usage of go-github, see the full &lt;a href=&quot;https://pkg.go.dev/github.com/google/go-github/v74/github&quot;&gt;package docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Testing code that uses &lt;code&gt;go-github&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;The repo &lt;a href=&quot;https://github.com/migueleliasweb/go-github-mock&quot;&gt;migueleliasweb/go-github-mock&lt;/a&gt; provides a way to mock responses. Check the repo for more details.&lt;/p&gt; 
&lt;h3&gt;Integration Tests&lt;/h3&gt; 
&lt;p&gt;You can run integration tests from the &lt;code&gt;test&lt;/code&gt; directory. See the integration tests &lt;a href=&quot;https://raw.githubusercontent.com/google/go-github/master/test/README.md&quot;&gt;README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;I would like to cover the entire GitHub API and contributions are of course always welcome. The calling pattern is pretty well established, so adding new methods is relatively straightforward. See &lt;a href=&quot;https://raw.githubusercontent.com/google/go-github/master/CONTRIBUTING.md&quot;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;In general, go-github follows &lt;a href=&quot;https://semver.org/&quot;&gt;semver&lt;/a&gt; as closely as we can for tagging releases of the package. For self-contained libraries, the application of semantic versioning is relatively straightforward and generally understood. But because go-github is a client library for the GitHub API, which itself changes behavior, and because we are typically pretty aggressive about implementing preview features of the GitHub API, we&#39;ve adopted the following versioning policy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We increment the &lt;strong&gt;major version&lt;/strong&gt; with any incompatible change to non-preview functionality, including changes to the exported Go API surface or behavior of the API.&lt;/li&gt; 
 &lt;li&gt;We increment the &lt;strong&gt;minor version&lt;/strong&gt; with any backwards-compatible changes to functionality, as well as any changes to preview functionality in the GitHub API. GitHub makes no guarantee about the stability of preview functionality, so neither do we consider it a stable part of the go-github API.&lt;/li&gt; 
 &lt;li&gt;We increment the &lt;strong&gt;patch version&lt;/strong&gt; with any backwards-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Preview functionality may take the form of entire methods or simply additional data returned from an otherwise non-preview method. Refer to the GitHub API documentation for details on preview functionality.&lt;/p&gt; 
&lt;h3&gt;Calendar Versioning&lt;/h3&gt; 
&lt;p&gt;As of 2022-11-28, GitHub &lt;a href=&quot;https://github.blog/2022-11-28-to-infinity-and-beyond-enabling-the-future-of-githubs-rest-api-with-api-versioning/&quot;&gt;has announced&lt;/a&gt; that they are starting to version their v3 API based on &quot;calendar-versioning&quot;.&lt;/p&gt; 
&lt;p&gt;In practice, our goal is to make per-method version overrides (at least in the core library) rare and temporary.&lt;/p&gt; 
&lt;p&gt;Our understanding of the GitHub docs is that they will be revving the entire API to each new date-based version, even if only a few methods have breaking changes. Other methods will accept the new version with their existing functionality. So when a new date-based version of the GitHub API is released, we (the repo maintainers) plan to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;update each method that had breaking changes, overriding their per-method API version header. This may happen in one or multiple commits and PRs, and is all done in the main branch.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;once all of the methods with breaking changes have been updated, have a final commit that bumps the default API version, and remove all of the per-method overrides. That would now get a major version bump when the next go-github release is made.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Version Compatibility Table&lt;/h3&gt; 
&lt;p&gt;The following table identifies which version of the GitHub API is supported by this (and past) versions of this repo (go-github). Versions prior to 48.2.0 are not listed.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;go-github Version&lt;/th&gt; 
   &lt;th&gt;GitHub v3 API Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;74.0.0&lt;/td&gt; 
   &lt;td&gt;2022-11-28&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;...&lt;/td&gt; 
   &lt;td&gt;2022-11-28&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48.2.0&lt;/td&gt; 
   &lt;td&gt;2022-11-28&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This library is distributed under the BSD-style license found in the &lt;a href=&quot;https://raw.githubusercontent.com/google/go-github/master/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>joho/godotenv</title>
      <link>https://github.com/joho/godotenv</link>
      <description>&lt;p&gt;A Go port of Ruby&#39;s dotenv library (Loads environment variables from .env files)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GoDotEnv &lt;img src=&quot;https://github.com/joho/godotenv/workflows/CI/badge.svg?sanitize=true&quot; alt=&quot;CI&quot; /&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/joho/godotenv&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/joho/godotenv&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;A Go (golang) port of the Ruby &lt;a href=&quot;https://github.com/bkeepers/dotenv&quot;&gt;dotenv&lt;/a&gt; project (which loads env vars from a .env file).&lt;/p&gt; 
&lt;p&gt;From the original Library:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Storing configuration in the environment is one of the tenets of a twelve-factor app. Anything that is likely to change between deployment environments–such as resource handles for databases or credentials for external services–should be extracted from the code into environment variables.&lt;/p&gt; 
 &lt;p&gt;But it is not always practical to set environment variables on development machines or continuous integration servers where multiple projects are run. Dotenv load variables from a .env file into ENV when the environment is bootstrapped.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It can be used as a library (for loading in env for your own daemons etc.) or as a bin command.&lt;/p&gt; 
&lt;p&gt;There is test coverage and CI for both linuxish and Windows environments, but I make no guarantees about the bin version working on Windows.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;As a library&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get github.com/joho/godotenv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or if you want to use it as a bin command&lt;/p&gt; 
&lt;p&gt;go &amp;gt;= 1.17&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go install github.com/joho/godotenv/cmd/godotenv@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;go &amp;lt; 1.17&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;go get github.com/joho/godotenv/cmd/godotenv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Add your application configuration to your &lt;code&gt;.env&lt;/code&gt; file in the root of your project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;S3_BUCKET=YOURS3BUCKET
SECRET_KEY=YOURSECRETKEYGOESHERE
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then in your Go app you can do something like&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
    &quot;log&quot;
    &quot;os&quot;

    &quot;github.com/joho/godotenv&quot;
)

func main() {
  err := godotenv.Load()
  if err != nil {
    log.Fatal(&quot;Error loading .env file&quot;)
  }

  s3Bucket := os.Getenv(&quot;S3_BUCKET&quot;)
  secretKey := os.Getenv(&quot;SECRET_KEY&quot;)

  // now do something with s3 or whatever
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you&#39;re even lazier than that, you can just take advantage of the autoload package which will read in &lt;code&gt;.env&lt;/code&gt; on import&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import _ &quot;github.com/joho/godotenv/autoload&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;While &lt;code&gt;.env&lt;/code&gt; in the project root is the default, you don&#39;t have to be constrained, both examples below are 100% legit&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;godotenv.Load(&quot;somerandomfile&quot;)
godotenv.Load(&quot;filenumberone.env&quot;, &quot;filenumbertwo.env&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to be really fancy with your env file you can do comments and exports (below is a valid env file)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# I am a comment and that is OK
SOME_VAR=someval
FOO=BAR # comments at line end are OK too
export BAR=BAZ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or finally you can do YAML(ish) style&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;FOO: bar
BAR: baz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;as a final aside, if you don&#39;t want godotenv munging your env you can just get a map back instead&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;var myEnv map[string]string
myEnv, err := godotenv.Read()

s3Bucket := myEnv[&quot;S3_BUCKET&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... or from an &lt;code&gt;io.Reader&lt;/code&gt; instead of a local file&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;reader := getRemoteFile()
myEnv, err := godotenv.Parse(reader)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... or from a &lt;code&gt;string&lt;/code&gt; if you so desire&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;content := getRemoteFileContent()
myEnv, err := godotenv.Unmarshal(content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Precedence &amp;amp; Conventions&lt;/h3&gt; 
&lt;p&gt;Existing envs take precedence of envs that are loaded later.&lt;/p&gt; 
&lt;p&gt;The &lt;a href=&quot;https://github.com/bkeepers/dotenv#what-other-env-files-can-i-use&quot;&gt;convention&lt;/a&gt; for managing multiple environments (i.e. development, test, production) is to create an env named &lt;code&gt;{YOURAPP}_ENV&lt;/code&gt; and load envs in this order:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;env := os.Getenv(&quot;FOO_ENV&quot;)
if &quot;&quot; == env {
  env = &quot;development&quot;
}

godotenv.Load(&quot;.env.&quot; + env + &quot;.local&quot;)
if &quot;test&quot; != env {
  godotenv.Load(&quot;.env.local&quot;)
}
godotenv.Load(&quot;.env.&quot; + env)
godotenv.Load() // The Original .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need to, you can also use &lt;code&gt;godotenv.Overload()&lt;/code&gt; to defy this convention and overwrite existing envs instead of only supplanting them. Use with caution.&lt;/p&gt; 
&lt;h3&gt;Command Mode&lt;/h3&gt; 
&lt;p&gt;Assuming you&#39;ve installed the command as above and you&#39;ve got &lt;code&gt;$GOPATH/bin&lt;/code&gt; in your &lt;code&gt;$PATH&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;godotenv -f /some/path/to/.env some_command with some args
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you don&#39;t specify &lt;code&gt;-f&lt;/code&gt; it will fall back on the default of loading &lt;code&gt;.env&lt;/code&gt; in &lt;code&gt;PWD&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;By default, it won&#39;t override existing environment variables; you can do that with the &lt;code&gt;-o&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h3&gt;Writing Env Files&lt;/h3&gt; 
&lt;p&gt;Godotenv can also write a map representing the environment to a correctly-formatted and escaped file&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;env, err := godotenv.Unmarshal(&quot;KEY=value&quot;)
err := godotenv.Write(env, &quot;./.env&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... or to a string&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;env, err := godotenv.Unmarshal(&quot;KEY=value&quot;)
content, err := godotenv.Marshal(env)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome, but with some caveats.&lt;/p&gt; 
&lt;p&gt;This library has been declared feature complete (see &lt;a href=&quot;https://github.com/joho/godotenv/issues/182&quot;&gt;#182&lt;/a&gt; for background) and will not be accepting issues or pull requests adding new functionality or breaking the library API.&lt;/p&gt; 
&lt;p&gt;Contributions would be gladly accepted that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;bring this library&#39;s parsing into closer compatibility with the mainline dotenv implementations, in particular &lt;a href=&quot;https://github.com/bkeepers/dotenv&quot;&gt;Ruby&#39;s dotenv&lt;/a&gt; and &lt;a href=&quot;https://github.com/motdotla/dotenv&quot;&gt;Node.js&#39; dotenv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;keep the library up to date with the go ecosystem (ie CI bumps, documentation changes, changes in the core libraries)&lt;/li&gt; 
 &lt;li&gt;bug fixes for use cases that pertain to the library&#39;s purpose of easing development of codebases deployed into twelve factor environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;code changes without tests and references to peer dotenv implementations will not be accepted&lt;/em&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork it&lt;/li&gt; 
 &lt;li&gt;Create your feature branch (&lt;code&gt;git checkout -b my-new-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Commit your changes (&lt;code&gt;git commit -am &#39;Added some feature&#39;&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Push to the branch (&lt;code&gt;git push origin my-new-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Create new Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;Releases should follow &lt;a href=&quot;http://semver.org/&quot;&gt;Semver&lt;/a&gt; though the first couple of releases are &lt;code&gt;v1&lt;/code&gt; and &lt;code&gt;v1.1&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Use &lt;a href=&quot;https://github.com/joho/godotenv/issues/30&quot;&gt;annotated tags for all releases&lt;/a&gt;. Example &lt;code&gt;git tag -a v1.2.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Who?&lt;/h2&gt; 
&lt;p&gt;The original library &lt;a href=&quot;https://github.com/bkeepers/dotenv&quot;&gt;dotenv&lt;/a&gt; was written by &lt;a href=&quot;http://opensoul.org/&quot;&gt;Brandon Keepers&lt;/a&gt;, and this port was done by &lt;a href=&quot;https://johnbarton.co/&quot;&gt;John Barton&lt;/a&gt; based off the tests/fixtures in the original library.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/pprof</title>
      <link>https://github.com/google/pprof</link>
      <description>&lt;p&gt;pprof is a tool for visualization and analysis of profiling data&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/google/pprof/actions&quot;&gt;&lt;img src=&quot;https://github.com/google/pprof/workflows/ci/badge.svg?sanitize=true&quot; alt=&quot;Github Action CI&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/google/pprof&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/google/pprof/graph/badge.svg?sanitize=true&quot; alt=&quot;Codecov&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/google/pprof/profile&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/google/pprof/profile.svg?sanitize=true&quot; alt=&quot;Go Reference&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;pprof is a tool for visualization and analysis of profiling data.&lt;/p&gt; 
&lt;p&gt;pprof reads a collection of profiling samples in profile.proto format and generates reports to visualize and help analyze the data. It can generate both text and graphical reports (through the use of the dot visualization package).&lt;/p&gt; 
&lt;p&gt;profile.proto is a protocol buffer that describes a set of callstacks and symbolization information. A common usage is to represent a set of sampled callstacks from statistical profiling. The format is described on the &lt;a href=&quot;https://raw.githubusercontent.com/google/pprof/main/proto/profile.proto&quot;&gt;proto/profile.proto&lt;/a&gt; file. For details on protocol buffers, see &lt;a href=&quot;https://developers.google.com/protocol-buffers&quot;&gt;https://developers.google.com/protocol-buffers&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Profiles can be read from a local file, or over http. Multiple profiles of the same type can be aggregated or compared.&lt;/p&gt; 
&lt;p&gt;If the profile samples contain machine addresses, pprof can symbolize them through the use of the native binutils tools (addr2line and nm).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This is not an official Google product.&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Building pprof&lt;/h1&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Go development kit of a &lt;a href=&quot;https://golang.org/doc/devel/release.html#policy&quot;&gt;supported version&lt;/a&gt;. Follow &lt;a href=&quot;http://golang.org/doc/code.html&quot;&gt;these instructions&lt;/a&gt; to prepare the environment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Graphviz: &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;http://www.graphviz.org/&lt;/a&gt; Optional, used to generate graphic visualizations of profiles&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To build and install it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/google/pprof@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The binary will be installed &lt;code&gt;$GOPATH/bin&lt;/code&gt; (&lt;code&gt;$HOME/go/bin&lt;/code&gt; by default).&lt;/p&gt; 
&lt;h1&gt;Basic usage&lt;/h1&gt; 
&lt;p&gt;pprof can read a profile from a file or directly from a server via http. Specify the profile input(s) in the command line, and use options to indicate how to format the report.&lt;/p&gt; 
&lt;h2&gt;Generate a text report of the profile, sorted by hotness:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;% pprof -top [main_binary] profile.pb.gz
Where
    main_binary:  Local path to the main program binary, to enable symbolization
    profile.pb.gz: Local path to the profile in a compressed protobuf, or
                   URL to the http service that serves a profile.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate a graph in an SVG file, and open it with a web browser:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pprof -web [main_binary] profile.pb.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run pprof on interactive mode:&lt;/h2&gt; 
&lt;p&gt;If no output formatting option is specified, pprof runs on interactive mode, where reads the profile and accepts interactive commands for visualization and refinement of the profile.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pprof [main_binary] profile.pb.gz

This will open a simple shell that takes pprof commands to generate reports.
Type &#39;help&#39; for available commands/options.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run pprof via a web interface&lt;/h2&gt; 
&lt;p&gt;If the &lt;code&gt;-http&lt;/code&gt; flag is specified, pprof starts a web server at the specified host:port that provides an interactive web-based interface to pprof. Host is optional, and is &quot;localhost&quot; by default. Port is optional, and is a random available port by default. &lt;code&gt;-http=&quot;:&quot;&lt;/code&gt; starts a server locally at a random port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pprof -http=[host]:[port] [main_binary] profile.pb.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The preceding command should automatically open your web browser at the right page; if not, you can manually visit the specified port in your web browser.&lt;/p&gt; 
&lt;h2&gt;Using pprof with Linux Perf&lt;/h2&gt; 
&lt;p&gt;pprof can read &lt;code&gt;perf.data&lt;/code&gt; files generated by the &lt;a href=&quot;https://perf.wiki.kernel.org/index.php/Main_Page&quot;&gt;Linux perf&lt;/a&gt; tool by using the &lt;code&gt;perf_to_profile&lt;/code&gt; program from the &lt;a href=&quot;https://github.com/google/perf_data_converter&quot;&gt;perf_data_converter&lt;/a&gt; package.&lt;/p&gt; 
&lt;h2&gt;Viewing disassembly on Windows&lt;/h2&gt; 
&lt;p&gt;To view disassembly of profiles collected from Go programs compiled as Windows executables, the executable must be built with &lt;code&gt;go build -buildmode=exe&lt;/code&gt;. LLVM or GCC must be installed, so required tools like &lt;code&gt;addr2line&lt;/code&gt; and &lt;code&gt;nm&lt;/code&gt; are available to &lt;code&gt;pprof&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Further documentation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/google/pprof/main/doc/README.md&quot;&gt;doc/README.md&lt;/a&gt; for more detailed end-user documentation.&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/google/pprof/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for contribution documentation.&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/google/pprof/main/proto/README.md&quot;&gt;proto/README.md&lt;/a&gt; for a description of the profile.proto format.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector-contrib</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
      <description>&lt;p&gt;Contrib repository for the OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;strong&gt; &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt; &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;amp;style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt; &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt; &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt; &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;amp;style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;amp;logo=data:image/png;base64,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&quot; /&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;strong&gt; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;OpenTelemetry Collector Contrib&lt;/h1&gt; 
&lt;p&gt;This is a repository for OpenTelemetry Collector components that are not suitable for the &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector&quot;&gt;core repository&lt;/a&gt; of the collector.&lt;/p&gt; 
&lt;p&gt;The official distributions, core and contrib, are available as part of the &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-releases&quot;&gt;opentelemetry-collector-releases&lt;/a&gt; repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder&quot;&gt;OpenTelemetry Collector Builder&lt;/a&gt;, using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.&lt;/p&gt; 
&lt;p&gt;Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#39;s a stability level, setting the right expectations. It is possible then that a component will be &lt;strong&gt;Stable&lt;/strong&gt; for traces but &lt;strong&gt;Alpha&lt;/strong&gt; for metrics and &lt;strong&gt;Development&lt;/strong&gt; for logs.&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;Stability level for components in this repository follow the &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector#stability-levels&quot;&gt;definitions&lt;/a&gt; from the OpenTelemetry Collector repository.&lt;/p&gt; 
&lt;h2&gt;Gated features&lt;/h2&gt; 
&lt;p&gt;Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle&quot;&gt;lifecycle stages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group &lt;a href=&quot;https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer&quot;&gt;@open-telemetry/collector-contrib-maintainer&lt;/a&gt;, or by specific vendors. See the individual README files for information about the specific components.&lt;/p&gt; 
&lt;p&gt;The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.&lt;/p&gt; 
&lt;p&gt;Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/codeboten&quot;&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/andrzej-stencel&quot;&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/atoulme&quot;&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/bogdandrutu&quot;&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dmitryax&quot;&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/edmocosta&quot;&gt;Edmo Vamerlatti Costa&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/evan-bradley&quot;&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mx-psi&quot;&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/MovieStoreGuy&quot;&gt;Sean Marciniak&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/TylerHelmuth&quot;&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/songy23&quot;&gt;Yang Song&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ArthurSens&quot;&gt;Arthur Silva Sens&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/braydonk&quot;&gt;Braydon Kains&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/ChrsMark&quot;&gt;Christos Markou&lt;/a&gt;, Elastic (On leave)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/crobert-1&quot;&gt;Curtis Robert&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dashpole&quot;&gt;David Ashpole&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mwear&quot;&gt;Matt Wear&lt;/a&gt;, Lightstep&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dehaansa&quot;&gt;Sam DeHaan&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/fatsheep9146&quot;&gt;Ziqi Zhao&lt;/a&gt;, Alibaba&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/axw&quot;&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/frzifus&quot;&gt;Benedikt Bongartz&lt;/a&gt;, Red Hat&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/bacherfl&quot;&gt;Florian Bacher&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/iblancasa&quot;&gt;Israel Blancas&lt;/a&gt;, Coralogix&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jamesmoessis&quot;&gt;James Moessis&lt;/a&gt;, Atlassian&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/JaredTan95&quot;&gt;Jared Tan&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Frapschen&quot;&gt;Murphy Chen&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/odubajDT&quot;&gt;Ondrej Dubaj&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pjanotti&quot;&gt;Paulo Janotti&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/VihasMakwana&quot;&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/djaglowski&quot;&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jpkrohling&quot;&gt;Juraci Paixão Kröhling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/tigrannajaryan&quot;&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Aneurysm9&quot;&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/bryan-aguilar&quot;&gt;Bryan Aguilar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pmm-sumo&quot;&gt;Przemek Maciolek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kovrus&quot;&gt;Ruslan Kovalov&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/alolita&quot;&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gbbr&quot;&gt;Gabriel Aszalos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gouthamve&quot;&gt;Goutham Veeramachaneni&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/punya&quot;&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/flands&quot;&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;No Over-Representation&lt;/h3&gt; 
&lt;p&gt;A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.&lt;/p&gt; 
&lt;h2&gt;PRs and Reviews&lt;/h2&gt; 
&lt;p&gt;When creating a PR please follow the process &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews&quot;&gt;described here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;New PRs will be automatically associated with the reviewers based on &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/.github/CODEOWNERS&quot;&gt;CODEOWNERS&lt;/a&gt;. PRs will be also automatically assigned to one of the maintainers or approvers for facilitation.&lt;/p&gt; 
&lt;p&gt;The facilitator is responsible for helping the PR author and reviewers to make progress or if progress cannot be made for closing the PR.&lt;/p&gt; 
&lt;p&gt;If the reviewers do not have approval rights the facilitator is also responsible for the official approval that is required for the PR to be merged and if the facilitator is a maintainer they are responsible for merging the PR as well.&lt;/p&gt; 
&lt;p&gt;The facilitator is not required to perform a thorough review, but they are encouraged to enforce Collector best practices and consistency across the codebase and component behavior. The facilitators will typically rely on codeowner&#39;s detailed review of the code when making the final approval decision.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/openai-go</title>
      <link>https://github.com/openai/openai-go</link>
      <description>&lt;p&gt;The official Go library for the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenAI Go API Library&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/openai/openai-go/v2&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/openai/openai-go.svg?sanitize=true&quot; alt=&quot;Go Reference&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The OpenAI Go library provides convenient access to the &lt;a href=&quot;https://platform.openai.com/docs&quot;&gt;OpenAI REST API&lt;/a&gt; from applications written in Go.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The latest version of this package has small and limited breaking changes. See the &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/CHANGELOG.md&quot;&gt;changelog&lt;/a&gt; for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;!-- x-release-please-start-version --&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
	&quot;github.com/openai/openai-go/v2&quot; // imported as openai
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- x-release-please-end --&gt; 
&lt;p&gt;Or to pin the version:&lt;/p&gt; 
&lt;!-- x-release-please-start-version --&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;go get -u &#39;github.com/openai/openai-go@v2.0.2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- x-release-please-end --&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;This library requires Go 1.21+.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;The full API of this library can be found in &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/api.md&quot;&gt;api.md&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/openai/openai-go/v2&quot;
	&quot;github.com/openai/openai-go/v2/option&quot;
	&quot;github.com/openai/openai-go/v2/shared&quot;
)

func main() {
	client := openai.NewClient(
		option.WithAPIKey(&quot;My API Key&quot;), // defaults to os.LookupEnv(&quot;OPENAI_API_KEY&quot;)
	)
	chatCompletion, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{
		Messages: []openai.ChatCompletionMessageParamUnion{
			openai.UserMessage(&quot;Say this is a test&quot;),
		},
		Model: openai.ChatModelGPT4o,
	})
	if err != nil {
		panic(err.Error())
	}
	println(chatCompletion.Choices[0].Message.Content)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Conversations&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;param := openai.ChatCompletionNewParams{
	Messages: []openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(&quot;What kind of houseplant is easy to take care of?&quot;),
	},
	Seed:     openai.Int(1),
	Model:    openai.ChatModelGPT4o,
}

completion, err := client.Chat.Completions.New(ctx, param)

param.Messages = append(param.Messages, completion.Choices[0].Message.ToParam())
param.Messages = append(param.Messages, openai.UserMessage(&quot;How big are those?&quot;))

// continue the conversation
completion, err = client.Chat.Completions.New(ctx, param)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Streaming responses&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;question := &quot;Write an epic&quot;

stream := client.Chat.Completions.NewStreaming(ctx, openai.ChatCompletionNewParams{
	Messages: []openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(question),
	},
	Seed:  openai.Int(0),
	Model: openai.ChatModelGPT4o,
})

// optionally, an accumulator helper can be used
acc := openai.ChatCompletionAccumulator{}

for stream.Next() {
	chunk := stream.Current()
	acc.AddChunk(chunk)

	if content, ok := acc.JustFinishedContent(); ok {
		println(&quot;Content stream finished:&quot;, content)
	}

	// if using tool calls
	if tool, ok := acc.JustFinishedToolCall(); ok {
		println(&quot;Tool call stream finished:&quot;, tool.Index, tool.Name, tool.Arguments)
	}

	if refusal, ok := acc.JustFinishedRefusal(); ok {
		println(&quot;Refusal stream finished:&quot;, refusal)
	}

	// it&#39;s best to use chunks after handling JustFinished events
	if len(chunk.Choices) &amp;gt; 0 {
		println(chunk.Choices[0].Delta.Content)
	}
}

if stream.Err() != nil {
	panic(stream.Err())
}

// After the stream is finished, acc can be used like a ChatCompletion
_ = acc.Choices[0].Message.Content
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/examples/chat-completion-accumulating/main.go&quot;&gt;full streaming and accumulation example&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Tool calling&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
	&quot;encoding/json&quot;
	// ...
)

// ...

question := &quot;What is the weather in New York City?&quot;

params := openai.ChatCompletionNewParams{
	Messages: []openai.ChatCompletionMessageParamUnion{
		openai.UserMessage(question),
	},
	Tools: []openai.ChatCompletionToolParam{
		{
			Function: openai.FunctionDefinitionParam{
				Name:        &quot;get_weather&quot;,
				Description: openai.String(&quot;Get weather at the given location&quot;),
				Parameters: openai.FunctionParameters{
					&quot;type&quot;: &quot;object&quot;,
					&quot;properties&quot;: map[string]interface{}{
						&quot;location&quot;: map[string]string{
							&quot;type&quot;: &quot;string&quot;,
						},
					},
					&quot;required&quot;: []string{&quot;location&quot;},
				},
			},
		},
	},
	Model: openai.ChatModelGPT4o,
}

// If there is a was a function call, continue the conversation
params.Messages = append(params.Messages, completion.Choices[0].Message.ToParam())
for _, toolCall := range toolCalls {
	if toolCall.Function.Name == &quot;get_weather&quot; {
		// Extract the location from the function call arguments
		var args map[string]interface{}
		err := json.Unmarshal([]byte(toolCall.Function.Arguments), &amp;amp;args)
		if err != nil {
			panic(err)
		}
		location := args[&quot;location&quot;].(string)

		// Simulate getting weather data
		weatherData := getWeather(location)

		// Print the weather data
		fmt.Printf(&quot;Weather in %s: %s\n&quot;, location, weatherData)

		params.Messages = append(params.Messages, openai.ToolMessage(weatherData, toolCall.ID))
	}
}

// ... continue the conversation with the information provided by the tool
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/examples/chat-completion-tool-calling/main.go&quot;&gt;full tool calling example&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Structured outputs&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (
	&quot;encoding/json&quot;
	&quot;github.com/invopop/jsonschema&quot;
	// ...
)

// A struct that will be converted to a Structured Outputs response schema
type HistoricalComputer struct {
	Origin       Origin   `json:&quot;origin&quot; jsonschema_description:&quot;The origin of the computer&quot;`
	Name         string   `json:&quot;full_name&quot; jsonschema_description:&quot;The name of the device model&quot;`
	Legacy       string   `json:&quot;legacy&quot; jsonschema:&quot;enum=positive,enum=neutral,enum=negative&quot; jsonschema_description:&quot;Its influence on the field of computing&quot;`
	NotableFacts []string `json:&quot;notable_facts&quot; jsonschema_description:&quot;A few key facts about the computer&quot;`
}

type Origin struct {
	YearBuilt    int64  `json:&quot;year_of_construction&quot; jsonschema_description:&quot;The year it was made&quot;`
	Organization string `json:&quot;organization&quot; jsonschema_description:&quot;The organization that was in charge of its development&quot;`
}

func GenerateSchema[T any]() interface{} {
	// Structured Outputs uses a subset of JSON schema
	// These flags are necessary to comply with the subset
	reflector := jsonschema.Reflector{
		AllowAdditionalProperties: false,
		DoNotReference:            true,
	}
	var v T
	schema := reflector.Reflect(v)
	return schema
}

// Generate the JSON schema at initialization time
var HistoricalComputerResponseSchema = GenerateSchema[HistoricalComputer]()

func main() {

	// ...

	question := &quot;What computer ran the first neural network?&quot;

	schemaParam := openai.ResponseFormatJSONSchemaJSONSchemaParam{
		Name:        &quot;historical_computer&quot;,
		Description: openai.String(&quot;Notable information about a computer&quot;),
		Schema:      HistoricalComputerResponseSchema,
		Strict:      openai.Bool(true),
	}

	chat, _ := client.Chat.Completions.New(ctx, openai.ChatCompletionNewParams{
		// ...
		ResponseFormat: openai.ChatCompletionNewParamsResponseFormatUnion{
			OfJSONSchema: &amp;amp;openai.ResponseFormatJSONSchemaParam{
				JSONSchema: schemaParam,
			},
		},
		// only certain models can perform structured outputs
		Model: openai.ChatModelGPT4o2024_08_06,
	})

	// extract into a well-typed struct
	var historicalComputer HistoricalComputer
	_ = json.Unmarshal([]byte(chat.Choices[0].Message.Content), &amp;amp;historicalComputer)

	historicalComputer.Name
	historicalComputer.Origin.YearBuilt
	historicalComputer.Origin.Organization
	for i, fact := range historicalComputer.NotableFacts {
		// ...
	}
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/examples/structured-outputs/main.go&quot;&gt;full structured outputs example&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;h3&gt;Request fields&lt;/h3&gt; 
&lt;p&gt;The openai library uses the &lt;a href=&quot;https://tip.golang.org/doc/go1.24#encodingjsonpkgencodingjson&quot;&gt;&lt;code&gt;omitzero&lt;/code&gt;&lt;/a&gt; semantics from the Go 1.24+ &lt;code&gt;encoding/json&lt;/code&gt; release for request fields.&lt;/p&gt; 
&lt;p&gt;Required primitive fields (&lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, etc.) feature the tag &lt;code&gt;`json:&quot;...,required&quot;`&lt;/code&gt;. These fields are always serialized, even their zero values.&lt;/p&gt; 
&lt;p&gt;Optional primitive types are wrapped in a &lt;code&gt;param.Opt[T]&lt;/code&gt;. These fields can be set with the provided constructors, &lt;code&gt;openai.String(string)&lt;/code&gt;, &lt;code&gt;openai.Int(int64)&lt;/code&gt;, etc.&lt;/p&gt; 
&lt;p&gt;Any &lt;code&gt;param.Opt[T]&lt;/code&gt;, map, slice, struct or string enum uses the tag &lt;code&gt;`json:&quot;...,omitzero&quot;`&lt;/code&gt;. Its zero value is considered omitted.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;param.IsOmitted(any)&lt;/code&gt; function can confirm the presence of any &lt;code&gt;omitzero&lt;/code&gt; field.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;p := openai.ExampleParams{
	ID:   &quot;id_xxx&quot;,             // required property
	Name: openai.String(&quot;...&quot;), // optional property

	Point: openai.Point{
		X: 0,             // required field will serialize as 0
		Y: openai.Int(1), // optional field will serialize as 1
		// ... omitted non-required fields will not be serialized
	},

	Origin: openai.Origin{}, // the zero value of [Origin] is considered omitted
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To send &lt;code&gt;null&lt;/code&gt; instead of a &lt;code&gt;param.Opt[T]&lt;/code&gt;, use &lt;code&gt;param.Null[T]()&lt;/code&gt;. To send &lt;code&gt;null&lt;/code&gt; instead of a struct &lt;code&gt;T&lt;/code&gt;, use &lt;code&gt;param.NullStruct[T]()&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;p.Name = param.Null[string]()       // &#39;null&#39; instead of string
p.Point = param.NullStruct[Point]() // &#39;null&#39; instead of struct

param.IsNull(p.Name)  // true
param.IsNull(p.Point) // true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Request structs contain a &lt;code&gt;.SetExtraFields(map[string]any)&lt;/code&gt; method which can send non-conforming fields in the request body. Extra fields overwrite any struct fields with a matching key. For security reasons, only use &lt;code&gt;SetExtraFields&lt;/code&gt; with trusted data.&lt;/p&gt; 
&lt;p&gt;To send a custom value instead of a struct, use &lt;code&gt;param.Override[T](value)&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// In cases where the API specifies a given type,
// but you want to send something else, use [SetExtraFields]:
p.SetExtraFields(map[string]any{
	&quot;x&quot;: 0.01, // send &quot;x&quot; as a float instead of int
})

// Send a number instead of an object
custom := param.Override[openai.FooParams](12)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Request unions&lt;/h3&gt; 
&lt;p&gt;Unions are represented as a struct with fields prefixed by &quot;Of&quot; for each of it&#39;s variants, only one field can be non-zero. The non-zero field will be serialized.&lt;/p&gt; 
&lt;p&gt;Sub-properties of the union can be accessed via methods on the union struct. These methods return a mutable pointer to the underlying data, if present.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Only one field can be non-zero, use param.IsOmitted() to check if a field is set
type AnimalUnionParam struct {
	OfCat *Cat `json:&quot;,omitzero,inline`
	OfDog *Dog `json:&quot;,omitzero,inline`
}

animal := AnimalUnionParam{
	OfCat: &amp;amp;Cat{
		Name: &quot;Whiskers&quot;,
		Owner: PersonParam{
			Address: AddressParam{Street: &quot;3333 Coyote Hill Rd&quot;, Zip: 0},
		},
	},
}

// Mutating a field
if address := animal.GetOwner().GetAddress(); address != nil {
	address.ZipCode = 94304
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response objects&lt;/h3&gt; 
&lt;p&gt;All fields in response structs are ordinary value types (not pointers or wrappers). Response structs also include a special &lt;code&gt;JSON&lt;/code&gt; field containing metadata about each property.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type Animal struct {
	Name   string `json:&quot;name,nullable&quot;`
	Owners int    `json:&quot;owners&quot;`
	Age    int    `json:&quot;age&quot;`
	JSON   struct {
		Name        respjson.Field
		Owner       respjson.Field
		Age         respjson.Field
		ExtraFields map[string]respjson.Field
	} `json:&quot;-&quot;`
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To handle optional data, use the &lt;code&gt;.Valid()&lt;/code&gt; method on the JSON field. &lt;code&gt;.Valid()&lt;/code&gt; returns true if a field is not &lt;code&gt;null&lt;/code&gt;, not present, or couldn&#39;t be marshaled.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;.Valid()&lt;/code&gt; is false, the corresponding field will simply be its zero value.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;raw := `{&quot;owners&quot;: 1, &quot;name&quot;: null}`

var res Animal
json.Unmarshal([]byte(raw), &amp;amp;res)

// Accessing regular fields

res.Owners // 1
res.Name   // &quot;&quot;
res.Age    // 0

// Optional field checks

res.JSON.Owners.Valid() // true
res.JSON.Name.Valid()   // false
res.JSON.Age.Valid()    // false

// Raw JSON values

res.JSON.Owners.Raw()                  // &quot;1&quot;
res.JSON.Name.Raw() == &quot;null&quot;          // true
res.JSON.Name.Raw() == respjson.Null   // true
res.JSON.Age.Raw() == &quot;&quot;               // true
res.JSON.Age.Raw() == respjson.Omitted // true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These &lt;code&gt;.JSON&lt;/code&gt; structs also include an &lt;code&gt;ExtraFields&lt;/code&gt; map containing any properties in the json response that were not specified in the struct. This can be useful for API features not yet present in the SDK.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;body := res.JSON.ExtraFields[&quot;my_unexpected_field&quot;].Raw()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response Unions&lt;/h3&gt; 
&lt;p&gt;In responses, unions are represented by a flattened struct containing all possible fields from each of the object variants. To convert it to a variant use the &lt;code&gt;.AsFooVariant()&lt;/code&gt; method or the &lt;code&gt;.AsAny()&lt;/code&gt; method if present.&lt;/p&gt; 
&lt;p&gt;If a response value union contains primitive values, primitive fields will be alongside the properties but prefixed with &lt;code&gt;Of&lt;/code&gt; and feature the tag &lt;code&gt;json:&quot;...,inline&quot;&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;type AnimalUnion struct {
	// From variants [Dog], [Cat]
	Owner Person `json:&quot;owner&quot;`
	// From variant [Dog]
	DogBreed string `json:&quot;dog_breed&quot;`
	// From variant [Cat]
	CatBreed string `json:&quot;cat_breed&quot;`
	// ...

	JSON struct {
		Owner respjson.Field
		// ...
	} `json:&quot;-&quot;`
}

// If animal variant
if animal.Owner.Address.ZipCode == &quot;&quot; {
	panic(&quot;missing zip code&quot;)
}

// Switch on the variant
switch variant := animal.AsAny().(type) {
case Dog:
case Cat:
default:
	panic(&quot;unexpected type&quot;)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;RequestOptions&lt;/h3&gt; 
&lt;p&gt;This library uses the functional options pattern. Functions defined in the &lt;code&gt;option&lt;/code&gt; package return a &lt;code&gt;RequestOption&lt;/code&gt;, which is a closure that mutates a &lt;code&gt;RequestConfig&lt;/code&gt;. These options can be supplied to the client or at individual requests. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;client := openai.NewClient(
	// Adds a header to every request made by the client
	option.WithHeader(&quot;X-Some-Header&quot;, &quot;custom_header_info&quot;),
)

client.Chat.Completions.New(context.TODO(), ...,
	// Override the header
	option.WithHeader(&quot;X-Some-Header&quot;, &quot;some_other_custom_header_info&quot;),
	// Add an undocumented field to the request body, using sjson syntax
	option.WithJSONSet(&quot;some.json.path&quot;, map[string]string{&quot;my&quot;: &quot;object&quot;}),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The request option &lt;code&gt;option.WithDebugLog(nil)&lt;/code&gt; may be helpful while debugging.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://pkg.go.dev/github.com/openai/openai-go/option&quot;&gt;full list of request options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Pagination&lt;/h3&gt; 
&lt;p&gt;This library provides some conveniences for working with paginated list endpoints.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;.ListAutoPaging()&lt;/code&gt; methods to iterate through items across all pages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;iter := client.FineTuning.Jobs.ListAutoPaging(context.TODO(), openai.FineTuningJobListParams{
	Limit: openai.Int(20),
})
// Automatically fetches more pages as needed.
for iter.Next() {
	fineTuningJob := iter.Current()
	fmt.Printf(&quot;%+v\n&quot;, fineTuningJob)
}
if err := iter.Err(); err != nil {
	panic(err.Error())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or you can use simple &lt;code&gt;.List()&lt;/code&gt; methods to fetch a single page and receive a standard response object with additional helper methods like &lt;code&gt;.GetNextPage()&lt;/code&gt;, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;page, err := client.FineTuning.Jobs.List(context.TODO(), openai.FineTuningJobListParams{
	Limit: openai.Int(20),
})
for page != nil {
	for _, job := range page.Data {
		fmt.Printf(&quot;%+v\n&quot;, job)
	}
	page, err = page.GetNextPage()
}
if err != nil {
	panic(err.Error())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Errors&lt;/h3&gt; 
&lt;p&gt;When the API returns a non-success status code, we return an error with type &lt;code&gt;*openai.Error&lt;/code&gt;. This contains the &lt;code&gt;StatusCode&lt;/code&gt;, &lt;code&gt;*http.Request&lt;/code&gt;, and &lt;code&gt;*http.Response&lt;/code&gt; values of the request, as well as the JSON of the error body (much like other response objects in the SDK).&lt;/p&gt; 
&lt;p&gt;To handle errors, we recommend that you use the &lt;code&gt;errors.As&lt;/code&gt; pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;_, err := client.FineTuning.Jobs.New(context.TODO(), openai.FineTuningJobNewParams{
	Model:        openai.FineTuningJobNewParamsModelBabbage002,
	TrainingFile: &quot;file-abc123&quot;,
})
if err != nil {
	var apierr *openai.Error
	if errors.As(err, &amp;amp;apierr) {
		println(string(apierr.DumpRequest(true)))  // Prints the serialized HTTP request
		println(string(apierr.DumpResponse(true))) // Prints the serialized HTTP response
	}
	panic(err.Error()) // GET &quot;/fine_tuning/jobs&quot;: 400 Bad Request { ... }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When other errors occur, they are returned unwrapped; for example, if HTTP transport fails, you might receive &lt;code&gt;*url.Error&lt;/code&gt; wrapping &lt;code&gt;*net.OpError&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Timeouts&lt;/h3&gt; 
&lt;p&gt;Requests do not time out by default; use context to configure a timeout for a request lifecycle.&lt;/p&gt; 
&lt;p&gt;Note that if a request is &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/#retries&quot;&gt;retried&lt;/a&gt;, the context timeout does not start over. To set a per-retry timeout, use &lt;code&gt;option.WithRequestTimeout()&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// This sets the timeout for the request, including all the retries.
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
defer cancel()
client.Chat.Completions.New(
	ctx,
	openai.ChatCompletionNewParams{
		Messages: []openai.ChatCompletionMessageParamUnion{{
			OfUser: &amp;amp;openai.ChatCompletionUserMessageParam{
				Content: openai.ChatCompletionUserMessageParamContentUnion{
					OfString: openai.String(&quot;How can I list all files in a directory using Python?&quot;),
				},
			},
		}},
		Model: shared.ChatModelGPT5,
	},
	// This sets the per-retry timeout
	option.WithRequestTimeout(20*time.Second),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;File uploads&lt;/h3&gt; 
&lt;p&gt;Request parameters that correspond to file uploads in multipart requests are typed as &lt;code&gt;io.Reader&lt;/code&gt;. The contents of the &lt;code&gt;io.Reader&lt;/code&gt; will by default be sent as a multipart form part with the file name of &quot;anonymous_file&quot; and content-type of &quot;application/octet-stream&quot;.&lt;/p&gt; 
&lt;p&gt;The file name and content-type can be customized by implementing &lt;code&gt;Name() string&lt;/code&gt; or &lt;code&gt;ContentType() string&lt;/code&gt; on the run-time type of &lt;code&gt;io.Reader&lt;/code&gt;. Note that &lt;code&gt;os.File&lt;/code&gt; implements &lt;code&gt;Name() string&lt;/code&gt;, so a file returned by &lt;code&gt;os.Open&lt;/code&gt; will be sent with the file name on disk.&lt;/p&gt; 
&lt;p&gt;We also provide a helper &lt;code&gt;openai.File(reader io.Reader, filename string, contentType string)&lt;/code&gt; which can be used to wrap any &lt;code&gt;io.Reader&lt;/code&gt; with the appropriate file name and content type.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// A file from the file system
file, err := os.Open(&quot;input.jsonl&quot;)
openai.FileNewParams{
	File:    file,
	Purpose: openai.FilePurposeFineTune,
}

// A file from a string
openai.FileNewParams{
	File:    strings.NewReader(&quot;my file contents&quot;),
	Purpose: openai.FilePurposeFineTune,
}

// With a custom filename and contentType
openai.FileNewParams{
	File:    openai.File(strings.NewReader(`{&quot;hello&quot;: &quot;foo&quot;}`), &quot;file.go&quot;, &quot;application/json&quot;),
	Purpose: openai.FilePurposeFineTune,
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Webhook Verification&lt;/h2&gt; 
&lt;p&gt;Verifying webhook signatures is &lt;em&gt;optional but encouraged&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;For more information about webhooks, see &lt;a href=&quot;https://platform.openai.com/docs/guides/webhooks&quot;&gt;the API docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Parsing webhook payloads&lt;/h3&gt; 
&lt;p&gt;For most use cases, you will likely want to verify the webhook and parse the payload at the same time. To achieve this, we provide the method &lt;code&gt;client.Webhooks.Unwrap()&lt;/code&gt;, which parses a webhook request and verifies that it was sent by OpenAI. This method will return an error if the signature is invalid.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;code&gt;body&lt;/code&gt; parameter should be the raw JSON bytes sent from the server (do not parse it first). The &lt;code&gt;Unwrap()&lt;/code&gt; method will parse this JSON for you into an event object after verifying the webhook was sent from OpenAI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;io&quot;
	&quot;log&quot;
	&quot;net/http&quot;
	&quot;os&quot;

	&quot;github.com/gin-gonic/gin&quot;
	&quot;github.com/openai/openai-go/v2&quot;
	&quot;github.com/openai/openai-go/v2/option&quot;
	&quot;github.com/openai/openai-go/v2/webhooks&quot;
)

func main() {
	client := openai.NewClient(
		option.WithWebhookSecret(os.Getenv(&quot;OPENAI_WEBHOOK_SECRET&quot;)), // env var used by default; explicit here.
	)

	r := gin.Default()

	r.POST(&quot;/webhook&quot;, func(c *gin.Context) {
		body, err := io.ReadAll(c.Request.Body)
		if err != nil {
			c.JSON(http.StatusInternalServerError, gin.H{&quot;error&quot;: &quot;Error reading request body&quot;})
			return
		}
		defer c.Request.Body.Close()

		webhookEvent, err := client.Webhooks.Unwrap(body, c.Request.Header)
		if err != nil {
			log.Printf(&quot;Invalid webhook signature: %v&quot;, err)
			c.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: &quot;invalid signature&quot;})
			return
		}

		switch event := webhookEvent.AsAny().(type) {
		case webhooks.ResponseCompletedWebhookEvent:
			log.Printf(&quot;Response completed: %+v&quot;, event.Data)
		case webhooks.ResponseFailedWebhookEvent:
			log.Printf(&quot;Response failed: %+v&quot;, event.Data)
		default:
			log.Printf(&quot;Unhandled event type: %T&quot;, event)
		}

		c.JSON(http.StatusOK, gin.H{&quot;message&quot;: &quot;ok&quot;})
	})

	r.Run(&quot;:8000&quot;)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verifying webhook payloads directly&lt;/h3&gt; 
&lt;p&gt;In some cases, you may want to verify the webhook separately from parsing the payload. If you prefer to handle these steps separately, we provide the method &lt;code&gt;client.Webhooks.VerifySignature()&lt;/code&gt; to &lt;em&gt;only verify&lt;/em&gt; the signature of a webhook request. Like &lt;code&gt;Unwrap()&lt;/code&gt;, this method will return an error if the signature is invalid.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;code&gt;body&lt;/code&gt; parameter should be the raw JSON bytes sent from the server (do not parse it first). You will then need to parse the body after verifying the signature.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;encoding/json&quot;
	&quot;io&quot;
	&quot;log&quot;
	&quot;net/http&quot;
	&quot;os&quot;

	&quot;github.com/gin-gonic/gin&quot;
	&quot;github.com/openai/openai-go/v2&quot;
	&quot;github.com/openai/openai-go/v2/option&quot;
)

func main() {
	client := openai.NewClient(
		option.WithWebhookSecret(os.Getenv(&quot;OPENAI_WEBHOOK_SECRET&quot;)), // env var used by default; explicit here.
	)

	r := gin.Default()

	r.POST(&quot;/webhook&quot;, func(c *gin.Context) {
		body, err := io.ReadAll(c.Request.Body)
		if err != nil {
			c.JSON(http.StatusInternalServerError, gin.H{&quot;error&quot;: &quot;Error reading request body&quot;})
			return
		}
		defer c.Request.Body.Close()

		err = client.Webhooks.VerifySignature(body, c.Request.Header)
		if err != nil {
			log.Printf(&quot;Invalid webhook signature: %v&quot;, err)
			c.JSON(http.StatusBadRequest, gin.H{&quot;error&quot;: &quot;invalid signature&quot;})
			return
		}

		c.JSON(http.StatusOK, gin.H{&quot;message&quot;: &quot;ok&quot;})
	})

	r.Run(&quot;:8000&quot;)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Retries&lt;/h3&gt; 
&lt;p&gt;Certain errors will be automatically retried 2 times by default, with a short exponential backoff. We retry by default all connection errors, 408 Request Timeout, 409 Conflict, 429 Rate Limit, and &amp;gt;=500 Internal errors.&lt;/p&gt; 
&lt;p&gt;You can use the &lt;code&gt;WithMaxRetries&lt;/code&gt; option to configure or disable this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Configure the default for all requests:
client := openai.NewClient(
	option.WithMaxRetries(0), // default is 2
)

// Override per-request:
client.Chat.Completions.New(
	context.TODO(),
	openai.ChatCompletionNewParams{
		Messages: []openai.ChatCompletionMessageParamUnion{{
			OfUser: &amp;amp;openai.ChatCompletionUserMessageParam{
				Content: openai.ChatCompletionUserMessageParamContentUnion{
					OfString: openai.String(&quot;How can I get the name of the current day in JavaScript?&quot;),
				},
			},
		}},
		Model: shared.ChatModelGPT5,
	},
	option.WithMaxRetries(5),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Accessing raw response data (e.g. response headers)&lt;/h3&gt; 
&lt;p&gt;You can access the raw HTTP response data by using the &lt;code&gt;option.WithResponseInto()&lt;/code&gt; request option. This is useful when you need to examine response headers, status codes, or other details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Create a variable to store the HTTP response
var response *http.Response
chatCompletion, err := client.Chat.Completions.New(
	context.TODO(),
	openai.ChatCompletionNewParams{
		Messages: []openai.ChatCompletionMessageParamUnion{{
			OfUser: &amp;amp;openai.ChatCompletionUserMessageParam{
				Content: openai.ChatCompletionUserMessageParamContentUnion{
					OfString: openai.String(&quot;Say this is a test&quot;),
				},
			},
		}},
		Model: shared.ChatModelGPT5,
	},
	option.WithResponseInto(&amp;amp;response),
)
if err != nil {
	// handle error
}
fmt.Printf(&quot;%+v\n&quot;, chatCompletion)

fmt.Printf(&quot;Status Code: %d\n&quot;, response.StatusCode)
fmt.Printf(&quot;Headers: %+#v\n&quot;, response.Header)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Making custom/undocumented requests&lt;/h3&gt; 
&lt;p&gt;This library is typed for convenient access to the documented API. If you need to access undocumented endpoints, params, or response properties, the library can still be used.&lt;/p&gt; 
&lt;h4&gt;Undocumented endpoints&lt;/h4&gt; 
&lt;p&gt;To make requests to undocumented endpoints, you can use &lt;code&gt;client.Get&lt;/code&gt;, &lt;code&gt;client.Post&lt;/code&gt;, and other HTTP verbs. &lt;code&gt;RequestOptions&lt;/code&gt; on the client, such as retries, will be respected when making these requests.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;var (
    // params can be an io.Reader, a []byte, an encoding/json serializable object,
    // or a &quot;…Params&quot; struct defined in this library.
    params map[string]any

    // result can be an []byte, *http.Response, a encoding/json deserializable object,
    // or a model defined in this library.
    result *http.Response
)
err := client.Post(context.Background(), &quot;/unspecified&quot;, params, &amp;amp;result)
if err != nil {
    …
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Undocumented request params&lt;/h4&gt; 
&lt;p&gt;To make requests using undocumented parameters, you may use either the &lt;code&gt;option.WithQuerySet()&lt;/code&gt; or the &lt;code&gt;option.WithJSONSet()&lt;/code&gt; methods.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;params := FooNewParams{
    ID:   &quot;id_xxxx&quot;,
    Data: FooNewParamsData{
        FirstName: openai.String(&quot;John&quot;),
    },
}
client.Foo.New(context.Background(), params, option.WithJSONSet(&quot;data.last_name&quot;, &quot;Doe&quot;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Undocumented response properties&lt;/h4&gt; 
&lt;p&gt;To access undocumented response properties, you may either access the raw JSON of the response as a string with &lt;code&gt;result.JSON.RawJSON()&lt;/code&gt;, or get the raw JSON of a particular field on the result with &lt;code&gt;result.JSON.Foo.Raw()&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Any fields that are not present on the response struct will be saved and can be accessed by &lt;code&gt;result.JSON.ExtraFields()&lt;/code&gt; which returns the extra fields as a &lt;code&gt;map[string]Field&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Middleware&lt;/h3&gt; 
&lt;p&gt;We provide &lt;code&gt;option.WithMiddleware&lt;/code&gt; which applies the given middleware to requests.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func Logger(req *http.Request, next option.MiddlewareNext) (res *http.Response, err error) {
	// Before the request
	start := time.Now()
	LogReq(req)

	// Forward the request to the next handler
	res, err = next(req)

	// Handle stuff after the request
	end := time.Now()
	LogRes(res, err, start - end)

    return res, err
}

client := openai.NewClient(
	option.WithMiddleware(Logger),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When multiple middlewares are provided as variadic arguments, the middlewares are applied left to right. If &lt;code&gt;option.WithMiddleware&lt;/code&gt; is given multiple times, for example first in the client then the method, the middleware in the client will run first and the middleware given in the method will run next.&lt;/p&gt; 
&lt;p&gt;You may also replace the default &lt;code&gt;http.Client&lt;/code&gt; with &lt;code&gt;option.WithHTTPClient(client)&lt;/code&gt;. Only one http client is accepted (this overwrites any previous client) and receives requests after any middleware has been applied.&lt;/p&gt; 
&lt;h2&gt;Microsoft Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;To use this library with [Azure OpenAI]&lt;a href=&quot;https://learn.microsoft.com/azure/ai-services/openai/overview&quot;&gt;https://learn.microsoft.com/azure/ai-services/openai/overview&lt;/a&gt;), use the option.RequestOption functions in the &lt;code&gt;azure&lt;/code&gt; package.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;github.com/Azure/azure-sdk-for-go/sdk/azidentity&quot;
	&quot;github.com/openai/openai-go/v2&quot;
	&quot;github.com/openai/openai-go/v2/azure&quot;
)

func main() {
	const azureOpenAIEndpoint = &quot;https://&amp;lt;azure-openai-resource&amp;gt;.openai.azure.com&quot;

	// The latest API versions, including previews, can be found here:
	// ttps://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versionng
	const azureOpenAIAPIVersion = &quot;2024-06-01&quot;

	tokenCredential, err := azidentity.NewDefaultAzureCredential(nil)

	if err != nil {
		fmt.Printf(&quot;Failed to create the DefaultAzureCredential: %s&quot;, err)
		os.Exit(1)
	}

	client := openai.NewClient(
		azure.WithEndpoint(azureOpenAIEndpoint, azureOpenAIAPIVersion),

		// Choose between authenticating using a TokenCredential or an API Key
		azure.WithTokenCredential(tokenCredential),
		// or azure.WithAPIKey(azureOpenAIAPIKey),
	)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Semantic versioning&lt;/h2&gt; 
&lt;p&gt;This package generally follows &lt;a href=&quot;https://semver.org/spec/v2.0.0.html&quot;&gt;SemVer&lt;/a&gt; conventions, though certain backwards-incompatible changes may be released as minor versions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Changes to library internals which are technically public but not intended or documented for external use. &lt;em&gt;(Please open a GitHub issue to let us know if you are relying on such internals.)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Changes that we do not expect to impact the vast majority of users in practice.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.&lt;/p&gt; 
&lt;p&gt;We are keen for your feedback; please open an &lt;a href=&quot;https://www.github.com/openai/openai-go/issues&quot;&gt;issue&lt;/a&gt; with questions, bugs, or suggestions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/openai/openai-go/main/CONTRIBUTING.md&quot;&gt;the contributing documentation&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes-sigs/controller-runtime</title>
      <link>https://github.com/kubernetes-sigs/controller-runtime</link>
      <description>&lt;p&gt;Repo for the controller-runtime subproject of kubebuilder (sig-apimachinery)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://goreportcard.com/report/sigs.k8s.io/controller-runtime&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/sigs.k8s.io/controller-runtime&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/sigs.k8s.io/controller-runtime&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/sigs.k8s.io/controller-runtime&quot; alt=&quot;godoc&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Kubernetes controller-runtime Project&lt;/h1&gt; 
&lt;p&gt;The Kubernetes controller-runtime Project is a set of go libraries for building Controllers. It is leveraged by &lt;a href=&quot;https://book.kubebuilder.io/&quot;&gt;Kubebuilder&lt;/a&gt; and &lt;a href=&quot;https://github.com/operator-framework/operator-sdk&quot;&gt;Operator SDK&lt;/a&gt;. Both are a great place to start for new projects. See &lt;a href=&quot;https://book.kubebuilder.io/quick-start.html&quot;&gt;Kubebuilder&#39;s Quick Start&lt;/a&gt; to see how it can be used.&lt;/p&gt; 
&lt;p&gt;Documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg&quot;&gt;Package overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/builder#example-Builder&quot;&gt;Basic controller using builder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/manager#example-New&quot;&gt;Creating a manager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/controller#example-New&quot;&gt;Creating a controller&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/controller-runtime/raw/main/examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-sigs/controller-runtime/raw/main/designs&quot;&gt;Designs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Versioning, Maintenance, and Compatibility&lt;/h1&gt; 
&lt;p&gt;The full documentation can be found at &lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/VERSIONING.md&quot;&gt;VERSIONING.md&lt;/a&gt;, but TL;DR:&lt;/p&gt; 
&lt;p&gt;Users:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We stick to a zero major version&lt;/li&gt; 
 &lt;li&gt;We publish a minor version for each Kubernetes minor release and allow breaking changes between minor versions&lt;/li&gt; 
 &lt;li&gt;We publish patch versions as needed and we don&#39;t allow breaking changes in them&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All code PR must be labeled with &lt;span&gt;🐛&lt;/span&gt; (patch fixes), &lt;span&gt;✨&lt;/span&gt; (backwards-compatible features), or &lt;span&gt;⚠&lt;/span&gt; (breaking changes)&lt;/li&gt; 
 &lt;li&gt;Breaking changes will find their way into the next major release, other changes will go into an semi-immediate patch or minor release&lt;/li&gt; 
 &lt;li&gt;For a quick PR template suggesting the right information, use one of these PR templates: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/.github/PULL_REQUEST_TEMPLATE/breaking_change.md&quot;&gt;Breaking Changes/Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/.github/PULL_REQUEST_TEMPLATE/compat_feature.md&quot;&gt;Backwards-Compatible Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/.github/PULL_REQUEST_TEMPLATE/bug_fix.md&quot;&gt;Bug fixes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/.github/PULL_REQUEST_TEMPLATE/docs.md&quot;&gt;Documentation Changes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/.github/PULL_REQUEST_TEMPLATE/other.md&quot;&gt;Test/Build/Other Changes&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;Every minor version of controller-runtime has been tested with a specific minor version of client-go. A controller-runtime minor version &lt;em&gt;may&lt;/em&gt; be compatible with other client-go minor versions, but this is by chance and neither supported nor tested. In general, we create one minor version of controller-runtime for each minor version of client-go and other k8s.io/* dependencies.&lt;/p&gt; 
&lt;p&gt;The minimum Go version of controller-runtime is the highest minimum Go version of our Go dependencies. Usually, this will be identical to the minimum Go version of the corresponding k8s.io/* dependencies.&lt;/p&gt; 
&lt;p&gt;Compatible k8s.io/*, client-go and minimum Go versions can be looked up in our &lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/go.mod&quot;&gt;go.mod&lt;/a&gt; file.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;k8s.io/*, client-go&lt;/th&gt; 
   &lt;th align=&quot;center&quot;&gt;minimum Go version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.21&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.33&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.24&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.20&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.32&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.23&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.19&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.31&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.22&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.18&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.30&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.22&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.17&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.29&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.21&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.16&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.28&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CR v0.15&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;v0.27&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;1.20&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/FAQ.md&quot;&gt;FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community, discussion, contribution, and support&lt;/h2&gt; 
&lt;p&gt;Learn how to engage with the Kubernetes community on the &lt;a href=&quot;http://kubernetes.io/community/&quot;&gt;community page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can reach the maintainers of this project at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Slack channel: &lt;a href=&quot;https://kubernetes.slack.com/archives/C02MRBMN00Z&quot;&gt;#controller-runtime&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google Group: &lt;a href=&quot;https://groups.google.com/forum/#!forum/kubebuilder&quot;&gt;kubebuilder@googlegroups.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are greatly appreciated. The maintainers actively manage the issues list, and try to highlight issues suitable for newcomers. The project follows the typical GitHub pull request model. See &lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt; for more details. Before starting any work, please either comment on an existing issue, or file a new one.&lt;/p&gt; 
&lt;h2&gt;Code of conduct&lt;/h2&gt; 
&lt;p&gt;Participation in the Kubernetes community is governed by the &lt;a href=&quot;https://raw.githubusercontent.com/kubernetes-sigs/controller-runtime/main/code-of-conduct.md&quot;&gt;Kubernetes Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sashabaranov/go-openai</title>
      <link>https://github.com/sashabaranov/go-openai</link>
      <description>&lt;p&gt;OpenAI ChatGPT, GPT-5, GPT-Image-1, Whisper API clients for Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Go OpenAI&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://pkg.go.dev/github.com/sashabaranov/go-openai&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/sashabaranov/go-openai.svg?sanitize=true&quot; alt=&quot;Go Reference&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/sashabaranov/go-openai&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/sashabaranov/go-openai&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/sashabaranov/go-openai&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/sashabaranov/go-openai/branch/master/graph/badge.svg?token=bCbIfHLIsW&quot; alt=&quot;codecov&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This library provides unofficial Go clients for &lt;a href=&quot;https://platform.openai.com/&quot;&gt;OpenAI API&lt;/a&gt;. We support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ChatGPT 4o, o1&lt;/li&gt; 
 &lt;li&gt;GPT-3, GPT-4&lt;/li&gt; 
 &lt;li&gt;DALL·E 2, DALL·E 3, GPT Image 1&lt;/li&gt; 
 &lt;li&gt;Whisper&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;go get github.com/sashabaranov/go-openai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Currently, go-openai requires Go version 1.18 or greater.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;ChatGPT example usage:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT3Dot5Turbo,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: &quot;Hello!&quot;,
				},
			},
		},
	)

	if err != nil {
		fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
		return
	}

	fmt.Println(resp.Choices[0].Message.Content)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Getting an OpenAI API Key:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Visit the OpenAI website at &lt;a href=&quot;https://platform.openai.com/account/api-keys&quot;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you don&#39;t have an account, click on &quot;Sign Up&quot; to create one. If you do, click &quot;Log In&quot;.&lt;/li&gt; 
 &lt;li&gt;Once logged in, navigate to your API key management page.&lt;/li&gt; 
 &lt;li&gt;Click on &quot;Create new secret key&quot;.&lt;/li&gt; 
 &lt;li&gt;Enter a name for your new key, then click &quot;Create secret key&quot;.&lt;/li&gt; 
 &lt;li&gt;Your new API key will be displayed. Use this key to interact with the OpenAI API.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Your API key is sensitive information. Do not share it with anyone.&lt;/p&gt; 
&lt;h3&gt;Other examples:&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ChatGPT streaming completion&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;errors&quot;
	&quot;fmt&quot;
	&quot;io&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.ChatCompletionRequest{
		Model:     openai.GPT3Dot5Turbo,
		MaxTokens: 20,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: &quot;Lorem ipsum&quot;,
			},
		},
		Stream: true,
	}
	stream, err := c.CreateChatCompletionStream(ctx, req)
	if err != nil {
		fmt.Printf(&quot;ChatCompletionStream error: %v\n&quot;, err)
		return
	}
	defer stream.Close()

	fmt.Printf(&quot;Stream response: &quot;)
	for {
		response, err := stream.Recv()
		if errors.Is(err, io.EOF) {
			fmt.Println(&quot;\nStream finished&quot;)
			return
		}

		if err != nil {
			fmt.Printf(&quot;\nStream error: %v\n&quot;, err)
			return
		}

		fmt.Printf(response.Choices[0].Delta.Content)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;GPT-3 completion&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.CompletionRequest{
		Model:     openai.GPT3Babbage002,
		MaxTokens: 5,
		Prompt:    &quot;Lorem ipsum&quot;,
	}
	resp, err := c.CreateCompletion(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Completion error: %v\n&quot;, err)
		return
	}
	fmt.Println(resp.Choices[0].Text)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;GPT-3 streaming completion&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;errors&quot;
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;io&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.CompletionRequest{
		Model:     openai.GPT3Babbage002,
		MaxTokens: 5,
		Prompt:    &quot;Lorem ipsum&quot;,
		Stream:    true,
	}
	stream, err := c.CreateCompletionStream(ctx, req)
	if err != nil {
		fmt.Printf(&quot;CompletionStream error: %v\n&quot;, err)
		return
	}
	defer stream.Close()

	for {
		response, err := stream.Recv()
		if errors.Is(err, io.EOF) {
			fmt.Println(&quot;Stream finished&quot;)
			return
		}

		if err != nil {
			fmt.Printf(&quot;Stream error: %v\n&quot;, err)
			return
		}


		fmt.Printf(&quot;Stream response: %v\n&quot;, response)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Audio Speech-To-Text&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.AudioRequest{
		Model:    openai.Whisper1,
		FilePath: &quot;recording.mp3&quot;,
	}
	resp, err := c.CreateTranscription(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Transcription error: %v\n&quot;, err)
		return
	}
	fmt.Println(resp.Text)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Audio Captions&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(os.Getenv(&quot;OPENAI_KEY&quot;))

	req := openai.AudioRequest{
		Model:    openai.Whisper1,
		FilePath: os.Args[1],
		Format:   openai.AudioResponseFormatSRT,
	}
	resp, err := c.CreateTranscription(context.Background(), req)
	if err != nil {
		fmt.Printf(&quot;Transcription error: %v\n&quot;, err)
		return
	}
	f, err := os.Create(os.Args[1] + &quot;.srt&quot;)
	if err != nil {
		fmt.Printf(&quot;Could not open file: %v\n&quot;, err)
		return
	}
	defer f.Close()
	if _, err := f.WriteString(resp.Text); err != nil {
		fmt.Printf(&quot;Error writing to file: %v\n&quot;, err)
		return
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DALL-E 2 image generation&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;bytes&quot;
	&quot;context&quot;
	&quot;encoding/base64&quot;
	&quot;fmt&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;
	&quot;image/png&quot;
	&quot;os&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	// Sample image by link
	reqUrl := openai.ImageRequest{
		Prompt:         &quot;Parrot on a skateboard performs a trick, cartoon style, natural light, high detail&quot;,
		Size:           openai.CreateImageSize256x256,
		ResponseFormat: openai.CreateImageResponseFormatURL,
		N:              1,
	}

	respUrl, err := c.CreateImage(ctx, reqUrl)
	if err != nil {
		fmt.Printf(&quot;Image creation error: %v\n&quot;, err)
		return
	}
	fmt.Println(respUrl.Data[0].URL)

	// Example image as base64
	reqBase64 := openai.ImageRequest{
		Prompt:         &quot;Portrait of a humanoid parrot in a classic costume, high detail, realistic light, unreal engine&quot;,
		Size:           openai.CreateImageSize256x256,
		ResponseFormat: openai.CreateImageResponseFormatB64JSON,
		N:              1,
	}

	respBase64, err := c.CreateImage(ctx, reqBase64)
	if err != nil {
		fmt.Printf(&quot;Image creation error: %v\n&quot;, err)
		return
	}

	imgBytes, err := base64.StdEncoding.DecodeString(respBase64.Data[0].B64JSON)
	if err != nil {
		fmt.Printf(&quot;Base64 decode error: %v\n&quot;, err)
		return
	}

	r := bytes.NewReader(imgBytes)
	imgData, err := png.Decode(r)
	if err != nil {
		fmt.Printf(&quot;PNG decode error: %v\n&quot;, err)
		return
	}

	file, err := os.Create(&quot;example.png&quot;)
	if err != nil {
		fmt.Printf(&quot;File creation error: %v\n&quot;, err)
		return
	}
	defer file.Close()

	if err := png.Encode(file, imgData); err != nil {
		fmt.Printf(&quot;PNG encode error: %v\n&quot;, err)
		return
	}

	fmt.Println(&quot;The image was saved as example.png&quot;)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;GPT Image 1 image generation&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;encoding/base64&quot;
	&quot;fmt&quot;
	&quot;os&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	c := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	req := openai.ImageRequest{
		Prompt:            &quot;Parrot on a skateboard performing a trick. Large bold text \&quot;SKATE MASTER\&quot; banner at the bottom of the image. Cartoon style, natural light, high detail, 1:1 aspect ratio.&quot;,
		Background:        openai.CreateImageBackgroundOpaque,
		Model:             openai.CreateImageModelGptImage1,
		Size:              openai.CreateImageSize1024x1024,
		N:                 1,
		Quality:           openai.CreateImageQualityLow,
		OutputCompression: 100,
		OutputFormat:      openai.CreateImageOutputFormatJPEG,
		// Moderation: 		 openai.CreateImageModerationLow,
		// User: 					 &quot;&quot;,
	}

	resp, err := c.CreateImage(ctx, req)
	if err != nil {
		fmt.Printf(&quot;Image creation Image generation with GPT Image 1error: %v\n&quot;, err)
		return
	}

	fmt.Println(&quot;Image Base64:&quot;, resp.Data[0].B64JSON)

	// Decode the base64 data
	imgBytes, err := base64.StdEncoding.DecodeString(resp.Data[0].B64JSON)
	if err != nil {
		fmt.Printf(&quot;Base64 decode error: %v\n&quot;, err)
		return
	}

	// Write image to file
	outputPath := &quot;generated_image.jpg&quot;
	err = os.WriteFile(outputPath, imgBytes, 0644)
	if err != nil {
		fmt.Printf(&quot;Failed to write image file: %v\n&quot;, err)
		return
	}

	fmt.Printf(&quot;The image was saved as %s\n&quot;, outputPath)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Configuring proxy&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;config := openai.DefaultConfig(&quot;token&quot;)
proxyUrl, err := url.Parse(&quot;http://localhost:{port}&quot;)
if err != nil {
	panic(err)
}
transport := &amp;amp;http.Transport{
	Proxy: http.ProxyURL(proxyUrl),
}
config.HTTPClient = &amp;amp;http.Client{
	Transport: transport,
}

c := openai.NewClientWithConfig(config)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See also: &lt;a href=&quot;https://pkg.go.dev/github.com/sashabaranov/go-openai#ClientConfig&quot;&gt;https://pkg.go.dev/github.com/sashabaranov/go-openai#ClientConfig&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ChatGPT support context&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;bufio&quot;
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;os&quot;
	&quot;strings&quot;

	&quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	messages := make([]openai.ChatCompletionMessage, 0)
	reader := bufio.NewReader(os.Stdin)
	fmt.Println(&quot;Conversation&quot;)
	fmt.Println(&quot;---------------------&quot;)

	for {
		fmt.Print(&quot;-&amp;gt; &quot;)
		text, _ := reader.ReadString(&#39;\n&#39;)
		// convert CRLF to LF
		text = strings.Replace(text, &quot;\n&quot;, &quot;&quot;, -1)
		messages = append(messages, openai.ChatCompletionMessage{
			Role:    openai.ChatMessageRoleUser,
			Content: text,
		})

		resp, err := client.CreateChatCompletion(
			context.Background(),
			openai.ChatCompletionRequest{
				Model:    openai.GPT3Dot5Turbo,
				Messages: messages,
			},
		)

		if err != nil {
			fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
			continue
		}

		content := resp.Choices[0].Message.Content
		messages = append(messages, openai.ChatCompletionMessage{
			Role:    openai.ChatMessageRoleAssistant,
			Content: content,
		})
		fmt.Println(content)
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Azure OpenAI ChatGPT&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	config := openai.DefaultAzureConfig(&quot;your Azure OpenAI Key&quot;, &quot;https://your Azure OpenAI Endpoint&quot;)
	// If you use a deployment name different from the model name, you can customize the AzureModelMapperFunc function
	// config.AzureModelMapperFunc = func(model string) string {
	// 	azureModelMapping := map[string]string{
	// 		&quot;gpt-3.5-turbo&quot;: &quot;your gpt-3.5-turbo deployment name&quot;,
	// 	}
	// 	return azureModelMapping[model]
	// }

	client := openai.NewClientWithConfig(config)
	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: openai.GPT3Dot5Turbo,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleUser,
					Content: &quot;Hello Azure OpenAI!&quot;,
				},
			},
		},
	)
	if err != nil {
		fmt.Printf(&quot;ChatCompletion error: %v\n&quot;, err)
		return
	}

	fmt.Println(resp.Choices[0].Message.Content)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Embedding Semantic Similarity&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;log&quot;
	openai &quot;github.com/sashabaranov/go-openai&quot;

)

func main() {
	client := openai.NewClient(&quot;your-token&quot;)

	// Create an EmbeddingRequest for the user query
	queryReq := openai.EmbeddingRequest{
		Input: []string{&quot;How many chucks would a woodchuck chuck&quot;},
		Model: openai.AdaEmbeddingV2,
	}

	// Create an embedding for the user query
	queryResponse, err := client.CreateEmbeddings(context.Background(), queryReq)
	if err != nil {
		log.Fatal(&quot;Error creating query embedding:&quot;, err)
	}

	// Create an EmbeddingRequest for the target text
	targetReq := openai.EmbeddingRequest{
		Input: []string{&quot;How many chucks would a woodchuck chuck if the woodchuck could chuck wood&quot;},
		Model: openai.AdaEmbeddingV2,
	}

	// Create an embedding for the target text
	targetResponse, err := client.CreateEmbeddings(context.Background(), targetReq)
	if err != nil {
		log.Fatal(&quot;Error creating target embedding:&quot;, err)
	}

	// Now that we have the embeddings for the user query and the target text, we
	// can calculate their similarity.
	queryEmbedding := queryResponse.Data[0]
	targetEmbedding := targetResponse.Data[0]

	similarity, err := queryEmbedding.DotProduct(&amp;amp;targetEmbedding)
	if err != nil {
		log.Fatal(&quot;Error calculating dot product:&quot;, err)
	}

	log.Printf(&quot;The similarity score between the query and the target is %f&quot;, similarity)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Azure OpenAI Embeddings&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	openai &quot;github.com/sashabaranov/go-openai&quot;
)

func main() {

	config := openai.DefaultAzureConfig(&quot;your Azure OpenAI Key&quot;, &quot;https://your Azure OpenAI Endpoint&quot;)
	config.APIVersion = &quot;2023-05-15&quot; // optional update to latest API version

	//If you use a deployment name different from the model name, you can customize the AzureModelMapperFunc function
	//config.AzureModelMapperFunc = func(model string) string {
	//    azureModelMapping := map[string]string{
	//        &quot;gpt-3.5-turbo&quot;:&quot;your gpt-3.5-turbo deployment name&quot;,
	//    }
	//    return azureModelMapping[model]
	//}

	input := &quot;Text to vectorize&quot;

	client := openai.NewClientWithConfig(config)
	resp, err := client.CreateEmbeddings(
		context.Background(),
		openai.EmbeddingRequest{
			Input: []string{input},
			Model: openai.AdaEmbeddingV2,
		})

	if err != nil {
		fmt.Printf(&quot;CreateEmbeddings error: %v\n&quot;, err)
		return
	}

	vectors := resp.Data[0].Embedding // []float32 with 1536 dimensions

	fmt.Println(vectors[:10], &quot;...&quot;, vectors[len(vectors)-10:])
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;JSON Schema for function calling&lt;/summary&gt; 
 &lt;p&gt;It is now possible for chat completion to choose to call a function for more information (&lt;a href=&quot;https://platform.openai.com/docs/guides/gpt/function-calling&quot;&gt;see developer docs here&lt;/a&gt;).&lt;/p&gt; 
 &lt;p&gt;In order to describe the type of functions that can be called, a JSON schema must be provided. Many JSON schema libraries exist and are more advanced than what we can offer in this library, however we have included a simple &lt;code&gt;jsonschema&lt;/code&gt; package for those who want to use this feature without formatting their own JSON schema payload.&lt;/p&gt; 
 &lt;p&gt;The developer documents give this JSON schema definition as an example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &quot;name&quot;:&quot;get_current_weather&quot;,
  &quot;description&quot;:&quot;Get the current weather in a given location&quot;,
  &quot;parameters&quot;:{
    &quot;type&quot;:&quot;object&quot;,
    &quot;properties&quot;:{
        &quot;location&quot;:{
          &quot;type&quot;:&quot;string&quot;,
          &quot;description&quot;:&quot;The city and state, e.g. San Francisco, CA&quot;
        },
        &quot;unit&quot;:{
          &quot;type&quot;:&quot;string&quot;,
          &quot;enum&quot;:[
              &quot;celsius&quot;,
              &quot;fahrenheit&quot;
          ]
        }
    },
    &quot;required&quot;:[
        &quot;location&quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Using the &lt;code&gt;jsonschema&lt;/code&gt; package, this schema could be created using structs as such:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;FunctionDefinition{
  Name: &quot;get_current_weather&quot;,
  Parameters: jsonschema.Definition{
    Type: jsonschema.Object,
    Properties: map[string]jsonschema.Definition{
      &quot;location&quot;: {
        Type: jsonschema.String,
        Description: &quot;The city and state, e.g. San Francisco, CA&quot;,
      },
      &quot;unit&quot;: {
        Type: jsonschema.String,
        Enum: []string{&quot;celsius&quot;, &quot;fahrenheit&quot;},
      },
    },
    Required: []string{&quot;location&quot;},
  },
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;Parameters&lt;/code&gt; field of a &lt;code&gt;FunctionDefinition&lt;/code&gt; can accept either of the above styles, or even a nested struct from another library (as long as it can be marshalled into JSON).&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Error handling&lt;/summary&gt; 
 &lt;p&gt;Open-AI maintains clear documentation on how to &lt;a href=&quot;https://platform.openai.com/docs/guides/error-codes/api-errors&quot;&gt;handle API errors&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;e := &amp;amp;openai.APIError{}
if errors.As(err, &amp;amp;e) {
  switch e.HTTPStatusCode {
    case 401:
      // invalid auth or key (do not retry)
    case 429:
      // rate limiting or engine overload (wait and retry) 
    case 500:
      // openai server error (retry)
    default:
      // unhandled
  }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Fine Tune Model&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;github.com/sashabaranov/go-openai&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	// create a .jsonl file with your training data for conversational model
	// {&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}
	// {&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}
	// {&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}

	// chat models are trained using the following file format:
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#39;s the capital of France?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Paris, as if everyone doesn&#39;t know that already.&quot;}]}
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who wrote &#39;Romeo and Juliet&#39;?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Oh, just some guy named William Shakespeare. Ever heard of him?&quot;}]}
	// {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How far is the Moon from Earth?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Around 384,400 kilometers. Give or take a few, like that really matters.&quot;}]}

	// you can use openai cli tool to validate the data
	// For more info - https://platform.openai.com/docs/guides/fine-tuning

	file, err := client.CreateFile(ctx, openai.FileRequest{
		FilePath: &quot;training_prepared.jsonl&quot;,
		Purpose:  &quot;fine-tune&quot;,
	})
	if err != nil {
		fmt.Printf(&quot;Upload JSONL file error: %v\n&quot;, err)
		return
	}

	// create a fine tuning job
	// Streams events until the job is done (this often takes minutes, but can take hours if there are many jobs in the queue or your dataset is large)
	// use below get method to know the status of your model
	fineTuningJob, err := client.CreateFineTuningJob(ctx, openai.FineTuningJobRequest{
		TrainingFile: file.ID,
		Model:        &quot;davinci-002&quot;, // gpt-3.5-turbo-0613, babbage-002.
	})
	if err != nil {
		fmt.Printf(&quot;Creating new fine tune model error: %v\n&quot;, err)
		return
	}

	fineTuningJob, err = client.RetrieveFineTuningJob(ctx, fineTuningJob.ID)
	if err != nil {
		fmt.Printf(&quot;Getting fine tune model error: %v\n&quot;, err)
		return
	}
	fmt.Println(fineTuningJob.FineTunedModel)

	// once the status of fineTuningJob is `succeeded`, you can use your fine tune model in Completion Request or Chat Completion Request

	// resp, err := client.CreateCompletion(ctx, openai.CompletionRequest{
	//	 Model:  fineTuningJob.FineTunedModel,
	//	 Prompt: &quot;your prompt&quot;,
	// })
	// if err != nil {
	//	 fmt.Printf(&quot;Create completion error %v\n&quot;, err)
	//	 return
	// }
	//
	// fmt.Println(resp.Choices[0].Text)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Structured Outputs&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/sashabaranov/go-openai&quot;
	&quot;github.com/sashabaranov/go-openai/jsonschema&quot;
)

func main() {
	client := openai.NewClient(&quot;your token&quot;)
	ctx := context.Background()

	type Result struct {
		Steps []struct {
			Explanation string `json:&quot;explanation&quot;`
			Output      string `json:&quot;output&quot;`
		} `json:&quot;steps&quot;`
		FinalAnswer string `json:&quot;final_answer&quot;`
	}
	var result Result
	schema, err := jsonschema.GenerateSchemaForType(result)
	if err != nil {
		log.Fatalf(&quot;GenerateSchemaForType error: %v&quot;, err)
	}
	resp, err := client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: openai.GPT4oMini,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: &quot;You are a helpful math tutor. Guide the user through the solution step by step.&quot;,
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: &quot;how can I solve 8x + 7 = -23&quot;,
			},
		},
		ResponseFormat: &amp;amp;openai.ChatCompletionResponseFormat{
			Type: openai.ChatCompletionResponseFormatTypeJSONSchema,
			JSONSchema: &amp;amp;openai.ChatCompletionResponseFormatJSONSchema{
				Name:   &quot;math_reasoning&quot;,
				Schema: schema,
				Strict: true,
			},
		},
	})
	if err != nil {
		log.Fatalf(&quot;CreateChatCompletion error: %v&quot;, err)
	}
	err = schema.Unmarshal(resp.Choices[0].Message.Content, &amp;amp;result)
	if err != nil {
		log.Fatalf(&quot;Unmarshal schema error: %v&quot;, err)
	}
	fmt.Println(result)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; See the `examples/` folder for more. 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;h3&gt;Why don&#39;t we get the same answer when specifying a temperature field of 0 and asking the same question?&lt;/h3&gt; 
&lt;p&gt;Even when specifying a temperature field of 0, it doesn&#39;t guarantee that you&#39;ll always get the same response. Several factors come into play.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go OpenAI Behavior: When you specify a temperature field of 0 in Go OpenAI, the omitempty tag causes that field to be removed from the request. Consequently, the OpenAI API applies the default value of 1.&lt;/li&gt; 
 &lt;li&gt;Token Count for Input/Output: If there&#39;s a large number of tokens in the input and output, setting the temperature to 0 can still result in non-deterministic behavior. In particular, when using around 32k tokens, the likelihood of non-deterministic behavior becomes highest even with a temperature of 0.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Due to the factors mentioned above, different answers may be returned even for the same question.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Workarounds:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;As of November 2023, use &lt;a href=&quot;https://platform.openai.com/docs/guides/text-generation/reproducible-outputs&quot;&gt;the new &lt;code&gt;seed&lt;/code&gt; parameter&lt;/a&gt; in conjunction with the &lt;code&gt;system_fingerprint&lt;/code&gt; response field, alongside Temperature management.&lt;/li&gt; 
 &lt;li&gt;Try using &lt;code&gt;math.SmallestNonzeroFloat32&lt;/code&gt;: By specifying &lt;code&gt;math.SmallestNonzeroFloat32&lt;/code&gt; in the temperature field instead of 0, you can mimic the behavior of setting it to 0.&lt;/li&gt; 
 &lt;li&gt;Limiting Token Count: By limiting the number of tokens in the input and output and especially avoiding large requests close to 32k tokens, you can reduce the risk of non-deterministic behavior.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By adopting these strategies, you can expect more consistent results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Related Issues:&lt;/strong&gt;&lt;br /&gt; &lt;a href=&quot;https://github.com/sashabaranov/go-openai/issues/9&quot;&gt;omitempty option of request struct will generate incorrect request when parameter is 0.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Does Go OpenAI provide a method to count tokens?&lt;/h3&gt; 
&lt;p&gt;No, Go OpenAI does not offer a feature to count tokens, and there are no plans to provide such a feature in the future. However, if there&#39;s a way to implement a token counting feature with zero dependencies, it might be possible to merge that feature into Go OpenAI. Otherwise, it would be more appropriate to implement it in a dedicated library or repository.&lt;/p&gt; 
&lt;p&gt;For counting tokens, you might find the following links helpful:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pkoukk/tiktoken-go#counting-tokens-for-chat-api-calls&quot;&gt;Counting Tokens For Chat API Calls&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/openai/openai-cookbook/raw/main/examples/How_to_count_tokens_with_tiktoken.ipynb&quot;&gt;How to count tokens with tiktoken&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Related Issues:&lt;/strong&gt;&lt;br /&gt; &lt;a href=&quot;https://github.com/sashabaranov/go-openai/issues/62&quot;&gt;Is it possible to join the implementation of GPT3 Tokenizer&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;By following &lt;a href=&quot;https://github.com/sashabaranov/go-openai/raw/master/CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt;, we hope to ensure that your contributions are made smoothly and efficiently.&lt;/p&gt; 
&lt;h2&gt;Thank you&lt;/h2&gt; 
&lt;p&gt;We want to take a moment to express our deepest gratitude to the &lt;a href=&quot;https://github.com/sashabaranov/go-openai/graphs/contributors&quot;&gt;contributors&lt;/a&gt; and sponsors of this project:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://carsonkahn.com&quot;&gt;Carson Kahn&lt;/a&gt; of &lt;a href=&quot;https://spindleai.com&quot;&gt;Spindle AI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To all of you: thank you. You&#39;ve helped us achieve more than we ever imagined possible. Can&#39;t wait to see where we go next, together!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fatedier/frp</title>
      <link>https://github.com/fatedier/frp</link>
      <description>&lt;p&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;frp&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://circleci.com/gh/fatedier/frp&quot;&gt;&lt;img src=&quot;https://circleci.com/gh/fatedier/frp.svg?style=shield&quot; alt=&quot;Build Status&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/fatedier/frp/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/tag/fatedier/frp.svg?label=release&quot; alt=&quot;GitHub release&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/fatedier/frp&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/fatedier/frp&quot; alt=&quot;Go Report Card&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;amp;repository=frp&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github&quot; alt=&quot;GitHub Releases Stats&quot; /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/README.md&quot;&gt;README&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/README_zh.md&quot;&gt;中文文档&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you&#39;d like to join them, please consider &lt;a href=&quot;https://github.com/sponsors/fatedier&quot;&gt;sponsoring frp&#39;s development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 align=&quot;center&quot;&gt;Gold Sponsors&lt;/h3&gt; 
&lt;!--gold sponsors start--&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://go.warp.dev/frp&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;360px&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-01.png&quot; /&gt; &lt;br /&gt; &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;Available for macOS, Linux and Windows&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://jb.gg/frp&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;420px&quot; src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg&quot; /&gt; &lt;br /&gt; &lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/daytonaio/daytona&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;420px&quot; src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_daytona.png&quot; /&gt; &lt;br /&gt; &lt;b&gt;Secure and Elastic Infrastructure for Running Your AI-Generated Code&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/beclab/Olares&quot; target=&quot;_blank&quot;&gt; &lt;img width=&quot;420px&quot; src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg&quot; /&gt; &lt;br /&gt; &lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;!--gold sponsors end--&gt; 
&lt;h2&gt;What is frp?&lt;/h2&gt; 
&lt;p&gt;frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;, as well as &lt;strong&gt;HTTP&lt;/strong&gt; and &lt;strong&gt;HTTPS&lt;/strong&gt; protocols, enabling requests to be forwarded to internal services via domain name.&lt;/p&gt; 
&lt;p&gt;frp also offers a P2P connect mode.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- vim-markdown-toc GFM --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#development-status&quot;&gt;Development Status&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#about-v2&quot;&gt;About V2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#architecture&quot;&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage&quot;&gt;Example Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#access-your-computer-in-a-lan-network-via-ssh&quot;&gt;Access your computer in a LAN network via SSH&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#multiple-ssh-services-sharing-the-same-port&quot;&gt;Multiple SSH services sharing the same port&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#accessing-internal-web-services-with-custom-domains-in-lan&quot;&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#forward-dns-query-requests&quot;&gt;Forward DNS query requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#forward-unix-domain-socket&quot;&gt;Forward Unix Domain Socket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#expose-a-simple-http-file-server&quot;&gt;Expose a simple HTTP file server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#enable-https-for-a-local-https-service&quot;&gt;Enable HTTPS for a local HTTP(S) service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#expose-your-service-privately&quot;&gt;Expose your service privately&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#p2p-mode&quot;&gt;P2P Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#features&quot;&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#configuration-files&quot;&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#using-environment-variables&quot;&gt;Using Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#split-configures-into-different-files&quot;&gt;Split Configures Into Different Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#server-dashboard&quot;&gt;Server Dashboard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#client-admin-ui&quot;&gt;Client Admin UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#monitor&quot;&gt;Monitor&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#prometheus&quot;&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#authenticating-the-client&quot;&gt;Authenticating the Client&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#token-authentication&quot;&gt;Token Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#oidc-authentication&quot;&gt;OIDC Authentication&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#encryption-and-compression&quot;&gt;Encryption and Compression&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#tls&quot;&gt;TLS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#hot-reloading-frpc-configuration&quot;&gt;Hot-Reloading frpc configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#get-proxy-status-from-client&quot;&gt;Get proxy status from client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#only-allowing-certain-ports-on-the-server&quot;&gt;Only allowing certain ports on the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#port-reuse&quot;&gt;Port Reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#bandwidth-limit&quot;&gt;Bandwidth Limit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#for-each-proxy&quot;&gt;For Each Proxy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-stream-multiplexing&quot;&gt;TCP Stream Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#support-kcp-protocol&quot;&gt;Support KCP Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#support-quic-protocol&quot;&gt;Support QUIC Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#connection-pooling&quot;&gt;Connection Pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#load-balancing&quot;&gt;Load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#service-health-check&quot;&gt;Service Health Check&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#rewriting-the-http-host-header&quot;&gt;Rewriting the HTTP Host Header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#setting-other-http-headers&quot;&gt;Setting other HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#get-real-ip&quot;&gt;Get Real IP&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#http-x-forwarded-for&quot;&gt;HTTP X-Forwarded-For&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#proxy-protocol&quot;&gt;Proxy Protocol&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#require-http-basic-auth-password-for-web-services&quot;&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#custom-subdomain-names&quot;&gt;Custom Subdomain Names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#url-routing&quot;&gt;URL Routing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-port-multiplexing&quot;&gt;TCP Port Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#connecting-to-frps-via-proxy&quot;&gt;Connecting to frps via PROXY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#port-range-mapping&quot;&gt;Port range mapping&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#client-plugins&quot;&gt;Client Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#server-manage-plugins&quot;&gt;Server Manage Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#ssh-tunnel-gateway&quot;&gt;SSH Tunnel Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#virtual-network-virtualnet&quot;&gt;Virtual Network (VirtualNet)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#feature-gates&quot;&gt;Feature Gates&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#available-feature-gates&quot;&gt;Available Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#enabling-feature-gates&quot;&gt;Enabling Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#feature-lifecycle&quot;&gt;Feature Lifecycle&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#related-projects&quot;&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#donation&quot;&gt;Donation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#github-sponsors&quot;&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#paypal&quot;&gt;PayPal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vim-markdown-toc --&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;frp is currently under development. You can try the latest release version in the &lt;code&gt;master&lt;/code&gt; branch, or use the &lt;code&gt;dev&lt;/code&gt; branch to access the version currently in development.&lt;/p&gt; 
&lt;p&gt;We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.&lt;/p&gt; 
&lt;p&gt;We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.&lt;/p&gt; 
&lt;h3&gt;About V2&lt;/h3&gt; 
&lt;p&gt;The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.&lt;/p&gt; 
&lt;p&gt;The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.&lt;/p&gt; 
&lt;p&gt;In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone&#39;s needs.&lt;/p&gt; 
&lt;p&gt;Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.&lt;/p&gt; 
&lt;p&gt;We sincerely appreciate your support for frp.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/architecture.png&quot; alt=&quot;architecture&quot; /&gt;&lt;/p&gt; 
&lt;h2&gt;Example Usage&lt;/h2&gt; 
&lt;p&gt;To begin, download the latest program for your operating system and architecture from the &lt;a href=&quot;https://github.com/fatedier/frp/releases&quot;&gt;Release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Next, place the &lt;code&gt;frps&lt;/code&gt; binary and server configuration file on Server A, which has a public IP address.&lt;/p&gt; 
&lt;p&gt;Finally, place the &lt;code&gt;frpc&lt;/code&gt; binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.&lt;/p&gt; 
&lt;p&gt;Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See &lt;a href=&quot;https://github.com/fatedier/frp/issues/3637&quot;&gt;issue 3637&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Access your computer in a LAN network via SSH&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; on server A by setting the &lt;code&gt;bindPort&lt;/code&gt; for frp clients to connect to:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt; on server A:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; on server B and set the &lt;code&gt;serverAddr&lt;/code&gt; field to the public IP address of your frps server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;localPort&lt;/code&gt; (listened on the client) and &lt;code&gt;remotePort&lt;/code&gt; (exposed on the server) are used for traffic going in and out of the frp system, while the &lt;code&gt;serverPort&lt;/code&gt; is used for communication between frps and frpc.&lt;/p&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on server B:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt;To access server B from another machine through server A via SSH (assuming the username is &lt;code&gt;test&lt;/code&gt;), use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 test@x.x.x.x&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple SSH services sharing the same port&lt;/h3&gt; 
&lt;p&gt;This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;bindPort = 7000
tcpmuxHTTPConnectPort = 5002
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Deploy frpc on the internal machine A with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;ssh1&quot;
type = &quot;tcpmux&quot;
multiplexer = &quot;httpconnect&quot;
customDomains = [&quot;machine-a.example.com&quot;]
localIP = &quot;127.0.0.1&quot;
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Deploy another frpc on the internal machine B with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;ssh2&quot;
type = &quot;tcpmux&quot;
multiplexer = &quot;httpconnect&quot;
customDomains = [&quot;machine-b.example.com&quot;]
localIP = &quot;127.0.0.1&quot;
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;To access internal machine A using SSH ProxyCommand, assuming the username is &quot;test&quot;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o &#39;proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002&#39; test@machine-a.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt;To access internal machine B, the only difference is the domain name, assuming the username is &quot;test&quot;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o &#39;proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002&#39; test@machine-b.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/h3&gt; 
&lt;p&gt;Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.&lt;/p&gt; 
&lt;p&gt;Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; and set the HTTP port for vhost to 8080:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
vhostHTTPPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to configure an https proxy, you need to set up the &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Specify the &lt;code&gt;localPort&lt;/code&gt; of your web service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localPort = 80
customDomains = [&quot;www.example.com&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Map the A record of &lt;code&gt;www.example.com&lt;/code&gt; to either the public IP of the remote frps server or a CNAME record pointing to your original domain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit your local web service using url &lt;code&gt;http://www.example.com:8080&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Forward DNS query requests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server &lt;code&gt;8.8.8.8:53&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;dns&quot;
type = &quot;udp&quot;
localIP = &quot;8.8.8.8&quot;
localPort = 53
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Start frpc:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start=&quot;5&quot;&gt; 
 &lt;li&gt;Test DNS resolution using the &lt;code&gt;dig&lt;/code&gt; command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;dig @x.x.x.x -p 6000 www.google.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Forward Unix Domain Socket&lt;/h3&gt; 
&lt;p&gt;Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;unix_domain_socket&quot;
type = &quot;tcp&quot;
remotePort = 6000
[proxies.plugin]
type = &quot;unix_domain_socket&quot;
unixPath = &quot;/var/run/docker.sock&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Test the configuration by getting the docker version using &lt;code&gt;curl&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;curl http://x.x.x.x:6000/version&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Expose a simple HTTP file server&lt;/h3&gt; 
&lt;p&gt;Expose a simple HTTP file server to access files stored in the LAN from the public Internet.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as described above, then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;test_static_file&quot;
type = &quot;tcp&quot;
remotePort = 6000
[proxies.plugin]
type = &quot;static_file&quot;
localPath = &quot;/tmp/files&quot;
stripPrefix = &quot;static&quot;
httpUser = &quot;abc&quot;
httpPassword = &quot;abc&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Visit &lt;code&gt;http://x.x.x.x:6000/static/&lt;/code&gt; from your browser and specify correct username and password to view files in &lt;code&gt;/tmp/files&lt;/code&gt; on the &lt;code&gt;frpc&lt;/code&gt; machine.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable HTTPS for a local HTTP(S) service&lt;/h3&gt; 
&lt;p&gt;You may substitute &lt;code&gt;https2https&lt;/code&gt; for the plugin, and point the &lt;code&gt;localAddr&lt;/code&gt; to a HTTPS endpoint.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;test_https2http&quot;
type = &quot;https&quot;
customDomains = [&quot;test.example.com&quot;]

[proxies.plugin]
type = &quot;https2http&quot;
localAddr = &quot;127.0.0.1:80&quot;
crtPath = &quot;./server.crt&quot;
keyPath = &quot;./server.key&quot;
hostHeaderRewrite = &quot;127.0.0.1&quot;
requestHeaders.set.x-from-where = &quot;frp&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Visit &lt;code&gt;https://test.example.com&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Expose your service privately&lt;/h3&gt; 
&lt;p&gt;To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; same as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B with the following config. This example is for exposing the SSH service (port 22), and note the &lt;code&gt;secretKey&lt;/code&gt; field for the preshared key, and that the &lt;code&gt;remotePort&lt;/code&gt; field is removed here:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;secret_ssh&quot;
type = &quot;stcp&quot;
secretKey = &quot;abcdefg&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the following config to access the SSH service with a security key (&lt;code&gt;secretKey&lt;/code&gt; field):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[visitors]]
name = &quot;secret_ssh_visitor&quot;
type = &quot;stcp&quot;
serverName = &quot;secret_ssh&quot;
secretKey = &quot;abcdefg&quot;
bindAddr = &quot;127.0.0.1&quot;
bindPort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;P2P Mode&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;xtcp&lt;/strong&gt; is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.&lt;/p&gt; 
&lt;p&gt;Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn&#39;t work.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B, and expose the SSH port. Note that the &lt;code&gt;remotePort&lt;/code&gt; field is removed:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = &quot;xxx&quot;

[[proxies]]
name = &quot;p2p_ssh&quot;
type = &quot;xtcp&quot;
secretKey = &quot;abcdefg&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the configuration to connect to SSH using P2P mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = &quot;xxx&quot;

[[visitors]]
name = &quot;p2p_ssh_visitor&quot;
type = &quot;xtcp&quot;
serverName = &quot;p2p_ssh&quot;
secretKey = &quot;abcdefg&quot;
bindAddr = &quot;127.0.0.1&quot;
bindPort = 6000
# when automatic tunnel persistence is required, set it to true
keepTunnelOpen = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.&lt;/p&gt; 
&lt;p&gt;Read the full example configuration files to find out even more features not described here.&lt;/p&gt; 
&lt;p&gt;Examples use TOML format, but you can still use YAML or JSON.&lt;/p&gt; 
&lt;p&gt;These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/conf/frps_full_example.toml&quot;&gt;Full configuration file for frps (Server)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/conf/frpc_full_example.toml&quot;&gt;Full configuration file for frpc (Client)&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Environment Variables&lt;/h3&gt; 
&lt;p&gt;Environment variables can be referenced in the configuration file, using Go&#39;s standard format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;{{ .Envs.FRP_SERVER_ADDR }}&quot;
serverPort = 7000

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
remotePort = &quot;{{ .Envs.FRP_SSH_REMOTE_PORT }}&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the config above, variables can be passed into &lt;code&gt;frpc&lt;/code&gt; program like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;frpc&lt;/code&gt; will render configuration file template using OS environment variables. Remember to prefix your reference with &lt;code&gt;.Envs&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Split Configures Into Different Files&lt;/h3&gt; 
&lt;p&gt;You can split multiple proxy configs into different files and include them in the main file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000
includes = [&quot;./confd/*.toml&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# ./confd/test.toml

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server Dashboard&lt;/h3&gt; 
&lt;p&gt;Check frp&#39;s status and proxies&#39; statistics information by Dashboard.&lt;/p&gt; 
&lt;p&gt;Configure a port for dashboard to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# The default value is 127.0.0.1. Change it to 0.0.0.0 when you want to access it from a public network.
webServer.addr = &quot;0.0.0.0&quot;
webServer.port = 7500
# dashboard&#39;s username and password are both optional
webServer.user = &quot;admin&quot;
webServer.password = &quot;admin&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://[serverAddr]:7500&lt;/code&gt; to see the dashboard, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can use HTTPS port by using your domains wildcard or normal SSL certificate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;webServer.port = 7500
# dashboard&#39;s username and password are both optional
webServer.user = &quot;admin&quot;
webServer.password = &quot;admin&quot;
webServer.tls.certFile = &quot;server.crt&quot;
webServer.tls.keyFile = &quot;server.key&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;https://[serverAddr]:7500&lt;/code&gt; to see the dashboard in secure HTTPS connection, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/dashboard.png&quot; alt=&quot;dashboard&quot; /&gt;&lt;/p&gt; 
&lt;h3&gt;Client Admin UI&lt;/h3&gt; 
&lt;p&gt;The Client Admin UI helps you check and manage frpc&#39;s configuration.&lt;/p&gt; 
&lt;p&gt;Configure an address for admin UI to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;webServer.addr = &quot;127.0.0.1&quot;
webServer.port = 7400
webServer.user = &quot;admin&quot;
webServer.password = &quot;admin&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://127.0.0.1:7400&lt;/code&gt; to see admin UI, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Monitor&lt;/h3&gt; 
&lt;p&gt;When web server is enabled, frps will save monitor data in cache for 7 days. It will be cleared after process restart.&lt;/p&gt; 
&lt;p&gt;Prometheus is also supported.&lt;/p&gt; 
&lt;h4&gt;Prometheus&lt;/h4&gt; 
&lt;p&gt;Enable dashboard first, then configure &lt;code&gt;enablePrometheus = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;http://{dashboard_addr}/metrics&lt;/code&gt; will provide prometheus monitor data.&lt;/p&gt; 
&lt;h3&gt;Authenticating the Client&lt;/h3&gt; 
&lt;p&gt;There are 2 authentication methods to authenticate frpc with frps.&lt;/p&gt; 
&lt;p&gt;You can decide which one to use by configuring &lt;code&gt;auth.method&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt;, the default one is token.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = [&quot;HeartBeats&quot;]&lt;/code&gt; will use the configured authentication method to add and validate authentication on every heartbeat between frpc and frps.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = [&quot;NewWorkConns&quot;]&lt;/code&gt; will do the same for every new work connection between frpc and frps.&lt;/p&gt; 
&lt;h4&gt;Token Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = &quot;token&quot;&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - token based authentication will be used.&lt;/p&gt; 
&lt;p&gt;Make sure to specify the same &lt;code&gt;auth.token&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt; for frpc to pass frps validation&lt;/p&gt; 
&lt;h5&gt;Token Source&lt;/h5&gt; 
&lt;p&gt;frp supports reading authentication tokens from external sources using the &lt;code&gt;tokenSource&lt;/code&gt; configuration. Currently, file-based token source is supported.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;File-based token source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
auth.method = &quot;token&quot;
auth.tokenSource.type = &quot;file&quot;
auth.tokenSource.file.path = &quot;/path/to/token/file&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The token will be read from the specified file at startup. This is useful for scenarios where tokens are managed by external systems or need to be kept separate from configuration files for security reasons.&lt;/p&gt; 
&lt;h4&gt;OIDC Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = &quot;oidc&quot;&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - OIDC based authentication will be used.&lt;/p&gt; 
&lt;p&gt;OIDC stands for OpenID Connect, and the flow used is called &lt;a href=&quot;https://tools.ietf.org/html/rfc6749#section-4.4&quot;&gt;Client Credentials Grant&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this authentication type - configure &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
auth.method = &quot;oidc&quot;
auth.oidc.issuer = &quot;https://example-oidc-issuer.com/&quot;
auth.oidc.audience = &quot;https://oidc-audience.com/.default&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
auth.method = &quot;oidc&quot;
auth.oidc.clientID = &quot;98692467-37de-409a-9fac-bb2585826f18&quot; # Replace with OIDC client ID
auth.oidc.clientSecret = &quot;oidc_secret&quot;
auth.oidc.audience = &quot;https://oidc-audience.com/.default&quot;
auth.oidc.tokenEndpointURL = &quot;https://example-oidc-endpoint.com/oauth2/v2.0/token&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encryption and Compression&lt;/h3&gt; 
&lt;p&gt;The features are off by default. You can turn on encryption and/or compression:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localPort = 22
remotePort = 6000
transport.useEncryption = true
transport.useCompression = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;TLS&lt;/h4&gt; 
&lt;p&gt;Since v0.50.0, the default value of &lt;code&gt;transport.tls.enable&lt;/code&gt; and &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; has been changed to true, and tls is enabled by default.&lt;/p&gt; 
&lt;p&gt;For port multiplexing, frp sends a first byte &lt;code&gt;0x17&lt;/code&gt; to dial a TLS connection. This only takes effect when you set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;To &lt;strong&gt;enforce&lt;/strong&gt; &lt;code&gt;frps&lt;/code&gt; to only accept TLS connections - configure &lt;code&gt;transport.tls.force = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;. &lt;strong&gt;This is optional.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frpc&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;transport.tls.enable = true
transport.tls.certFile = &quot;certificate.crt&quot;
transport.tls.keyFile = &quot;certificate.key&quot;
transport.tls.trustedCaFile = &quot;ca.crt&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frps&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;transport.tls.force = true
transport.tls.certFile = &quot;certificate.crt&quot;
transport.tls.keyFile = &quot;certificate.key&quot;
transport.tls.trustedCaFile = &quot;ca.crt&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need &lt;strong&gt;a root CA cert&lt;/strong&gt; and &lt;strong&gt;at least one SSL/TLS certificate&lt;/strong&gt;. It &lt;strong&gt;can&lt;/strong&gt; be self-signed or regular (such as Let&#39;s Encrypt or another SSL/TLS certificate provider).&lt;/p&gt; 
&lt;p&gt;If you using &lt;code&gt;frp&lt;/code&gt; via IP address and not hostname, make sure to set the appropriate IP address in the Subject Alternative Name (SAN) area when generating SSL/TLS Certificates.&lt;/p&gt; 
&lt;p&gt;Given an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare openssl config file. It exists at &lt;code&gt;/etc/pki/tls/openssl.cnf&lt;/code&gt; in Linux System and &lt;code&gt;/System/Library/OpenSSL/openssl.cnf&lt;/code&gt; in MacOS, and you can copy it to current path, like &lt;code&gt;cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf&lt;/code&gt;. If not, you can build it by yourself, like:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;cat &amp;gt; my-openssl.cnf &amp;lt;&amp;lt; EOF
[ ca ]
default_ca = CA_default
[ CA_default ]
x509_extensions = usr_cert
[ req ]
default_bits        = 2048
default_md          = sha256
default_keyfile     = privkey.pem
distinguished_name  = req_distinguished_name
attributes          = req_attributes
x509_extensions     = v3_ca
string_mask         = utf8only
[ req_distinguished_name ]
[ req_attributes ]
[ usr_cert ]
basicConstraints       = CA:FALSE
nsComment              = &quot;OpenSSL Generated Certificate&quot;
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
[ v3_ca ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always,issuer
basicConstraints       = CA:true
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build ca certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=example.ca.com&quot; -days 5000 -out ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frps certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048

openssl req -new -sha256 -key server.key \
    -subj &quot;/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com&quot; \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf &quot;\n[SAN]\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com&quot;)) \
    -out server.csr

openssl x509 -req -days 365 -sha256 \
	-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf &quot;subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com&quot;) \
	-out server.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frpc certificates：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out client.key 2048
openssl req -new -sha256 -key client.key \
    -subj &quot;/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com&quot; \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf &quot;\n[SAN]\nsubjectAltName=DNS:client.com,DNS:example.client.com&quot;)) \
    -out client.csr

openssl x509 -req -days 365 -sha256 \
    -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf &quot;subjectAltName=DNS:client.com,DNS:example.client.com&quot;) \
	-out client.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hot-Reloading frpc configuration&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
webServer.addr = &quot;127.0.0.1&quot;
webServer.port = 7400
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run command &lt;code&gt;frpc reload -c ./frpc.toml&lt;/code&gt; and wait for about 10 seconds to let &lt;code&gt;frpc&lt;/code&gt; create or update or remove proxies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that global client parameters won&#39;t be modified except &#39;start&#39;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can run command &lt;code&gt;frpc verify -c ./frpc.toml&lt;/code&gt; before reloading to check if there are config errors.&lt;/p&gt; 
&lt;h3&gt;Get proxy status from client&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;frpc status -c ./frpc.toml&lt;/code&gt; to get status of all proxies. The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API.&lt;/p&gt; 
&lt;h3&gt;Only allowing certain ports on the server&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;allowPorts&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; is used to avoid abuse of ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
allowPorts = [
  { start = 2000, end = 3000 },
  { single = 3001 },
  { single = 3003 },
  { start = 4000, end = 50000 }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port Reuse&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt; in frps can use same port with &lt;code&gt;bindPort&lt;/code&gt;. frps will detect the connection&#39;s protocol and handle it correspondingly.&lt;/p&gt; 
&lt;p&gt;What you need to pay attention to is that if you want to configure &lt;code&gt;vhostHTTPSPort&lt;/code&gt; and &lt;code&gt;bindPort&lt;/code&gt; to the same port, you need to first set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;We would like to try to allow multiple proxies bind a same remote port with different protocols in the future.&lt;/p&gt; 
&lt;h3&gt;Bandwidth Limit&lt;/h3&gt; 
&lt;h4&gt;For Each Proxy&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localPort = 22
remotePort = 6000
transport.bandwidthLimit = &quot;1MB&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimit&lt;/code&gt; in each proxy&#39;s configure to enable this feature. Supported units are &lt;code&gt;MB&lt;/code&gt; and &lt;code&gt;KB&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimitMode&lt;/code&gt; to &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;server&lt;/code&gt; to limit bandwidth on the client or server side. Default is &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Stream Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports tcp stream multiplexing since v0.10.0 like HTTP2 Multiplexing, in which case all logic connections to the same frpc are multiplexed into the same TCP connection.&lt;/p&gt; 
&lt;p&gt;You can disable this feature by modify &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml and frpc.toml, must be same
transport.tcpMux = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support KCP Protocol&lt;/h3&gt; 
&lt;p&gt;KCP is a fast and reliable protocol that can achieve the transmission effect of a reduction of the average latency by 30% to 40% and reduction of the maximum delay by a factor of three, at the cost of 10% to 20% more bandwidth wasted than TCP.&lt;/p&gt; 
&lt;p&gt;KCP mode uses UDP as the underlying transport. Using KCP in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable KCP in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for KCP.
kcpBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;kcpBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use KCP to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
# Same as the &#39;kcpBindPort&#39; in frps.toml
serverPort = 7000
transport.protocol = &quot;kcp&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support QUIC Protocol&lt;/h3&gt; 
&lt;p&gt;QUIC is a new multiplexed transport built on top of UDP.&lt;/p&gt; 
&lt;p&gt;Using QUIC in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable QUIC in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for QUIC.
quicBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;quicBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use QUIC to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
# Same as the &#39;quicBindPort&#39; in frps.toml
serverPort = 7000
transport.protocol = &quot;quic&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connection Pooling&lt;/h3&gt; 
&lt;p&gt;By default, frps creates a new frpc connection to the backend service upon a user request. With connection pooling, frps keeps a certain number of pre-established connections, reducing the time needed to establish a connection.&lt;/p&gt; 
&lt;p&gt;This feature is suitable for a large number of short connections.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure the limit of pool count each proxy can use in &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
transport.maxPoolCount = 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;Enable and specify the number of connection pool:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
transport.poolCount = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load balancing&lt;/h3&gt; 
&lt;p&gt;Load balancing is supported by &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This feature is only available for types &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;tcpmux&lt;/code&gt; now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;test1&quot;
type = &quot;tcp&quot;
localPort = 8080
remotePort = 80
loadBalancer.group = &quot;web&quot;
loadBalancer.groupKey = &quot;123&quot;

[[proxies]]
name = &quot;test2&quot;
type = &quot;tcp&quot;
localPort = 8081
remotePort = 80
loadBalancer.group = &quot;web&quot;
loadBalancer.groupKey = &quot;123&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;loadBalancer.groupKey&lt;/code&gt; is used for authentication.&lt;/p&gt; 
&lt;p&gt;Connections to port 80 will be dispatched to proxies in the same group randomly.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;remotePort&lt;/code&gt; in the same group should be the same.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;customDomains&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;, &lt;code&gt;locations&lt;/code&gt; should be the same.&lt;/p&gt; 
&lt;h3&gt;Service Health Check&lt;/h3&gt; 
&lt;p&gt;Health check feature can help you achieve high availability with load balancing.&lt;/p&gt; 
&lt;p&gt;Add &lt;code&gt;healthCheck.type = &quot;tcp&quot;&lt;/code&gt; or &lt;code&gt;healthCheck.type = &quot;http&quot;&lt;/code&gt; to enable health check.&lt;/p&gt; 
&lt;p&gt;With health check type &lt;strong&gt;tcp&lt;/strong&gt;, the service port will be pinged (TCPing):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;test1&quot;
type = &quot;tcp&quot;
localPort = 22
remotePort = 6000
# Enable TCP health check
healthCheck.type = &quot;tcp&quot;
# TCPing timeout seconds
healthCheck.timeoutSeconds = 3
# If health check failed 3 times in a row, the proxy will be removed from frps
healthCheck.maxFailed = 3
# A health check every 10 seconds
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With health check type &lt;strong&gt;http&lt;/strong&gt;, an HTTP request will be sent to the service and an HTTP 2xx OK response is expected:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 80
customDomains = [&quot;test.example.com&quot;]
# Enable HTTP health check
healthCheck.type = &quot;http&quot;
# frpc will send a GET request to &#39;/status&#39;
# and expect an HTTP 2xx OK response
healthCheck.path = &quot;/status&quot;
healthCheck.timeoutSeconds = 3
healthCheck.maxFailed = 3
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rewriting the HTTP Host Header&lt;/h3&gt; 
&lt;p&gt;By default frp does not modify the tunneled HTTP requests at all as it&#39;s a byte-for-byte copy.&lt;/p&gt; 
&lt;p&gt;However, speaking of web servers and HTTP requests, your web server might rely on the &lt;code&gt;Host&lt;/code&gt; HTTP header to determine the website to be accessed. frp can rewrite the &lt;code&gt;Host&lt;/code&gt; header when forwarding the HTTP requests, with the &lt;code&gt;hostHeaderRewrite&lt;/code&gt; field:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localPort = 80
customDomains = [&quot;test.example.com&quot;]
hostHeaderRewrite = &quot;dev.example.com&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The HTTP request will have the &lt;code&gt;Host&lt;/code&gt; header rewritten to &lt;code&gt;Host: dev.example.com&lt;/code&gt; when it reaches the actual web server, although the request from the browser probably has &lt;code&gt;Host: test.example.com&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Setting other HTTP Headers&lt;/h3&gt; 
&lt;p&gt;Similar to &lt;code&gt;Host&lt;/code&gt;, You can override other HTTP request and response headers with proxy type &lt;code&gt;http&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localPort = 80
customDomains = [&quot;test.example.com&quot;]
hostHeaderRewrite = &quot;dev.example.com&quot;
requestHeaders.set.x-from-where = &quot;frp&quot;
responseHeaders.set.foo = &quot;bar&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, it will set header &lt;code&gt;x-from-where: frp&lt;/code&gt; in the HTTP request and &lt;code&gt;foo: bar&lt;/code&gt; in the HTTP response.&lt;/p&gt; 
&lt;h3&gt;Get Real IP&lt;/h3&gt; 
&lt;h4&gt;HTTP X-Forwarded-For&lt;/h4&gt; 
&lt;p&gt;This feature is for &lt;code&gt;http&lt;/code&gt; proxies or proxies with the &lt;code&gt;https2http&lt;/code&gt; and &lt;code&gt;https2https&lt;/code&gt; plugins enabled.&lt;/p&gt; 
&lt;p&gt;You can get user&#39;s real IP from HTTP request headers &lt;code&gt;X-Forwarded-For&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Proxy Protocol&lt;/h4&gt; 
&lt;p&gt;frp supports Proxy Protocol to send user&#39;s real IP to local services.&lt;/p&gt; 
&lt;p&gt;Here is an example for https service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;https&quot;
localPort = 443
customDomains = [&quot;test.example.com&quot;]

# now v1 and v2 are supported
transport.proxyProtocolVersion = &quot;v2&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable Proxy Protocol support in nginx to expose user&#39;s real IP in HTTP header &lt;code&gt;X-Real-IP&lt;/code&gt;, and then read &lt;code&gt;X-Real-IP&lt;/code&gt; header in your web service for the real IP.&lt;/p&gt; 
&lt;h3&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/h3&gt; 
&lt;p&gt;Anyone who can guess your tunnel URL can access your local web server unless you protect it with a password.&lt;/p&gt; 
&lt;p&gt;This enforces HTTP Basic Auth on all requests with the username and password specified in frpc&#39;s configure file.&lt;/p&gt; 
&lt;p&gt;It can only be enabled when proxy type is http.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localPort = 80
customDomains = [&quot;test.example.com&quot;]
httpUser = &quot;abc&quot;
httpPassword = &quot;abc&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://test.example.com&lt;/code&gt; in the browser and now you are prompted to enter the username and password.&lt;/p&gt; 
&lt;h3&gt;Custom Subdomain Names&lt;/h3&gt; 
&lt;p&gt;It is convenient to use &lt;code&gt;subdomain&lt;/code&gt; configure for http and https types when many people share one frps server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
subDomainHost = &quot;frps.com&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Resolve &lt;code&gt;*.frps.com&lt;/code&gt; to the frps server&#39;s IP. This is usually called a Wildcard DNS record.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web&quot;
type = &quot;http&quot;
localPort = 80
subdomain = &quot;test&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can visit your web service on &lt;code&gt;test.frps.com&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that if &lt;code&gt;subdomainHost&lt;/code&gt; is not empty, &lt;code&gt;customDomains&lt;/code&gt; should not be the subdomain of &lt;code&gt;subdomainHost&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;URL Routing&lt;/h3&gt; 
&lt;p&gt;frp supports forwarding HTTP requests to different backend web services by url routing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;locations&lt;/code&gt; specifies the prefix of URL used for routing. frps first searches for the most specific prefix location given by literal strings regardless of the listed order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;web01&quot;
type = &quot;http&quot;
localPort = 80
customDomains = [&quot;web.example.com&quot;]
locations = [&quot;/&quot;]

[[proxies]]
name = &quot;web02&quot;
type = &quot;http&quot;
localPort = 81
customDomains = [&quot;web.example.com&quot;]
locations = [&quot;/news&quot;, &quot;/about&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;HTTP requests with URL prefix &lt;code&gt;/news&lt;/code&gt; or &lt;code&gt;/about&lt;/code&gt; will be forwarded to &lt;strong&gt;web02&lt;/strong&gt; and other requests to &lt;strong&gt;web01&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Port Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to &lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The only supported TCP port multiplexing method available at the moment is &lt;code&gt;httpconnect&lt;/code&gt; - HTTP CONNECT tunnel.&lt;/p&gt; 
&lt;p&gt;When setting &lt;code&gt;tcpmuxHTTPConnectPort&lt;/code&gt; to anything other than 0 in frps, frps will listen on this port for HTTP CONNECT requests.&lt;/p&gt; 
&lt;p&gt;The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring &lt;code&gt;customDomains&lt;/code&gt; and / or &lt;code&gt;subdomain&lt;/code&gt; under &lt;code&gt;tcpmux&lt;/code&gt; proxies, when &lt;code&gt;multiplexer = &quot;httpconnect&quot;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
bindPort = 7000
tcpmuxHTTPConnectPort = 1337
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000

[[proxies]]
name = &quot;proxy1&quot;
type = &quot;tcpmux&quot;
multiplexer = &quot;httpconnect&quot;
customDomains = [&quot;test1&quot;]
localPort = 80

[[proxies]]
name = &quot;proxy2&quot;
type = &quot;tcpmux&quot;
multiplexer = &quot;httpconnect&quot;
customDomains = [&quot;test2&quot;]
localPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CONNECT test1 HTTP/1.1\r\n\r\n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the connection will be routed to &lt;code&gt;proxy1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting to frps via PROXY&lt;/h3&gt; 
&lt;p&gt;frpc can connect to frps through proxy if you set OS environment variable &lt;code&gt;HTTP_PROXY&lt;/code&gt;, or if &lt;code&gt;transport.proxyURL&lt;/code&gt; is set in frpc.toml file.&lt;/p&gt; 
&lt;p&gt;It only works when protocol is tcp.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000
transport.proxyURL = &quot;http://user:pwd@192.168.1.128:8080&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port range mapping&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Added in v0.56.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;We can use the range syntax of Go template combined with the built-in &lt;code&gt;parseNumberRangePair&lt;/code&gt; function to achieve port range mapping.&lt;/p&gt; 
&lt;p&gt;The following example, when run, will create 8 proxies named &lt;code&gt;test-6000, test-6001 ... test-6007&lt;/code&gt;, each mapping the remote port to the local port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{{- range $_, $v := parseNumberRangePair &quot;6000-6006,6007&quot; &quot;6000-6006,6007&quot; }}
[[proxies]]
name = &quot;tcp-{{ $v.First }}&quot;
type = &quot;tcp&quot;
localPort = {{ $v.First }}
remotePort = {{ $v.Second }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client Plugins&lt;/h3&gt; 
&lt;p&gt;frpc only forwards requests to local TCP or UDP ports by default.&lt;/p&gt; 
&lt;p&gt;Plugins are used for providing rich features. There are built-in plugins such as &lt;code&gt;unix_domain_socket&lt;/code&gt;, &lt;code&gt;http_proxy&lt;/code&gt;, &lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;static_file&lt;/code&gt;, &lt;code&gt;http2https&lt;/code&gt;, &lt;code&gt;https2http&lt;/code&gt;, &lt;code&gt;https2https&lt;/code&gt; and you can see &lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage&quot;&gt;example usage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Using plugin &lt;strong&gt;http_proxy&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frpc.toml

[[proxies]]
name = &quot;http_proxy&quot;
type = &quot;tcp&quot;
remotePort = 6000
[proxies.plugin]
type = &quot;http_proxy&quot;
httpUser = &quot;abc&quot;
httpPassword = &quot;abc&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;httpUser&lt;/code&gt; and &lt;code&gt;httpPassword&lt;/code&gt; are configuration parameters used in &lt;code&gt;http_proxy&lt;/code&gt; plugin.&lt;/p&gt; 
&lt;h3&gt;Server Manage Plugins&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/server_plugin.md&quot;&gt;document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find more plugins in &lt;a href=&quot;https://github.com/gofrp/plugin&quot;&gt;gofrp/plugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SSH Tunnel Gateway&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;added in v0.53.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;frp supports listening to an SSH port on the frps side and achieves TCP protocol proxying through the SSH -R protocol, without relying on frpc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;# frps.toml
sshTunnelGateway.bindPort = 2200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running &lt;code&gt;./frps -c frps.toml&lt;/code&gt;, a private key file named &lt;code&gt;.autogen_ssh_key&lt;/code&gt; will be automatically created in the current working directory. This generated private key file will be used by the SSH server in frps.&lt;/p&gt; 
&lt;p&gt;Executing the command&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ssh -R :80:127.0.0.1:8080 v0@{frp address} -p 2200 tcp --proxy_name &quot;test-tcp&quot; --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;sets up a proxy on frps that forwards the local 8080 service to the port 9090.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;frp (via SSH) (Ctrl+C to quit)

User:
ProxyName: test-tcp
Type: tcp
RemoteAddress: :9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is equivalent to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;frpc tcp --proxy_name &quot;test-tcp&quot; --local_ip 127.0.0.1 --local_port 8080 --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to this &lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/ssh_tunnel_gateway.md&quot;&gt;document&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Virtual Network (VirtualNet)&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Alpha feature added in v0.62.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The VirtualNet feature enables frp to create and manage virtual network connections between clients and visitors through a TUN interface. This allows for IP-level routing between machines, extending frp beyond simple port forwarding to support full network connectivity.&lt;/p&gt; 
&lt;p&gt;For detailed information about configuration and usage, please refer to the &lt;a href=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/virtual_net.md&quot;&gt;VirtualNet documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Gates&lt;/h2&gt; 
&lt;p&gt;frp supports feature gates to enable or disable experimental features. This allows users to try out new features before they&#39;re considered stable.&lt;/p&gt; 
&lt;h3&gt;Available Feature Gates&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VirtualNet&lt;/td&gt; 
   &lt;td&gt;ALPHA&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Virtual network capabilities for frp&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabling Feature Gates&lt;/h3&gt; 
&lt;p&gt;To enable an experimental feature, add the feature gate to your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;featureGates = { VirtualNet = true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Lifecycle&lt;/h3&gt; 
&lt;p&gt;Features typically go through three stages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ALPHA&lt;/strong&gt;: Disabled by default, may be unstable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BETA&lt;/strong&gt;: May be enabled by default, more stable but still evolving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GA (Generally Available)&lt;/strong&gt;: Enabled by default, ready for production use&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gofrp/plugin&quot;&gt;gofrp/plugin&lt;/a&gt; - A repository for frp plugins that contains a variety of plugins implemented based on the frp extension mechanism, meeting the customization needs of different scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gofrp/tiny-frpc&quot;&gt;gofrp/tiny-frpc&lt;/a&gt; - A lightweight version of the frp client (around 3.5MB at minimum) implemented using the ssh protocol, supporting some of the most commonly used features, suitable for devices with limited resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in getting involved? We would like to help you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take a look at our &lt;a href=&quot;https://github.com/fatedier/frp/issues&quot;&gt;issues list&lt;/a&gt; and consider sending a Pull Request to &lt;strong&gt;dev branch&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to add a new feature, please create an issue first to describe the new feature, as well as the implementation approach. Once a proposal is accepted, create an implementation of the new features and submit it as a pull request.&lt;/li&gt; 
 &lt;li&gt;Sorry for my poor English. Improvements for this document are welcome, even some typo fixes.&lt;/li&gt; 
 &lt;li&gt;If you have great ideas, send an email to &lt;a href=&quot;mailto:fatedier@gmail.com&quot;&gt;fatedier@gmail.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note: We prefer you to give your advise in &lt;a href=&quot;https://github.com/fatedier/frp/issues&quot;&gt;issues&lt;/a&gt;, so others with a same question can search it quickly and we don&#39;t need to answer them repeatedly.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Donation&lt;/h2&gt; 
&lt;p&gt;If frp helps you a lot, you can support us by:&lt;/p&gt; 
&lt;h3&gt;GitHub Sponsors&lt;/h3&gt; 
&lt;p&gt;Support us by &lt;a href=&quot;https://github.com/sponsors/fatedier&quot;&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can have your company&#39;s logo placed on README file of this project.&lt;/p&gt; 
&lt;h3&gt;PayPal&lt;/h3&gt; 
&lt;p&gt;Donate money by &lt;a href=&quot;https://www.paypal.me/fatedier&quot;&gt;PayPal&lt;/a&gt; to my account &lt;strong&gt;&lt;a href=&quot;mailto:fatedier@gmail.com&quot;&gt;fatedier@gmail.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector</link>
      <description>&lt;p&gt;OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;strong&gt; &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt; &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;amp;style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt; &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt; &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt; &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;amp;style=for-the-badge&quot; /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot; /&gt; &lt;/a&gt; &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:opentelemetry&quot;&gt; &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg?sanitize=true&quot; /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;strong&gt; &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot; /&gt; OpenTelemetry Collector&lt;/h1&gt; 
&lt;p&gt;The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.&lt;/p&gt; 
&lt;p&gt;Objectives:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.&lt;/li&gt; 
 &lt;li&gt;Performant: Highly stable and performant under varying loads and configurations.&lt;/li&gt; 
 &lt;li&gt;Observable: An exemplar of an observable service.&lt;/li&gt; 
 &lt;li&gt;Extensible: Customizable without touching the core code.&lt;/li&gt; 
 &lt;li&gt;Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The OpenTelemetry Collector SIG is present at the &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;#otel-collector&lt;/a&gt; channel on the CNCF Slack and &lt;a href=&quot;https://github.com/open-telemetry/community#implementation-sigs&quot;&gt;meets once a week&lt;/a&gt; via video calls. Everyone is invited to join those calls, which typically serves the following purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;meet the humans behind the project&lt;/li&gt; 
 &lt;li&gt;get an opinion about specific proposals&lt;/li&gt; 
 &lt;li&gt;look for a sponsor for a proposed component after trying already via GitHub and Slack&lt;/li&gt; 
 &lt;li&gt;get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We rotate our video calls between three time slots, in order to allow everyone to join at least once every three meetings. The rotation order is as follows:&lt;/p&gt; 
&lt;p&gt;Tuesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dateful.com/convert/pst-pdt-pacific-time?t=1700&quot;&gt;17:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Wednesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dateful.com/convert/pst-pdt-pacific-time?t=0900&quot;&gt;09:00 PT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dateful.com/convert/pst-pdt-pacific-time?t=0500&quot;&gt;05:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points. Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to identify who would be the other contributors interested on that topic and in which timezones they are.&lt;/p&gt; 
&lt;p&gt;Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous calls and don&#39;t want them to feel excluded.&lt;/p&gt; 
&lt;h2&gt;Supported OTLP version&lt;/h2&gt; 
&lt;p&gt;This code base is currently built against using OTLP protocol v1.5.0, considered Stable. &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition&quot;&gt;See the OpenTelemetry Protocol Stability definition here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/component-stability.md&quot;&gt;Stability Levels and versioning&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as &lt;a href=&quot;https://go.dev/doc/devel/release#policy&quot;&gt;defined by the Go team&lt;/a&gt;. Removing support for an unsupported Go version is not considered a breaking change.&lt;/p&gt; 
&lt;p&gt;Support for Go versions on the OpenTelemetry Collector is updated as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will add build and tests steps for the new Go minor version.&lt;/li&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will remove support for Go version &lt;code&gt;N-2&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.&lt;/p&gt; 
&lt;h2&gt;Verifying the images signatures&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To verify a signed artifact or blob, first &lt;a href=&quot;https://docs.sigstore.dev/cosign/system_config/installation/&quot;&gt;install Cosign&lt;/a&gt;, then follow the instructions below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We are signing the images &lt;code&gt;otel/opentelemetry-collector&lt;/code&gt; and &lt;code&gt;otel/opentelemetry-collector-contrib&lt;/code&gt; using &lt;a href=&quot;https://github.com/sigstore/cosign&quot;&gt;sigstore cosign&lt;/a&gt; tool and to verify the signatures you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-console&quot;&gt;$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&amp;lt;RELEASE_TAG&amp;gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;RELEASE_TAG&amp;gt;&lt;/code&gt;: is the release that you want to validate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;&lt;/code&gt;: is the image that you want to check&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-console&quot;&gt;$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809122,&quot;logIndex&quot;:84797940,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We started signing the images with release &lt;code&gt;v0.95.0&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md&quot;&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Here is a list of community roles with current and previous members:&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/codeboten&quot;&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/BogdanDrutu&quot;&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dmitryax&quot;&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mx-psi&quot;&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/atoulme&quot;&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dmathieu&quot;&gt;Damien Mathieu&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/evan-bradley&quot;&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jade-guiton-dd&quot;&gt;Jade Guiton&lt;/a&gt;, Datadog&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jmacd&quot;&gt;Joshua MacDonald&lt;/a&gt;, Microsoft&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/TylerHelmuth&quot;&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/songy23&quot;&gt;Yang Song&lt;/a&gt;, Datadog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating the role of the &lt;a href=&quot;https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/release.md#release-manager&quot;&gt;release manager&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/andrzej-stencel&quot;&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sincejune&quot;&gt;Chao Weng&lt;/a&gt;, AppDynamics&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/VihasMakwana&quot;&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pjanotti&quot;&gt;Paulo Janotti&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/tigrannajaryan&quot;&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Aneurysm9&quot;&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/djaglowski&quot;&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/james-bebbington&quot;&gt;James Bebbington&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jrcamp&quot;&gt;Jay Camp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jpkrohling&quot;&gt;Juraci Paixão Kröhling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/nilebox&quot;&gt;Nail Islamov&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/owais&quot;&gt;Owais Lone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/rghetia&quot;&gt;Rahul Patel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/sjkaris&quot;&gt;Steven Karis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/alolita&quot;&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/andrewhsu&quot;&gt;Andrew Hsu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/punya&quot;&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/flands&quot;&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href=&quot;https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager&quot;&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thanks to all of our contributors!&lt;/h3&gt; 
&lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors&quot;&gt; &lt;img alt=&quot;Repo contributors&quot; src=&quot;https://contrib.rocks/image?repo=open-telemetry/opentelemetry-collector&quot; /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>getsops/sops</title>
      <link>https://github.com/getsops/sops</link>
      <description>&lt;p&gt;Simple and flexible tool for managing secrets&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SOPS: Secrets OPerationS&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;SOPS&lt;/strong&gt; is an editor of encrypted files that supports YAML, JSON, ENV, INI and BINARY formats and encrypts with AWS KMS, GCP KMS, Azure Key Vault, age, and PGP. (&lt;code&gt;demo &amp;lt;https://www.youtube.com/watch?v=YTEVyLXFiq0&amp;gt;&lt;/code&gt;_)&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://i.imgur.com/X0TM5NI.gif&quot;&gt;https://i.imgur.com/X0TM5NI.gif&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://pkg.go.dev/badge/github.com/getsops/sops/v3.svg&quot;&gt;https://pkg.go.dev/badge/github.com/getsops/sops/v3.svg&lt;/a&gt; :target: &lt;a href=&quot;https://pkg.go.dev/github.com/getsops/sops/v3&quot;&gt;https://pkg.go.dev/github.com/getsops/sops/v3&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;Stable release&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Binaries and packages of the latest stable release are available at `https://github.com/getsops/sops/releases &amp;lt;https://github.com/getsops/sops/releases&amp;gt;`_.

Development branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the adventurous, unstable features are available in the &lt;code&gt;main&lt;/code&gt; branch, which you can install from source:&lt;/p&gt; 
&lt;p&gt;.. code:: bash&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/getsops/sops/
$ git clone https://github.com/getsops/sops.git $GOPATH/src/github.com/getsops/sops/
$ cd $GOPATH/src/github.com/getsops/sops/
$ make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(requires Go &amp;gt;= 1.19)&lt;/p&gt; 
&lt;p&gt;If you don&#39;t have Go installed, set it up with:&lt;/p&gt; 
&lt;p&gt;.. code:: bash&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ {apt,yum,brew} install golang
$ echo &#39;export GOPATH=~/go&#39; &amp;gt;&amp;gt; ~/.bashrc
$ source ~/.bashrc
$ mkdir $GOPATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or whatever variation of the above fits your system and shell.&lt;/p&gt; 
&lt;p&gt;To use &lt;strong&gt;SOPS&lt;/strong&gt; as a library, take a look at the &lt;code&gt;decrypt package &amp;lt;https://pkg.go.dev/github.com/getsops/sops/v3/decrypt&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. sectnum:: .. contents:: Table of Contents&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;For a quick presentation of SOPS, check out this Youtube tutorial:&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://img.youtube.com/vi/V2PRhxphH2w/0.jpg&quot;&gt;https://img.youtube.com/vi/V2PRhxphH2w/0.jpg&lt;/a&gt; :target: &lt;a href=&quot;https://www.youtube.com/watch?v=V2PRhxphH2w&quot;&gt;https://www.youtube.com/watch?v=V2PRhxphH2w&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you&#39;re using AWS KMS, create one or multiple master keys in the IAM console and export them, comma separated, in the &lt;strong&gt;SOPS_KMS_ARN&lt;/strong&gt; env variable. It is recommended to use at least two master keys in different regions.&lt;/p&gt; 
&lt;p&gt;.. code:: bash&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export SOPS_KMS_ARN=&quot;arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e,arn:aws:kms:ap-southeast-1:656532927350:key/9006a8aa-0fa6-4c14-930e-a2dfb916de1d&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS uses &lt;code&gt;aws-sdk-go-v2 &amp;lt;https://github.com/aws/aws-sdk-go-v2&amp;gt;&lt;/code&gt;_ to communicate with AWS KMS. It will automatically read the credentials from the &lt;code&gt;~/.aws/credentials&lt;/code&gt; file which can be created with the &lt;code&gt;aws configure&lt;/code&gt; command.&lt;/p&gt; 
&lt;p&gt;An example of the &lt;code&gt;~/.aws/credentials&lt;/code&gt; file is shown below:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat ~/.aws/credentials
[default]
aws_access_key_id = AKI.....
aws_secret_access_key = mw......
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to the &lt;code&gt;~/.aws/credentials&lt;/code&gt; file, you can also use the &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt; and &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt; environment variables to specify your credentials:&lt;/p&gt; 
&lt;p&gt;.. code:: bash&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=&quot;AKI......&quot;
export AWS_SECRET_ACCESS_KEY=&quot;mw......&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information and additional environment variables, see &lt;code&gt;specifying credentials &amp;lt;https://aws.github.io/aws-sdk-go-v2/docs/configuring-sdk/#specifying-credentials&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;If you want to use PGP, export the fingerprints of the public keys, comma separated, in the &lt;strong&gt;SOPS_PGP_FP&lt;/strong&gt; env variable.&lt;/p&gt; 
&lt;p&gt;.. code:: bash&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export SOPS_PGP_FP=&quot;85D77543B3D624B63CEA9E6DBC17301B491B3F21,E60892BB9BD89A69F759A1A0A3D652173B763E8F&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: you can use both PGP and KMS simultaneously.&lt;/p&gt; 
&lt;p&gt;Then simply call &lt;code&gt;sops edit&lt;/code&gt; with a file path as argument. It will handle the encryption/decryption transparently and open the cleartext file in an editor&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops edit mynewtestfile.yaml
mynewtestfile.yaml doesn&#39;t exist, creating it.
please wait while an encryption key is being generated and stored in a secure fashion
file written to mynewtestfile.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Editing will happen in whatever &lt;code&gt;$SOPS_EDITOR&lt;/code&gt; or &lt;code&gt;$EDITOR&lt;/code&gt; is set to, or, if it&#39;s not set, in vim, nano, or vi. Keep in mind that SOPS will wait for the editor to exit, and then try to reencrypt the file. Some GUI editors (atom, sublime) spawn a child process and then exit immediately. They usually have an option to wait for the main editor window to be closed before exiting. See &lt;code&gt;#127 &amp;lt;https://github.com/getsops/sops/issues/127&amp;gt;&lt;/code&gt;_ for more information.&lt;/p&gt; 
&lt;p&gt;The resulting encrypted file looks like this:&lt;/p&gt; 
&lt;p&gt;.. code:: yaml&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;myapp1: ENC[AES256_GCM,data:Tr7o=,iv:1=,aad:No=,tag:k=]
app2:
    db:
        user: ENC[AES256_GCM,data:CwE4O1s=,iv:2k=,aad:o=,tag:w==]
        password: ENC[AES256_GCM,data:p673w==,iv:YY=,aad:UQ=,tag:A=]
    # private key for secret operations in app2
    key: |-
        ENC[AES256_GCM,data:Ea3kL5O5U8=,iv:DM=,aad:FKA=,tag:EA==]
an_array:
    - ENC[AES256_GCM,data:v8jQ=,iv:HBE=,aad:21c=,tag:gA==]
    - ENC[AES256_GCM,data:X10=,iv:o8=,aad:CQ=,tag:Hw==]
    - ENC[AES256_GCM,data:KN=,iv:160=,aad:fI4=,tag:tNw==]
sops:
    kms:
        - created_at: 1441570389.775376
          enc: CiC....Pm1Hm
          arn: arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e
        - created_at: 1441570391.925734
          enc: Ci...awNx
          arn: arn:aws:kms:ap-southeast-1:656532927350:key/9006a8aa-0fa6-4c14-930e-a2dfb916de1d
    pgp:
        - fp: 85D77543B3D624B63CEA9E6DBC17301B491B3F21
          created_at: 1441570391.930042
          enc: |
              -----BEGIN PGP MESSAGE-----
              hQIMA0t4uZHfl9qgAQ//UvGAwGePyHuf2/zayWcloGaDs0MzI+zw6CmXvMRNPUsA
              ...=oJgS
              -----END PGP MESSAGE-----
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A copy of the encryption/decryption key is stored securely in each KMS and PGP block. As long as one of the KMS or PGP method is still usable, you will be able to access your data.&lt;/p&gt; 
&lt;p&gt;To decrypt a file in a &lt;code&gt;cat&lt;/code&gt; fashion, use the &lt;code&gt;-d&lt;/code&gt; flag:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops decrypt mynewtestfile.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS encrypted files contain the necessary information to decrypt their content. All a user of SOPS needs is valid AWS credentials and the necessary permissions on KMS keys.&lt;/p&gt; 
&lt;p&gt;Given that, the only command a SOPS user needs is:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops edit &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;&amp;lt;file&amp;gt;&lt;/code&gt; will be opened, decrypted, passed to a text editor (vim by default), encrypted if modified, and saved back to its original location. All of these steps, apart from the actual editing, are transparent to the user.&lt;/p&gt; 
&lt;p&gt;The order in which available decryption methods are tried can be specified with &lt;code&gt;--decryption-order&lt;/code&gt; option or &lt;strong&gt;SOPS_DECRYPTION_ORDER&lt;/strong&gt; environment variable as a comma separated list. The default order is &lt;code&gt;age,pgp&lt;/code&gt;. Offline methods are tried first and then the remaining ones.&lt;/p&gt; 
&lt;p&gt;Test with the dev PGP key&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
If you want to test **SOPS** without having to do a bunch of setup, you can use
the example files and pgp key provided with the repository::

    $ git clone https://github.com/getsops/sops.git
    $ cd sops
    $ gpg --import pgp/sops_functional_tests_key.asc
    $ sops edit example.yaml

This last step will decrypt ``example.yaml`` using the test private key.

Encrypting with GnuPG subkeys
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to encrypt with specific GnuPG subkeys, it does not suffice to provide the exact key ID of the subkey to SOPS, since GnuPG might use &lt;em&gt;another&lt;/em&gt; subkey instead to encrypt the file key with. To force GnuPG to use a specific subkey, you need to append &lt;code&gt;!&lt;/code&gt; to the key&#39;s fingerprint.&lt;/p&gt; 
&lt;p&gt;.. code:: yaml&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;creation_rules:
    - pgp: &amp;gt;-
        85D77543B3D624B63CEA9E6DBC17301B491B3F21!,
        E60892BB9BD89A69F759A1A0A3D652173B763E8F!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please note that this is only passed on correctly to GnuPG since SOPS 3.9.3.&lt;/p&gt; 
&lt;p&gt;Encrypting using age&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
`age &amp;lt;https://age-encryption.org/&amp;gt;`_ is a simple, modern, and secure tool for
encrypting files. It&#39;s recommended to use age over PGP, if possible.

You can encrypt a file for one or more age recipients (comma separated) using
the ``--age`` option or the **SOPS_AGE_RECIPIENTS** environment variable:

.. code:: sh

    $ sops encrypt --age age1yt3tfqlfrwdwx0z0ynwplcr6qxcxfaqycuprpmy89nr83ltx74tqdpszlw test.yaml &amp;gt; test.enc.yaml

When decrypting a file with the corresponding identity, SOPS will look for a
text file name ``keys.txt`` located in a ``sops`` subdirectory of your user
configuration directory. 

- **Linux**

  - Looks for ``keys.txt`` in ``$XDG_CONFIG_HOME/sops/age/keys.txt``;
  - Falls back to ``$HOME/.config/sops/age/keys.txt`` if ``$XDG_CONFIG_HOME`` isn’t set.

- **macOS**

  - Looks for ``keys.txt`` in ``$XDG_CONFIG_HOME/sops/age/keys.txt``;
  - Falls back to ``$HOME/Library/Application Support/sops/age/keys.txt``.

- **Windows**

  - Looks for ``keys.txt`` in `%AppData%\\sops\\age\\keys.txt``.

You can override the default lookup by:

- setting the environment variable **SOPS_AGE_KEY_FILE**;
- setting the **SOPS_AGE_KEY** environment variable;
- providing a command to output the age keys by setting the **SOPS_AGE_KEY_CMD** environment variable..

The contents of this key file should be a list of age X25519 identities, one
per line. Lines beginning with ``#`` are considered comments and ignored. Each
identity will be tried in sequence until one is able to decrypt the data.

Encrypting with SSH keys via age is also supported by SOPS. You can use SSH public keys
(&quot;ssh-ed25519 AAAA...&quot;, &quot;ssh-rsa AAAA...&quot;) as age recipients when encrypting a file.
When decrypting a file, SOPS will look for ``~/.ssh/id_ed25519`` and falls back to
``~/.ssh/id_rsa``. You can specify the location of the private key manually by setting
the environment variable **SOPS_AGE_SSH_PRIVATE_KEY_FILE**.

Note that only ``ssh-rsa`` and ``ssh-ed25519`` are supported.

A list of age recipients can be added to the ``.sops.yaml``:

.. code:: yaml

    creation_rules:
        - age: &amp;gt;-
            age1s3cqcks5genc6ru8chl0hkkd04zmxvczsvdxq99ekffe4gmvjpzsedk23c,
            age1qe5lxzzeppw5k79vxn3872272sgy224g2nzqlzy3uljs84say3yqgvd0sw

It is also possible to use ``updatekeys``, when adding or removing age recipients. For example:

.. code:: sh

  $ sops updatekeys secret.enc.yaml
  2022/02/09 16:32:02 Syncing keys for file /iac/solution1/secret.enc.yaml
  The following changes will be made to the file&#39;s groups:
  Group 1
      age1s3cqcks5genc6ru8chl0hkkd04zmxvczsvdxq99ekffe4gmvjpzsedk23c
  +++ age1qe5lxzzeppw5k79vxn3872272sgy224g2nzqlzy3uljs84say3yqgvd0sw
  Is this okay? (y/n):y
  2022/02/09 16:32:04 File /iac/solution1/secret.enc.yaml synced with new keys
  
Encrypting using GCP KMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;GCP KMS has support for authorization with the use of &lt;code&gt;Application Default Credentials &amp;lt;https://developers.google.com/identity/protocols/application-default-credentials&amp;gt;&lt;/code&gt;_ and using an OAuth 2.0 token. Application default credentials precedes the use of access token.&lt;/p&gt; 
&lt;p&gt;Using Application Default Credentials you can authorize by doing this:&lt;/p&gt; 
&lt;p&gt;If you already logged in using&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ gcloud auth login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;you can enable application default credentials using the sdk:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ gcloud auth application-default login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using OAauth tokens you can authorize by doing this:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ export GOOGLE_OAUTH_ACCESS_TOKEN=&amp;lt;your access token&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or if you are logged in you can authorize by generating an access token:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ export GOOGLE_OAUTH_ACCESS_TOKEN=&quot;$(gcloud auth print-access-token)&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Encrypting/decrypting with GCP KMS requires a KMS ResourceID. You can use the cloud console the get the ResourceID or you can create one using the gcloud sdk:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ gcloud kms keyrings create sops --location global
$ gcloud kms keys create sops-key --location global --keyring sops --purpose encryption
$ gcloud kms keys list --location global --keyring sops

# you should see
NAME                                                                   PURPOSE          PRIMARY_STATE
projects/my-project/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT  ENABLED
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can encrypt a file using::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops encrypt --gcp-kms projects/my-project/locations/global/keyRings/sops/cryptoKeys/sops-key test.yaml &amp;gt; test.enc.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And decrypt it using::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; $ sops decrypt test.enc.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Encrypting using Azure Key Vault&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
The Azure Key Vault integration uses the
`default credential chain &amp;lt;https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#DefaultAzureCredential&amp;gt;`_
which tries several authentication methods, in this order:

1. `Environment credentials &amp;lt;https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#EnvironmentCredential&amp;gt;`_

   i. Service Principal with Client Secret
   ii. Service Principal with Certificate
   iii. User with username and password
   iv. Configuration for multi-tenant applications

2. `Workload Identity credentials &amp;lt;https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#WorkloadIdentityCredential&amp;gt;`_
3. `Managed Identity credentials &amp;lt;https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#ManagedIdentityCredential&amp;gt;`_
4. `Azure CLI credentials &amp;lt;https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/azidentity#AzureCLICredential&amp;gt;`_

For example, you can use a Service Principal with the following environment variables:

.. code:: bash

    AZURE_TENANT_ID
    AZURE_CLIENT_ID
    AZURE_CLIENT_SECRET

You can create a Service Principal using the CLI like this:

.. code:: sh

    $ az ad sp create-for-rbac -n my-keyvault-sp

    {
        &quot;appId&quot;: &quot;&amp;lt;some-uuid&amp;gt;&quot;,
        &quot;displayName&quot;: &quot;my-keyvault-sp&quot;,
        &quot;name&quot;: &quot;http://my-keyvault-sp&quot;,
        &quot;password&quot;: &quot;&amp;lt;random-string&amp;gt;&quot;,
        &quot;tenant&quot;: &quot;&amp;lt;tenant-uuid&amp;gt;&quot;
    }

The `appId` is the client ID, and the `password` is the client secret.

Encrypting/decrypting with Azure Key Vault requires the resource identifier for
a key. This has the following form::

    https://${VAULT_URL}/keys/${KEY_NAME}/${KEY_VERSION}

To create a Key Vault and assign your service principal permissions on it
from the commandline:

.. code:: sh

    # Create a resource group if you do not have one:
    $ az group create --name sops-rg --location westeurope
    # Key Vault names are globally unique, so generate one:
    $ keyvault_name=sops-$(uuidgen | tr -d - | head -c 16)
    # Create a Vault, a key, and give the service principal access:
    $ az keyvault create --name $keyvault_name --resource-group sops-rg --location westeurope
    $ az keyvault key create --name sops-key --vault-name $keyvault_name --protection software --ops encrypt decrypt
    $ az keyvault set-policy --name $keyvault_name --resource-group sops-rg --spn $AZURE_CLIENT_ID \
        --key-permissions encrypt decrypt
    # Read the key id:
    $ az keyvault key show --name sops-key --vault-name $keyvault_name --query key.kid

    https://sops.vault.azure.net/keys/sops-key/some-string

Now you can encrypt a file using::

    $ sops encrypt --azure-kv https://sops.vault.azure.net/keys/sops-key/some-string test.yaml &amp;gt; test.enc.yaml

And decrypt it using::

    $ sops decrypt test.enc.yaml


Encrypting and decrypting from other programs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using &lt;code&gt;sops&lt;/code&gt; in scripts or from other programs, there are often situations where you do not want to write encrypted or decrypted data to disk. The best way to avoid this is to pass data to SOPS via stdin, and to let SOPS write data to stdout. By default, the encrypt and decrypt operations write data to stdout already. To pass data via stdin, you need to not provide an input filename. For encryption, you also must provide the &lt;code&gt;--filename-override&lt;/code&gt; option with the file&#39;s filename. The filename will be used to determine the input and output types, and to select the correct creation rule.&lt;/p&gt; 
&lt;p&gt;The simplest way to decrypt data from stdin is as follows:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat encrypted-data | sops decrypt &amp;gt; decrypted-data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, &lt;code&gt;sops&lt;/code&gt; determines the input and output format from the provided filename. Since in this case, no filename is provided, &lt;code&gt;sops&lt;/code&gt; will use the binary store which expects JSON input and outputs binary data on decryption. This is often not what you want.&lt;/p&gt; 
&lt;p&gt;To avoid this, you can either provide a filename with &lt;code&gt;--filename-override&lt;/code&gt;, or explicitly control the input and output formats by passing &lt;code&gt;--input-type&lt;/code&gt; and &lt;code&gt;--output-type&lt;/code&gt; as appropriate:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat encrypted-data | sops decrypt --filename-override filename.yaml &amp;gt; decrypted-data
$ cat encrypted-data | sops decrypt --input-type yaml --output-type yaml &amp;gt; decrypted-data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In both cases, &lt;code&gt;sops&lt;/code&gt; will assume that the data you provide is in YAML format, and will encode the decrypted data in YAML as well. The second form allows to use different formats for input and output.&lt;/p&gt; 
&lt;p&gt;To encrypt, it is important to note that SOPS also uses the filename to look up the correct creation rule from &lt;code&gt;.sops.yaml&lt;/code&gt;. Therefore, you must provide the &lt;code&gt;--filename-override&lt;/code&gt; parameter which allows you to tell SOPS which filename to use to match creation rules:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ echo &#39;foo: bar&#39; | sops encrypt --filename-override path/filename.sops.yaml &amp;gt; encrypted-data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS will find a matching creation rule for &lt;code&gt;path/filename.sops.yaml&lt;/code&gt; in &lt;code&gt;.sops.yaml&lt;/code&gt; and use that one to encrypt the data from stdin. This filename will also be used to determine the input and output store. As always, the input store type can be adjusted by passing &lt;code&gt;--input-type&lt;/code&gt;, and the output store type by passing &lt;code&gt;--output-type&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ echo foo=bar | sops encrypt --filename-override path/filename.sops.yaml --input-type dotenv &amp;gt; encrypted-data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Encrypting using Hashicorp Vault&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
We assume you have an instance (or more) of Vault running and you have privileged access to it. For instructions on how to deploy a secure instance of Vault, refer to Hashicorp&#39;s official documentation.

To easily deploy Vault locally: (DO NOT DO THIS FOR PRODUCTION!!!) 

.. code:: sh

    $ docker run -d -p8200:8200 vault:1.2.0 server -dev -dev-root-token-id=toor


.. code:: sh

    $ # Substitute this with the address Vault is running on
    $ export VAULT_ADDR=http://127.0.0.1:8200 

    $ # this may not be necessary in case you previously used `vault login` for production use
    $ export VAULT_TOKEN=toor 
    
    $ # to check if Vault started and is configured correctly
    $ vault status
    Key             Value
    ---             -----
    Seal Type       shamir
    Initialized     true
    Sealed          false
    Total Shares    1
    Threshold       1
    Version         1.2.0
    Cluster Name    vault-cluster-618cc902
    Cluster ID      e532e461-e8f0-1352-8a41-fc7c11096908
    HA Enabled      false

    $ # It is required to enable a transit engine if not already done (It is suggested to create a transit engine specifically for SOPS, in which it is possible to have multiple keys with various permission levels)
    $ vault secrets enable -path=sops transit
    Success! Enabled the transit secrets engine at: sops/

    $ # Then create one or more keys
    $ vault write sops/keys/firstkey type=rsa-4096
    Success! Data written to: sops/keys/firstkey

    $ vault write sops/keys/secondkey type=rsa-2048
    Success! Data written to: sops/keys/secondkey

    $ vault write sops/keys/thirdkey type=chacha20-poly1305
    Success! Data written to: sops/keys/thirdkey

    $ sops encrypt --hc-vault-transit $VAULT_ADDR/v1/sops/keys/firstkey vault_example.yml

    $ cat &amp;lt;&amp;lt;EOF &amp;gt; .sops.yaml
    creation_rules:
        - path_regex: \.dev\.yaml$
          hc_vault_transit_uri: &quot;$VAULT_ADDR/v1/sops/keys/secondkey&quot;
        - path_regex: \.prod\.yaml$
          hc_vault_transit_uri: &quot;$VAULT_ADDR/v1/sops/keys/thirdkey&quot;
    EOF

    $ sops encrypt --verbose prod/raw.yaml &amp;gt; prod/encrypted.yaml

Adding and removing keys
~~~~~~~~~~~~~~~~~~~~~~~~

When creating new files, ``sops`` uses the PGP, KMS and GCP KMS defined in the
command line arguments ``--kms``, ``--pgp``, ``--gcp-kms`` or ``--azure-kv``, or from
the environment variables ``SOPS_KMS_ARN``, ``SOPS_PGP_FP``, ``SOPS_GCP_KMS_IDS``,
``SOPS_AZURE_KEYVAULT_URLS``. That information is stored in the file under the
``sops`` section, such that decrypting files does not require providing those
parameters again.

Master PGP and KMS keys can be added and removed from a ``sops`` file in one of
three ways:

1. By using a ``.sops.yaml`` file and the ``updatekeys`` command.

2. By using command line flags.

3. By editing the file directly.

The SOPS team recommends the ``updatekeys`` approach.


``updatekeys`` command
**********************

The ``updatekeys`` command uses the `.sops.yaml &amp;lt;#using-sops-yaml-conf-to-select-kms-pgp-for-new-files&amp;gt;`_
configuration file to update (add or remove) the corresponding secrets in the
encrypted file. Note that the example below uses the
`Block Scalar yaml construct &amp;lt;https://yaml-multiline.info/&amp;gt;`_ to build a space
separated list.

.. code:: yaml

    creation_rules:
        - pgp: &amp;gt;-
            85D77543B3D624B63CEA9E6DBC17301B491B3F21,
            FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4

.. code:: sh

    $ sops updatekeys test.enc.yaml

SOPS will prompt you with the changes to be made. This interactivity can be
disabled by supplying the ``-y`` flag.

``rotate`` command
******************

The ``rotate`` command generates a new data encryption key and reencrypt all values
with the new key. At the same time, the command line flag ``--add-kms``, ``--add-pgp``,
``--add-gcp-kms``, ``--add-azure-kv``, ``--rm-kms``, ``--rm-pgp``, ``--rm-gcp-kms``
and ``--rm-azure-kv`` can be used to add and remove keys from a file. These flags use
the comma separated syntax as the ``--kms``, ``--pgp``, ``--gcp-kms`` and ``--azure-kv``
arguments when creating new files.

Use ``updatekeys`` if you want to add a key without rotating the data key.

.. code:: sh

    # add a new pgp key to the file and rotate the data key
    $ sops rotate -i --add-pgp 85D77543B3D624B63CEA9E6DBC17301B491B3F21 example.yaml

    # remove a pgp key from the file and rotate the data key
    $ sops rotate -i --rm-pgp 85D77543B3D624B63CEA9E6DBC17301B491B3F21 example.yaml


Direct Editing
**************

Alternatively, invoking ``sops edit`` with the flag **-s** will display the master keys
while editing. This method can be used to add or remove ``kms`` or ``pgp`` keys under the
``sops`` section.

For example, to add a KMS master key to a file, add the following entry while
editing:

.. code:: yaml

    sops:
        kms:
            - arn: arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e

And, similarly, to add a PGP master key, we add its fingerprint:

.. code:: yaml

    sops:
        pgp:
            - fp: 85D77543B3D624B63CEA9E6DBC17301B491B3F21

When the file is saved, SOPS will update its metadata and encrypt the data key
with the freshly added master keys. The removed entries are simply deleted from
the file.

When removing keys, it is recommended to rotate the data key using ``-r``,
otherwise, owners of the removed key may have add access to the data key in the
past.

KMS AWS Profiles
~~~~~~~~~~~~~~~~

If you want to use a specific profile, you can do so with `aws_profile`:

.. code:: yaml

    sops:
        kms:
            - arn: arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e
              aws_profile: foo

If no AWS profile is set, default credentials will be used.

Similarly the `--aws-profile` flag can be set with the command line with any of the KMS commands.


Assuming roles and using KMS in various AWS accounts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS has the ability to use KMS in multiple AWS accounts by assuming roles in each account. Being able to assume roles is a nice feature of AWS that allows administrators to establish trust relationships between accounts, typically from the most secure account to the least secure one. In our use-case, we use roles to indicate that a user of the Master AWS account is allowed to make use of KMS master keys in development and staging AWS accounts. Using roles, a single file can be encrypted with KMS keys in multiple accounts, thus increasing reliability and ease of use.&lt;/p&gt; 
&lt;p&gt;You can use keys in various accounts by tying each KMS master key to a role that the user is allowed to assume in each account. The &lt;code&gt;IAM roles &amp;lt;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use.html&amp;gt;&lt;/code&gt;_ documentation has full details on how this needs to be configured on AWS&#39;s side.&lt;/p&gt; 
&lt;p&gt;From the point of view of SOPS, you only need to specify the role a KMS key must assume alongside its ARN, as follows:&lt;/p&gt; 
&lt;p&gt;.. code:: yaml&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sops:
    kms:
        - arn: arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e
          role: arn:aws:iam::927034868273:role/sops-dev-xyz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The role must have permission to call Encrypt and Decrypt using KMS. An example policy is shown below.&lt;/p&gt; 
&lt;p&gt;.. code:: json&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
  &quot;Sid&quot;: &quot;Allow use of the key&quot;,
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Action&quot;: [
    &quot;kms:Encrypt&quot;,
    &quot;kms:Decrypt&quot;,
    &quot;kms:ReEncrypt*&quot;,
    &quot;kms:GenerateDataKey*&quot;,
    &quot;kms:DescribeKey&quot;
  ],
  &quot;Resource&quot;: &quot;*&quot;,
  &quot;Principal&quot;: {
    &quot;AWS&quot;: [
      &quot;arn:aws:iam::927034868273:role/sops-dev-xyz&quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can specify a role in the &lt;code&gt;--kms&lt;/code&gt; flag and &lt;code&gt;SOPS_KMS_ARN&lt;/code&gt; variable by appending it to the ARN of the master key, separated by a &lt;strong&gt;+&lt;/strong&gt; sign::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;KMS ARN&amp;gt;+&amp;lt;ROLE ARN&amp;gt;
arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500+arn:aws:iam::927034868273:role/sops-dev-xyz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;AWS KMS Encryption Context&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
SOPS has the ability to use `AWS KMS key policy and encryption context
&amp;lt;http://docs.aws.amazon.com/kms/latest/developerguide/encryption-context.html&amp;gt;`_
to refine the access control of a given KMS master key.

When creating a new file, you can specify the encryption context in the
``--encryption-context`` flag by comma separated list of key-value pairs:

.. code:: sh

    $ sops edit --encryption-context Environment:production,Role:web-server test.dev.yaml

The format of the Encrypt Context string is ``&amp;lt;EncryptionContext Key&amp;gt;:&amp;lt;EncryptionContext Value&amp;gt;,&amp;lt;EncryptionContext Key&amp;gt;:&amp;lt;EncryptionContext Value&amp;gt;,...``

The encryption context will be stored in the file metadata and does
not need to be provided at decryption.

Encryption contexts can be used in conjunction with KMS Key Policies to define
roles that can only access a given context. An example policy is shown below:

.. code:: json

    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;AWS&quot;: &quot;arn:aws:iam::111122223333:role/RoleForExampleApp&quot;
      },
      &quot;Action&quot;: &quot;kms:Decrypt&quot;,
      &quot;Resource&quot;: &quot;*&quot;,
      &quot;Condition&quot;: {
        &quot;StringEquals&quot;: {
          &quot;kms:EncryptionContext:AppName&quot;: &quot;ExampleApp&quot;,
          &quot;kms:EncryptionContext:FilePath&quot;: &quot;/var/opt/secrets/&quot;
        }
      }
    }

Key Rotation
~~~~~~~~~~~~

It is recommended to renew the data key on a regular basis. ``sops`` supports key
rotation via the ``rotate`` command. Invoking it on an existing file causes ``sops``
to reencrypt the file with a new data key, which is then encrypted with the various
KMS and PGP master keys defined in the file.

Add the ``-i`` option to write the rotated file back, instead of printing it to
stdout.

.. code:: sh

    $ sops rotate example.yaml

Using .sops.yaml conf to select KMS, PGP and age for new files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is often tedious to specify the &lt;code&gt;--kms&lt;/code&gt; &lt;code&gt;--gcp-kms&lt;/code&gt; &lt;code&gt;--pgp&lt;/code&gt; and &lt;code&gt;--age&lt;/code&gt; parameters for creation of all new files. If your secrets are stored under a specific directory, like a &lt;code&gt;git&lt;/code&gt; repository, you can create a &lt;code&gt;.sops.yaml&lt;/code&gt; configuration file at the root directory to define which keys are used for which filename.&lt;/p&gt; 
&lt;p&gt;.. note::&lt;/p&gt; 
&lt;p&gt;The file needs to be named &lt;code&gt;.sops.yaml&lt;/code&gt;. Other names (i.e. &lt;code&gt;.sops.yml&lt;/code&gt;) won&#39;t be automatically discovered by SOPS. You&#39;ll need to pass the &lt;code&gt;--config .sops.yml&lt;/code&gt; option for it to be picked up.&lt;/p&gt; 
&lt;p&gt;Let&#39;s take an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;file named &lt;strong&gt;something.dev.yaml&lt;/strong&gt; should use one set of KMS A, PGP and age&lt;/li&gt; 
 &lt;li&gt;file named &lt;strong&gt;something.prod.yaml&lt;/strong&gt; should use another set of KMS B, PGP and age&lt;/li&gt; 
 &lt;li&gt;other files use a third set of KMS C and PGP&lt;/li&gt; 
 &lt;li&gt;all live under &lt;strong&gt;mysecretrepo/something.{dev,prod,gcp}.yaml&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Under those circumstances, a file placed at &lt;strong&gt;mysecretrepo/.sops.yaml&lt;/strong&gt; can manage the three sets of configurations for the three types of files:&lt;/p&gt; 
&lt;p&gt;.. code:: yaml&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# creation rules are evaluated sequentially, the first match wins
creation_rules:
    # upon creation of a file that matches the pattern *.dev.yaml,
    # KMS set A as well as PGP and age is used
    - path_regex: \.dev\.yaml$
      kms: &#39;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500,arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e+arn:aws:iam::361527076523:role/hiera-sops-prod&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;
      age: &#39;age129h70qwx39k7h5x6l9hg566nwm53527zvamre8vep9e3plsm44uqgy8gla&#39;

    # prod files use KMS set B in the PROD IAM, PGP and age
    - path_regex: \.prod\.yaml$
      kms: &#39;arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e+arn:aws:iam::361527076523:role/hiera-sops-prod,arn:aws:kms:eu-central-1:361527076523:key/cb1fab90-8d17-42a1-a9d8-334968904f94+arn:aws:iam::361527076523:role/hiera-sops-prod&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;
      age: &#39;age129h70qwx39k7h5x6l9hg566nwm53527zvamre8vep9e3plsm44uqgy8gla&#39;
      hc_vault_uris: &quot;http://localhost:8200/v1/sops/keys/thirdkey&quot;

    # gcp files using GCP KMS
    - path_regex: \.gcp\.yaml$
      gcp_kms: projects/mygcproject/locations/global/keyRings/mykeyring/cryptoKeys/thekey

    # Finally, if the rules above have not matched, this one is a
    # catchall that will encrypt the file using KMS set C as well as PGP
    # The absence of a path_regex means it will match everything
    - kms: &#39;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500,arn:aws:kms:us-west-2:142069644989:key/846cfb17-373d-49b9-8baf-f36b04512e47,arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When creating any file under &lt;strong&gt;mysecretrepo&lt;/strong&gt;, whether at the root or under a subdirectory, SOPS will recursively look for a &lt;code&gt;.sops.yaml&lt;/code&gt; file. If one is found, the filename of the file being created is compared with the filename regexes of the configuration file. The first regex that matches is selected, and its KMS and PGP keys are used to encrypt the file. It should be noted that the looking up of &lt;code&gt;.sops.yaml&lt;/code&gt; is from the working directory (CWD) instead of the directory of the encrypting file (see &lt;code&gt;Issue 242 &amp;lt;https://github.com/getsops/sops/issues/242&amp;gt;&lt;/code&gt;_).&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;path_regex&lt;/code&gt; checks the path of the encrypting file relative to the &lt;code&gt;.sops.yaml&lt;/code&gt; config file. Here is another example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;files located under directory &lt;strong&gt;development&lt;/strong&gt; should use one set of KMS A&lt;/li&gt; 
 &lt;li&gt;files located under directory &lt;strong&gt;production&lt;/strong&gt; should use another set of KMS B&lt;/li&gt; 
 &lt;li&gt;other files use a third set of KMS C&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;.. code:: yaml&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;creation_rules:
    # upon creation of a file under development,
    # KMS set A is used
    - path_regex: .*/development/.*
      kms: &#39;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500,arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e+arn:aws:iam::361527076523:role/hiera-sops-prod&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;

    # prod files use KMS set B in the PROD IAM
    - path_regex: .*/production/.*
      kms: &#39;arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e+arn:aws:iam::361527076523:role/hiera-sops-prod,arn:aws:kms:eu-central-1:361527076523:key/cb1fab90-8d17-42a1-a9d8-334968904f94+arn:aws:iam::361527076523:role/hiera-sops-prod&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;

    # other files use KMS set C
    - kms: &#39;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500,arn:aws:kms:us-west-2:142069644989:key/846cfb17-373d-49b9-8baf-f36b04512e47,arn:aws:kms:us-west-2:361527076523:key/5052f06a-5d3f-489e-b86c-57201e06f31e&#39;
      pgp: &#39;FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Creating a new file with the right keys is now as simple as&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops edit &amp;lt;newfile&amp;gt;.prod.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the configuration file is ignored when KMS or PGP parameters are passed on the SOPS command line or in environment variables.&lt;/p&gt; 
&lt;p&gt;Specify a different GPG executable&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
SOPS checks for the ``SOPS_GPG_EXEC`` environment variable. If specified,
it will attempt to use the executable set there instead of the default
of ``gpg``.

Example: place the following in your ``~/.bashrc``

.. code:: bash

    SOPS_GPG_EXEC = &#39;your_gpg_client_wrapper&#39;


Specify a different GPG key server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, SOPS uses the key server &lt;code&gt;keys.openpgp.org&lt;/code&gt; to retrieve the GPG keys that are not present in the local keyring. This is no longer configurable. You can learn more about why from this write-up: &lt;code&gt;SKS Keyserver Network Under Attack &amp;lt;https://gist.github.com/rjhansen/67ab921ffb4084c865b3618d6955275f&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Key groups&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
By default, SOPS encrypts the data key for a file with each of the master keys,
such that if any of the master keys is available, the file can be decrypted.
However, it is sometimes desirable to require access to multiple master keys
in order to decrypt files. This can be achieved with key groups.

When using key groups in SOPS, data keys are split into parts such that keys from
multiple groups are required to decrypt a file. SOPS uses Shamir&#39;s Secret Sharing
to split the data key such that each key group has a fragment, each key in the
key group can decrypt that fragment, and a configurable number of fragments (threshold)
are needed to decrypt and piece together the complete data key. When decrypting a
file using multiple key groups, SOPS goes through key groups in order, and in
each group, tries to recover the fragment of the data key using a master key from
that group. Once the fragment is recovered, SOPS moves on to the next group,
until enough fragments have been recovered to obtain the complete data key.

By default, the threshold is set to the number of key groups. For example, if
you have three key groups configured in your SOPS file and you don&#39;t override
the default threshold, then one master key from each of the three groups will
be required to decrypt the file.

Management of key groups is done with the ``sops groups`` command.

For example, you can add a new key group with 3 PGP keys and 3 KMS keys to the
file ``my_file.yaml``:

.. code:: sh

    $ sops groups add --file my_file.yaml --pgp fingerprint1 --pgp fingerprint2 --pgp fingerprint3 --kms arn1 --kms arn2 --kms arn3

Or you can delete the 1st group (group number 0, as groups are zero-indexed)
from ``my_file.yaml``:

.. code:: sh

    $ sops groups delete --file my_file.yaml 0

Key groups can also be specified in the ``.sops.yaml`` config file,
like so:

.. code:: yaml

    creation_rules:
        - path_regex: .*keygroups.*
          key_groups:
              # First key group
              - pgp:
                    - fingerprint1
                    - fingerprint2
                kms:
                    - arn: arn1
                      role: role1
                      context:
                          foo: bar
                    - arn: arn2
                      aws_profile: myprofile
              # Second key group
              - pgp:
                    - fingerprint3
                    - fingerprint4
                kms:
                    - arn: arn3
                    - arn: arn4
              # Third key group
              - pgp:
                    - fingerprint5

Given this configuration, we can create a new encrypted file like we normally
would, and optionally provide the ``--shamir-secret-sharing-threshold`` command line
flag if we want to override the default threshold. SOPS will then split the data
key into three parts (from the number of key groups) and encrypt each fragment with
the master keys found in each group.

For example:

.. code:: sh

    $ sops edit --shamir-secret-sharing-threshold 2 example.json

Alternatively, you can configure the Shamir threshold for each creation rule in the ``.sops.yaml`` config
with ``shamir_threshold``:

.. code:: yaml

    creation_rules:
        - path_regex: .*keygroups.*
          shamir_threshold: 2
          key_groups:
              # First key group
              - pgp:
                    - fingerprint1
                    - fingerprint2
                kms:
                    - arn: arn1
                      role: role1
                      context:
                          foo: bar
                    - arn: arn2
                      aws_profile: myprofile
              # Second key group
              - pgp:
                    - fingerprint3
                    - fingerprint4
                kms:
                    - arn: arn3
                    - arn: arn4
              # Third key group
              - pgp:
                    - fingerprint5

And then run ``sops edit example.json``.

The threshold (``shamir_threshold``) is set to 2, so this configuration will require
master keys from two of the three different key groups in order to decrypt the file.
You can then decrypt the file the same way as with any other SOPS file:

.. code:: sh

    $ sops decrypt example.json

Key service
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are situations where you might want to run SOPS on a machine that doesn&#39;t have direct access to encryption keys such as PGP keys. The &lt;code&gt;sops&lt;/code&gt; key service allows you to forward a socket so that SOPS can access encryption keys stored on a remote machine. This is similar to GPG Agent, but more portable.&lt;/p&gt; 
&lt;p&gt;SOPS uses a client-server approach to encrypting and decrypting the data key. By default, SOPS runs a local key service in-process. SOPS uses a key service client to send an encrypt or decrypt request to a key service, which then performs the operation. The requests are sent using gRPC and Protocol Buffers. The requests contain an identifier for the key they should perform the operation with, and the plaintext or encrypted data key. The requests do not contain any cryptographic keys, public or private.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING: the key service connection currently does not use any sort of authentication or encryption. Therefore, it is recommended that you make sure the connection is authenticated and encrypted in some other way, for example through an SSH tunnel.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Whenever we try to encrypt or decrypt a data key, SOPS will try to do so first with the local key service (unless it&#39;s disabled), and if that fails, it will try all other remote key services until one succeeds.&lt;/p&gt; 
&lt;p&gt;You can start a key service server by running &lt;code&gt;sops keyservice&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can specify the key services the &lt;code&gt;sops&lt;/code&gt; binary uses with &lt;code&gt;--keyservice&lt;/code&gt;. This flag can be specified more than once, so you can use multiple key services. The local key service can be disabled with &lt;code&gt;enable-local-keyservice=false&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, to decrypt a file using both the local key service and the key service exposed on the unix socket located in &lt;code&gt;/tmp/sops.sock&lt;/code&gt;, you can run:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops decrypt --keyservice unix:///tmp/sops.sock file.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And if you only want to use the key service exposed on the unix socket located in &lt;code&gt;/tmp/sops.sock&lt;/code&gt; and not the local key service, you can run:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops decrypt --enable-local-keyservice=false --keyservice unix:///tmp/sops.sock file.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Auditing&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
Sometimes, users want to be able to tell what files were accessed by whom in an
environment they control. For this reason, SOPS can generate audit logs to
record activity on encrypted files. When enabled, SOPS will write a log entry
into a pre-configured PostgreSQL database when a file is decrypted. The log
includes a timestamp, the username SOPS is running as, and the file that was
decrypted.

In order to enable auditing, you must first create the database and credentials
using the schema found in ``audit/schema.sql``. This schema defines the
tables that store the audit events and a role named ``sops`` that only has
permission to add entries to the audit event tables. The default password for
the role ``sops`` is ``sops``. You should change this password.

Once you have created the database, you have to tell SOPS how to connect to it.
Because we don&#39;t want users of SOPS to be able to control auditing, the audit
configuration file location is not configurable, and must be at
``/etc/sops/audit.yaml``. This file should have strict permissions such
that only the root user can modify it.

For example, to enable auditing to a PostgreSQL database named ``sops`` running
on localhost, using the user ``sops`` and the password ``sops``,
``/etc/sops/audit.yaml`` should have the following contents:

.. code:: yaml

    backends:
        postgres:
            - connection_string: &quot;postgres://sops:sops@localhost/sops?sslmode=verify-full&quot;


You can find more information on the ``connection_string`` format in the
`PostgreSQL docs &amp;lt;https://www.postgresql.org/docs/current/static/libpq-connect.html#libpq-connstring&amp;gt;`_.

Under the ``postgres`` map entry in the above YAML is a list, so one can
provide more than one backend, and SOPS will log to all of them:

.. code:: yaml

    backends:
        postgres:
            - connection_string: &quot;postgres://sops:sops@localhost/sops?sslmode=verify-full&quot;
            - connection_string: &quot;postgres://sops:sops@remotehost/sops?sslmode=verify-full&quot;

Saving Output to a File
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default SOPS just dumps all the output to the standard output. We can use the &lt;code&gt;--output&lt;/code&gt; flag followed by a filename to save the output to the file specified. Beware using both &lt;code&gt;--in-place&lt;/code&gt; and &lt;code&gt;--output&lt;/code&gt; flags will result in an error.&lt;/p&gt; 
&lt;p&gt;Passing Secrets to Other Processes&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;In addition to writing secrets to standard output and to files on disk, SOPS
has two commands for passing decrypted secrets to a new process: ``exec-env``
and ``exec-file``. These commands will place all output into the environment of
a child process and into a temporary file, respectively. For example, if a
program looks for credentials in its environment, ``exec-env`` can be used to
ensure that the decrypted contents are available only to this process and never
written to disk.

.. code:: sh

    # print secrets to stdout to confirm values
    $ sops decrypt out.json
    {
            &quot;database_password&quot;: &quot;jf48t9wfw094gf4nhdf023r&quot;,
            &quot;AWS_ACCESS_KEY_ID&quot;: &quot;AKIAIOSFODNN7EXAMPLE&quot;,
            &quot;AWS_SECRET_KEY&quot;: &quot;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&quot;
    }

    # decrypt out.json and run a command
    # the command prints the environment variable and runs a script that uses it
    $ sops exec-env out.json &#39;echo secret: $database_password; ./database-import&#39;
    secret: jf48t9wfw094gf4nhdf023r

    # launch a shell with the secrets available in its environment
    $ sops exec-env out.json &#39;sh&#39;
    sh-3.2# echo $database_password
    jf48t9wfw094gf4nhdf023r

    # the secret is not accessible anywhere else
    sh-3.2$ exit
    $ echo your password: $database_password
    your password:

If you want process signals to be sent to the command, for example if you are
running ``exec-env`` to launch a server and your server handles SIGTERM, then the
``--same-process`` flag can be used to instruct ``sops`` to start your command in
the same process instead of a child process. This uses the ``execve`` system call
and is supported on Unix-like systems.

If the command you want to run only operates on files, you can use ``exec-file``
instead. By default, SOPS will use a FIFO to pass the contents of the
decrypted file to the new program. Using a FIFO, secrets are only passed in
memory which has two benefits: the plaintext secrets never touch the disk, and
the child process can only read the secrets once. In contexts where this won&#39;t
work, eg platforms like Windows where FIFOs unavailable or secret files that need
to be available to the child process longer term, the ``--no-fifo`` flag can be
used to instruct SOPS to use a traditional temporary file that will get cleaned
up once the process is finished executing. ``exec-file`` behaves similar to
``find(1)`` in that ``{}`` is used as a placeholder in the command which will be
substituted with the temporary file path (whether a FIFO or an actual file).

.. code:: sh

    # operating on the same file as before, but as a file this time
    $ sops exec-file out.json &#39;echo your temporary file: {}; cat {}&#39;
    your temporary file: /tmp/.sops894650499/tmp-file
    {
            &quot;database_password&quot;: &quot;jf48t9wfw094gf4nhdf023r&quot;,
            &quot;AWS_ACCESS_KEY_ID&quot;: &quot;AKIAIOSFODNN7EXAMPLE&quot;,
            &quot;AWS_SECRET_KEY&quot;: &quot;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&quot;
    }

    # launch a shell with a variable TMPFILE pointing to the temporary file
    $ sops exec-file --no-fifo out.json &#39;TMPFILE={} sh&#39;
    sh-3.2$ echo $TMPFILE
    /tmp/.sops506055069/tmp-file291138648
    sh-3.2$ cat $TMPFILE
    {
            &quot;database_password&quot;: &quot;jf48t9wfw094gf4nhdf023r&quot;,
            &quot;AWS_ACCESS_KEY_ID&quot;: &quot;AKIAIOSFODNN7EXAMPLE&quot;,
            &quot;AWS_SECRET_KEY&quot;: &quot;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&quot;
    }
    sh-3.2$ ./program --config $TMPFILE
    sh-3.2$ exit

    # try to open the temporary file from earlier
    $ cat /tmp/.sops506055069/tmp-file291138648
    cat: /tmp/.sops506055069/tmp-file291138648: No such file or directory

Additionally, on unix-like platforms, both ``exec-env`` and ``exec-file``
support dropping privileges before executing the new program via the
``--user &amp;lt;username&amp;gt;`` flag. This is particularly useful in cases where the
encrypted file is only readable by root, but the target program does not
need root privileges to function. This flag should be used where possible
for added security.

To overwrite the default file name (``tmp-file``) in ``exec-file`` use the
``--filename &amp;lt;filename&amp;gt;`` parameter.

.. code:: sh

    # the encrypted file can&#39;t be read by the current user
    $ cat out.json
    cat: out.json: Permission denied

    # execute sops as root, decrypt secrets, then drop privileges
    $ sudo sops exec-env --user nobody out.json &#39;sh&#39;
    sh-3.2$ echo $database_password
    jf48t9wfw094gf4nhdf023r

    # dropped privileges, still can&#39;t load the original file
    sh-3.2$ id
    uid=4294967294(nobody) gid=4294967294(nobody) groups=4294967294(nobody)
    sh-3.2$ cat out.json
    cat: out.json: Permission denied

Using the publish command
~~~~~~~~~~~~~~~~~~~~~~~~~
``sops publish $file`` publishes a file to a pre-configured destination (this lives in the SOPS
config file). Additionally, support re-encryption rules that work just like the creation rules.

This command requires a ``.sops.yaml`` configuration file. Below is an example:

.. code:: yaml

    destination_rules:
        - s3_bucket: &quot;sops-secrets&quot;
          path_regex: s3/*
          recreation_rule:
              pgp: F69E4901EDBAD2D1753F8C67A64535C4163FB307
        - gcs_bucket: &quot;sops-secrets&quot;
          path_regex: gcs/*
          recreation_rule:
              pgp: F69E4901EDBAD2D1753F8C67A64535C4163FB307
        - vault_path: &quot;sops/&quot;
          vault_kv_mount_name: &quot;secret/&quot; # default
          vault_kv_version: 2 # default
          path_regex: vault/*
          omit_extensions: true

The above configuration will place all files under ``s3/*`` into the S3 bucket ``sops-secrets``,
all files under ``gcs/*`` into the GCS bucket ``sops-secrets``, and the contents of all files under
``vault/*`` into Vault&#39;s KV store under the path ``secrets/sops/``. For the files that will be
published to S3 and GCS, it will decrypt them and re-encrypt them using the
``F69E4901EDBAD2D1753F8C67A64535C4163FB307`` pgp key.

You would deploy a file to S3 with a command like: ``sops publish s3/app.yaml``

To publish all files in selected directory recursively, you need to specify ``--recursive`` flag.

If you don&#39;t want file extension to appear in destination secret path, use ``--omit-extensions``
flag or ``omit_extensions: true`` in the destination rule in ``.sops.yaml``.

Publishing to Vault
*******************

There are a few settings for Vault that you can place in your destination rules. The first
is ``vault_path``, which is required. The others are optional, and they are
``vault_address``, ``vault_kv_mount_name``, ``vault_kv_version``.

SOPS uses the official Vault API provided by Hashicorp, which makes use of `environment
variables &amp;lt;https://www.vaultproject.io/docs/commands/#environment-variables&amp;gt;`_ for
configuring the client.

``vault_kv_mount_name`` is used if your Vault KV is mounted somewhere other than ``secret/``.
``vault_kv_version`` supports ``1`` and ``2``, with ``2`` being the default.

If the destination secret path already exists in Vault and contains the same data as the source
file, it will be skipped.

Below is an example of publishing to Vault (using token auth with a local dev instance of Vault).

.. code:: sh

    $ export VAULT_TOKEN=...
    $ export VAULT_ADDR=&#39;http://127.0.0.1:8200&#39;
    $ sops decrypt vault/test.yaml
    example_string: bar
    example_number: 42
    example_map:
        key: value
    $ sops publish vault/test.yaml
    uploading /home/user/sops_directory/vault/test.yaml to http://127.0.0.1:8200/v1/secret/data/sops/test.yaml ? (y/n): y
    $ vault kv get secret/sops/test.yaml
    ====== Metadata ======
    Key              Value
    ---              -----
    created_time     2019-07-11T03:32:17.074792017Z
    deletion_time    n/a
    destroyed        false
    version          3

    ========= Data =========
    Key               Value
    ---               -----
    example_map       map[key:value]
    example_number    42
    example_string    bar


Important information on types
------------------------------

YAML, JSON, ENV and INI type extensions
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS uses the file extension to decide which encryption method to use on the file content. &lt;code&gt;YAML&lt;/code&gt;, &lt;code&gt;JSON&lt;/code&gt;, &lt;code&gt;ENV&lt;/code&gt;, and &lt;code&gt;INI&lt;/code&gt; files are treated as trees of data, and key/values are extracted from the files to only encrypt the leaf values. The tree structure is also used to check the integrity of the file.&lt;/p&gt; 
&lt;p&gt;Therefore, if a file is encrypted using a specific format, it needs to be decrypted in the same format. The easiest way to achieve this is to conserve the original file extension after encrypting a file. For example:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops encrypt -i myfile.json
$ sops decrypt myfile.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to change the extension of the file once encrypted, you need to provide &lt;code&gt;sops&lt;/code&gt; with the &lt;code&gt;--input-type&lt;/code&gt; flag upon decryption. For example:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops encrypt myfile.json &amp;gt; myfile.json.enc

$ sops decrypt --input-type json myfile.json.enc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When operating on stdin, use the &lt;code&gt;--input-type&lt;/code&gt; and &lt;code&gt;--output-type&lt;/code&gt; flags as follows:&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat myfile.json | sops decrypt --input-type json --output-type json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;JSON and JSON_binary indentation&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
SOPS indents ``JSON`` files by default using one ``tab``. However, you can change
this default behaviour to use ``spaces`` by either using the additional ``--indent=2`` CLI option or
by configuring ``.sops.yaml`` with the code below.

The special value ``0`` disables indentation, and ``-1`` uses a single tab.

.. code:: yaml

  stores:
      json:
          indent: 2
      json_binary:
          indent: 2

YAML indentation
~~~~~~~~~~~~~~~~

SOPS indents ``YAML`` files by default using 4 spaces. However, you can change
this default behaviour by either using the additional ``--indent=2`` CLI option or
by configuring ``.sops.yaml`` with:

.. code:: yaml

  stores:
      yaml:
          indent: 2

.. note::

  The YAML emitter used by sops only supports values between 2 and 9. If you specify 1,
  or 10 and larger, the indent will be 2.

YAML anchors
~~~~~~~~~~~~

SOPS only supports a subset of ``YAML``&#39;s many types. Encrypting YAML files that
contain strings, numbers and booleans will work fine, but files that contain anchors
will not work, because the anchors redefine the structure of the file at load time.

This file will not work in SOPS:

.. code:: yaml

    bill-to:  &amp;amp;id001
        street: |
            123 Tornado Alley
            Suite 16
        city:   East Centerville
        state:  KS

    ship-to:  *id001

SOPS uses the path to a value as additional data in the AEAD encryption, and thus
dynamic paths generated by anchors break the authentication step.

JSON and TEXT file types do not support anchors and thus have no such limitation.

YAML Streams
~~~~~~~~~~~~

``YAML`` supports having more than one &quot;document&quot; in a single file, while
formats like ``JSON`` do not. SOPS is able to handle both. This means the
following multi-document will be encrypted as expected:

.. code:: yaml-stream

    ---
    data: foo
    ---
    data: bar

Note that the ``sops`` metadata, i.e. the hash, etc, is computed for the physical
file rather than each internal &quot;document&quot;.

Top-level arrays
~~~~~~~~~~~~~~~~
``YAML`` and ``JSON`` top-level arrays are not supported, because SOPS
needs a top-level ``sops`` key to store its metadata.

This file will not work in SOPS:

.. code:: yaml

    ---
      - some
      - array
      - elements

But this one will work because the ``sops`` key can be added at the same level as the
``data`` key.

.. code:: yaml

    data:
        - some
        - array
        - elements

Similarly, with ``JSON`` arrays, this document will not work:

.. code:: json

    [
      &quot;some&quot;,
      &quot;array&quot;,
      &quot;elements&quot;
    ]


But this one will work just fine:

.. code:: json

    {
      &quot;data&quot;: [
        &quot;some&quot;,
        &quot;array&quot;,
        &quot;elements&quot;
      ]
    }


Examples
--------

Take a look into the `examples folder &amp;lt;https://github.com/getsops/sops/tree/main/examples&amp;gt;`_ for detailed use cases of SOPS in a CI environment. The section below describes specific tips for common use cases.

Creating a new file
~~~~~~~~~~~~~~~~~~~

The command below creates a new file with a data key encrypted by KMS and PGP.

.. code:: sh

    $ sops edit --kms &quot;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500&quot; --pgp C9CAB0AF1165060DB58D6D6B2653B624D620786D /path/to/new/file.yaml

Encrypting an existing file
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Similar to the previous command, we tell SOPS to use one KMS and one PGP key.
The path points to an existing cleartext file, so we give ``sops`` the flag ``-e`` to
encrypt the file, and redirect the output to a destination file.

.. code:: sh

    $ export SOPS_KMS_ARN=&quot;arn:aws:kms:us-west-2:927034868273:key/fe86dd69-4132-404c-ab86-4269956b4500&quot;
    $ export SOPS_PGP_FP=&quot;C9CAB0AF1165060DB58D6D6B2653B624D620786D&quot;
    $ sops encrypt /path/to/existing/file.yaml &amp;gt; /path/to/new/encrypted/file.yaml

Decrypt the file with ``-d``.

.. code:: sh

    $ sops decrypt /path/to/new/encrypted/file.yaml

Encrypt or decrypt a file in place
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rather than redirecting the output of &lt;code&gt;-e&lt;/code&gt; or &lt;code&gt;-d&lt;/code&gt;, &lt;code&gt;sops&lt;/code&gt; can replace the original file after encrypting or decrypting it.&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# file.yaml is in cleartext
$ sops encrypt -i /path/to/existing/file.yaml
# file.yaml is now encrypted
$ sops decrypt -i /path/to/existing/file.yaml
# file.yaml is back in cleartext
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Encrypting binary files&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
SOPS primary use case is encrypting YAML, JSON, ENV, and INI configuration files, but it
also has the ability to manage binary files. When encrypting a binary, SOPS will
read the data as bytes, encrypt it, store the encrypted base64 under
``tree[&#39;data&#39;]`` and write the result as JSON.

Note that the base64 encoding of encrypted data can actually make the encrypted
file larger than the cleartext one.

In-place encryption/decryption also works on binary files.

.. code:: sh

    $ dd if=/dev/urandom of=/tmp/somerandom bs=1024
    count=512
    512+0 records in
    512+0 records out
    524288 bytes (524 kB) copied, 0.0466158 s, 11.2 MB/s

    $ sha512sum /tmp/somerandom
    9589bb20280e9d381f7a192000498c994e921b3cdb11d2ef5a986578dc2239a340b25ef30691bac72bdb14028270828dad7e8bd31e274af9828c40d216e60cbe /tmp/somerandom

    $ sops encrypt -i /tmp/somerandom
    please wait while a data encryption key is being generated and stored securely

    $ sops decrypt -i /tmp/somerandom

    $ sha512sum /tmp/somerandom
    9589bb20280e9d381f7a192000498c994e921b3cdb11d2ef5a986578dc2239a340b25ef30691bac72bdb14028270828dad7e8bd31e274af9828c40d216e60cbe /tmp/somerandom

Extract a sub-part of a document tree
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOPS can extract a specific part of a YAML or JSON document, by provided the path in the &lt;code&gt;--extract&lt;/code&gt; command line flag. This is useful to extract specific values, like keys, without needing an extra parser.&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops decrypt --extract &#39;[&quot;app2&quot;][&quot;key&quot;]&#39; ~/git/svc/sops/example.yaml
-----BEGIN RSA PRIVATE KEY-----
MIIBPAIBAAJBAPTMNIyHuZtpLYc7VsHQtwOkWYobkUblmHWRmbXzlAX6K8tMf3Wf
ImcbNkqAKnELzFAPSBeEMhrBN0PyOC9lYlMCAwEAAQJBALXD4sjuBn1E7Y9aGiMz
bJEBuZJ4wbhYxomVoQKfaCu+kH80uLFZKoSz85/ySauWE8LgZcMLIBoiXNhDKfQL
vHECIQD6tCG9NMFWor69kgbX8vK5Y+QL+kRq+9HK6yZ9a+hsLQIhAPn4Ie6HGTjw
fHSTXWZpGSan7NwTkIu4U5q2SlLjcZh/AiEA78NYRRBwGwAYNUqzutGBqyXKUl4u
Erb0xAEyVV7e8J0CIQC8VBY8f8yg+Y7Kxbw4zDYGyb3KkXL10YorpeuZR4LuQQIg
bKGPkMM4w5blyE1tqGN0T7sJwEx+EUOgacRNqM2ljVA=
-----END RSA PRIVATE KEY-----
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The tree path syntax uses regular python dictionary syntax, without the variable name. Extract keys by naming them, and array elements by numbering them.&lt;/p&gt; 
&lt;p&gt;.. code:: sh&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ sops decrypt --extract &#39;[&quot;an_array&quot;][1]&#39; ~/git/svc/sops/example.yaml
secretuser2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set a sub-part in a document tree&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
SOPS can set a specific part of a YAML or JSON document, by providing
the path and value in the ``set`` command. This is useful to set specific
values, like keys, without needing an editor.

.. code:: sh

    $ sops set ~/git/svc/sops/example.yaml &#39;[&quot;app2&quot;][&quot;key&quot;]&#39; &#39;&quot;app2keystringvalue&quot;&#39;

The tree path syntax uses regular python dictionary syntax, without the
variable name. Set to keys by naming them, and array elements by
numbering them.

.. code:: sh

    $ sops set ~/git/svc/sops/example.yaml &#39;[&quot;an_array&quot;][1]&#39; &#39;&quot;secretuser2&quot;&#39;

The value must be formatted as json.

.. code:: sh

    $ sops set ~/git/svc/sops/example.yaml &#39;[&quot;an_array&quot;][1]&#39; &#39;{&quot;uid1&quot;:null,&quot;uid2&quot;:1000,&quot;uid3&quot;:[&quot;bob&quot;]}&#39;

You can also provide the value from a file or stdin:

.. code:: sh

    # Provide the value from a file
    $ echo &#39;{&quot;uid1&quot;:null,&quot;uid2&quot;:1000,&quot;uid3&quot;:[&quot;bob&quot;]}&#39; &amp;gt; /tmp/example-value
    $ sops set ~/git/svc/sops/example.yaml --value-file &#39;[&quot;an_array&quot;][1]&#39; /tmp/example-value

    # Provide the value from stdin
    $ echo &#39;{&quot;uid1&quot;:null,&quot;uid2&quot;:1000,&quot;uid3&quot;:[&quot;bob&quot;]}&#39; | sops set ~/git/svc/sops/example.yaml --value-stdin &#39;[&quot;an_array&quot;][1]&#39;

Unset a sub-part in a document tree
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Symmetrically, SOPS can unset a specific part of a YAML or JSON document, by providing
the path in the ``unset`` command. This is useful to unset specific values, like keys, without
needing an editor.

.. code:: sh

    $ sops unset ~/git/svc/sops/example.yaml &#39;[&quot;app2&quot;][&quot;key&quot;]&#39;

The tree path syntax uses regular python dictionary syntax, without the
variable name. Set to keys by naming them, and array elements by
numbering them.

.. code:: sh

    $ sops unset ~/git/svc/sops/example.yaml &#39;[&quot;an_array&quot;][1]&#39;

Showing diffs in cleartext in git
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You most likely want to store encrypted files in a version controlled repository.
SOPS can be used with git to decrypt files when showing diffs between versions.
This is very handy for reviewing changes or visualizing history.

To configure SOPS to decrypt files during diff, create a ``.gitattributes`` file
at the root of your repository that contains a filter and a command.

.. code:: text

    *.yaml diff=sopsdiffer

Here we only care about YAML files. ``sopsdiffer`` is an arbitrary name that we map
to a SOPS command in the git configuration file of the repository.

.. code:: sh

    $ git config diff.sopsdiffer.textconv &quot;sops decrypt&quot;

    $ grep -A 1 sopsdiffer .git/config
    [diff &quot;sopsdiffer&quot;]
        textconv = &quot;sops decrypt&quot;

With this in place, calls to ``git diff`` will decrypt both previous and current
versions of the target file prior to displaying the diff. And it even works with
git client interfaces, because they call git diff under the hood!

Encrypting only parts of a file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Note: this only works on YAML, JSON, ENV, and INI files, not on BINARY files.

By default, SOPS encrypts all the values of a YAML, JSON, ENV, or INI file and leaves the
keys in cleartext. In some instances, you may want to exclude some values from
being encrypted. This can be accomplished by adding the suffix **_unencrypted**
to any key of a file. When set, all values underneath the key that set the
**_unencrypted** suffix will be left in cleartext.

Note that, while in cleartext, unencrypted content is still added to the
checksum of the file, and thus cannot be modified outside of SOPS without
breaking the file integrity check.
This behavior can be modified using ``--mac-only-encrypted`` flag or ``.sops.yaml``
config file which makes SOPS compute a MAC only over values it encrypted and
not all values.

The unencrypted suffix can be set to a different value using the
``--unencrypted-suffix`` option.

Conversely, you can opt in to only encrypt some values in a YAML or JSON file,
by adding a chosen suffix to those keys and passing it to the ``--encrypted-suffix`` option.

A third method is to use the ``--encrypted-regex`` which will only encrypt values under
keys that match the supplied regular expression.  For example, this command:

.. code:: sh

    $ sops encrypt --encrypted-regex &#39;^(data|stringData)$&#39; k8s-secrets.yaml

will encrypt the values under the ``data`` and ``stringData`` keys in a YAML file
containing kubernetes secrets.  It will not encrypt other values that help you to
navigate the file, like ``metadata`` which contains the secrets&#39; names.

Conversely, you can opt in to only leave certain keys without encrypting by using the 
``--unencrypted-regex`` option, which will leave the values unencrypted of those keys 
that match the supplied regular expression. For example, this command:

.. code:: sh

    $ sops encrypt --unencrypted-regex &#39;^(description|metadata)$&#39; k8s-secrets.yaml

will not encrypt the values under the ``description`` and ``metadata`` keys in a YAML file
containing kubernetes secrets, while encrypting everything else.

For YAML files, another method is to use ``--encrypted-comment-regex`` which will
only encrypt comments and values which have a preceding comment matching the supplied
regular expression.

Conversely, you can opt in to only left certain keys without encrypting by using the
``--unencrypted-comment-regex`` option, which will leave the values and comments
unencrypted when they have a preeceding comment, or a trailing comment on the same line,
that matches the supplied regular expression.

You can also specify these options in the ``.sops.yaml`` config file.

Note: these six options ``--unencrypted-suffix``, ``--encrypted-suffix``, ``--encrypted-regex``,
``--unencrypted-regex``, ``--encrypted-comment-regex``, and ``--unencrypted-comment-regex`` are
mutually exclusive and cannot all be used in the same file.

Encryption Protocol
-------------------

When SOPS creates a file, it generates a random 256 bit data key and asks each
KMS and PGP master key to encrypt the data key. The encrypted version of the data
key is stored in the ``sops`` metadata under ``sops.kms`` and ``sops.pgp``.

For KMS:

.. code:: yaml

    sops:
        kms:
            - enc: CiC6yCOtzsnFhkfdIslYZ0bAf//gYLYCmIu87B3sy/5yYxKnAQEBAQB4usgjrc7JxYZH3SLJWGdGwH//4GC2ApiLvOwd7Mv+cmMAAAB+MHwGCSqGSIb3DQEHBqBvMG0CAQAwaAYJKoZIhvcNAQcBMB4GCWCGSAFlAwQBLjARBAyGdRODuYMHbA8Ozj8CARCAO7opMolPJUmBXd39Zlp0L2H9fzMKidHm1vvaF6nNFq0ClRY7FlIZmTm4JfnOebPseffiXFn9tG8cq7oi
              enc_ts: 1439568549.245995
              arn: arn:aws:kms:us-east-1:656532927350:key/920aff2e-c5f1-4040-943a-047fa387b27e

For PGP:

.. code:: yaml

    sops:
        pgp:
            - fp: 85D77543B3D624B63CEA9E6DBC17301B491B3F21
              created_at: 1441570391.930042
              enc: |
                  -----BEGIN PGP MESSAGE-----
                  Version: GnuPG v1

                  hQIMA0t4uZHfl9qgAQ//UvGAwGePyHuf2/zayWcloGaDs0MzI+zw6CmXvMRNPUsA
                  pAgRKczJmDu4+XzN+cxX5Iq9xEWIbny9B5rOjwTXT3qcUYZ4Gkzbq4MWkjuPp/Iv
                  qO4MJaYzoH5YxC4YORQ2LvzhA2YGsCzYnljmatGEUNg01yJ6r5mwFwDxl4Nc80Cn
                  RwnHuGExK8j1jYJZu/juK1qRbuBOAuruIPPWVdFB845PA7waacG1IdUW3ZtBkOy3
                  O0BIfG2ekRg0Nik6sTOhDUA+l2bewCcECI8FYCEjwHm9Sg5cxmP2V5m1mby+uKAm
                  kewaoOyjbmV1Mh3iI1b/AQMr+/6ZE9MT2KnsoWosYamFyjxV5r1ZZM7cWKnOT+tu
                  KOvGhTV1TeOfVpajNTNwtV/Oyh3mMLQ0F0HgCTqomQVqw5+sj7OWAASuD3CU/dyo
                  pcmY5Qe0TNL1JsMNEH8LJDqSh+E0hsUxdY1ouVsg3ysf6mdM8ciWb3WRGxih1Vmf
                  unfLy8Ly3V7ZIC8EHV8aLJqh32jIZV4i2zXIoO4ZBKrudKcECY1C2+zb/TziVAL8
                  qyPe47q8gi1rIyEv5uirLZjgpP+JkDUgoMnzlX334FZ9pWtQMYW4Y67urAI4xUq6
                  /q1zBAeHoeeeQK+YKDB7Ak/Y22YsiqQbNp2n4CKSKAE4erZLWVtDvSp+49SWmS/S
                  XgGi+13MaXIp0ecPKyNTBjF+NOw/I3muyKr8EbDHrd2XgIT06QXqjYLsCb1TZ0zm
                  xgXsOTY3b+ONQ2zjhcovanDp7/k77B+gFitLYKg4BLZsl7gJB12T8MQnpfSmRT4=
                  =oJgS
                  -----END PGP MESSAGE-----

SOPS then opens a text editor on the newly created file. The user adds data to the
file and saves it when done.

Upon save, SOPS browses the entire file as a key/value tree. Every time SOPS
encounters a leaf value (a value that does not have children), it encrypts the
value with AES256_GCM using the data key and a 256 bit random initialization
vector.

Each file uses a single data key to encrypt all values of a document, but each
value receives a unique initialization vector and has unique authentication data.

Additional data is used to guarantee the integrity of the encrypted data
and of the tree structure: when encrypting the tree, key names are concatenated
into a byte string that is used as AEAD additional data (aad) when encrypting
values. We expect that keys do not carry sensitive information, and
keeping them in cleartext allows for better diff and overall readability.

Any valid KMS or PGP master key can later decrypt the data key and access the
data.

Multiple master keys allow for sharing encrypted files without sharing master
keys, and provide a disaster recovery solution. The recommended way to use SOPS
is to have two KMS master keys in different regions and one PGP public key with
the private key stored offline. If, by any chance, both KMS master keys are
lost, you can always recover the encrypted data using the PGP private key.

Message Authentication Code
~~~~~~~~~~~~~~~~~~~~~~~~~~~

In addition to authenticating branches of the tree using keys as additional
data, SOPS computes a MAC on all the values to ensure that no value has been
added or removed fraudulently. The MAC is stored encrypted with AES_GCM and
the data key under tree -&amp;gt; ``sops`` -&amp;gt; ``mac``.
This behavior can be modified using ``--mac-only-encrypted`` flag or ``.sops.yaml``
config file which makes SOPS compute a MAC only over values it encrypted and
not all values.

Motivation
----------

   📝 **A note from the maintainers**

   This section was written by the original authors of SOPS while they were
   working at Mozilla. It is kept here for historical reasons and to provide
   technical background on the project. It is not necessarily representative
   of the views of the current maintainers, nor are they currently affiliated
   with Mozilla.

Automating the distribution of secrets and credentials to components of an
infrastructure is a hard problem. We know how to encrypt secrets and share them
between humans, but extending that trust to systems is difficult. Particularly
when these systems follow devops principles and are created and destroyed
without human intervention. The issue boils down to establishing the initial
trust of a system that just joined the infrastructure, and providing it access
to the secrets it needs to configure itself.

The initial trust
~~~~~~~~~~~~~~~~~

In many infrastructures, even highly dynamic ones, the initial trust is
established by a human. An example is seen in Puppet by the way certificates are
issued: when a new system attempts to join a Puppetmaster, an administrator
must, by default, manually approve the issuance of the certificate the system
needs. This is cumbersome, and many puppetmasters are configured to auto-sign
new certificates to work around that issue. This is obviously not recommended
and far from ideal.

AWS provides a more flexible approach to trusting new systems. It uses a
powerful mechanism of roles and identities. In AWS, it is possible to verify
that a new system has been granted a specific role at creation, and it is
possible to map that role to specific resources. Instead of trusting new systems
directly, the administrator trusts the AWS permission model and its automation
infrastructure. As long as AWS keys are safe, and the AWS API is secure, we can
assume that trust is maintained and systems are who they say they are.

KMS, Trust and secrets distribution
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using the AWS trust model, we can create fine grained access controls to
Amazon&#39;s Key Management Service (KMS). KMS is a service that encrypts and
decrypts data with AES_GCM, using keys that are never visible to users of the
service. Each KMS master key has a set of role-based access controls, and
individual roles are permitted to encrypt or decrypt using the master key. KMS
helps solve the problem of distributing keys, by shifting it into an access
control problem that can be solved using AWS&#39;s trust model.

Operational requirements
~~~~~~~~~~~~~~~~~~~~~~~~

When Mozilla&#39;s Services Operations team started revisiting the issue of
distributing secrets to EC2 instances, we set a goal to store these secrets
encrypted until the very last moment, when they need to be decrypted on target
systems. Not unlike many other organizations that operate sufficiently complex
automation, we found this to be a hard problem with a number of prerequisites:

1. Secrets must be stored in YAML files for easy integration into hiera

2. Secrets must be stored in GIT, and when a new CloudFormation stack is
   built, the current HEAD is pinned to the stack. (This allows secrets to
   be changed in GIT without impacting the current stack that may
   autoscale).

3. Entries must be encrypted separately. Encrypting entire files as blobs makes
   git conflict resolution almost impossible. Encrypting each entry
   separately is much easier to manage.

4. Secrets must always be encrypted on disk (admin laptop, upstream
   git repo, jenkins and S3) and only be decrypted on the target
   systems

SOPS can be used to encrypt YAML, JSON, ENV, INI, and BINARY files. In BINARY mode, the
content of the file is treated as a blob, the same way PGP would encrypt an
entire file. In YAML, JSON, ENV, and INI modes, however, the content of the file is
manipulated as a tree where keys are stored in cleartext, and values are
encrypted. hiera-eyaml does something similar, and over the years we learned
to appreciate its benefits, namely:

* diffs are meaningful. If a single value of a file is modified, only that
  value will show up in the diff. The diff is still limited to only showing
  encrypted data, but that information is already more granular that
  indicating that an entire file has changed.

* conflicts are easier to resolve. If multiple users are working on the
  same encrypted files, as long as they don&#39;t modify the same values,
  changes are easy to merge. This is an improvement over the PGP
  encryption approach where unsolvable conflicts often happen when
  multiple users work on the same file.

OpenPGP integration
~~~~~~~~~~~~~~~~~~~

OpenPGP gets a lot of bad press for being an outdated crypto protocol, and while
true, what really made us look for alternatives is the difficulty of managing and
distributing keys to systems. With KMS, we manage permissions to an API, not keys,
and that&#39;s a lot easier to do.

But PGP is not dead yet, and we still rely on it heavily as a backup solution:
all our files are encrypted with KMS and with one PGP public key, with its
private key stored securely for emergency decryption in the event that we lose
all our KMS master keys.

SOPS can be used without KMS entirely, the same way you would use an encrypted
PGP file: by referencing the pubkeys of each individual who has access to the file.
It can easily be done by providing SOPS with a comma-separated list of public keys
when creating a new file:

.. code:: sh

    $ sops edit --pgp &quot;E60892BB9BD89A69F759A1A0A3D652173B763E8F,84050F1D61AF7C230A12217687DF65059EF093D3,85D77543B3D624B63CEA9E6DBC17301B491B3F21&quot; mynewfile.yaml

Threat Model
------------

The security of the data stored using SOPS is as strong as the weakest
cryptographic mechanism. Values are encrypted using AES256_GCM which is the
strongest symmetric encryption algorithm known today. Data keys are encrypted
in either KMS, which also uses AES256_GCM, or PGP which uses either RSA or
ECDSA keys.

Going from the most likely to the least likely, the threats are as follows:

Compromised AWS credentials grant access to KMS master key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An attacker with access to an AWS console can grant itself access to one of the KMS master keys used to encrypt a &lt;code&gt;sops&lt;/code&gt; data key. This threat should be mitigated by protecting AWS accesses with strong controls, such as multi-factor authentication, and also by performing regular audits of permissions granted to AWS users.&lt;/p&gt; 
&lt;p&gt;Compromised PGP key&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
PGP keys are routinely mishandled, either because owners copy them from
machine to machine, or because the key is left forgotten on an unused machine
an attacker gains access to. When using PGP encryption, SOPS users should take
special care of PGP private keys, and store them on smart cards or offline
as often as possible.

Factorized RSA key
~~~~~~~~~~~~~~~~~~

SOPS doesn&#39;t apply any restriction on the size or type of PGP keys. A weak PGP
keys, for example 512 bits RSA, could be factorized by an attacker to gain
access to the private key and decrypt the data key. Users of SOPS should rely
on strong keys, such as 2048+ bits RSA keys, or 256+ bits ECDSA keys.

Weak AES cryptography
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A vulnerability in AES256_GCM could potentially leak the data key or the KMS master key used by a SOPS encrypted file. While no such vulnerability exists today, we recommend that users keep their encrypted files reasonably private.&lt;/p&gt; 
&lt;h2&gt;Backward compatibility&lt;/h2&gt; 
&lt;p&gt;SOPS will remain backward compatible on the major version, meaning that all improvements brought to the 1.X and 2.X branches (current) will maintain the file format introduced in &lt;strong&gt;1.0&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;Please report any security issues privately using &lt;code&gt;GitHub&#39;s advisory form &amp;lt;https://github.com/getsops/sops/security/advisories&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Mozilla Public License Version 2.0&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;SOPS was initially launched as a project at Mozilla in 2015 and has been graciously donated to the CNCF as a Sandbox project in 2023, now under the stewardship of a &lt;code&gt;new group of maintainers &amp;lt;https://github.com/getsops/community/blob/main/MAINTAINERS.md&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;The original authors of the project were:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adrian Utrilla @autrilla&lt;/li&gt; 
 &lt;li&gt;Julien Vehent @jvehent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Furthermore, the project has been carried for a long time by AJ Bahnken @ajvb, and had not been possible without the contributions of numerous &lt;code&gt;contributors &amp;lt;https://github.com/getsops/sops/graphs/contributors&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;SOPS was inspired by &lt;code&gt;hiera-eyaml &amp;lt;https://github.com/TomPoulton/hiera-eyaml&amp;gt;&lt;/code&gt;&lt;em&gt;, &lt;code&gt;credstash &amp;lt;https://github.com/LuminalOSS/credstash&amp;gt;&lt;/code&gt;&lt;/em&gt;, &lt;code&gt;sneaker &amp;lt;https://github.com/codahale/sneaker&amp;gt;&lt;/code&gt;&lt;em&gt;, &lt;code&gt;password store &amp;lt;http://www.passwordstore.org/&amp;gt;&lt;/code&gt;&lt;/em&gt; and too many years managing PGP encrypted files by hand...&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;.. image:: docs/images/cncf-color-bg.svg :width: 400 :alt: CNCF Sandbox Project&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We are a&lt;/strong&gt; &lt;code&gt;Cloud Native Computing Foundation &amp;lt;https://cncf.io&amp;gt;&lt;/code&gt;_ &lt;strong&gt;sandbox project.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
